Training Log
20241118_224751
-----------
Configuration: c:\Users\rasmu\OneDrive\Skrivebord\Dev\NN cartrack\config.py

Training Metrics
---------------
Configuration Items
--------------------
torch: <module 'torch' from 'C:\\Users\\rasmu\\OneDrive\\Skrivebord\\Dev\\NN cartrack\\.venv\\lib\\site-packages\\torch\\__init__.py'>
np: <module 'numpy' from 'C:\\Users\\rasmu\\OneDrive\\Skrivebord\\Dev\\NN cartrack\\.venv\\lib\\site-packages\\numpy\\__init__.py'>
DEVICE: cuda
TRACK_LENGTH: 300
TRACK_WIDTH: 50
MAX_TIMESTEPS: 1100
BORDER_THRESHOLD: 10.0
OBSTACLE_THRESHOLD: 1.0
OBSTACLES: [{'center': array([150.,  25.], dtype=float32), 'size': array([50., 30.], dtype=float32)}, {'center': array([225.,  45.], dtype=float32), 'size': array([30., 20.], dtype=float32)}, {'center': array([225.,   5.], dtype=float32), 'size': array([30., 20.], dtype=float32)}]
LEARNING_RATE: 0.0005
BATCH_SIZE: 64
GAMMA: 0.98
EPS_START: 1.0
EPS_END: 0.1
EPS_DECAY: 1500
TARGET_UPDATE: 5
MEMORY_CAPACITY: 30000
NUM_EPISODES: 15000
MAX_SPEED: 4.0
ACCELERATION: 0.9
STEERING: 0.8
HIDDEN_LAYERS: {256, 128}
REWARD_GOAL: 200000
PENALTY_OFF_TRACK: -1000
PENALTY_OBSTACLE: -90
PENALTY_BORDER: 3000
PENALTY_BACKWARDS: -100
PENALTY_TIME_LIMIT: -25
DELTA_X_REWARD_FACTOR: 250
TIME_PENALTY: -1
STATE_SIZE: 12
ACTION_SIZE: 4
PROCENTAGE_TO_DRAW: 0.9
DRAW_BEST_TRAJECTORIES: 13501

Training Progress
-----------------
Episode 1: Reward = -577.19, Avg Reward (100) = 0.00, Epsilon = 0.999, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -577.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2: Reward = -63603.18, Avg Reward (100) = -577.19, Epsilon = 0.999, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -63603.18, Border Penalty: -32617.04, Obstacle Penalty: -50.00
Episode 3: Reward = -6277.01, Avg Reward (100) = -32090.18, Epsilon = 0.998, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -6277.01, Border Penalty: -9397.11, Obstacle Penalty: -50.00
Episode 4: Reward = -631.28, Avg Reward (100) = -23485.79, Epsilon = 0.998, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -631.28, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5: Reward = -1098.00, Avg Reward (100) = -17772.16, Epsilon = 0.997, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6: Reward = -1000.00, Avg Reward (100) = -14437.33, Epsilon = 0.996, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7: Reward = -1393.00, Avg Reward (100) = -12197.77, Epsilon = 0.996, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8: Reward = -1098.00, Avg Reward (100) = -10654.24, Epsilon = 0.995, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9: Reward = -157502.50, Avg Reward (100) = -9459.71, Epsilon = 0.995, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 74, Reward Breakdown -> Delta_x Reward: -157502.50, Border Penalty: -30482.65, Obstacle Penalty: -100.00
Episode 10: Reward = -1000.00, Avg Reward (100) = -25908.91, Epsilon = 0.994, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11: Reward = -1000.00, Avg Reward (100) = -23418.01, Epsilon = 0.993, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12: Reward = -1049.00, Avg Reward (100) = -21380.01, Epsilon = 0.993, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13: Reward = -1049.00, Avg Reward (100) = -19685.76, Epsilon = 0.992, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14: Reward = -784.25, Avg Reward (100) = -18252.17, Epsilon = 0.992, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 15: Reward = -1147.00, Avg Reward (100) = -17004.46, Epsilon = 0.991, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 16: Reward = -52382.13, Avg Reward (100) = -15947.29, Epsilon = 0.990, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -52382.13, Border Penalty: -36030.47, Obstacle Penalty: -50.00
Episode 17: Reward = -1147.00, Avg Reward (100) = -18224.47, Epsilon = 0.990, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 18: Reward = -1000.00, Avg Reward (100) = -17219.91, Epsilon = 0.989, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 19: Reward = -1147.00, Avg Reward (100) = -16318.81, Epsilon = 0.989, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 20: Reward = -121945.82, Avg Reward (100) = -15520.29, Epsilon = 0.988, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -121945.82, Border Penalty: -34017.53, Obstacle Penalty: -50.00
Episode 21: Reward = -1000.00, Avg Reward (100) = -20841.57, Epsilon = 0.987, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 22: Reward = -40315.59, Avg Reward (100) = -19896.73, Epsilon = 0.987, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -40315.59, Border Penalty: -33043.42, Obstacle Penalty: -50.00
Episode 23: Reward = -139462.64, Avg Reward (100) = -20824.86, Epsilon = 0.986, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 95, Reward Breakdown -> Delta_x Reward: -139462.64, Border Penalty: -31336.51, Obstacle Penalty: -50.00
Episode 24: Reward = -87629.04, Avg Reward (100) = -25983.03, Epsilon = 0.986, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -87629.04, Border Penalty: -37532.57, Obstacle Penalty: -50.00
Episode 25: Reward = -55411.98, Avg Reward (100) = -28551.61, Epsilon = 0.985, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -55411.98, Border Penalty: -34653.60, Obstacle Penalty: -50.00
Episode 26: Reward = -784.25, Avg Reward (100) = -29626.02, Epsilon = 0.984, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 27: Reward = -152019.69, Avg Reward (100) = -28516.73, Epsilon = 0.984, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 65, Reward Breakdown -> Delta_x Reward: -152019.69, Border Penalty: -30691.07, Obstacle Penalty: -50.00
Episode 28: Reward = -1000.00, Avg Reward (100) = -33090.91, Epsilon = 0.983, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 29: Reward = -1147.00, Avg Reward (100) = -31944.80, Epsilon = 0.983, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 30: Reward = -1049.00, Avg Reward (100) = -30882.81, Epsilon = 0.982, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 31: Reward = -1049.00, Avg Reward (100) = -29888.35, Epsilon = 0.981, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 32: Reward = -1049.00, Avg Reward (100) = -28958.05, Epsilon = 0.981, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 33: Reward = -1049.00, Avg Reward (100) = -28085.89, Epsilon = 0.980, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 34: Reward = -1000.00, Avg Reward (100) = -27266.59, Epsilon = 0.980, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 35: Reward = -1049.00, Avg Reward (100) = -26494.05, Epsilon = 0.979, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 36: Reward = -1000.00, Avg Reward (100) = -25767.04, Epsilon = 0.978, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 37: Reward = 5459.64, Avg Reward (100) = -25079.07, Epsilon = 0.978, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 51, Reward Breakdown -> Delta_x Reward: 5459.64, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 38: Reward = -1000.00, Avg Reward (100) = -24253.70, Epsilon = 0.977, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 39: Reward = -1000.00, Avg Reward (100) = -23641.76, Epsilon = 0.977, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 40: Reward = -75778.73, Avg Reward (100) = -23061.20, Epsilon = 0.976, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -75778.73, Border Penalty: -33224.69, Obstacle Penalty: -50.00
Episode 41: Reward = -84697.16, Avg Reward (100) = -24379.14, Epsilon = 0.975, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -84697.16, Border Penalty: -30288.68, Obstacle Penalty: -50.00
Episode 42: Reward = -1000.00, Avg Reward (100) = -25850.31, Epsilon = 0.975, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 43: Reward = -445891.41, Avg Reward (100) = -25258.64, Epsilon = 0.974, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 35, Reward Breakdown -> Delta_x Reward: -445891.41, Border Penalty: -35481.04, Obstacle Penalty: -50.00
Episode 44: Reward = -1049.00, Avg Reward (100) = -35040.80, Epsilon = 0.974, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 45: Reward = 2057.49, Avg Reward (100) = -34268.25, Epsilon = 0.973, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 33, Reward Breakdown -> Delta_x Reward: 2057.49, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 46: Reward = -1000.00, Avg Reward (100) = -33461.02, Epsilon = 0.972, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 47: Reward = 311.20, Avg Reward (100) = -32755.34, Epsilon = 0.972, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 311.20, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 48: Reward = -1049.00, Avg Reward (100) = -32051.80, Epsilon = 0.971, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 49: Reward = -1000.00, Avg Reward (100) = -31405.91, Epsilon = 0.971, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 50: Reward = -579.19, Avg Reward (100) = -30785.38, Epsilon = 0.970, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -579.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 51: Reward = -216200.28, Avg Reward (100) = -30181.25, Epsilon = 0.969, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 46, Reward Breakdown -> Delta_x Reward: -216200.28, Border Penalty: -32587.52, Obstacle Penalty: -50.00
Episode 52: Reward = -137395.19, Avg Reward (100) = -33828.69, Epsilon = 0.969, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -137395.19, Border Penalty: -34092.17, Obstacle Penalty: -50.00
Episode 53: Reward = -680.25, Avg Reward (100) = -35820.35, Epsilon = 0.968, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -680.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 54: Reward = -79.22, Avg Reward (100) = -35157.33, Epsilon = 0.968, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -79.22, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 55: Reward = -121568.91, Avg Reward (100) = -34507.73, Epsilon = 0.967, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -121568.91, Border Penalty: -30834.94, Obstacle Penalty: -50.00
Episode 56: Reward = -528.19, Avg Reward (100) = -36090.66, Epsilon = 0.966, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -528.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 57: Reward = -784.25, Avg Reward (100) = -35455.62, Epsilon = 0.966, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 58: Reward = -1000.00, Avg Reward (100) = -34847.35, Epsilon = 0.965, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 59: Reward = -1245.00, Avg Reward (100) = -34263.78, Epsilon = 0.965, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 60: Reward = -631.25, Avg Reward (100) = -33704.14, Epsilon = 0.964, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -631.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 61: Reward = -98231.50, Avg Reward (100) = -33152.92, Epsilon = 0.963, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 40, Reward Breakdown -> Delta_x Reward: -98231.50, Border Penalty: -30722.50, Obstacle Penalty: -50.00
Episode 62: Reward = -1000.00, Avg Reward (100) = -34219.78, Epsilon = 0.963, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 63: Reward = -26908.16, Avg Reward (100) = -33683.98, Epsilon = 0.962, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 41, Reward Breakdown -> Delta_x Reward: -26908.16, Border Penalty: -30875.60, Obstacle Penalty: -50.00
Episode 64: Reward = -831.25, Avg Reward (100) = -33576.43, Epsilon = 0.962, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -831.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 65: Reward = 1707.68, Avg Reward (100) = -33064.78, Epsilon = 0.961, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: 1707.68, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 66: Reward = -1098.00, Avg Reward (100) = -32529.82, Epsilon = 0.960, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 67: Reward = -48536.38, Avg Reward (100) = -32053.58, Epsilon = 0.960, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 39, Reward Breakdown -> Delta_x Reward: -48536.38, Border Penalty: -34248.94, Obstacle Penalty: -50.00
Episode 68: Reward = -1098.00, Avg Reward (100) = -32299.59, Epsilon = 0.959, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 69: Reward = -32637.36, Avg Reward (100) = -31840.75, Epsilon = 0.959, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -32637.36, Border Penalty: -20752.92, Obstacle Penalty: -50.00
Episode 70: Reward = -1049.00, Avg Reward (100) = -31852.29, Epsilon = 0.958, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 71: Reward = -1000.00, Avg Reward (100) = -31412.25, Epsilon = 0.957, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 72: Reward = -1098.00, Avg Reward (100) = -30983.90, Epsilon = 0.957, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 73: Reward = -149718.56, Avg Reward (100) = -30568.82, Epsilon = 0.956, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -149718.56, Border Penalty: -30907.87, Obstacle Penalty: -50.00
Episode 74: Reward = -1098.00, Avg Reward (100) = -32201.01, Epsilon = 0.956, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 75: Reward = -1147.00, Avg Reward (100) = -31780.70, Epsilon = 0.955, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 76: Reward = -224809.55, Avg Reward (100) = -31372.25, Epsilon = 0.954, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 90, Reward Breakdown -> Delta_x Reward: -224809.55, Border Penalty: -30059.21, Obstacle Penalty: -100.00
Episode 77: Reward = -1049.00, Avg Reward (100) = -33917.48, Epsilon = 0.954, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 78: Reward = 866.03, Avg Reward (100) = -33490.61, Epsilon = 0.953, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: 866.03, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 79: Reward = -31764.82, Avg Reward (100) = -33050.14, Epsilon = 0.953, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 28, Reward Breakdown -> Delta_x Reward: -31764.82, Border Penalty: -33032.26, Obstacle Penalty: -50.00
Episode 80: Reward = -1000.00, Avg Reward (100) = -33033.87, Epsilon = 0.952, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 81: Reward = -167690.89, Avg Reward (100) = -32633.45, Epsilon = 0.951, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: -167690.89, Border Penalty: -32717.58, Obstacle Penalty: -50.00
Episode 82: Reward = -148932.73, Avg Reward (100) = -34300.83, Epsilon = 0.951, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 41, Reward Breakdown -> Delta_x Reward: -148932.73, Border Penalty: -32227.59, Obstacle Penalty: -50.00
Episode 83: Reward = -78532.07, Avg Reward (100) = -35698.78, Epsilon = 0.950, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -78532.07, Border Penalty: -34259.33, Obstacle Penalty: -50.00
Episode 84: Reward = -24153.60, Avg Reward (100) = -36214.84, Epsilon = 0.950, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 53, Reward Breakdown -> Delta_x Reward: -24153.60, Border Penalty: 0.00, Obstacle Penalty: -89.31
Episode 85: Reward = -1049.00, Avg Reward (100) = -36071.25, Epsilon = 0.949, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 86: Reward = -107075.15, Avg Reward (100) = -35659.23, Epsilon = 0.948, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 39, Reward Breakdown -> Delta_x Reward: -107075.15, Border Penalty: -30561.58, Obstacle Penalty: -50.00
Episode 87: Reward = -1000.00, Avg Reward (100) = -36489.65, Epsilon = 0.948, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 88: Reward = -579.19, Avg Reward (100) = -36081.72, Epsilon = 0.947, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -579.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 89: Reward = -526.19, Avg Reward (100) = -35678.28, Epsilon = 0.947, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -526.19, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 90: Reward = -1049.00, Avg Reward (100) = -35283.31, Epsilon = 0.946, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 91: Reward = -1049.00, Avg Reward (100) = -34902.93, Epsilon = 0.945, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 92: Reward = -1049.00, Avg Reward (100) = -34530.91, Epsilon = 0.945, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 93: Reward = -64056.27, Avg Reward (100) = -34166.98, Epsilon = 0.944, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 30, Reward Breakdown -> Delta_x Reward: -64056.27, Border Penalty: -36797.12, Obstacle Penalty: -50.00
Episode 94: Reward = -1098.00, Avg Reward (100) = -34488.37, Epsilon = 0.944, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 95: Reward = -1245.00, Avg Reward (100) = -34133.15, Epsilon = 0.943, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 96: Reward = -1000.00, Avg Reward (100) = -33786.96, Epsilon = 0.942, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 97: Reward = -1098.00, Avg Reward (100) = -33445.43, Epsilon = 0.942, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 98: Reward = -1000.00, Avg Reward (100) = -33111.95, Epsilon = 0.941, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 99: Reward = -73891.00, Avg Reward (100) = -32784.28, Epsilon = 0.941, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -73891.00, Border Penalty: -30535.94, Obstacle Penalty: -50.00
Episode 100: Reward = -1098.00, Avg Reward (100) = -33199.50, Epsilon = 0.940, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 101: Reward = -1294.00, Avg Reward (100) = -32878.48, Epsilon = 0.939, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 102: Reward = 1132.91, Avg Reward (100) = -32885.65, Epsilon = 0.939, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: 1132.91, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 103: Reward = 267.58, Avg Reward (100) = -32238.29, Epsilon = 0.938, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: 267.58, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 104: Reward = -216854.86, Avg Reward (100) = -32172.84, Epsilon = 0.938, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 39, Reward Breakdown -> Delta_x Reward: -216854.86, Border Penalty: -30784.47, Obstacle Penalty: -50.00
Episode 105: Reward = -37244.61, Avg Reward (100) = -34335.08, Epsilon = 0.937, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 59, Reward Breakdown -> Delta_x Reward: -37244.61, Border Penalty: -31138.36, Obstacle Penalty: -50.00
Episode 106: Reward = -88608.62, Avg Reward (100) = -34696.55, Epsilon = 0.936, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: -88608.62, Border Penalty: -32893.57, Obstacle Penalty: -50.00
Episode 107: Reward = -220958.22, Avg Reward (100) = -35572.63, Epsilon = 0.936, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 42, Reward Breakdown -> Delta_x Reward: -220958.22, Border Penalty: -31558.54, Obstacle Penalty: -50.00
Episode 108: Reward = -1000.00, Avg Reward (100) = -37768.28, Epsilon = 0.935, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 109: Reward = -1147.00, Avg Reward (100) = -37767.30, Epsilon = 0.935, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 110: Reward = -1351.40, Avg Reward (100) = -36203.75, Epsilon = 0.934, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 111: Reward = -1049.00, Avg Reward (100) = -36207.26, Epsilon = 0.933, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 112: Reward = -1196.00, Avg Reward (100) = -36207.75, Epsilon = 0.933, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 113: Reward = -1049.00, Avg Reward (100) = -36209.22, Epsilon = 0.932, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 114: Reward = -38957.67, Avg Reward (100) = -36209.22, Epsilon = 0.932, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38957.67, Border Penalty: -35811.29, Obstacle Penalty: -50.00
Episode 115: Reward = -1049.00, Avg Reward (100) = -36590.96, Epsilon = 0.931, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 116: Reward = -113919.70, Avg Reward (100) = -36589.98, Epsilon = 0.930, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -113919.70, Border Penalty: -30275.99, Obstacle Penalty: -50.00
Episode 117: Reward = -63140.55, Avg Reward (100) = -37205.35, Epsilon = 0.930, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -63140.55, Border Penalty: -34554.57, Obstacle Penalty: -50.00
Episode 118: Reward = -1000.00, Avg Reward (100) = -37825.29, Epsilon = 0.929, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 119: Reward = -30881.12, Avg Reward (100) = -37825.29, Epsilon = 0.929, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 44, Reward Breakdown -> Delta_x Reward: -30881.12, Border Penalty: -30747.23, Obstacle Penalty: -50.00
Episode 120: Reward = -65224.75, Avg Reward (100) = -38122.63, Epsilon = 0.928, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -65224.75, Border Penalty: -37381.48, Obstacle Penalty: -50.00
Episode 121: Reward = -1049.00, Avg Reward (100) = -37555.42, Epsilon = 0.927, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 122: Reward = -1049.00, Avg Reward (100) = -37555.91, Epsilon = 0.927, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 123: Reward = -1907.62, Avg Reward (100) = -37163.24, Epsilon = 0.926, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 30, Reward Breakdown -> Delta_x Reward: -1907.62, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 124: Reward = -1098.00, Avg Reward (100) = -35787.69, Epsilon = 0.926, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 125: Reward = -1000.00, Avg Reward (100) = -34922.38, Epsilon = 0.925, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 126: Reward = -75626.45, Avg Reward (100) = -34378.26, Epsilon = 0.924, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -75626.45, Border Penalty: -37512.62, Obstacle Penalty: -50.00
Episode 127: Reward = -74222.67, Avg Reward (100) = -35126.68, Epsilon = 0.924, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -74222.67, Border Penalty: -30061.26, Obstacle Penalty: -50.00
Episode 128: Reward = -37008.05, Avg Reward (100) = -34348.71, Epsilon = 0.923, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -37008.05, Border Penalty: -31855.16, Obstacle Penalty: -50.00
Episode 129: Reward = -1000.00, Avg Reward (100) = -34708.79, Epsilon = 0.923, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 130: Reward = -48044.60, Avg Reward (100) = -34707.32, Epsilon = 0.922, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 131: Reward = -572.65, Avg Reward (100) = -35177.28, Epsilon = 0.921, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -572.65, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 132: Reward = -29955.75, Avg Reward (100) = -35172.52, Epsilon = 0.921, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 56, Reward Breakdown -> Delta_x Reward: -29955.75, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 133: Reward = -95932.77, Avg Reward (100) = -35461.58, Epsilon = 0.920, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -95932.77, Border Penalty: -32042.26, Obstacle Penalty: -50.00
Episode 134: Reward = -39577.81, Avg Reward (100) = -36410.42, Epsilon = 0.920, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -39577.81, Border Penalty: -32768.16, Obstacle Penalty: -50.00
Episode 135: Reward = -1147.00, Avg Reward (100) = -36796.20, Epsilon = 0.919, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 136: Reward = -70293.36, Avg Reward (100) = -36797.18, Epsilon = 0.918, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 40, Reward Breakdown -> Delta_x Reward: -70293.36, Border Penalty: -30577.93, Obstacle Penalty: -50.00
Episode 137: Reward = 112.35, Avg Reward (100) = -37490.11, Epsilon = 0.918, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: 112.35, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 138: Reward = -1000.00, Avg Reward (100) = -37543.59, Epsilon = 0.917, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 139: Reward = -41005.27, Avg Reward (100) = -37543.59, Epsilon = 0.917, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -41005.27, Border Penalty: -36256.55, Obstacle Penalty: -50.00
Episode 140: Reward = -1098.00, Avg Reward (100) = -37943.64, Epsilon = 0.916, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 141: Reward = -56418.67, Avg Reward (100) = -37196.83, Epsilon = 0.915, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 28, Reward Breakdown -> Delta_x Reward: -56418.67, Border Penalty: -34566.50, Obstacle Penalty: -50.00
Episode 142: Reward = -1000.00, Avg Reward (100) = -36914.05, Epsilon = 0.915, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 143: Reward = -580.25, Avg Reward (100) = -36914.05, Epsilon = 0.914, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -580.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 144: Reward = -1000.00, Avg Reward (100) = -32460.94, Epsilon = 0.914, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 145: Reward = -1000.00, Avg Reward (100) = -32460.45, Epsilon = 0.913, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 146: Reward = -1000.00, Avg Reward (100) = -32491.02, Epsilon = 0.912, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 147: Reward = -1000.00, Avg Reward (100) = -32491.02, Epsilon = 0.912, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 148: Reward = -1049.00, Avg Reward (100) = -32504.13, Epsilon = 0.911, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 149: Reward = -1049.00, Avg Reward (100) = -32504.13, Epsilon = 0.911, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 150: Reward = -1000.00, Avg Reward (100) = -32504.62, Epsilon = 0.910, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 151: Reward = -1196.00, Avg Reward (100) = -32508.83, Epsilon = 0.909, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 152: Reward = -1000.00, Avg Reward (100) = -30358.79, Epsilon = 0.909, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 153: Reward = -1000.00, Avg Reward (100) = -28994.84, Epsilon = 0.908, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 154: Reward = -1000.00, Avg Reward (100) = -28998.03, Epsilon = 0.908, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 155: Reward = 62.82, Avg Reward (100) = -29007.24, Epsilon = 0.907, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 62.82, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 156: Reward = -1049.00, Avg Reward (100) = -27790.92, Epsilon = 0.906, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 157: Reward = -1049.00, Avg Reward (100) = -27796.13, Epsilon = 0.906, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 158: Reward = -1000.00, Avg Reward (100) = -27798.78, Epsilon = 0.905, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 159: Reward = -38194.76, Avg Reward (100) = -27798.78, Epsilon = 0.905, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -38194.76, Border Penalty: -33293.24, Obstacle Penalty: -50.00
Episode 160: Reward = -97006.67, Avg Reward (100) = -28168.28, Epsilon = 0.904, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -97006.67, Border Penalty: -32262.10, Obstacle Penalty: -50.00
Episode 161: Reward = -239539.72, Avg Reward (100) = -29132.03, Epsilon = 0.903, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 63, Reward Breakdown -> Delta_x Reward: -239539.72, Border Penalty: -35058.87, Obstacle Penalty: -50.00
Episode 162: Reward = -784.25, Avg Reward (100) = -30545.11, Epsilon = 0.903, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 163: Reward = -1196.00, Avg Reward (100) = -30542.96, Epsilon = 0.902, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 164: Reward = -53718.04, Avg Reward (100) = -30285.83, Epsilon = 0.902, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -53718.04, Border Penalty: -38896.68, Obstacle Penalty: -50.00
Episode 165: Reward = -733.25, Avg Reward (100) = -30814.70, Epsilon = 0.901, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 166: Reward = 10.64, Avg Reward (100) = -30839.11, Epsilon = 0.900, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: 10.64, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 167: Reward = -50449.07, Avg Reward (100) = -30828.03, Epsilon = 0.900, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 38, Reward Breakdown -> Delta_x Reward: -50449.07, Border Penalty: -32695.18, Obstacle Penalty: -50.00
Episode 168: Reward = -42368.98, Avg Reward (100) = -30847.15, Epsilon = 0.899, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -42368.98, Border Penalty: -32369.44, Obstacle Penalty: -50.00
Episode 169: Reward = -1000.00, Avg Reward (100) = -31259.86, Epsilon = 0.899, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 170: Reward = -1049.00, Avg Reward (100) = -30943.49, Epsilon = 0.898, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 171: Reward = -50190.11, Avg Reward (100) = -30943.49, Epsilon = 0.897, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 45, Reward Breakdown -> Delta_x Reward: -50190.11, Border Penalty: -30659.59, Obstacle Penalty: -50.00
Episode 172: Reward = -130.22, Avg Reward (100) = -31435.39, Epsilon = 0.897, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -130.22, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 173: Reward = -1147.00, Avg Reward (100) = -31425.71, Epsilon = 0.896, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 174: Reward = -44095.49, Avg Reward (100) = -29940.00, Epsilon = 0.896, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -44095.49, Border Penalty: -33410.15, Obstacle Penalty: -50.00
Episode 175: Reward = -177053.28, Avg Reward (100) = -30369.97, Epsilon = 0.895, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -177053.28, Border Penalty: -19941.72, Obstacle Penalty: -50.00
Episode 176: Reward = -373.21, Avg Reward (100) = -32129.03, Epsilon = 0.894, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -373.21, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 177: Reward = -1000.00, Avg Reward (100) = -29884.67, Epsilon = 0.894, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 178: Reward = -193.50, Avg Reward (100) = -29884.18, Epsilon = 0.893, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 41, Reward Breakdown -> Delta_x Reward: -193.50, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 179: Reward = -1000.00, Avg Reward (100) = -29894.78, Epsilon = 0.893, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 180: Reward = -1049.00, Avg Reward (100) = -29587.13, Epsilon = 0.892, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 181: Reward = -1000.00, Avg Reward (100) = -29587.62, Epsilon = 0.891, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 182: Reward = -193829.09, Avg Reward (100) = -27920.71, Epsilon = 0.891, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: -193829.09, Border Penalty: -33293.69, Obstacle Penalty: -50.00
Episode 183: Reward = -63222.70, Avg Reward (100) = -28369.67, Epsilon = 0.890, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -63222.70, Border Penalty: -35851.72, Obstacle Penalty: -50.00
Episode 184: Reward = 1056.15, Avg Reward (100) = -28216.58, Epsilon = 0.890, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 1056.15, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 185: Reward = -67540.72, Avg Reward (100) = -27964.48, Epsilon = 0.889, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 53, Reward Breakdown -> Delta_x Reward: -67540.72, Border Penalty: -18279.81, Obstacle Penalty: -50.00
Episode 186: Reward = -1000.00, Avg Reward (100) = -28629.40, Epsilon = 0.888, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 187: Reward = -1000.00, Avg Reward (100) = -27568.65, Epsilon = 0.888, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 188: Reward = -78.34, Avg Reward (100) = -27568.65, Epsilon = 0.887, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -78.34, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 189: Reward = -1147.00, Avg Reward (100) = -27563.64, Epsilon = 0.887, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 190: Reward = -49742.16, Avg Reward (100) = -27569.85, Epsilon = 0.886, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 44, Reward Breakdown -> Delta_x Reward: -49742.16, Border Penalty: -31675.59, Obstacle Penalty: -50.00
Episode 191: Reward = -1000.00, Avg Reward (100) = -28056.78, Epsilon = 0.885, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 192: Reward = -1049.00, Avg Reward (100) = -28056.29, Epsilon = 0.885, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 193: Reward = 170.10, Avg Reward (100) = -28056.29, Epsilon = 0.884, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 170.10, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 194: Reward = -527.65, Avg Reward (100) = -27414.02, Epsilon = 0.884, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -527.65, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 195: Reward = -23436.84, Avg Reward (100) = -27408.32, Epsilon = 0.883, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 38, Reward Breakdown -> Delta_x Reward: -23436.84, Border Penalty: -34582.42, Obstacle Penalty: -50.00
Episode 196: Reward = -1147.00, Avg Reward (100) = -27630.24, Epsilon = 0.882, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 197: Reward = -103554.02, Avg Reward (100) = -27631.71, Epsilon = 0.882, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -103554.02, Border Penalty: -35043.95, Obstacle Penalty: -50.00
Episode 198: Reward = -922.65, Avg Reward (100) = -28656.27, Epsilon = 0.881, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -922.65, Border Penalty: -49.59, Obstacle Penalty: -99.17
Episode 199: Reward = -79419.97, Avg Reward (100) = -28655.50, Epsilon = 0.881, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 43, Reward Breakdown -> Delta_x Reward: -79419.97, Border Penalty: -37335.36, Obstacle Penalty: -50.00
Episode 200: Reward = -1098.00, Avg Reward (100) = -28710.79, Epsilon = 0.880, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 201: Reward = -257736.16, Avg Reward (100) = -28710.79, Epsilon = 0.879, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 38, Reward Breakdown -> Delta_x Reward: -257736.16, Border Penalty: -35958.34, Obstacle Penalty: -50.00
Episode 202: Reward = -1147.00, Avg Reward (100) = -31275.21, Epsilon = 0.879, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 203: Reward = -1049.00, Avg Reward (100) = -31298.01, Epsilon = 0.878, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 204: Reward = -1000.00, Avg Reward (100) = -31311.17, Epsilon = 0.878, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 205: Reward = -1098.00, Avg Reward (100) = -29152.62, Epsilon = 0.877, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 206: Reward = -1000.00, Avg Reward (100) = -28791.16, Epsilon = 0.876, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 207: Reward = -57276.18, Avg Reward (100) = -27915.07, Epsilon = 0.876, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -57276.18, Border Penalty: -36248.09, Obstacle Penalty: -50.00
Episode 208: Reward = -1000.00, Avg Reward (100) = -26278.25, Epsilon = 0.875, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 209: Reward = -1049.00, Avg Reward (100) = -26278.25, Epsilon = 0.875, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 210: Reward = -1098.00, Avg Reward (100) = -26277.27, Epsilon = 0.874, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 211: Reward = -1049.00, Avg Reward (100) = -26274.74, Epsilon = 0.873, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 212: Reward = -71392.82, Avg Reward (100) = -26274.74, Epsilon = 0.873, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -71392.82, Border Penalty: -33641.12, Obstacle Penalty: -50.00
Episode 213: Reward = -1000.00, Avg Reward (100) = -26976.71, Epsilon = 0.872, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 214: Reward = -58696.21, Avg Reward (100) = -26976.22, Epsilon = 0.872, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 43, Reward Breakdown -> Delta_x Reward: -58696.21, Border Penalty: -30988.73, Obstacle Penalty: -50.00
Episode 215: Reward = -1000.00, Avg Reward (100) = -27173.60, Epsilon = 0.871, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 216: Reward = -81389.95, Avg Reward (100) = -27173.11, Epsilon = 0.870, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 32, Reward Breakdown -> Delta_x Reward: -81389.95, Border Penalty: -34524.40, Obstacle Penalty: -50.00
Episode 217: Reward = -39453.71, Avg Reward (100) = -26847.81, Epsilon = 0.870, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 52, Reward Breakdown -> Delta_x Reward: -39453.71, Border Penalty: -34010.16, Obstacle Penalty: -50.00
Episode 218: Reward = -14624.72, Avg Reward (100) = -26610.94, Epsilon = 0.869, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -14624.72, Border Penalty: -8866.15, Obstacle Penalty: -50.00
Episode 219: Reward = -14491.54, Avg Reward (100) = -26747.19, Epsilon = 0.869, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -14491.54, Border Penalty: -14449.53, Obstacle Penalty: -50.00
Episode 220: Reward = -579.19, Avg Reward (100) = -26583.30, Epsilon = 0.868, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -579.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 221: Reward = -169426.09, Avg Reward (100) = -25936.84, Epsilon = 0.867, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 36, Reward Breakdown -> Delta_x Reward: -169426.09, Border Penalty: -33941.30, Obstacle Penalty: -50.00
Episode 222: Reward = -259200.78, Avg Reward (100) = -27620.61, Epsilon = 0.867, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 53, Reward Breakdown -> Delta_x Reward: -259200.78, Border Penalty: -30224.11, Obstacle Penalty: -50.00
Episode 223: Reward = 1763.57, Avg Reward (100) = -30202.13, Epsilon = 0.866, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 1763.57, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 224: Reward = -1049.00, Avg Reward (100) = -30165.42, Epsilon = 0.866, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 225: Reward = -46823.66, Avg Reward (100) = -30164.93, Epsilon = 0.865, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -46823.66, Border Penalty: -32624.88, Obstacle Penalty: -50.00
Episode 226: Reward = -1000.00, Avg Reward (100) = -30623.16, Epsilon = 0.864, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 227: Reward = -60020.24, Avg Reward (100) = -29876.90, Epsilon = 0.864, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 49, Reward Breakdown -> Delta_x Reward: -60020.24, Border Penalty: -34348.66, Obstacle Penalty: -50.00
Episode 228: Reward = -299.01, Avg Reward (100) = -29734.88, Epsilon = 0.863, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -299.01, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 229: Reward = -1000.00, Avg Reward (100) = -29367.78, Epsilon = 0.863, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 230: Reward = -1098.00, Avg Reward (100) = -29367.78, Epsilon = 0.862, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 231: Reward = -107806.92, Avg Reward (100) = -28898.32, Epsilon = 0.861, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 37, Reward Breakdown -> Delta_x Reward: -107806.92, Border Penalty: -32980.12, Obstacle Penalty: -50.00
Episode 232: Reward = -203720.11, Avg Reward (100) = -29970.66, Epsilon = 0.861, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -203720.11, Border Penalty: -30470.33, Obstacle Penalty: -50.00
Episode 233: Reward = -183736.64, Avg Reward (100) = -31708.31, Epsilon = 0.860, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 32, Reward Breakdown -> Delta_x Reward: -183736.64, Border Penalty: -32539.87, Obstacle Penalty: -50.00
Episode 234: Reward = -1000.00, Avg Reward (100) = -32586.34, Epsilon = 0.860, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 235: Reward = -534761.94, Avg Reward (100) = -32200.57, Epsilon = 0.859, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 74, Reward Breakdown -> Delta_x Reward: -534761.94, Border Penalty: -34244.59, Obstacle Penalty: -100.00
Episode 236: Reward = -1049.00, Avg Reward (100) = -37536.71, Epsilon = 0.858, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 237: Reward = -44653.84, Avg Reward (100) = -36844.27, Epsilon = 0.858, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 28, Reward Breakdown -> Delta_x Reward: -44653.84, Border Penalty: -30922.98, Obstacle Penalty: -50.00
Episode 238: Reward = -1049.00, Avg Reward (100) = -37291.93, Epsilon = 0.857, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 239: Reward = -1000.00, Avg Reward (100) = -37292.42, Epsilon = 0.857, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 240: Reward = -148229.16, Avg Reward (100) = -36892.37, Epsilon = 0.856, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -148229.16, Border Penalty: -32079.60, Obstacle Penalty: -50.00
Episode 241: Reward = -197523.33, Avg Reward (100) = -38363.68, Epsilon = 0.855, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 34, Reward Breakdown -> Delta_x Reward: -197523.33, Border Penalty: -30074.18, Obstacle Penalty: -50.00
Episode 242: Reward = -1196.00, Avg Reward (100) = -39774.73, Epsilon = 0.855, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 243: Reward = -1000.00, Avg Reward (100) = -39776.69, Epsilon = 0.854, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 244: Reward = -1049.00, Avg Reward (100) = -39780.89, Epsilon = 0.854, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 245: Reward = -1049.00, Avg Reward (100) = -39781.38, Epsilon = 0.853, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 246: Reward = -69870.05, Avg Reward (100) = -39781.87, Epsilon = 0.852, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 55, Reward Breakdown -> Delta_x Reward: -69870.05, Border Penalty: -31660.68, Obstacle Penalty: -50.00
Episode 247: Reward = -1000.00, Avg Reward (100) = -40470.57, Epsilon = 0.852, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 248: Reward = -1000.00, Avg Reward (100) = -40470.57, Epsilon = 0.851, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 249: Reward = -1049.00, Avg Reward (100) = -40470.08, Epsilon = 0.851, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 250: Reward = -1147.00, Avg Reward (100) = -40470.08, Epsilon = 0.850, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 251: Reward = -1343.00, Avg Reward (100) = -40471.55, Epsilon = 0.849, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1343.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 252: Reward = -1000.00, Avg Reward (100) = -40473.02, Epsilon = 0.849, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 253: Reward = -62215.24, Avg Reward (100) = -40473.02, Epsilon = 0.848, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -62215.24, Border Penalty: -34216.43, Obstacle Penalty: -50.00
Episode 254: Reward = -84901.34, Avg Reward (100) = -41085.17, Epsilon = 0.848, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -84901.34, Border Penalty: -36210.98, Obstacle Penalty: -50.00
Episode 255: Reward = -1000.00, Avg Reward (100) = -41924.18, Epsilon = 0.847, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 256: Reward = -1049.00, Avg Reward (100) = -41934.81, Epsilon = 0.846, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 257: Reward = 1224.21, Avg Reward (100) = -41934.81, Epsilon = 0.846, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: 1224.21, Border Penalty: 0.00, Obstacle Penalty: -83.29
Episode 258: Reward = -1049.00, Avg Reward (100) = -41912.08, Epsilon = 0.845, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 259: Reward = -79.22, Avg Reward (100) = -41912.57, Epsilon = 0.845, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -79.22, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 260: Reward = -1147.00, Avg Reward (100) = -41531.41, Epsilon = 0.844, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 261: Reward = -2323.44, Avg Reward (100) = -40572.82, Epsilon = 0.843, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -2323.44, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 262: Reward = -1098.00, Avg Reward (100) = -38200.65, Epsilon = 0.843, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 263: Reward = -75568.05, Avg Reward (100) = -38203.79, Epsilon = 0.842, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -75568.05, Border Penalty: -35422.94, Obstacle Penalty: -50.00
Episode 264: Reward = -71142.09, Avg Reward (100) = -38947.51, Epsilon = 0.842, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -71142.09, Border Penalty: -36450.28, Obstacle Penalty: -50.00
Episode 265: Reward = -1000.00, Avg Reward (100) = -39121.75, Epsilon = 0.841, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 266: Reward = -52920.69, Avg Reward (100) = -39124.42, Epsilon = 0.840, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -52920.69, Border Penalty: -30101.50, Obstacle Penalty: -50.00
Episode 267: Reward = -1196.00, Avg Reward (100) = -39653.73, Epsilon = 0.840, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 268: Reward = -1196.00, Avg Reward (100) = -39161.20, Epsilon = 0.839, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 269: Reward = -137426.05, Avg Reward (100) = -38749.47, Epsilon = 0.839, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -137426.05, Border Penalty: -31925.49, Obstacle Penalty: -50.00
Episode 270: Reward = -1098.00, Avg Reward (100) = -40113.73, Epsilon = 0.838, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 271: Reward = -1196.00, Avg Reward (100) = -40114.22, Epsilon = 0.837, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 272: Reward = -1098.00, Avg Reward (100) = -39624.28, Epsilon = 0.837, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 273: Reward = -1000.00, Avg Reward (100) = -39633.96, Epsilon = 0.836, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 274: Reward = -1049.00, Avg Reward (100) = -39632.49, Epsilon = 0.836, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 275: Reward = -106558.67, Avg Reward (100) = -39202.02, Epsilon = 0.835, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 61, Reward Breakdown -> Delta_x Reward: -106558.67, Border Penalty: -35072.49, Obstacle Penalty: -50.00
Episode 276: Reward = -116108.36, Avg Reward (100) = -38497.08, Epsilon = 0.834, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -116108.36, Border Penalty: -30463.45, Obstacle Penalty: -50.00
Episode 277: Reward = -1049.00, Avg Reward (100) = -39654.43, Epsilon = 0.834, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 278: Reward = -91970.42, Avg Reward (100) = -39654.92, Epsilon = 0.833, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -91970.42, Border Penalty: -36091.73, Obstacle Penalty: -50.00
Episode 279: Reward = -1147.00, Avg Reward (100) = -40572.69, Epsilon = 0.833, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 280: Reward = -1000.00, Avg Reward (100) = -40574.16, Epsilon = 0.832, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 281: Reward = -384.28, Avg Reward (100) = -40573.67, Epsilon = 0.831, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -384.28, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 282: Reward = -65264.93, Avg Reward (100) = -40567.51, Epsilon = 0.831, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -65264.93, Border Penalty: -32794.32, Obstacle Penalty: -50.00
Episode 283: Reward = -1098.00, Avg Reward (100) = -39281.87, Epsilon = 0.830, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 284: Reward = -51418.74, Avg Reward (100) = -38660.62, Epsilon = 0.830, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -51418.74, Border Penalty: -32712.24, Obstacle Penalty: -50.00
Episode 285: Reward = -48776.70, Avg Reward (100) = -39185.37, Epsilon = 0.829, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -48776.70, Border Penalty: -36424.99, Obstacle Penalty: -50.00
Episode 286: Reward = -1147.00, Avg Reward (100) = -38997.73, Epsilon = 0.828, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 287: Reward = -628.19, Avg Reward (100) = -38999.20, Epsilon = 0.828, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -628.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 288: Reward = -43583.48, Avg Reward (100) = -38995.48, Epsilon = 0.827, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43583.48, Border Penalty: -30853.75, Obstacle Penalty: -50.00
Episode 289: Reward = -1000.00, Avg Reward (100) = -39430.54, Epsilon = 0.827, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 290: Reward = -1000.00, Avg Reward (100) = -39429.07, Epsilon = 0.826, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 291: Reward = -53983.79, Avg Reward (100) = -38941.64, Epsilon = 0.825, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 32, Reward Breakdown -> Delta_x Reward: -53983.79, Border Penalty: -35379.10, Obstacle Penalty: -50.00
Episode 292: Reward = -1000.00, Avg Reward (100) = -39471.48, Epsilon = 0.825, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 293: Reward = -678.25, Avg Reward (100) = -39470.99, Epsilon = 0.824, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -678.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 294: Reward = -1343.00, Avg Reward (100) = -39479.48, Epsilon = 0.824, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1343.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 295: Reward = -1000.00, Avg Reward (100) = -39487.63, Epsilon = 0.823, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 296: Reward = -173.07, Avg Reward (100) = -39263.26, Epsilon = 0.822, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -173.07, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 297: Reward = -52467.76, Avg Reward (100) = -39253.52, Epsilon = 0.822, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 36, Reward Breakdown -> Delta_x Reward: -52467.76, Border Penalty: -37336.43, Obstacle Penalty: -50.00
Episode 298: Reward = -64035.83, Avg Reward (100) = -38742.66, Epsilon = 0.821, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -64035.83, Border Penalty: -36783.71, Obstacle Penalty: -50.00
Episode 299: Reward = -57285.54, Avg Reward (100) = -39373.79, Epsilon = 0.821, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -57285.54, Border Penalty: -33949.59, Obstacle Penalty: -50.00
Episode 300: Reward = -731.25, Avg Reward (100) = -39152.45, Epsilon = 0.820, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -731.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 301: Reward = -678.25, Avg Reward (100) = -39148.78, Epsilon = 0.819, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -678.25, Border Penalty: 0.00, Obstacle Penalty: -71.56
Episode 302: Reward = -1098.00, Avg Reward (100) = -36578.20, Epsilon = 0.819, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 303: Reward = -1000.00, Avg Reward (100) = -36577.71, Epsilon = 0.818, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 304: Reward = -51892.84, Avg Reward (100) = -36577.22, Epsilon = 0.818, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51892.84, Border Penalty: -31656.71, Obstacle Penalty: -50.00
Episode 305: Reward = -1196.00, Avg Reward (100) = -37086.15, Epsilon = 0.817, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 306: Reward = -1000.00, Avg Reward (100) = -37087.13, Epsilon = 0.816, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 307: Reward = -1000.00, Avg Reward (100) = -37087.13, Epsilon = 0.816, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 308: Reward = -1000.00, Avg Reward (100) = -36524.37, Epsilon = 0.815, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 309: Reward = -1049.00, Avg Reward (100) = -36524.37, Epsilon = 0.815, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 310: Reward = -31056.67, Avg Reward (100) = -36524.37, Epsilon = 0.814, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -31056.67, Border Penalty: -30925.39, Obstacle Penalty: -50.00
Episode 311: Reward = -1098.00, Avg Reward (100) = -36823.95, Epsilon = 0.813, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 312: Reward = -50906.52, Avg Reward (100) = -36824.44, Epsilon = 0.813, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -50906.52, Border Penalty: -39640.31, Obstacle Penalty: -50.00
Episode 313: Reward = -1392.00, Avg Reward (100) = -36619.58, Epsilon = 0.812, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1392.00, Border Penalty: 0.00, Obstacle Penalty: -70.63
Episode 314: Reward = -1000.00, Avg Reward (100) = -36623.50, Epsilon = 0.812, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 315: Reward = -25228.52, Avg Reward (100) = -36046.54, Epsilon = 0.811, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 316: Reward = -1000.00, Avg Reward (100) = -36288.82, Epsilon = 0.810, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 317: Reward = -1049.00, Avg Reward (100) = -35484.92, Epsilon = 0.810, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 318: Reward = -1000.00, Avg Reward (100) = -35100.88, Epsilon = 0.809, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 319: Reward = -1000.00, Avg Reward (100) = -34964.63, Epsilon = 0.809, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 320: Reward = -1098.00, Avg Reward (100) = -34829.71, Epsilon = 0.808, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 321: Reward = -1000.00, Avg Reward (100) = -34834.90, Epsilon = 0.807, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 322: Reward = -1049.00, Avg Reward (100) = -33150.64, Epsilon = 0.807, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 323: Reward = -1000.00, Avg Reward (100) = -30569.12, Epsilon = 0.806, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 324: Reward = -1000.00, Avg Reward (100) = -30596.76, Epsilon = 0.806, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 325: Reward = -1098.00, Avg Reward (100) = -30596.27, Epsilon = 0.805, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 326: Reward = 2097.30, Avg Reward (100) = -30139.01, Epsilon = 0.804, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: 2097.30, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 327: Reward = -1049.00, Avg Reward (100) = -30108.04, Epsilon = 0.804, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 328: Reward = -1000.00, Avg Reward (100) = -29518.33, Epsilon = 0.803, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 329: Reward = -47175.20, Avg Reward (100) = -29525.34, Epsilon = 0.803, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -47175.20, Border Penalty: -32764.90, Obstacle Penalty: -50.00
Episode 330: Reward = -1000.00, Avg Reward (100) = -29987.09, Epsilon = 0.802, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 331: Reward = -95534.98, Avg Reward (100) = -29986.11, Epsilon = 0.801, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -95534.98, Border Penalty: -32123.41, Obstacle Penalty: -50.00
Episode 332: Reward = -424.19, Avg Reward (100) = -29863.39, Epsilon = 0.801, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -424.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 333: Reward = -33701.04, Avg Reward (100) = -27830.43, Epsilon = 0.800, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 334: Reward = -70471.03, Avg Reward (100) = -26330.07, Epsilon = 0.800, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -70471.03, Border Penalty: -32987.32, Obstacle Penalty: -50.00
Episode 335: Reward = -56461.97, Avg Reward (100) = -27024.78, Epsilon = 0.799, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -56461.97, Border Penalty: -36930.39, Obstacle Penalty: -50.00
Episode 336: Reward = -1049.00, Avg Reward (100) = -22241.78, Epsilon = 0.798, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 337: Reward = -111681.38, Avg Reward (100) = -22241.78, Epsilon = 0.798, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -111681.38, Border Penalty: -31713.95, Obstacle Penalty: -50.00
Episode 338: Reward = -1000.00, Avg Reward (100) = -22912.06, Epsilon = 0.797, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 339: Reward = -1000.00, Avg Reward (100) = -22911.57, Epsilon = 0.797, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 340: Reward = -73768.76, Avg Reward (100) = -22911.57, Epsilon = 0.796, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -73768.76, Border Penalty: -32909.61, Obstacle Penalty: -50.00
Episode 341: Reward = -1049.00, Avg Reward (100) = -22166.97, Epsilon = 0.795, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 342: Reward = -1049.00, Avg Reward (100) = -20202.22, Epsilon = 0.795, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 343: Reward = -1049.00, Avg Reward (100) = -20200.75, Epsilon = 0.794, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 344: Reward = -228.31, Avg Reward (100) = -20201.24, Epsilon = 0.794, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -228.31, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 345: Reward = -43387.07, Avg Reward (100) = -20193.04, Epsilon = 0.793, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43387.07, Border Penalty: -32438.64, Obstacle Penalty: -50.00
Episode 346: Reward = -337.10, Avg Reward (100) = -20616.42, Epsilon = 0.792, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -337.10, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 347: Reward = -1049.00, Avg Reward (100) = -19921.09, Epsilon = 0.792, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 348: Reward = -1000.00, Avg Reward (100) = -19921.58, Epsilon = 0.791, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 349: Reward = -1098.00, Avg Reward (100) = -19921.58, Epsilon = 0.791, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 350: Reward = -1098.00, Avg Reward (100) = -19922.07, Epsilon = 0.790, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 351: Reward = -54133.95, Avg Reward (100) = -19921.58, Epsilon = 0.789, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -54133.95, Border Penalty: -38056.47, Obstacle Penalty: -50.00
Episode 352: Reward = -1000.00, Avg Reward (100) = -20449.49, Epsilon = 0.789, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 353: Reward = -1000.00, Avg Reward (100) = -20449.49, Epsilon = 0.788, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 354: Reward = -1000.00, Avg Reward (100) = -19837.33, Epsilon = 0.788, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 355: Reward = -1196.00, Avg Reward (100) = -18998.32, Epsilon = 0.787, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 356: Reward = -59425.37, Avg Reward (100) = -19000.28, Epsilon = 0.786, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -59425.37, Border Penalty: -37958.88, Obstacle Penalty: -50.00
Episode 357: Reward = -1049.00, Avg Reward (100) = -19584.04, Epsilon = 0.786, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 358: Reward = -61135.04, Avg Reward (100) = -19606.78, Epsilon = 0.785, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -61135.04, Border Penalty: -30529.95, Obstacle Penalty: -50.00
Episode 359: Reward = -133356.75, Avg Reward (100) = -20207.64, Epsilon = 0.785, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 51, Reward Breakdown -> Delta_x Reward: -133356.75, Border Penalty: -31270.17, Obstacle Penalty: -50.00
Episode 360: Reward = -37006.77, Avg Reward (100) = -21540.41, Epsilon = 0.784, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -37006.77, Border Penalty: -31414.86, Obstacle Penalty: -50.00
Episode 361: Reward = -1000.00, Avg Reward (100) = -21899.01, Epsilon = 0.783, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 362: Reward = -1098.00, Avg Reward (100) = -21885.78, Epsilon = 0.783, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 363: Reward = -1049.00, Avg Reward (100) = -21885.78, Epsilon = 0.782, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 364: Reward = -1000.00, Avg Reward (100) = -21140.58, Epsilon = 0.782, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 365: Reward = -1098.00, Avg Reward (100) = -20439.16, Epsilon = 0.781, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 366: Reward = 1050.39, Avg Reward (100) = -20440.14, Epsilon = 0.780, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: 1050.39, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 367: Reward = -61884.86, Avg Reward (100) = -19900.43, Epsilon = 0.780, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -61884.86, Border Penalty: -37129.91, Obstacle Penalty: -50.00
Episode 368: Reward = -1000.00, Avg Reward (100) = -20507.32, Epsilon = 0.779, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 369: Reward = -42048.46, Avg Reward (100) = -20505.36, Epsilon = 0.779, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -42048.46, Border Penalty: -33338.52, Obstacle Penalty: -50.00
Episode 370: Reward = -1098.00, Avg Reward (100) = -19551.59, Epsilon = 0.778, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 371: Reward = -1049.00, Avg Reward (100) = -19551.59, Epsilon = 0.777, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 372: Reward = -1245.00, Avg Reward (100) = -19550.12, Epsilon = 0.777, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 373: Reward = -56850.60, Avg Reward (100) = -19551.59, Epsilon = 0.776, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -56850.60, Border Penalty: -36890.50, Obstacle Penalty: -50.00
Episode 374: Reward = -47312.18, Avg Reward (100) = -20110.09, Epsilon = 0.776, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 33, Reward Breakdown -> Delta_x Reward: -47312.18, Border Penalty: -37882.21, Obstacle Penalty: -50.00
Episode 375: Reward = -1049.00, Avg Reward (100) = -20572.72, Epsilon = 0.775, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 376: Reward = -1147.00, Avg Reward (100) = -19517.63, Epsilon = 0.774, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 377: Reward = -626.19, Avg Reward (100) = -18368.01, Epsilon = 0.774, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -626.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 378: Reward = -1000.00, Avg Reward (100) = -18363.79, Epsilon = 0.773, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 379: Reward = -1098.00, Avg Reward (100) = -17454.08, Epsilon = 0.773, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 380: Reward = -1098.00, Avg Reward (100) = -17453.59, Epsilon = 0.772, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 381: Reward = -1000.00, Avg Reward (100) = -17454.57, Epsilon = 0.771, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 382: Reward = -1000.00, Avg Reward (100) = -17460.73, Epsilon = 0.771, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 383: Reward = -1000.00, Avg Reward (100) = -16818.08, Epsilon = 0.770, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 384: Reward = -47022.70, Avg Reward (100) = -16817.10, Epsilon = 0.770, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -47022.70, Border Penalty: -39079.47, Obstacle Penalty: -50.00
Episode 385: Reward = -1000.00, Avg Reward (100) = -16773.14, Epsilon = 0.769, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 386: Reward = -78191.53, Avg Reward (100) = -16295.37, Epsilon = 0.768, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -78191.53, Border Penalty: -32976.55, Obstacle Penalty: -50.00
Episode 387: Reward = -1000.00, Avg Reward (100) = -17065.82, Epsilon = 0.768, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 388: Reward = -50968.57, Avg Reward (100) = -17069.53, Epsilon = 0.767, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -37193.87, Obstacle Penalty: -50.00
Episode 389: Reward = -1049.00, Avg Reward (100) = -17143.39, Epsilon = 0.767, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 390: Reward = -73711.42, Avg Reward (100) = -17143.88, Epsilon = 0.766, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -73711.42, Border Penalty: -35700.62, Obstacle Penalty: -50.00
Episode 391: Reward = -1245.00, Avg Reward (100) = -17870.99, Epsilon = 0.765, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -79.94
Episode 392: Reward = -44935.62, Avg Reward (100) = -17343.60, Epsilon = 0.765, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 35, Reward Breakdown -> Delta_x Reward: -44935.62, Border Penalty: -30392.83, Obstacle Penalty: -50.00
Episode 393: Reward = -1000.00, Avg Reward (100) = -17782.96, Epsilon = 0.764, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 394: Reward = -1000.00, Avg Reward (100) = -17786.18, Epsilon = 0.764, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 395: Reward = -1196.00, Avg Reward (100) = -17782.75, Epsilon = 0.763, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 396: Reward = -40794.19, Avg Reward (100) = -17784.71, Epsilon = 0.762, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40794.19, Border Penalty: -36523.59, Obstacle Penalty: -50.00
Episode 397: Reward = -62582.78, Avg Reward (100) = -18190.92, Epsilon = 0.762, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -62582.78, Border Penalty: -31418.00, Obstacle Penalty: -50.00
Episode 398: Reward = -1098.00, Avg Reward (100) = -18292.07, Epsilon = 0.761, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 399: Reward = -733.25, Avg Reward (100) = -17662.69, Epsilon = 0.761, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 400: Reward = -116352.12, Avg Reward (100) = -17097.17, Epsilon = 0.760, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -116352.12, Border Penalty: -35087.14, Obstacle Penalty: -50.00
Episode 401: Reward = -39112.22, Avg Reward (100) = -18253.37, Epsilon = 0.759, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39112.22, Border Penalty: -35240.46, Obstacle Penalty: -50.00
Episode 402: Reward = -1049.00, Avg Reward (100) = -18637.71, Epsilon = 0.759, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 403: Reward = -1098.00, Avg Reward (100) = -18637.22, Epsilon = 0.758, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 404: Reward = -1000.00, Avg Reward (100) = -18638.20, Epsilon = 0.758, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 405: Reward = -83456.28, Avg Reward (100) = -18129.28, Epsilon = 0.757, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 36, Reward Breakdown -> Delta_x Reward: -83456.28, Border Penalty: -32307.66, Obstacle Penalty: -50.00
Episode 406: Reward = -1049.00, Avg Reward (100) = -18951.88, Epsilon = 0.756, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 407: Reward = -41579.57, Avg Reward (100) = -18952.37, Epsilon = 0.756, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -41579.57, Border Penalty: -34160.96, Obstacle Penalty: -50.00
Episode 408: Reward = -1000.00, Avg Reward (100) = -19358.16, Epsilon = 0.755, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 409: Reward = -35873.28, Avg Reward (100) = -19358.16, Epsilon = 0.755, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -35873.28, Border Penalty: -32398.22, Obstacle Penalty: -50.00
Episode 410: Reward = -130870.73, Avg Reward (100) = -19706.41, Epsilon = 0.754, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -130870.73, Border Penalty: -33860.17, Obstacle Penalty: -50.00
Episode 411: Reward = -31703.78, Avg Reward (100) = -20704.55, Epsilon = 0.753, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -31703.78, Border Penalty: -32975.34, Obstacle Penalty: -50.00
Episode 412: Reward = -1147.00, Avg Reward (100) = -21010.61, Epsilon = 0.753, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 413: Reward = -1049.00, Avg Reward (100) = -20513.01, Epsilon = 0.752, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 414: Reward = -153549.56, Avg Reward (100) = -20509.58, Epsilon = 0.752, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -153549.56, Border Penalty: -32542.06, Obstacle Penalty: -50.00
Episode 415: Reward = -1196.00, Avg Reward (100) = -22035.08, Epsilon = 0.751, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 416: Reward = -1098.00, Avg Reward (100) = -21794.75, Epsilon = 0.750, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 417: Reward = -1000.00, Avg Reward (100) = -21795.73, Epsilon = 0.750, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 418: Reward = -100113.25, Avg Reward (100) = -21795.24, Epsilon = 0.749, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -100113.25, Border Penalty: -33186.89, Obstacle Penalty: -50.00
Episode 419: Reward = -34059.64, Avg Reward (100) = -22786.37, Epsilon = 0.749, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -34059.64, Border Penalty: -30313.72, Obstacle Penalty: -50.00
Episode 420: Reward = -384.28, Avg Reward (100) = -23116.97, Epsilon = 0.748, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -384.28, Border Penalty: 0.00, Obstacle Penalty: -85.36
Episode 421: Reward = -733.25, Avg Reward (100) = -23109.83, Epsilon = 0.747, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 422: Reward = -833.25, Avg Reward (100) = -23107.17, Epsilon = 0.747, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -833.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 423: Reward = -780.25, Avg Reward (100) = -23105.01, Epsilon = 0.746, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -780.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 424: Reward = -60211.78, Avg Reward (100) = -23102.81, Epsilon = 0.746, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -60211.78, Border Penalty: -36098.77, Obstacle Penalty: -50.00
Episode 425: Reward = -38290.75, Avg Reward (100) = -23694.93, Epsilon = 0.745, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 26, Reward Breakdown -> Delta_x Reward: -38290.75, Border Penalty: -35727.68, Obstacle Penalty: -50.00
Episode 426: Reward = -1049.00, Avg Reward (100) = -24066.86, Epsilon = 0.744, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 427: Reward = -58108.24, Avg Reward (100) = -24098.32, Epsilon = 0.744, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -58108.24, Border Penalty: -41354.05, Obstacle Penalty: -50.00
Episode 428: Reward = -1196.00, Avg Reward (100) = -24668.91, Epsilon = 0.743, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 429: Reward = -1000.00, Avg Reward (100) = -24670.87, Epsilon = 0.743, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 430: Reward = -1000.00, Avg Reward (100) = -24209.12, Epsilon = 0.742, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 431: Reward = -1049.00, Avg Reward (100) = -24209.12, Epsilon = 0.741, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 432: Reward = -133848.34, Avg Reward (100) = -23264.26, Epsilon = 0.741, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -133848.34, Border Penalty: -30495.46, Obstacle Penalty: -50.00
Episode 433: Reward = -1000.00, Avg Reward (100) = -24598.50, Epsilon = 0.740, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 434: Reward = -64329.12, Avg Reward (100) = -24271.49, Epsilon = 0.740, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -64329.12, Border Penalty: -34852.88, Obstacle Penalty: -50.00
Episode 435: Reward = -682.25, Avg Reward (100) = -24210.07, Epsilon = 0.739, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -682.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 436: Reward = -40620.65, Avg Reward (100) = -23652.27, Epsilon = 0.738, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -40620.65, Border Penalty: -35782.57, Obstacle Penalty: -50.00
Episode 437: Reward = -1049.00, Avg Reward (100) = -24047.99, Epsilon = 0.738, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 438: Reward = -1147.00, Avg Reward (100) = -22941.67, Epsilon = 0.737, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 439: Reward = -1049.00, Avg Reward (100) = -22943.14, Epsilon = 0.737, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 440: Reward = -1000.00, Avg Reward (100) = -22943.63, Epsilon = 0.736, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 441: Reward = -1000.00, Avg Reward (100) = -22215.94, Epsilon = 0.735, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 442: Reward = -1049.00, Avg Reward (100) = -22215.45, Epsilon = 0.735, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 443: Reward = -91679.84, Avg Reward (100) = -22215.45, Epsilon = 0.734, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -91679.84, Border Penalty: -30575.96, Obstacle Penalty: -50.00
Episode 444: Reward = -5734.23, Avg Reward (100) = -23121.76, Epsilon = 0.734, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -5734.23, Border Penalty: -14612.55, Obstacle Penalty: -50.00
Episode 445: Reward = -26357.89, Avg Reward (100) = -23176.82, Epsilon = 0.733, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 34, Reward Breakdown -> Delta_x Reward: -26357.89, Border Penalty: -31311.39, Obstacle Penalty: -50.00
Episode 446: Reward = -69532.27, Avg Reward (100) = -23006.52, Epsilon = 0.732, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -69532.27, Border Penalty: -33651.90, Obstacle Penalty: -50.00
Episode 447: Reward = -1098.00, Avg Reward (100) = -23698.48, Epsilon = 0.732, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 448: Reward = -782.25, Avg Reward (100) = -23698.97, Epsilon = 0.731, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -782.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 449: Reward = -1027.25, Avg Reward (100) = -23696.79, Epsilon = 0.731, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -1027.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 450: Reward = -682.25, Avg Reward (100) = -23696.08, Epsilon = 0.730, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -682.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 451: Reward = -43801.09, Avg Reward (100) = -23691.92, Epsilon = 0.729, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43801.09, Border Penalty: -38519.27, Obstacle Penalty: -50.00
Episode 452: Reward = -36031.12, Avg Reward (100) = -23588.60, Epsilon = 0.729, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -36031.12, Border Penalty: -35475.46, Obstacle Penalty: -50.00
Episode 453: Reward = -1049.00, Avg Reward (100) = -23938.91, Epsilon = 0.728, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 454: Reward = -1196.00, Avg Reward (100) = -23939.40, Epsilon = 0.728, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 455: Reward = -42617.51, Avg Reward (100) = -23941.36, Epsilon = 0.727, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -42617.51, Border Penalty: -35657.47, Obstacle Penalty: -50.00
Episode 456: Reward = -34142.68, Avg Reward (100) = -24355.57, Epsilon = 0.726, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -34142.68, Border Penalty: -34524.80, Obstacle Penalty: -50.00
Episode 457: Reward = -39685.66, Avg Reward (100) = -24102.74, Epsilon = 0.726, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -39685.66, Border Penalty: -30403.21, Obstacle Penalty: -50.00
Episode 458: Reward = -27446.61, Avg Reward (100) = -24489.11, Epsilon = 0.725, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 39, Reward Breakdown -> Delta_x Reward: -27446.61, Border Penalty: -33530.52, Obstacle Penalty: -50.00
Episode 459: Reward = -1049.00, Avg Reward (100) = -24152.23, Epsilon = 0.725, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 460: Reward = -40713.00, Avg Reward (100) = -22829.15, Epsilon = 0.724, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -40713.00, Border Penalty: -34491.79, Obstacle Penalty: -50.00
Episode 461: Reward = -56058.36, Avg Reward (100) = -22866.21, Epsilon = 0.723, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -56058.36, Border Penalty: -36682.14, Obstacle Penalty: -50.00
Episode 462: Reward = -49434.18, Avg Reward (100) = -23416.80, Epsilon = 0.723, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -49434.18, Border Penalty: -35149.95, Obstacle Penalty: -50.00
Episode 463: Reward = -21179.69, Avg Reward (100) = -23900.16, Epsilon = 0.722, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -21179.69, Border Penalty: -23359.86, Obstacle Penalty: -50.00
Episode 464: Reward = -1000.00, Avg Reward (100) = -24101.46, Epsilon = 0.722, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 465: Reward = 267.17, Avg Reward (100) = -24101.46, Epsilon = 0.721, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: 267.17, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 466: Reward = -34826.82, Avg Reward (100) = -24087.81, Epsilon = 0.720, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -34826.82, Border Penalty: -33630.98, Obstacle Penalty: -50.00
Episode 467: Reward = -1000.00, Avg Reward (100) = -24446.58, Epsilon = 0.720, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 468: Reward = -680.25, Avg Reward (100) = -23837.74, Epsilon = 0.719, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -680.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 469: Reward = -1049.00, Avg Reward (100) = -23834.54, Epsilon = 0.719, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 470: Reward = -50062.20, Avg Reward (100) = -23424.54, Epsilon = 0.718, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -50062.20, Border Penalty: -33384.73, Obstacle Penalty: -50.00
Episode 471: Reward = -1000.00, Avg Reward (100) = -23914.19, Epsilon = 0.717, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 472: Reward = -1000.00, Avg Reward (100) = -23913.70, Epsilon = 0.717, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 473: Reward = -34745.03, Avg Reward (100) = -23911.25, Epsilon = 0.716, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34745.03, Border Penalty: -30071.37, Obstacle Penalty: -50.00
Episode 474: Reward = -931.25, Avg Reward (100) = -23690.19, Epsilon = 0.716, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -931.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 475: Reward = -269.19, Avg Reward (100) = -23226.38, Epsilon = 0.715, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -269.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 476: Reward = -1000.00, Avg Reward (100) = -23218.58, Epsilon = 0.714, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 477: Reward = -1049.00, Avg Reward (100) = -23217.11, Epsilon = 0.714, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 478: Reward = -5.65, Avg Reward (100) = -23221.34, Epsilon = 0.713, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -5.65, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 479: Reward = -1049.00, Avg Reward (100) = -23211.40, Epsilon = 0.713, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 480: Reward = -1049.00, Avg Reward (100) = -23210.91, Epsilon = 0.712, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 481: Reward = -784.25, Avg Reward (100) = -23210.42, Epsilon = 0.711, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 482: Reward = -33275.32, Avg Reward (100) = -23208.26, Epsilon = 0.711, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 35, Reward Breakdown -> Delta_x Reward: -33275.32, Border Penalty: -37793.60, Obstacle Penalty: -50.00
Episode 483: Reward = -54397.07, Avg Reward (100) = -23531.01, Epsilon = 0.710, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -54397.07, Border Penalty: -36436.46, Obstacle Penalty: -50.00
Episode 484: Reward = -4740.36, Avg Reward (100) = -24064.98, Epsilon = 0.710, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -4740.36, Border Penalty: -13120.87, Obstacle Penalty: -50.00
Episode 485: Reward = -1049.00, Avg Reward (100) = -23642.16, Epsilon = 0.709, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 486: Reward = -54216.90, Avg Reward (100) = -23642.65, Epsilon = 0.708, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -54216.90, Border Penalty: -40372.41, Obstacle Penalty: -50.00
Episode 487: Reward = -1049.00, Avg Reward (100) = -23402.90, Epsilon = 0.708, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 488: Reward = -1098.00, Avg Reward (100) = -23403.39, Epsilon = 0.707, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 489: Reward = -32455.23, Avg Reward (100) = -22904.69, Epsilon = 0.707, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -32455.23, Border Penalty: -34159.55, Obstacle Penalty: -50.00
Episode 490: Reward = -21687.10, Avg Reward (100) = -23218.75, Epsilon = 0.706, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 25, Reward Breakdown -> Delta_x Reward: -21687.10, Border Penalty: -30295.75, Obstacle Penalty: -50.00
Episode 491: Reward = 454.88, Avg Reward (100) = -22698.51, Epsilon = 0.705, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: 454.88, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 492: Reward = -332.28, Avg Reward (100) = -22681.51, Epsilon = 0.705, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -332.28, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 493: Reward = -1196.00, Avg Reward (100) = -22235.48, Epsilon = 0.704, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 494: Reward = -1098.00, Avg Reward (100) = -22237.44, Epsilon = 0.704, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 495: Reward = -1000.00, Avg Reward (100) = -22238.42, Epsilon = 0.703, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 496: Reward = -40975.04, Avg Reward (100) = -22236.46, Epsilon = 0.702, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40975.04, Border Penalty: -30271.05, Obstacle Penalty: -50.00
Episode 497: Reward = -66594.74, Avg Reward (100) = -22238.26, Epsilon = 0.702, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -66594.74, Border Penalty: -35836.91, Obstacle Penalty: -50.00
Episode 498: Reward = -1147.00, Avg Reward (100) = -22278.38, Epsilon = 0.701, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 499: Reward = 50.35, Avg Reward (100) = -22278.87, Epsilon = 0.701, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: 50.35, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 500: Reward = -44957.39, Avg Reward (100) = -22271.04, Epsilon = 0.700, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44957.39, Border Penalty: -35853.92, Obstacle Penalty: -50.00
Episode 501: Reward = -24818.46, Avg Reward (100) = -21557.09, Epsilon = 0.699, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -24818.46, Border Penalty: -30839.74, Obstacle Penalty: -50.00
Episode 502: Reward = -1098.00, Avg Reward (100) = -21414.15, Epsilon = 0.699, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 503: Reward = -83752.34, Avg Reward (100) = -21414.64, Epsilon = 0.698, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -83752.34, Border Penalty: -30059.04, Obstacle Penalty: -50.00
Episode 504: Reward = -50707.57, Avg Reward (100) = -22241.19, Epsilon = 0.698, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -50707.57, Border Penalty: -31899.85, Obstacle Penalty: -50.00
Episode 505: Reward = -682.25, Avg Reward (100) = -22738.26, Epsilon = 0.697, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -682.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 506: Reward = -1098.00, Avg Reward (100) = -21910.52, Epsilon = 0.696, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 507: Reward = -1098.00, Avg Reward (100) = -21911.01, Epsilon = 0.696, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 508: Reward = -1049.00, Avg Reward (100) = -21506.20, Epsilon = 0.695, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 509: Reward = -1000.00, Avg Reward (100) = -21506.69, Epsilon = 0.695, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 510: Reward = -1196.00, Avg Reward (100) = -21157.95, Epsilon = 0.694, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 511: Reward = -1098.00, Avg Reward (100) = -19861.21, Epsilon = 0.693, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 512: Reward = -55276.69, Avg Reward (100) = -19555.15, Epsilon = 0.693, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -55276.69, Border Penalty: -35367.15, Obstacle Penalty: -50.00
Episode 513: Reward = -1147.00, Avg Reward (100) = -20096.44, Epsilon = 0.692, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 514: Reward = -628.19, Avg Reward (100) = -20097.42, Epsilon = 0.692, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -628.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 515: Reward = -18698.59, Avg Reward (100) = -18568.21, Epsilon = 0.691, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: -18698.59, Border Penalty: -34066.41, Obstacle Penalty: -50.00
Episode 516: Reward = -32459.17, Avg Reward (100) = -18743.24, Epsilon = 0.690, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 26, Reward Breakdown -> Delta_x Reward: -32459.17, Border Penalty: -34659.31, Obstacle Penalty: -50.00
Episode 517: Reward = -1147.00, Avg Reward (100) = -19056.85, Epsilon = 0.690, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 518: Reward = -30750.01, Avg Reward (100) = -19058.32, Epsilon = 0.689, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -30750.01, Border Penalty: -31757.94, Obstacle Penalty: -50.00
Episode 519: Reward = -1000.00, Avg Reward (100) = -18364.69, Epsilon = 0.689, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 520: Reward = -431.28, Avg Reward (100) = -18034.09, Epsilon = 0.688, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -431.28, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 521: Reward = -1098.00, Avg Reward (100) = -18034.56, Epsilon = 0.687, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 522: Reward = -1049.00, Avg Reward (100) = -18038.21, Epsilon = 0.687, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 523: Reward = -103595.67, Avg Reward (100) = -18040.37, Epsilon = 0.686, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -103595.67, Border Penalty: -35502.54, Obstacle Penalty: -50.00
Episode 524: Reward = -1049.00, Avg Reward (100) = -19068.52, Epsilon = 0.686, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 525: Reward = -1000.00, Avg Reward (100) = -18476.89, Epsilon = 0.685, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 526: Reward = -1000.00, Avg Reward (100) = -18103.98, Epsilon = 0.684, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 527: Reward = -1098.00, Avg Reward (100) = -18103.49, Epsilon = 0.684, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 528: Reward = 1059.78, Avg Reward (100) = -17533.39, Epsilon = 0.683, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: 1059.78, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 529: Reward = 596.42, Avg Reward (100) = -17510.83, Epsilon = 0.683, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: 596.42, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 530: Reward = -54698.68, Avg Reward (100) = -17494.87, Epsilon = 0.682, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54698.68, Border Penalty: -31775.94, Obstacle Penalty: -50.00
Episode 531: Reward = -1000.00, Avg Reward (100) = -18031.86, Epsilon = 0.681, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 532: Reward = -1049.00, Avg Reward (100) = -18031.37, Epsilon = 0.681, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 533: Reward = -1147.00, Avg Reward (100) = -16703.37, Epsilon = 0.680, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 534: Reward = 155.68, Avg Reward (100) = -16704.84, Epsilon = 0.680, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: 155.68, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 535: Reward = -52088.25, Avg Reward (100) = -16059.99, Epsilon = 0.679, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52088.25, Border Penalty: -31777.53, Obstacle Penalty: -50.00
Episode 536: Reward = -65062.41, Avg Reward (100) = -16574.05, Epsilon = 0.678, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -65062.41, Border Penalty: -37051.19, Obstacle Penalty: -50.00
Episode 537: Reward = -40510.27, Avg Reward (100) = -16818.47, Epsilon = 0.678, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40510.27, Border Penalty: -33999.73, Obstacle Penalty: -50.00
Episode 538: Reward = -56850.63, Avg Reward (100) = -17213.09, Epsilon = 0.677, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -56850.63, Border Penalty: -35887.88, Obstacle Penalty: -50.00
Episode 539: Reward = -1000.00, Avg Reward (100) = -17770.12, Epsilon = 0.677, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 540: Reward = -56435.48, Avg Reward (100) = -17769.63, Epsilon = 0.676, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -56435.48, Border Penalty: -36380.63, Obstacle Penalty: -50.00
Episode 541: Reward = -36911.26, Avg Reward (100) = -18323.99, Epsilon = 0.675, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36911.26, Border Penalty: -34897.87, Obstacle Penalty: -50.00
Episode 542: Reward = -1049.00, Avg Reward (100) = -18683.10, Epsilon = 0.675, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 543: Reward = -172287.78, Avg Reward (100) = -18683.10, Epsilon = 0.674, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -172287.78, Border Penalty: -31502.04, Obstacle Penalty: -50.00
Episode 544: Reward = -30092.93, Avg Reward (100) = -19489.18, Epsilon = 0.674, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30092.93, Border Penalty: -31776.74, Obstacle Penalty: -50.00
Episode 545: Reward = -1049.00, Avg Reward (100) = -19732.77, Epsilon = 0.673, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 546: Reward = -1000.00, Avg Reward (100) = -19479.68, Epsilon = 0.672, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 547: Reward = -65344.81, Avg Reward (100) = -18794.35, Epsilon = 0.672, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -65344.81, Border Penalty: -37361.66, Obstacle Penalty: -50.00
Episode 548: Reward = -31955.86, Avg Reward (100) = -19436.82, Epsilon = 0.671, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -31955.86, Border Penalty: -33817.21, Obstacle Penalty: -50.00
Episode 549: Reward = -42380.70, Avg Reward (100) = -19748.56, Epsilon = 0.671, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -42380.70, Border Penalty: -34783.76, Obstacle Penalty: -50.00
Episode 550: Reward = -59329.74, Avg Reward (100) = -20162.09, Epsilon = 0.670, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -59329.74, Border Penalty: -36038.27, Obstacle Penalty: -50.00
Episode 551: Reward = -1098.00, Avg Reward (100) = -20748.57, Epsilon = 0.669, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 552: Reward = -1147.00, Avg Reward (100) = -20321.54, Epsilon = 0.669, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 553: Reward = -1049.00, Avg Reward (100) = -19972.70, Epsilon = 0.668, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 554: Reward = -1000.00, Avg Reward (100) = -19972.70, Epsilon = 0.668, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 555: Reward = -1000.00, Avg Reward (100) = -19970.74, Epsilon = 0.667, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 556: Reward = -210180.31, Avg Reward (100) = -19554.56, Epsilon = 0.666, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 26, Reward Breakdown -> Delta_x Reward: -210180.31, Border Penalty: -34249.24, Obstacle Penalty: -50.00
Episode 557: Reward = -86339.00, Avg Reward (100) = -21314.94, Epsilon = 0.666, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -86339.00, Border Penalty: -34809.72, Obstacle Penalty: -50.00
Episode 558: Reward = -35468.23, Avg Reward (100) = -21781.47, Epsilon = 0.665, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35468.23, Border Penalty: -35365.46, Obstacle Penalty: -50.00
Episode 559: Reward = -682.25, Avg Reward (100) = -21861.69, Epsilon = 0.665, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -682.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 560: Reward = -1049.00, Avg Reward (100) = -21858.02, Epsilon = 0.664, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 561: Reward = -38036.91, Avg Reward (100) = -21461.38, Epsilon = 0.663, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -38036.91, Border Penalty: -32239.33, Obstacle Penalty: -50.00
Episode 562: Reward = -37671.46, Avg Reward (100) = -21281.16, Epsilon = 0.663, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -37671.46, Border Penalty: -32688.89, Obstacle Penalty: -50.00
Episode 563: Reward = -1098.00, Avg Reward (100) = -21163.54, Epsilon = 0.662, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 564: Reward = -50155.14, Avg Reward (100) = -20962.72, Epsilon = 0.662, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50155.14, Border Penalty: -30950.66, Obstacle Penalty: -50.00
Episode 565: Reward = -54857.61, Avg Reward (100) = -21454.27, Epsilon = 0.661, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -54857.61, Border Penalty: -32224.42, Obstacle Penalty: -50.00
Episode 566: Reward = -52002.38, Avg Reward (100) = -22005.52, Epsilon = 0.660, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -52002.38, Border Penalty: -31358.43, Obstacle Penalty: -50.00
Episode 567: Reward = -43675.56, Avg Reward (100) = -22177.27, Epsilon = 0.660, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -43675.56, Border Penalty: -30445.13, Obstacle Penalty: -50.00
Episode 568: Reward = -31203.56, Avg Reward (100) = -22604.03, Epsilon = 0.659, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -31203.56, Border Penalty: -31711.81, Obstacle Penalty: -50.00
Episode 569: Reward = -81990.18, Avg Reward (100) = -22909.26, Epsilon = 0.659, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -81990.18, Border Penalty: -33187.99, Obstacle Penalty: -50.00
Episode 570: Reward = -5140.18, Avg Reward (100) = -23718.68, Epsilon = 0.658, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -5140.18, Border Penalty: -11162.13, Obstacle Penalty: -50.00
Episode 571: Reward = -57069.01, Avg Reward (100) = -23269.46, Epsilon = 0.657, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -57069.01, Border Penalty: -26972.20, Obstacle Penalty: -50.00
Episode 572: Reward = -1049.00, Avg Reward (100) = -23830.15, Epsilon = 0.657, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 573: Reward = -1490.00, Avg Reward (100) = -23830.64, Epsilon = 0.656, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -1490.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 574: Reward = -1049.00, Avg Reward (100) = -23498.08, Epsilon = 0.656, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 575: Reward = -1000.00, Avg Reward (100) = -23499.26, Epsilon = 0.655, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 576: Reward = -37669.33, Avg Reward (100) = -23506.57, Epsilon = 0.654, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 577: Reward = -1000.00, Avg Reward (100) = -23873.26, Epsilon = 0.654, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 578: Reward = -1000.00, Avg Reward (100) = -23872.77, Epsilon = 0.653, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 579: Reward = -1098.00, Avg Reward (100) = -23882.72, Epsilon = 0.653, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 580: Reward = -1049.00, Avg Reward (100) = -23883.21, Epsilon = 0.652, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 581: Reward = -48602.26, Avg Reward (100) = -23883.21, Epsilon = 0.651, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -48602.26, Border Penalty: -34258.24, Obstacle Penalty: -50.00
Episode 582: Reward = -50974.41, Avg Reward (100) = -24361.39, Epsilon = 0.651, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -50974.41, Border Penalty: -39326.55, Obstacle Penalty: -50.00
Episode 583: Reward = -116.26, Avg Reward (100) = -24538.38, Epsilon = 0.650, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -116.26, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 584: Reward = -1049.00, Avg Reward (100) = -23995.57, Epsilon = 0.650, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 585: Reward = -30982.22, Avg Reward (100) = -23958.66, Epsilon = 0.649, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -30982.22, Border Penalty: -29253.89, Obstacle Penalty: -50.00
Episode 586: Reward = -1147.00, Avg Reward (100) = -24257.99, Epsilon = 0.648, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 587: Reward = -60748.25, Avg Reward (100) = -23727.29, Epsilon = 0.648, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -60748.25, Border Penalty: -36371.45, Obstacle Penalty: -50.00
Episode 588: Reward = -35499.61, Avg Reward (100) = -24324.28, Epsilon = 0.647, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 589: Reward = -30056.79, Avg Reward (100) = -24668.30, Epsilon = 0.647, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -32422.54, Obstacle Penalty: -50.00
Episode 590: Reward = -1000.00, Avg Reward (100) = -24644.31, Epsilon = 0.646, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 591: Reward = -1049.00, Avg Reward (100) = -24437.44, Epsilon = 0.645, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 592: Reward = -1049.00, Avg Reward (100) = -24452.48, Epsilon = 0.645, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 593: Reward = -40950.19, Avg Reward (100) = -24459.65, Epsilon = 0.644, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -40950.19, Border Penalty: -32398.04, Obstacle Penalty: -50.00
Episode 594: Reward = -1000.00, Avg Reward (100) = -24857.19, Epsilon = 0.644, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 595: Reward = -1196.00, Avg Reward (100) = -24856.21, Epsilon = 0.643, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 596: Reward = -1294.00, Avg Reward (100) = -24858.17, Epsilon = 0.642, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 597: Reward = -6495.37, Avg Reward (100) = -24461.36, Epsilon = 0.642, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -6495.37, Border Penalty: -17334.33, Obstacle Penalty: -50.00
Episode 598: Reward = -46184.86, Avg Reward (100) = -23860.37, Epsilon = 0.641, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -46184.86, Border Penalty: -32423.37, Obstacle Penalty: -50.00
Episode 599: Reward = -36522.78, Avg Reward (100) = -24310.75, Epsilon = 0.641, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36522.78, Border Penalty: -30698.05, Obstacle Penalty: -50.00
Episode 600: Reward = -71489.60, Avg Reward (100) = -24676.48, Epsilon = 0.640, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -71489.60, Border Penalty: -35632.51, Obstacle Penalty: -50.00
Episode 601: Reward = 571.66, Avg Reward (100) = -24941.80, Epsilon = 0.639, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: 571.66, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 602: Reward = -1098.00, Avg Reward (100) = -24687.90, Epsilon = 0.639, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 603: Reward = -20619.50, Avg Reward (100) = -24687.90, Epsilon = 0.638, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -20619.50, Border Penalty: -25851.06, Obstacle Penalty: -50.00
Episode 604: Reward = -41573.02, Avg Reward (100) = -24056.57, Epsilon = 0.638, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41573.02, Border Penalty: -36084.49, Obstacle Penalty: -50.00
Episode 605: Reward = -1245.00, Avg Reward (100) = -23965.22, Epsilon = 0.637, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 606: Reward = -1049.00, Avg Reward (100) = -23970.85, Epsilon = 0.636, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 607: Reward = -222.19, Avg Reward (100) = -23970.36, Epsilon = 0.636, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -222.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 608: Reward = -56559.37, Avg Reward (100) = -23961.60, Epsilon = 0.635, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -56559.37, Border Penalty: -36901.63, Obstacle Penalty: -50.00
Episode 609: Reward = -55662.45, Avg Reward (100) = -24516.71, Epsilon = 0.635, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -55662.45, Border Penalty: -41672.52, Obstacle Penalty: -50.00
Episode 610: Reward = -1098.00, Avg Reward (100) = -25063.33, Epsilon = 0.634, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 611: Reward = -47377.12, Avg Reward (100) = -25062.35, Epsilon = 0.633, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -47377.12, Border Penalty: -34574.34, Obstacle Penalty: -50.00
Episode 612: Reward = -47735.08, Avg Reward (100) = -25525.14, Epsilon = 0.633, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -47735.08, Border Penalty: -30305.43, Obstacle Penalty: -50.00
Episode 613: Reward = -1147.00, Avg Reward (100) = -25449.73, Epsilon = 0.632, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 614: Reward = -31726.27, Avg Reward (100) = -25449.73, Epsilon = 0.632, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -31726.27, Border Penalty: -31490.27, Obstacle Penalty: -50.00
Episode 615: Reward = -1098.00, Avg Reward (100) = -25760.71, Epsilon = 0.631, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 616: Reward = -37669.33, Avg Reward (100) = -25584.70, Epsilon = 0.630, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 617: Reward = -1147.00, Avg Reward (100) = -25636.80, Epsilon = 0.630, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 618: Reward = -30673.14, Avg Reward (100) = -25636.80, Epsilon = 0.629, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -30673.14, Border Penalty: -32696.54, Obstacle Penalty: -50.00
Episode 619: Reward = -42280.48, Avg Reward (100) = -25636.03, Epsilon = 0.629, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -42280.48, Border Penalty: -30093.01, Obstacle Penalty: -50.00
Episode 620: Reward = -1049.00, Avg Reward (100) = -26048.84, Epsilon = 0.628, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 621: Reward = -60527.98, Avg Reward (100) = -26055.02, Epsilon = 0.627, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -60527.98, Border Penalty: -36730.61, Obstacle Penalty: -50.00
Episode 622: Reward = -1344.00, Avg Reward (100) = -26649.32, Epsilon = 0.627, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 623: Reward = -1000.00, Avg Reward (100) = -26652.27, Epsilon = 0.626, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 624: Reward = -44747.43, Avg Reward (100) = -25626.31, Epsilon = 0.626, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -44747.43, Border Penalty: -32831.13, Obstacle Penalty: -50.00
Episode 625: Reward = -230.24, Avg Reward (100) = -26063.29, Epsilon = 0.625, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -230.24, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 626: Reward = -18867.09, Avg Reward (100) = -26055.60, Epsilon = 0.624, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -18867.09, Border Penalty: -24620.20, Obstacle Penalty: -50.00
Episode 627: Reward = -68976.83, Avg Reward (100) = -26234.27, Epsilon = 0.624, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -68976.83, Border Penalty: -38612.12, Obstacle Penalty: -50.00
Episode 628: Reward = -1098.00, Avg Reward (100) = -26913.05, Epsilon = 0.623, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 629: Reward = -1000.00, Avg Reward (100) = -26934.63, Epsilon = 0.623, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 630: Reward = -1147.00, Avg Reward (100) = -26950.60, Epsilon = 0.622, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 631: Reward = -1294.00, Avg Reward (100) = -26415.08, Epsilon = 0.621, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 632: Reward = -1049.00, Avg Reward (100) = -26418.02, Epsilon = 0.621, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 633: Reward = -74483.65, Avg Reward (100) = -26418.02, Epsilon = 0.620, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -74483.65, Border Penalty: -36966.51, Obstacle Penalty: -50.00
Episode 634: Reward = -44719.81, Avg Reward (100) = -27151.39, Epsilon = 0.620, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -44719.81, Border Penalty: -36770.85, Obstacle Penalty: -50.00
Episode 635: Reward = -1000.00, Avg Reward (100) = -27600.14, Epsilon = 0.619, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 636: Reward = -1049.00, Avg Reward (100) = -27089.26, Epsilon = 0.618, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 637: Reward = -383.28, Avg Reward (100) = -26449.12, Epsilon = 0.618, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -383.28, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 638: Reward = 4.05, Avg Reward (100) = -26047.85, Epsilon = 0.617, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: 4.05, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 639: Reward = -1049.00, Avg Reward (100) = -25479.31, Epsilon = 0.617, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 640: Reward = -1049.00, Avg Reward (100) = -25479.80, Epsilon = 0.616, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 641: Reward = -1098.00, Avg Reward (100) = -24925.93, Epsilon = 0.615, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 642: Reward = -1295.00, Avg Reward (100) = -24567.80, Epsilon = 0.615, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 643: Reward = -1000.00, Avg Reward (100) = -24570.26, Epsilon = 0.614, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 644: Reward = -1000.00, Avg Reward (100) = -22857.38, Epsilon = 0.614, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 645: Reward = -1098.00, Avg Reward (100) = -22566.45, Epsilon = 0.613, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 646: Reward = -37962.77, Avg Reward (100) = -22566.94, Epsilon = 0.612, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -37962.77, Border Penalty: -36133.76, Obstacle Penalty: -50.00
Episode 647: Reward = -31068.49, Avg Reward (100) = -22936.57, Epsilon = 0.612, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -31068.49, Border Penalty: -34601.27, Obstacle Penalty: -50.00
Episode 648: Reward = -1000.00, Avg Reward (100) = -22593.81, Epsilon = 0.611, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 649: Reward = -48277.38, Avg Reward (100) = -22284.25, Epsilon = 0.611, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -48277.38, Border Penalty: -35123.46, Obstacle Penalty: -50.00
Episode 650: Reward = -1147.00, Avg Reward (100) = -22343.22, Epsilon = 0.610, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 651: Reward = -1294.00, Avg Reward (100) = -21761.39, Epsilon = 0.609, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 652: Reward = -1000.00, Avg Reward (100) = -21763.35, Epsilon = 0.609, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 653: Reward = -1000.00, Avg Reward (100) = -21761.88, Epsilon = 0.608, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 654: Reward = -1394.00, Avg Reward (100) = -21761.39, Epsilon = 0.608, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 655: Reward = -1049.00, Avg Reward (100) = -21765.33, Epsilon = 0.607, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 656: Reward = -1000.00, Avg Reward (100) = -21765.82, Epsilon = 0.606, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 657: Reward = -52144.57, Avg Reward (100) = -19674.02, Epsilon = 0.606, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -52144.57, Border Penalty: -40157.86, Obstacle Penalty: -50.00
Episode 658: Reward = -48684.45, Avg Reward (100) = -19332.07, Epsilon = 0.605, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48684.45, Border Penalty: -39515.91, Obstacle Penalty: -50.00
Episode 659: Reward = -1147.00, Avg Reward (100) = -19464.23, Epsilon = 0.605, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 660: Reward = -1049.00, Avg Reward (100) = -19468.88, Epsilon = 0.604, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 661: Reward = -1196.00, Avg Reward (100) = -19468.88, Epsilon = 0.603, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 662: Reward = -1049.00, Avg Reward (100) = -19100.47, Epsilon = 0.603, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 663: Reward = -32619.61, Avg Reward (100) = -18734.25, Epsilon = 0.602, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 664: Reward = -61091.33, Avg Reward (100) = -19049.46, Epsilon = 0.602, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -61091.33, Border Penalty: -33365.57, Obstacle Penalty: -50.00
Episode 665: Reward = -37669.33, Avg Reward (100) = -19158.83, Epsilon = 0.601, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 666: Reward = -28683.61, Avg Reward (100) = -18986.94, Epsilon = 0.600, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 667: Reward = -54870.38, Avg Reward (100) = -18753.75, Epsilon = 0.600, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -54870.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 668: Reward = -43263.20, Avg Reward (100) = -18865.70, Epsilon = 0.599, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 669: Reward = -43007.38, Avg Reward (100) = -18986.30, Epsilon = 0.599, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -43007.38, Border Penalty: -32351.25, Obstacle Penalty: -50.00
Episode 670: Reward = -1098.00, Avg Reward (100) = -18596.47, Epsilon = 0.598, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 671: Reward = -76309.12, Avg Reward (100) = -18556.05, Epsilon = 0.597, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -76309.12, Border Penalty: -39182.51, Obstacle Penalty: -50.00
Episode 672: Reward = -1000.00, Avg Reward (100) = -18748.45, Epsilon = 0.597, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 673: Reward = -48098.98, Avg Reward (100) = -18747.96, Epsilon = 0.596, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -48098.98, Border Penalty: -34762.91, Obstacle Penalty: -50.00
Episode 674: Reward = -1098.00, Avg Reward (100) = -19214.05, Epsilon = 0.596, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 675: Reward = -1000.00, Avg Reward (100) = -19214.54, Epsilon = 0.595, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 676: Reward = -36658.32, Avg Reward (100) = -19214.54, Epsilon = 0.594, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36658.32, Border Penalty: -32919.01, Obstacle Penalty: -50.00
Episode 677: Reward = -1245.00, Avg Reward (100) = -19204.43, Epsilon = 0.594, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 678: Reward = -680.25, Avg Reward (100) = -19206.88, Epsilon = 0.593, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -680.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 679: Reward = -1049.00, Avg Reward (100) = -19203.68, Epsilon = 0.593, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 680: Reward = -16694.74, Avg Reward (100) = -19203.19, Epsilon = 0.592, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -16694.74, Border Penalty: -21114.39, Obstacle Penalty: -50.00
Episode 681: Reward = 587.14, Avg Reward (100) = -19359.65, Epsilon = 0.591, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: 587.14, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 682: Reward = -31155.13, Avg Reward (100) = -18867.76, Epsilon = 0.591, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -31155.13, Border Penalty: -31425.34, Obstacle Penalty: -50.00
Episode 683: Reward = 44.48, Avg Reward (100) = -18669.56, Epsilon = 0.590, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: 44.48, Border Penalty: -9875.08, Obstacle Penalty: -50.00
Episode 684: Reward = -1147.00, Avg Reward (100) = -18667.96, Epsilon = 0.590, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 685: Reward = -53426.59, Avg Reward (100) = -18668.94, Epsilon = 0.589, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -53426.59, Border Penalty: -32495.06, Obstacle Penalty: -50.00
Episode 686: Reward = -1049.00, Avg Reward (100) = -18893.38, Epsilon = 0.588, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 687: Reward = -41624.27, Avg Reward (100) = -18892.40, Epsilon = 0.588, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 31, Reward Breakdown -> Delta_x Reward: -41624.27, Border Penalty: -36417.91, Obstacle Penalty: -50.00
Episode 688: Reward = -1098.00, Avg Reward (100) = -18701.16, Epsilon = 0.587, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 689: Reward = -628.19, Avg Reward (100) = -18357.14, Epsilon = 0.587, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -628.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 690: Reward = -40826.57, Avg Reward (100) = -18062.86, Epsilon = 0.586, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40826.57, Border Penalty: -32612.07, Obstacle Penalty: -50.00
Episode 691: Reward = -42817.56, Avg Reward (100) = -18461.12, Epsilon = 0.585, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42817.56, Border Penalty: -32173.76, Obstacle Penalty: -50.00
Episode 692: Reward = -733.25, Avg Reward (100) = -18878.81, Epsilon = 0.585, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 693: Reward = -44979.98, Avg Reward (100) = -18875.65, Epsilon = 0.584, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -44979.98, Border Penalty: -31415.97, Obstacle Penalty: -50.00
Episode 694: Reward = -51253.04, Avg Reward (100) = -18915.95, Epsilon = 0.584, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51253.04, Border Penalty: -39502.41, Obstacle Penalty: -50.00
Episode 695: Reward = -784.25, Avg Reward (100) = -19418.48, Epsilon = 0.583, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 696: Reward = -26943.44, Avg Reward (100) = -19414.36, Epsilon = 0.582, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26943.44, Border Penalty: -31417.73, Obstacle Penalty: -50.00
Episode 697: Reward = -1147.00, Avg Reward (100) = -19670.86, Epsilon = 0.582, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 698: Reward = -1049.00, Avg Reward (100) = -19617.37, Epsilon = 0.581, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 699: Reward = -1049.00, Avg Reward (100) = -19166.01, Epsilon = 0.581, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 700: Reward = -1049.00, Avg Reward (100) = -18811.28, Epsilon = 0.580, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 701: Reward = -1196.00, Avg Reward (100) = -18106.87, Epsilon = 0.579, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 702: Reward = -16533.81, Avg Reward (100) = -18124.55, Epsilon = 0.579, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -16533.81, Border Penalty: -20546.64, Obstacle Penalty: -50.00
Episode 703: Reward = -37665.72, Avg Reward (100) = -18278.91, Epsilon = 0.578, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -37665.72, Border Penalty: -32795.39, Obstacle Penalty: -50.00
Episode 704: Reward = -49680.39, Avg Reward (100) = -18449.37, Epsilon = 0.578, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -49680.39, Border Penalty: -38220.59, Obstacle Penalty: -50.00
Episode 705: Reward = -1000.00, Avg Reward (100) = -18530.44, Epsilon = 0.577, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 706: Reward = -1000.00, Avg Reward (100) = -18527.99, Epsilon = 0.576, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 707: Reward = -36406.37, Avg Reward (100) = -18527.50, Epsilon = 0.576, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -36406.37, Border Penalty: -33361.45, Obstacle Penalty: -50.00
Episode 708: Reward = -73963.90, Avg Reward (100) = -18889.34, Epsilon = 0.575, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -73963.90, Border Penalty: -33878.92, Obstacle Penalty: -50.00
Episode 709: Reward = -1098.00, Avg Reward (100) = -19063.39, Epsilon = 0.575, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 710: Reward = -44837.08, Avg Reward (100) = -18517.74, Epsilon = 0.574, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -44837.08, Border Penalty: -38943.91, Obstacle Penalty: -50.00
Episode 711: Reward = -1049.00, Avg Reward (100) = -18955.13, Epsilon = 0.573, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 712: Reward = -708.84, Avg Reward (100) = -18491.85, Epsilon = 0.573, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -708.84, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 713: Reward = -51832.05, Avg Reward (100) = -18021.59, Epsilon = 0.572, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51832.05, Border Penalty: -37257.60, Obstacle Penalty: -50.00
Episode 714: Reward = -1000.00, Avg Reward (100) = -18528.44, Epsilon = 0.572, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 715: Reward = -59018.25, Avg Reward (100) = -18221.18, Epsilon = 0.571, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -59018.25, Border Penalty: -40778.31, Obstacle Penalty: -50.00
Episode 716: Reward = -29987.54, Avg Reward (100) = -18800.38, Epsilon = 0.570, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -29987.54, Border Penalty: -31412.07, Obstacle Penalty: -50.00
Episode 717: Reward = -35499.61, Avg Reward (100) = -18723.56, Epsilon = 0.570, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 718: Reward = -1492.00, Avg Reward (100) = -19067.09, Epsilon = 0.569, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -3180.03, Obstacle Penalty: -50.00
Episode 719: Reward = -1049.00, Avg Reward (100) = -18775.28, Epsilon = 0.569, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 720: Reward = -53277.96, Avg Reward (100) = -18362.96, Epsilon = 0.568, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -53277.96, Border Penalty: -40365.50, Obstacle Penalty: -50.00
Episode 721: Reward = -1049.00, Avg Reward (100) = -18885.25, Epsilon = 0.567, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 722: Reward = -1049.00, Avg Reward (100) = -18290.46, Epsilon = 0.567, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 723: Reward = -1098.00, Avg Reward (100) = -18287.51, Epsilon = 0.566, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 724: Reward = -49000.08, Avg Reward (100) = -18288.49, Epsilon = 0.566, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -49000.08, Border Penalty: -33404.81, Obstacle Penalty: -50.00
Episode 725: Reward = -41107.62, Avg Reward (100) = -18331.02, Epsilon = 0.565, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41107.62, Border Penalty: -33104.76, Obstacle Penalty: -50.00
Episode 726: Reward = -1049.00, Avg Reward (100) = -18739.79, Epsilon = 0.564, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 727: Reward = -45161.16, Avg Reward (100) = -18561.61, Epsilon = 0.564, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45161.16, Border Penalty: -32869.74, Obstacle Penalty: -50.00
Episode 728: Reward = -1000.00, Avg Reward (100) = -18323.46, Epsilon = 0.563, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 729: Reward = -1049.00, Avg Reward (100) = -18322.48, Epsilon = 0.563, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 730: Reward = -35499.61, Avg Reward (100) = -18322.97, Epsilon = 0.562, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 731: Reward = -59248.43, Avg Reward (100) = -18666.49, Epsilon = 0.561, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -59248.43, Border Penalty: -31357.33, Obstacle Penalty: -50.00
Episode 732: Reward = -31630.82, Avg Reward (100) = -19246.04, Epsilon = 0.561, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -31630.82, Border Penalty: -30174.45, Obstacle Penalty: -50.00
Episode 733: Reward = -28653.56, Avg Reward (100) = -19551.85, Epsilon = 0.560, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 734: Reward = -1000.00, Avg Reward (100) = -19093.55, Epsilon = 0.560, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 735: Reward = -1049.00, Avg Reward (100) = -18656.36, Epsilon = 0.559, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 736: Reward = -1098.00, Avg Reward (100) = -18656.85, Epsilon = 0.558, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 737: Reward = -1049.00, Avg Reward (100) = -18657.34, Epsilon = 0.558, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 738: Reward = -733.25, Avg Reward (100) = -18663.99, Epsilon = 0.557, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 739: Reward = -731.25, Avg Reward (100) = -18671.37, Epsilon = 0.557, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -731.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 740: Reward = -203.49, Avg Reward (100) = -18668.19, Epsilon = 0.556, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -203.49, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 741: Reward = -1245.00, Avg Reward (100) = -18659.73, Epsilon = 0.555, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 742: Reward = -882.25, Avg Reward (100) = -18661.20, Epsilon = 0.555, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -882.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 743: Reward = -1147.00, Avg Reward (100) = -18657.08, Epsilon = 0.554, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 744: Reward = -26242.97, Avg Reward (100) = -18658.55, Epsilon = 0.554, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26242.97, Border Penalty: -30144.94, Obstacle Penalty: -50.00
Episode 745: Reward = -1049.00, Avg Reward (100) = -18910.98, Epsilon = 0.553, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 746: Reward = -1000.00, Avg Reward (100) = -18910.49, Epsilon = 0.552, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 747: Reward = -1000.00, Avg Reward (100) = -18540.86, Epsilon = 0.552, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 748: Reward = -148.01, Avg Reward (100) = -18240.17, Epsilon = 0.551, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -148.01, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 749: Reward = -1196.00, Avg Reward (100) = -18231.65, Epsilon = 0.551, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 750: Reward = -1049.00, Avg Reward (100) = -17760.84, Epsilon = 0.550, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 751: Reward = -1049.00, Avg Reward (100) = -17759.86, Epsilon = 0.549, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 752: Reward = -39216.62, Avg Reward (100) = -17757.41, Epsilon = 0.549, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39216.62, Border Penalty: -36024.72, Obstacle Penalty: -50.00
Episode 753: Reward = -1049.00, Avg Reward (100) = -18139.58, Epsilon = 0.548, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 754: Reward = -1252.40, Avg Reward (100) = -18140.07, Epsilon = 0.548, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 755: Reward = -1196.00, Avg Reward (100) = -18138.65, Epsilon = 0.547, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 756: Reward = -57503.40, Avg Reward (100) = -18140.12, Epsilon = 0.546, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -57503.40, Border Penalty: -37520.93, Obstacle Penalty: -50.00
Episode 757: Reward = -43902.06, Avg Reward (100) = -18705.15, Epsilon = 0.546, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 758: Reward = -1196.00, Avg Reward (100) = -18622.73, Epsilon = 0.545, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 759: Reward = -67794.47, Avg Reward (100) = -18147.84, Epsilon = 0.545, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -67794.47, Border Penalty: -30517.72, Obstacle Penalty: -50.00
Episode 760: Reward = -51729.55, Avg Reward (100) = -18814.32, Epsilon = 0.544, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -51729.55, Border Penalty: -41124.36, Obstacle Penalty: -50.00
Episode 761: Reward = -1098.00, Avg Reward (100) = -19321.12, Epsilon = 0.543, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 762: Reward = -55035.57, Avg Reward (100) = -19320.14, Epsilon = 0.543, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -55035.57, Border Penalty: -40246.50, Obstacle Penalty: -50.00
Episode 763: Reward = -48044.60, Avg Reward (100) = -19860.01, Epsilon = 0.542, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 764: Reward = -24832.48, Avg Reward (100) = -20014.26, Epsilon = 0.542, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -24832.48, Border Penalty: -30321.71, Obstacle Penalty: -50.00
Episode 765: Reward = -52497.49, Avg Reward (100) = -19651.67, Epsilon = 0.541, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -52497.49, Border Penalty: -31047.23, Obstacle Penalty: -50.00
Episode 766: Reward = -1098.00, Avg Reward (100) = -19799.95, Epsilon = 0.540, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 767: Reward = -1098.00, Avg Reward (100) = -19524.10, Epsilon = 0.540, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 768: Reward = -34651.70, Avg Reward (100) = -18986.37, Epsilon = 0.539, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -34651.70, Border Penalty: -31646.31, Obstacle Penalty: -50.00
Episode 769: Reward = -1049.00, Avg Reward (100) = -18900.26, Epsilon = 0.539, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 770: Reward = -36329.69, Avg Reward (100) = -18480.67, Epsilon = 0.538, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36329.69, Border Penalty: -30392.69, Obstacle Penalty: -50.00
Episode 771: Reward = -53615.70, Avg Reward (100) = -18832.99, Epsilon = 0.537, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -38356.81, Obstacle Penalty: -50.00
Episode 772: Reward = -1049.00, Avg Reward (100) = -18606.06, Epsilon = 0.537, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 773: Reward = -1196.00, Avg Reward (100) = -18606.55, Epsilon = 0.536, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 774: Reward = -1049.00, Avg Reward (100) = -18137.52, Epsilon = 0.536, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 775: Reward = -97660.78, Avg Reward (100) = -18137.03, Epsilon = 0.535, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 23, Reward Breakdown -> Delta_x Reward: -97660.78, Border Penalty: -30008.67, Obstacle Penalty: -50.00
Episode 776: Reward = -48812.51, Avg Reward (100) = -19103.63, Epsilon = 0.534, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48812.51, Border Penalty: -38257.83, Obstacle Penalty: -50.00
Episode 777: Reward = -1000.00, Avg Reward (100) = -19225.18, Epsilon = 0.534, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 778: Reward = -1147.00, Avg Reward (100) = -19222.73, Epsilon = 0.533, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 779: Reward = -1000.00, Avg Reward (100) = -19227.39, Epsilon = 0.533, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 780: Reward = -1000.00, Avg Reward (100) = -19226.90, Epsilon = 0.532, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 781: Reward = -42320.55, Avg Reward (100) = -19069.96, Epsilon = 0.531, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -42320.55, Border Penalty: -34616.71, Obstacle Penalty: -50.00
Episode 782: Reward = -37991.07, Avg Reward (100) = -19499.03, Epsilon = 0.531, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37991.07, Border Penalty: -34420.79, Obstacle Penalty: -50.00
Episode 783: Reward = -1000.00, Avg Reward (100) = -19567.39, Epsilon = 0.530, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 784: Reward = -32051.60, Avg Reward (100) = -19577.84, Epsilon = 0.530, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -32051.60, Border Penalty: -30530.33, Obstacle Penalty: -50.00
Episode 785: Reward = -45624.08, Avg Reward (100) = -19886.88, Epsilon = 0.529, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45624.08, Border Penalty: -32328.75, Obstacle Penalty: -50.00
Episode 786: Reward = -1049.00, Avg Reward (100) = -19808.86, Epsilon = 0.528, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 787: Reward = -41882.16, Avg Reward (100) = -19808.86, Epsilon = 0.528, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -41882.16, Border Penalty: -33326.77, Obstacle Penalty: -50.00
Episode 788: Reward = -72991.55, Avg Reward (100) = -19811.44, Epsilon = 0.527, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -72991.55, Border Penalty: -36253.64, Obstacle Penalty: -50.00
Episode 789: Reward = -1450.40, Avg Reward (100) = -20530.37, Epsilon = 0.527, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 790: Reward = -1098.00, Avg Reward (100) = -20538.59, Epsilon = 0.526, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 791: Reward = -37799.90, Avg Reward (100) = -20141.31, Epsilon = 0.525, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35077.79, Obstacle Penalty: -50.00
Episode 792: Reward = -1049.00, Avg Reward (100) = -20091.13, Epsilon = 0.525, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 793: Reward = -51766.43, Avg Reward (100) = -20094.29, Epsilon = 0.524, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -51766.43, Border Penalty: -39483.29, Obstacle Penalty: -50.00
Episode 794: Reward = -475.19, Avg Reward (100) = -20162.15, Epsilon = 0.524, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -475.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 795: Reward = -678.25, Avg Reward (100) = -19654.38, Epsilon = 0.523, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -678.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 796: Reward = -34323.93, Avg Reward (100) = -19653.32, Epsilon = 0.522, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -34323.93, Border Penalty: -33898.44, Obstacle Penalty: -50.00
Episode 797: Reward = -1098.00, Avg Reward (100) = -19727.12, Epsilon = 0.522, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 798: Reward = -39462.22, Avg Reward (100) = -19726.63, Epsilon = 0.521, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -39462.22, Border Penalty: -33286.34, Obstacle Penalty: -50.00
Episode 799: Reward = -1000.00, Avg Reward (100) = -20110.76, Epsilon = 0.521, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 800: Reward = -55140.39, Avg Reward (100) = -20110.27, Epsilon = 0.520, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -55140.39, Border Penalty: -40271.46, Obstacle Penalty: -50.00
Episode 801: Reward = -1018.19, Avg Reward (100) = -20651.19, Epsilon = 0.519, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -1018.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 802: Reward = -7242.67, Avg Reward (100) = -20649.41, Epsilon = 0.519, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -7242.67, Border Penalty: -14957.75, Obstacle Penalty: -50.00
Episode 803: Reward = -1049.00, Avg Reward (100) = -20556.50, Epsilon = 0.518, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 804: Reward = -27641.84, Avg Reward (100) = -20190.33, Epsilon = 0.518, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27641.84, Border Penalty: -30705.20, Obstacle Penalty: -50.00
Episode 805: Reward = -50743.74, Avg Reward (100) = -19969.95, Epsilon = 0.517, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -50743.74, Border Penalty: -36105.08, Obstacle Penalty: -50.00
Episode 806: Reward = -33636.41, Avg Reward (100) = -20467.38, Epsilon = 0.516, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -33636.41, Border Penalty: -33352.16, Obstacle Penalty: -50.00
Episode 807: Reward = -1098.00, Avg Reward (100) = -20793.75, Epsilon = 0.516, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 808: Reward = -1147.00, Avg Reward (100) = -20440.66, Epsilon = 0.515, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 809: Reward = -48252.80, Avg Reward (100) = -19712.49, Epsilon = 0.515, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 810: Reward = -52308.14, Avg Reward (100) = -20184.04, Epsilon = 0.514, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -52308.14, Border Penalty: -41059.63, Obstacle Penalty: -50.00
Episode 811: Reward = -1049.00, Avg Reward (100) = -20258.75, Epsilon = 0.513, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 812: Reward = -49578.31, Avg Reward (100) = -20258.75, Epsilon = 0.513, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 24, Reward Breakdown -> Delta_x Reward: -49578.31, Border Penalty: -40369.27, Obstacle Penalty: -50.00
Episode 813: Reward = -51541.34, Avg Reward (100) = -20747.45, Epsilon = 0.512, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51541.34, Border Penalty: -31642.55, Obstacle Penalty: -50.00
Episode 814: Reward = -34555.88, Avg Reward (100) = -20744.54, Epsilon = 0.512, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -34555.88, Border Penalty: -30322.76, Obstacle Penalty: -50.00
Episode 815: Reward = -87194.89, Avg Reward (100) = -21080.10, Epsilon = 0.511, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -87194.89, Border Penalty: -36437.15, Obstacle Penalty: -50.00
Episode 816: Reward = -78.28, Avg Reward (100) = -21361.87, Epsilon = 0.510, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -78.28, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 817: Reward = -32779.00, Avg Reward (100) = -21062.77, Epsilon = 0.510, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32779.00, Border Penalty: -32732.43, Obstacle Penalty: -50.00
Episode 818: Reward = -48618.25, Avg Reward (100) = -21035.57, Epsilon = 0.509, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 20, Reward Breakdown -> Delta_x Reward: -48618.25, Border Penalty: -38973.02, Obstacle Penalty: -50.00
Episode 819: Reward = -51114.60, Avg Reward (100) = -21506.83, Epsilon = 0.509, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51114.60, Border Penalty: -36200.96, Obstacle Penalty: -50.00
Episode 820: Reward = -1098.00, Avg Reward (100) = -22007.49, Epsilon = 0.508, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 821: Reward = -231.28, Avg Reward (100) = -21485.69, Epsilon = 0.507, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -231.28, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 822: Reward = -1000.00, Avg Reward (100) = -21477.51, Epsilon = 0.507, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 823: Reward = -73129.92, Avg Reward (100) = -21477.02, Epsilon = 0.506, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -73129.92, Border Penalty: -32198.78, Obstacle Penalty: -50.00
Episode 824: Reward = -1049.00, Avg Reward (100) = -22197.34, Epsilon = 0.506, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 825: Reward = -1098.00, Avg Reward (100) = -21717.83, Epsilon = 0.505, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 826: Reward = -1000.00, Avg Reward (100) = -21317.73, Epsilon = 0.504, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 827: Reward = -52270.10, Avg Reward (100) = -21317.24, Epsilon = 0.504, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 828: Reward = -782.25, Avg Reward (100) = -21388.33, Epsilon = 0.503, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -782.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 829: Reward = -51862.70, Avg Reward (100) = -21386.15, Epsilon = 0.503, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51862.70, Border Penalty: -41205.92, Obstacle Penalty: -50.00
Episode 830: Reward = -1295.00, Avg Reward (100) = -21894.29, Epsilon = 0.502, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 831: Reward = -733.25, Avg Reward (100) = -21552.24, Epsilon = 0.501, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 832: Reward = -1000.00, Avg Reward (100) = -20967.09, Epsilon = 0.501, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 833: Reward = -580.25, Avg Reward (100) = -20660.78, Epsilon = 0.500, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -580.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 834: Reward = -1049.00, Avg Reward (100) = -20380.05, Epsilon = 0.500, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 835: Reward = -1000.00, Avg Reward (100) = -20380.54, Epsilon = 0.499, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 836: Reward = -27862.61, Avg Reward (100) = -20380.05, Epsilon = 0.498, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -27862.61, Border Penalty: -32357.99, Obstacle Penalty: -50.00
Episode 837: Reward = -37944.63, Avg Reward (100) = -20647.70, Epsilon = 0.498, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37944.63, Border Penalty: -33557.54, Obstacle Penalty: -50.00
Episode 838: Reward = -35045.30, Avg Reward (100) = -21016.65, Epsilon = 0.497, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -35045.30, Border Penalty: -33964.84, Obstacle Penalty: -50.00
Episode 839: Reward = -33305.90, Avg Reward (100) = -21359.77, Epsilon = 0.497, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33305.90, Border Penalty: -30953.45, Obstacle Penalty: -50.00
Episode 840: Reward = -29358.58, Avg Reward (100) = -21685.52, Epsilon = 0.496, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 841: Reward = -1098.00, Avg Reward (100) = -21977.07, Epsilon = 0.495, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 842: Reward = -246.01, Avg Reward (100) = -21975.60, Epsilon = 0.495, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -246.01, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 843: Reward = -528.19, Avg Reward (100) = -21969.24, Epsilon = 0.494, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -528.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 844: Reward = -41106.36, Avg Reward (100) = -21963.05, Epsilon = 0.494, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -41106.36, Border Penalty: -30368.08, Obstacle Penalty: -50.00
Episode 845: Reward = -36089.25, Avg Reward (100) = -22111.68, Epsilon = 0.493, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 846: Reward = -35499.61, Avg Reward (100) = -22462.09, Epsilon = 0.492, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 847: Reward = -51766.03, Avg Reward (100) = -22807.08, Epsilon = 0.492, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51766.03, Border Penalty: -35576.68, Obstacle Penalty: -50.00
Episode 848: Reward = -1000.00, Avg Reward (100) = -23314.74, Epsilon = 0.491, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 849: Reward = -1245.00, Avg Reward (100) = -23323.26, Epsilon = 0.491, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 850: Reward = -51766.03, Avg Reward (100) = -23323.75, Epsilon = 0.490, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51766.03, Border Penalty: -35576.68, Obstacle Penalty: -50.00
Episode 851: Reward = -57458.08, Avg Reward (100) = -23830.92, Epsilon = 0.489, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57458.08, Border Penalty: -34792.67, Obstacle Penalty: -50.00
Episode 852: Reward = -1000.00, Avg Reward (100) = -24395.01, Epsilon = 0.489, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 853: Reward = -1049.00, Avg Reward (100) = -24012.85, Epsilon = 0.488, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 854: Reward = -25839.30, Avg Reward (100) = -24012.85, Epsilon = 0.488, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 22, Reward Breakdown -> Delta_x Reward: -25839.30, Border Penalty: -30299.04, Obstacle Penalty: -50.00
Episode 855: Reward = -55523.82, Avg Reward (100) = -24258.72, Epsilon = 0.487, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -55523.82, Border Penalty: -40638.25, Obstacle Penalty: -50.00
Episode 856: Reward = -36289.30, Avg Reward (100) = -24802.00, Epsilon = 0.486, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -36289.30, Border Penalty: -32879.59, Obstacle Penalty: -50.00
Episode 857: Reward = -1049.00, Avg Reward (100) = -24589.85, Epsilon = 0.486, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 858: Reward = -63191.45, Avg Reward (100) = -24161.32, Epsilon = 0.485, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -63191.45, Border Penalty: -32822.84, Obstacle Penalty: -50.00
Episode 859: Reward = -1000.00, Avg Reward (100) = -24781.28, Epsilon = 0.485, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 860: Reward = -1196.00, Avg Reward (100) = -24113.33, Epsilon = 0.484, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 861: Reward = -1049.00, Avg Reward (100) = -23608.00, Epsilon = 0.483, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 862: Reward = -1098.00, Avg Reward (100) = -23607.51, Epsilon = 0.483, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 863: Reward = -39818.73, Avg Reward (100) = -23068.13, Epsilon = 0.482, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -39818.73, Border Penalty: -36431.17, Obstacle Penalty: -50.00
Episode 864: Reward = -1049.00, Avg Reward (100) = -22985.87, Epsilon = 0.482, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 865: Reward = -1098.00, Avg Reward (100) = -22748.04, Epsilon = 0.481, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 866: Reward = -41879.23, Avg Reward (100) = -22234.04, Epsilon = 0.480, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -41879.23, Border Penalty: -35770.27, Obstacle Penalty: -50.00
Episode 867: Reward = -30092.93, Avg Reward (100) = -22641.86, Epsilon = 0.480, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30092.93, Border Penalty: -31776.74, Obstacle Penalty: -50.00
Episode 868: Reward = -56447.08, Avg Reward (100) = -22931.81, Epsilon = 0.479, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -56447.08, Border Penalty: -40677.35, Obstacle Penalty: -50.00
Episode 869: Reward = -1098.00, Avg Reward (100) = -23149.76, Epsilon = 0.479, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 870: Reward = -30187.48, Avg Reward (100) = -23150.25, Epsilon = 0.478, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -30187.48, Border Penalty: -33015.89, Obstacle Penalty: -50.00
Episode 871: Reward = -1147.00, Avg Reward (100) = -23088.83, Epsilon = 0.477, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 872: Reward = -61671.96, Avg Reward (100) = -22564.14, Epsilon = 0.477, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -61671.96, Border Penalty: -33135.65, Obstacle Penalty: -50.00
Episode 873: Reward = -1000.00, Avg Reward (100) = -23170.37, Epsilon = 0.476, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 874: Reward = -1049.00, Avg Reward (100) = -23168.41, Epsilon = 0.476, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 875: Reward = -34685.86, Avg Reward (100) = -23168.41, Epsilon = 0.475, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 876: Reward = -42304.65, Avg Reward (100) = -22538.66, Epsilon = 0.474, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -31719.73, Obstacle Penalty: -50.00
Episode 877: Reward = -680.25, Avg Reward (100) = -22473.58, Epsilon = 0.474, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -680.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 878: Reward = -50763.70, Avg Reward (100) = -22470.38, Epsilon = 0.473, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -50763.70, Border Penalty: -35374.62, Obstacle Penalty: -50.00
Episode 879: Reward = -1295.00, Avg Reward (100) = -22966.55, Epsilon = 0.473, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 880: Reward = -42721.71, Avg Reward (100) = -22969.50, Epsilon = 0.472, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -42721.71, Border Penalty: -34140.29, Obstacle Penalty: -50.00
Episode 881: Reward = -56983.76, Avg Reward (100) = -23386.72, Epsilon = 0.471, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -56983.76, Border Penalty: -39714.19, Obstacle Penalty: -50.00
Episode 882: Reward = -36499.46, Avg Reward (100) = -23533.35, Epsilon = 0.471, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36499.46, Border Penalty: -35826.99, Obstacle Penalty: -50.00
Episode 883: Reward = -1049.00, Avg Reward (100) = -23518.43, Epsilon = 0.470, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 884: Reward = -50738.76, Avg Reward (100) = -23518.92, Epsilon = 0.470, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50738.76, Border Penalty: -40478.38, Obstacle Penalty: -50.00
Episode 885: Reward = -1000.00, Avg Reward (100) = -23705.80, Epsilon = 0.469, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 886: Reward = -1245.00, Avg Reward (100) = -23259.56, Epsilon = 0.468, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 887: Reward = -24438.40, Avg Reward (100) = -23261.52, Epsilon = 0.468, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -24438.40, Border Penalty: -30462.62, Obstacle Penalty: -50.00
Episode 888: Reward = -97133.66, Avg Reward (100) = -23087.08, Epsilon = 0.467, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 27, Reward Breakdown -> Delta_x Reward: -97133.66, Border Penalty: -30109.93, Obstacle Penalty: -50.00
Episode 889: Reward = -477.25, Avg Reward (100) = -23328.50, Epsilon = 0.467, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -477.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 890: Reward = -1000.00, Avg Reward (100) = -23318.77, Epsilon = 0.466, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 891: Reward = -1000.00, Avg Reward (100) = -23317.79, Epsilon = 0.465, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 892: Reward = -46132.20, Avg Reward (100) = -22949.79, Epsilon = 0.465, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46132.20, Border Penalty: -36389.93, Obstacle Penalty: -50.00
Episode 893: Reward = -32779.00, Avg Reward (100) = -23400.62, Epsilon = 0.464, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32779.00, Border Penalty: -32732.43, Obstacle Penalty: -50.00
Episode 894: Reward = -51305.68, Avg Reward (100) = -23210.75, Epsilon = 0.464, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -51305.68, Border Penalty: -39159.19, Obstacle Penalty: -50.00
Episode 895: Reward = -70642.70, Avg Reward (100) = -23719.05, Epsilon = 0.463, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -70642.70, Border Penalty: -32150.33, Obstacle Penalty: -50.00
Episode 896: Reward = -1147.00, Avg Reward (100) = -24418.70, Epsilon = 0.462, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 897: Reward = -36555.19, Avg Reward (100) = -24086.93, Epsilon = 0.462, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36555.19, Border Penalty: -35523.20, Obstacle Penalty: -50.00
Episode 898: Reward = -41811.33, Avg Reward (100) = -24441.50, Epsilon = 0.461, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41811.33, Border Penalty: -36291.59, Obstacle Penalty: -50.00
Episode 899: Reward = -69998.27, Avg Reward (100) = -24464.99, Epsilon = 0.461, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -69998.27, Border Penalty: -35939.55, Obstacle Penalty: -50.00
Episode 900: Reward = -1000.00, Avg Reward (100) = -25154.97, Epsilon = 0.460, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 901: Reward = -1000.00, Avg Reward (100) = -24613.57, Epsilon = 0.459, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 902: Reward = -1394.00, Avg Reward (100) = -24613.39, Epsilon = 0.459, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 903: Reward = -32882.25, Avg Reward (100) = -24554.90, Epsilon = 0.458, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -32882.25, Border Penalty: -32616.27, Obstacle Penalty: -50.00
Episode 904: Reward = -35499.61, Avg Reward (100) = -24873.23, Epsilon = 0.458, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 905: Reward = -50156.44, Avg Reward (100) = -24951.81, Epsilon = 0.457, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -50156.44, Border Penalty: -35684.62, Obstacle Penalty: -50.00
Episode 906: Reward = -65008.56, Avg Reward (100) = -24945.94, Epsilon = 0.456, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -65008.56, Border Penalty: -37675.53, Obstacle Penalty: -50.00
Episode 907: Reward = -35499.61, Avg Reward (100) = -25259.66, Epsilon = 0.456, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 908: Reward = -49810.47, Avg Reward (100) = -25603.67, Epsilon = 0.455, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -49810.47, Border Penalty: -39728.13, Obstacle Penalty: -50.00
Episode 909: Reward = -44693.41, Avg Reward (100) = -26090.31, Epsilon = 0.455, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -44693.41, Border Penalty: -37741.96, Obstacle Penalty: -50.00
Episode 910: Reward = -35499.61, Avg Reward (100) = -26054.71, Epsilon = 0.454, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 911: Reward = -1000.00, Avg Reward (100) = -25886.63, Epsilon = 0.453, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 912: Reward = -1295.00, Avg Reward (100) = -25886.14, Epsilon = 0.453, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 913: Reward = -44687.94, Avg Reward (100) = -25403.31, Epsilon = 0.452, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -44687.94, Border Penalty: -36898.48, Obstacle Penalty: -50.00
Episode 914: Reward = -35499.61, Avg Reward (100) = -25334.77, Epsilon = 0.452, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 915: Reward = -1049.00, Avg Reward (100) = -25344.21, Epsilon = 0.451, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 916: Reward = -1049.00, Avg Reward (100) = -24482.75, Epsilon = 0.450, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 917: Reward = -36277.49, Avg Reward (100) = -24492.46, Epsilon = 0.450, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -36277.49, Border Penalty: -34815.98, Obstacle Penalty: -50.00
Episode 918: Reward = -35499.61, Avg Reward (100) = -24527.44, Epsilon = 0.449, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 919: Reward = -1147.00, Avg Reward (100) = -24396.26, Epsilon = 0.449, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 920: Reward = -35499.61, Avg Reward (100) = -23896.58, Epsilon = 0.448, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 921: Reward = -27692.18, Avg Reward (100) = -24240.60, Epsilon = 0.447, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27692.18, Border Penalty: -31548.54, Obstacle Penalty: -50.00
Episode 922: Reward = -50824.45, Avg Reward (100) = -24515.21, Epsilon = 0.447, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 19, Reward Breakdown -> Delta_x Reward: -50824.45, Border Penalty: -37771.62, Obstacle Penalty: -50.00
Episode 923: Reward = -1098.00, Avg Reward (100) = -25013.45, Epsilon = 0.446, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 924: Reward = -46274.34, Avg Reward (100) = -24293.13, Epsilon = 0.446, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46274.34, Border Penalty: -38436.52, Obstacle Penalty: -50.00
Episode 925: Reward = -54867.87, Avg Reward (100) = -24745.38, Epsilon = 0.445, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54867.87, Border Penalty: -41844.88, Obstacle Penalty: -50.00
Episode 926: Reward = -39178.48, Avg Reward (100) = -25283.08, Epsilon = 0.444, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -39178.48, Border Penalty: -31739.15, Obstacle Penalty: -50.00
Episode 927: Reward = -1098.00, Avg Reward (100) = -25664.87, Epsilon = 0.444, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 928: Reward = -48475.50, Avg Reward (100) = -25153.15, Epsilon = 0.443, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48475.50, Border Penalty: -31456.74, Obstacle Penalty: -50.00
Episode 929: Reward = -483.98, Avg Reward (100) = -25630.08, Epsilon = 0.443, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -483.98, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 930: Reward = -1245.00, Avg Reward (100) = -25116.29, Epsilon = 0.442, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 931: Reward = -1098.00, Avg Reward (100) = -25115.79, Epsilon = 0.441, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 932: Reward = -1049.00, Avg Reward (100) = -25119.44, Epsilon = 0.441, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 933: Reward = -1196.00, Avg Reward (100) = -25119.93, Epsilon = 0.440, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 934: Reward = -1196.00, Avg Reward (100) = -25126.09, Epsilon = 0.440, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 935: Reward = -1000.00, Avg Reward (100) = -25127.56, Epsilon = 0.439, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 936: Reward = -42411.93, Avg Reward (100) = -25127.56, Epsilon = 0.438, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 27, Reward Breakdown -> Delta_x Reward: -42411.93, Border Penalty: -38354.71, Obstacle Penalty: -50.00
Episode 937: Reward = -34869.17, Avg Reward (100) = -25273.05, Epsilon = 0.438, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -34869.17, Border Penalty: -32338.76, Obstacle Penalty: -50.00
Episode 938: Reward = -44984.77, Avg Reward (100) = -25242.30, Epsilon = 0.437, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -44984.77, Border Penalty: -38139.80, Obstacle Penalty: -50.00
Episode 939: Reward = -14239.46, Avg Reward (100) = -25341.69, Epsilon = 0.437, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -14239.46, Border Penalty: -22847.51, Obstacle Penalty: -50.00
Episode 940: Reward = -1343.00, Avg Reward (100) = -25151.03, Epsilon = 0.436, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1343.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 941: Reward = -1147.00, Avg Reward (100) = -24870.87, Epsilon = 0.435, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 942: Reward = -1049.00, Avg Reward (100) = -24871.36, Epsilon = 0.435, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 943: Reward = -55488.56, Avg Reward (100) = -24879.39, Epsilon = 0.434, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -55488.56, Border Penalty: -39501.47, Obstacle Penalty: -50.00
Episode 944: Reward = -35499.61, Avg Reward (100) = -25428.99, Epsilon = 0.434, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 945: Reward = -1196.00, Avg Reward (100) = -25372.93, Epsilon = 0.433, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 946: Reward = -32619.61, Avg Reward (100) = -25023.99, Epsilon = 0.432, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 947: Reward = -33822.36, Avg Reward (100) = -24995.19, Epsilon = 0.432, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33822.36, Border Penalty: -30658.66, Obstacle Penalty: -50.00
Episode 948: Reward = -20.91, Avg Reward (100) = -24815.76, Epsilon = 0.431, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -20.91, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 949: Reward = -1000.00, Avg Reward (100) = -24805.97, Epsilon = 0.431, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 950: Reward = -1049.00, Avg Reward (100) = -24803.52, Epsilon = 0.430, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 951: Reward = -1000.00, Avg Reward (100) = -24296.35, Epsilon = 0.429, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 952: Reward = -40401.34, Avg Reward (100) = -23731.76, Epsilon = 0.429, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -40401.34, Border Penalty: -37480.51, Obstacle Penalty: -50.00
Episode 953: Reward = -52315.20, Avg Reward (100) = -24125.78, Epsilon = 0.428, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 954: Reward = -46025.94, Avg Reward (100) = -24638.44, Epsilon = 0.428, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46025.94, Border Penalty: -37376.39, Obstacle Penalty: -50.00
Episode 955: Reward = -1000.00, Avg Reward (100) = -24840.31, Epsilon = 0.427, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 956: Reward = -1294.00, Avg Reward (100) = -24295.07, Epsilon = 0.426, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 957: Reward = -12446.80, Avg Reward (100) = -23945.12, Epsilon = 0.426, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 958: Reward = -384.28, Avg Reward (100) = -24059.09, Epsilon = 0.425, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -384.28, Border Penalty: 0.00, Obstacle Penalty: -85.36
Episode 959: Reward = -58049.10, Avg Reward (100) = -23431.02, Epsilon = 0.425, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -58049.10, Border Penalty: -38879.60, Obstacle Penalty: -50.00
Episode 960: Reward = -41280.90, Avg Reward (100) = -24001.51, Epsilon = 0.424, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -36624.40, Obstacle Penalty: -50.00
Episode 961: Reward = -1394.00, Avg Reward (100) = -24402.36, Epsilon = 0.423, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 962: Reward = -1098.00, Avg Reward (100) = -24405.81, Epsilon = 0.423, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 963: Reward = -54854.49, Avg Reward (100) = -24405.81, Epsilon = 0.422, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -54854.49, Border Penalty: -41995.69, Obstacle Penalty: -50.00
Episode 964: Reward = -1196.00, Avg Reward (100) = -24556.17, Epsilon = 0.422, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 965: Reward = -1245.00, Avg Reward (100) = -24557.64, Epsilon = 0.421, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 966: Reward = -43263.20, Avg Reward (100) = -24559.11, Epsilon = 0.420, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 967: Reward = -33701.04, Avg Reward (100) = -24572.95, Epsilon = 0.420, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 968: Reward = -26271.81, Avg Reward (100) = -24609.03, Epsilon = 0.419, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -26271.81, Border Penalty: -31383.26, Obstacle Penalty: -50.00
Episode 969: Reward = -1049.00, Avg Reward (100) = -24307.28, Epsilon = 0.419, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 970: Reward = -1049.00, Avg Reward (100) = -24306.79, Epsilon = 0.418, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 971: Reward = -1294.00, Avg Reward (100) = -24015.40, Epsilon = 0.417, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 972: Reward = -1049.00, Avg Reward (100) = -24016.87, Epsilon = 0.417, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 973: Reward = -65135.05, Avg Reward (100) = -23410.64, Epsilon = 0.416, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -65135.05, Border Penalty: -32381.06, Obstacle Penalty: -50.00
Episode 974: Reward = -1295.00, Avg Reward (100) = -24051.99, Epsilon = 0.416, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 975: Reward = -45257.74, Avg Reward (100) = -24054.45, Epsilon = 0.415, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45257.74, Border Penalty: -38590.91, Obstacle Penalty: -50.00
Episode 976: Reward = -1000.00, Avg Reward (100) = -24160.17, Epsilon = 0.414, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 977: Reward = -16916.62, Avg Reward (100) = -23747.13, Epsilon = 0.414, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -16916.62, Border Penalty: -25828.81, Obstacle Penalty: -50.00
Episode 978: Reward = -49078.39, Avg Reward (100) = -23909.49, Epsilon = 0.413, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 21, Reward Breakdown -> Delta_x Reward: -49078.39, Border Penalty: -39863.46, Obstacle Penalty: -50.00
Episode 979: Reward = -41830.88, Avg Reward (100) = -23892.64, Epsilon = 0.413, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -41830.88, Border Penalty: -37438.07, Obstacle Penalty: -50.00
Episode 980: Reward = -48812.51, Avg Reward (100) = -24298.00, Epsilon = 0.412, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48812.51, Border Penalty: -38257.83, Obstacle Penalty: -50.00
Episode 981: Reward = -1196.00, Avg Reward (100) = -24358.90, Epsilon = 0.411, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 982: Reward = -35687.12, Avg Reward (100) = -23801.03, Epsilon = 0.411, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -35687.12, Border Penalty: -32669.38, Obstacle Penalty: -50.00
Episode 983: Reward = -34685.86, Avg Reward (100) = -23792.90, Epsilon = 0.410, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 984: Reward = -1147.00, Avg Reward (100) = -24129.27, Epsilon = 0.410, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 985: Reward = -37781.61, Avg Reward (100) = -23633.35, Epsilon = 0.409, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37781.61, Border Penalty: -33913.39, Obstacle Penalty: -50.00
Episode 986: Reward = -39784.16, Avg Reward (100) = -24001.17, Epsilon = 0.408, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -39784.16, Border Penalty: -31650.59, Obstacle Penalty: -50.00
Episode 987: Reward = -47439.38, Avg Reward (100) = -24386.56, Epsilon = 0.408, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 988: Reward = -57739.59, Avg Reward (100) = -24616.57, Epsilon = 0.407, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -57739.59, Border Penalty: -41543.66, Obstacle Penalty: -50.00
Episode 989: Reward = -1196.00, Avg Reward (100) = -24222.63, Epsilon = 0.407, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 990: Reward = -35499.61, Avg Reward (100) = -24229.82, Epsilon = 0.406, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 991: Reward = -628.19, Avg Reward (100) = -24574.81, Epsilon = 0.405, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -628.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 992: Reward = -21854.41, Avg Reward (100) = -24571.10, Epsilon = 0.405, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -21854.41, Border Penalty: -26375.96, Obstacle Penalty: -50.00
Episode 993: Reward = -35499.61, Avg Reward (100) = -24328.32, Epsilon = 0.404, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 994: Reward = -1147.00, Avg Reward (100) = -24355.52, Epsilon = 0.404, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 995: Reward = -1049.00, Avg Reward (100) = -23853.94, Epsilon = 0.403, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 996: Reward = -34745.03, Avg Reward (100) = -23158.00, Epsilon = 0.402, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34745.03, Border Penalty: -32351.37, Obstacle Penalty: -50.00
Episode 997: Reward = -1147.00, Avg Reward (100) = -23493.98, Epsilon = 0.402, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 998: Reward = -48471.30, Avg Reward (100) = -23139.90, Epsilon = 0.401, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48471.30, Border Penalty: -34021.80, Obstacle Penalty: -50.00
Episode 999: Reward = -1000.00, Avg Reward (100) = -23206.50, Epsilon = 0.401, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1000: Reward = -733.25, Avg Reward (100) = -22516.52, Epsilon = 0.400, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -733.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1001: Reward = -10188.21, Avg Reward (100) = -22513.85, Epsilon = 0.399, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -10188.21, Border Penalty: -17362.21, Obstacle Penalty: -50.00
Episode 1002: Reward = -65103.65, Avg Reward (100) = -22605.73, Epsilon = 0.399, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -65103.65, Border Penalty: -41707.10, Obstacle Penalty: -50.00
Episode 1003: Reward = -24323.40, Avg Reward (100) = -23242.83, Epsilon = 0.398, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -24323.40, Border Penalty: -30335.57, Obstacle Penalty: -50.00
Episode 1004: Reward = -35295.52, Avg Reward (100) = -23157.24, Epsilon = 0.398, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -31754.35, Obstacle Penalty: -50.00
Episode 1005: Reward = -33795.25, Avg Reward (100) = -23155.20, Epsilon = 0.397, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33795.25, Border Penalty: -33728.42, Obstacle Penalty: -50.00
Episode 1006: Reward = -44524.86, Avg Reward (100) = -22991.58, Epsilon = 0.396, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44524.86, Border Penalty: -38099.33, Obstacle Penalty: -50.00
Episode 1007: Reward = -1295.00, Avg Reward (100) = -22786.75, Epsilon = 0.396, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1008: Reward = -1000.00, Avg Reward (100) = -22444.70, Epsilon = 0.395, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1009: Reward = -1049.00, Avg Reward (100) = -21956.60, Epsilon = 0.395, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1010: Reward = -41888.43, Avg Reward (100) = -21520.15, Epsilon = 0.394, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -41888.43, Border Penalty: -37871.66, Obstacle Penalty: -50.00
Episode 1011: Reward = -1245.00, Avg Reward (100) = -21584.04, Epsilon = 0.393, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1012: Reward = -27346.47, Avg Reward (100) = -21586.49, Epsilon = 0.393, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -27346.47, Border Penalty: -31405.01, Obstacle Penalty: -50.00
Episode 1013: Reward = -62573.41, Avg Reward (100) = -21847.01, Epsilon = 0.392, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -62573.41, Border Penalty: -41895.43, Obstacle Penalty: -50.00
Episode 1014: Reward = -39606.20, Avg Reward (100) = -22025.86, Epsilon = 0.392, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1015: Reward = -35499.61, Avg Reward (100) = -22066.93, Epsilon = 0.391, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1016: Reward = -35499.61, Avg Reward (100) = -22411.43, Epsilon = 0.390, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1017: Reward = -1000.00, Avg Reward (100) = -22755.94, Epsilon = 0.390, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1018: Reward = -28653.56, Avg Reward (100) = -22403.16, Epsilon = 0.389, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 1019: Reward = -35499.61, Avg Reward (100) = -22334.70, Epsilon = 0.389, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1020: Reward = -1049.00, Avg Reward (100) = -22678.23, Epsilon = 0.388, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1021: Reward = -32493.44, Avg Reward (100) = -22333.72, Epsilon = 0.387, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32493.44, Border Penalty: -31080.54, Obstacle Penalty: -50.00
Episode 1022: Reward = -58998.20, Avg Reward (100) = -22381.74, Epsilon = 0.387, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -58998.20, Border Penalty: -40652.23, Obstacle Penalty: -50.00
Episode 1023: Reward = -27553.17, Avg Reward (100) = -22463.47, Epsilon = 0.386, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -27553.17, Border Penalty: -31744.07, Obstacle Penalty: -50.00
Episode 1024: Reward = -28653.56, Avg Reward (100) = -22728.03, Epsilon = 0.386, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1025: Reward = -477.19, Avg Reward (100) = -22551.82, Epsilon = 0.385, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -477.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1026: Reward = -35499.61, Avg Reward (100) = -22007.91, Epsilon = 0.384, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1027: Reward = -1147.00, Avg Reward (100) = -21971.12, Epsilon = 0.384, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1028: Reward = -579.19, Avg Reward (100) = -21971.61, Epsilon = 0.383, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -579.19, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1029: Reward = -1000.00, Avg Reward (100) = -21492.65, Epsilon = 0.383, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1030: Reward = -37679.04, Avg Reward (100) = -21497.81, Epsilon = 0.382, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37679.04, Border Penalty: -32015.81, Obstacle Penalty: -50.00
Episode 1031: Reward = -40230.68, Avg Reward (100) = -21862.15, Epsilon = 0.381, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40230.68, Border Penalty: -36015.16, Obstacle Penalty: -50.00
Episode 1032: Reward = -48252.80, Avg Reward (100) = -22253.48, Epsilon = 0.381, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 1033: Reward = -52276.34, Avg Reward (100) = -22725.51, Epsilon = 0.380, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -52276.34, Border Penalty: -41071.23, Obstacle Penalty: -50.00
Episode 1034: Reward = -49904.29, Avg Reward (100) = -23236.32, Epsilon = 0.380, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49904.29, Border Penalty: -35679.57, Obstacle Penalty: -50.00
Episode 1035: Reward = -47848.55, Avg Reward (100) = -23723.40, Epsilon = 0.379, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1036: Reward = -35499.61, Avg Reward (100) = -24191.89, Epsilon = 0.378, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1037: Reward = -1394.00, Avg Reward (100) = -24122.76, Epsilon = 0.378, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1038: Reward = -1000.00, Avg Reward (100) = -23788.01, Epsilon = 0.377, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1039: Reward = -1000.00, Avg Reward (100) = -23348.16, Epsilon = 0.377, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1040: Reward = -1098.00, Avg Reward (100) = -23215.77, Epsilon = 0.376, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1041: Reward = -1000.00, Avg Reward (100) = -23213.32, Epsilon = 0.375, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1042: Reward = -49176.10, Avg Reward (100) = -23211.85, Epsilon = 0.375, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1043: Reward = -39813.53, Avg Reward (100) = -23693.12, Epsilon = 0.374, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39813.53, Border Penalty: -36223.90, Obstacle Penalty: -50.00
Episode 1044: Reward = -114790.57, Avg Reward (100) = -23536.37, Epsilon = 0.374, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -114790.57, Border Penalty: -32309.35, Obstacle Penalty: -50.00
Episode 1045: Reward = -33469.53, Avg Reward (100) = -24329.28, Epsilon = 0.373, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1046: Reward = -53651.91, Avg Reward (100) = -24652.01, Epsilon = 0.372, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -53651.91, Border Penalty: -39467.75, Obstacle Penalty: -50.00
Episode 1047: Reward = -9566.81, Avg Reward (100) = -24862.34, Epsilon = 0.372, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 1048: Reward = -1000.00, Avg Reward (100) = -24619.78, Epsilon = 0.371, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1049: Reward = -33469.53, Avg Reward (100) = -24629.57, Epsilon = 0.371, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1050: Reward = -33469.53, Avg Reward (100) = -24954.27, Epsilon = 0.370, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1051: Reward = -34927.46, Avg Reward (100) = -25278.47, Epsilon = 0.369, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -32068.83, Obstacle Penalty: -50.00
Episode 1052: Reward = -38738.26, Avg Reward (100) = -25617.75, Epsilon = 0.369, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -38738.26, Border Penalty: -36640.41, Obstacle Penalty: -50.00
Episode 1053: Reward = -39606.20, Avg Reward (100) = -25601.12, Epsilon = 0.368, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 1054: Reward = -53932.41, Avg Reward (100) = -25474.03, Epsilon = 0.368, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -53932.41, Border Penalty: -33487.88, Obstacle Penalty: -50.00
Episode 1055: Reward = -1000.00, Avg Reward (100) = -25553.09, Epsilon = 0.367, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1056: Reward = -26563.12, Avg Reward (100) = -25553.09, Epsilon = 0.366, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -26563.12, Border Penalty: -31012.63, Obstacle Penalty: -50.00
Episode 1057: Reward = -1000.00, Avg Reward (100) = -25805.78, Epsilon = 0.366, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1058: Reward = -64984.83, Avg Reward (100) = -25691.32, Epsilon = 0.365, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -64984.83, Border Penalty: -31090.23, Obstacle Penalty: -50.00
Episode 1059: Reward = -1049.00, Avg Reward (100) = -26337.32, Epsilon = 0.365, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1060: Reward = -33469.53, Avg Reward (100) = -25767.32, Epsilon = 0.364, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1061: Reward = -1295.00, Avg Reward (100) = -25689.21, Epsilon = 0.363, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1062: Reward = -1395.78, Avg Reward (100) = -25688.22, Epsilon = 0.363, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1395.78, Border Penalty: -1747.83, Obstacle Penalty: -70.87
Episode 1063: Reward = -28653.56, Avg Reward (100) = -25691.19, Epsilon = 0.362, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1064: Reward = -1049.00, Avg Reward (100) = -25429.18, Epsilon = 0.362, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1065: Reward = -45417.44, Avg Reward (100) = -25427.71, Epsilon = 0.361, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45417.44, Border Penalty: -38590.88, Obstacle Penalty: -50.00
Episode 1066: Reward = -29624.22, Avg Reward (100) = -25869.44, Epsilon = 0.360, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -29624.22, Border Penalty: -31279.72, Obstacle Penalty: -50.00
Episode 1067: Reward = -45723.38, Avg Reward (100) = -25733.05, Epsilon = 0.360, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -45723.38, Border Penalty: -38065.23, Obstacle Penalty: -50.00
Episode 1068: Reward = -1049.00, Avg Reward (100) = -25853.27, Epsilon = 0.359, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1069: Reward = -32619.61, Avg Reward (100) = -25601.04, Epsilon = 0.359, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1070: Reward = -37799.90, Avg Reward (100) = -25916.75, Epsilon = 0.358, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 1071: Reward = -34685.86, Avg Reward (100) = -26284.26, Epsilon = 0.357, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1072: Reward = -1000.00, Avg Reward (100) = -26618.18, Epsilon = 0.357, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1073: Reward = -1049.00, Avg Reward (100) = -26617.69, Epsilon = 0.356, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1074: Reward = -35499.61, Avg Reward (100) = -25976.83, Epsilon = 0.356, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1075: Reward = -32763.21, Avg Reward (100) = -26318.87, Epsilon = 0.355, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -32763.21, Border Penalty: -31654.90, Obstacle Penalty: -50.00
Episode 1076: Reward = -59911.60, Avg Reward (100) = -26193.93, Epsilon = 0.354, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -59911.60, Border Penalty: -35715.11, Obstacle Penalty: -50.00
Episode 1077: Reward = -1196.00, Avg Reward (100) = -26783.04, Epsilon = 0.354, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1078: Reward = -1049.00, Avg Reward (100) = -26625.84, Epsilon = 0.353, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1079: Reward = -32824.81, Avg Reward (100) = -26145.54, Epsilon = 0.353, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -32824.81, Border Penalty: -34237.92, Obstacle Penalty: -50.00
Episode 1080: Reward = -49626.26, Avg Reward (100) = -26055.48, Epsilon = 0.352, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1081: Reward = -1245.00, Avg Reward (100) = -26063.62, Epsilon = 0.351, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -79.94
Episode 1082: Reward = -1098.00, Avg Reward (100) = -26064.11, Epsilon = 0.351, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1083: Reward = -28283.14, Avg Reward (100) = -25718.22, Epsilon = 0.350, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -28283.14, Border Penalty: -31945.95, Obstacle Penalty: -50.00
Episode 1084: Reward = -51157.47, Avg Reward (100) = -25654.19, Epsilon = 0.350, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51157.47, Border Penalty: -35117.87, Obstacle Penalty: -50.00
Episode 1085: Reward = -1000.00, Avg Reward (100) = -26154.30, Epsilon = 0.349, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1086: Reward = -43591.77, Avg Reward (100) = -25786.48, Epsilon = 0.348, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43591.77, Border Penalty: -38351.20, Obstacle Penalty: -50.00
Episode 1087: Reward = -1147.00, Avg Reward (100) = -25824.56, Epsilon = 0.348, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1088: Reward = -45971.72, Avg Reward (100) = -25361.63, Epsilon = 0.347, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -45971.72, Border Penalty: -39067.91, Obstacle Penalty: -50.00
Episode 1089: Reward = -39606.20, Avg Reward (100) = -25243.95, Epsilon = 0.347, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1090: Reward = -32632.70, Avg Reward (100) = -25628.06, Epsilon = 0.346, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -32853.88, Obstacle Penalty: -50.00
Episode 1091: Reward = -43263.20, Avg Reward (100) = -25599.39, Epsilon = 0.345, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1092: Reward = -1392.00, Avg Reward (100) = -26025.74, Epsilon = 0.345, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1392.00, Border Penalty: 0.00, Obstacle Penalty: -98.12
Episode 1093: Reward = -42103.12, Avg Reward (100) = -25821.11, Epsilon = 0.344, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -42103.12, Border Penalty: -32661.64, Obstacle Penalty: -50.00
Episode 1094: Reward = -1000.00, Avg Reward (100) = -25887.15, Epsilon = 0.344, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1095: Reward = -32499.04, Avg Reward (100) = -25885.68, Epsilon = 0.343, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32499.04, Border Penalty: -32458.42, Obstacle Penalty: -50.00
Episode 1096: Reward = -35499.61, Avg Reward (100) = -26200.18, Epsilon = 0.342, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1097: Reward = -1000.00, Avg Reward (100) = -26207.72, Epsilon = 0.342, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1098: Reward = -1196.00, Avg Reward (100) = -26206.25, Epsilon = 0.341, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1099: Reward = -50329.95, Avg Reward (100) = -25733.50, Epsilon = 0.341, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50329.95, Border Penalty: -39553.62, Obstacle Penalty: -50.00
Episode 1100: Reward = -30970.69, Avg Reward (100) = -26226.80, Epsilon = 0.340, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30970.69, Border Penalty: -32260.43, Obstacle Penalty: -50.00
Episode 1101: Reward = -44232.58, Avg Reward (100) = -26529.18, Epsilon = 0.339, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44232.58, Border Penalty: -35388.78, Obstacle Penalty: -50.00
Episode 1102: Reward = -25228.52, Avg Reward (100) = -26869.62, Epsilon = 0.339, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1103: Reward = -52393.30, Avg Reward (100) = -26470.87, Epsilon = 0.338, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52393.30, Border Penalty: -40427.91, Obstacle Penalty: -50.00
Episode 1104: Reward = -1245.00, Avg Reward (100) = -26751.57, Epsilon = 0.338, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1105: Reward = -37669.33, Avg Reward (100) = -26411.06, Epsilon = 0.337, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1106: Reward = -35499.61, Avg Reward (100) = -26449.80, Epsilon = 0.336, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1107: Reward = -784.25, Avg Reward (100) = -26359.55, Epsilon = 0.336, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -784.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1108: Reward = -1147.00, Avg Reward (100) = -26354.44, Epsilon = 0.335, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1109: Reward = -1000.00, Avg Reward (100) = -26355.91, Epsilon = 0.335, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1110: Reward = -35499.61, Avg Reward (100) = -26355.42, Epsilon = 0.334, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1111: Reward = -1460.67, Avg Reward (100) = -26291.53, Epsilon = 0.333, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -1460.67, Border Penalty: 0.00, Obstacle Penalty: -82.16
Episode 1112: Reward = -1000.00, Avg Reward (100) = -26293.69, Epsilon = 0.333, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1113: Reward = -1294.00, Avg Reward (100) = -26030.23, Epsilon = 0.332, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1114: Reward = -9872.65, Avg Reward (100) = -25417.43, Epsilon = 0.332, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -9872.65, Border Penalty: -20063.76, Obstacle Penalty: -50.00
Episode 1115: Reward = -15302.76, Avg Reward (100) = -25120.10, Epsilon = 0.331, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -15302.76, Border Penalty: -24981.32, Obstacle Penalty: -50.00
Episode 1116: Reward = -50738.76, Avg Reward (100) = -24918.13, Epsilon = 0.330, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50738.76, Border Penalty: -40478.38, Obstacle Penalty: -50.00
Episode 1117: Reward = -26976.56, Avg Reward (100) = -25070.52, Epsilon = 0.330, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26976.56, Border Penalty: -30987.82, Obstacle Penalty: -50.00
Episode 1118: Reward = -1196.00, Avg Reward (100) = -25330.29, Epsilon = 0.329, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1119: Reward = -33701.04, Avg Reward (100) = -25055.71, Epsilon = 0.329, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -33286.29, Obstacle Penalty: -50.00
Episode 1120: Reward = -1098.00, Avg Reward (100) = -25037.72, Epsilon = 0.328, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1121: Reward = -33469.53, Avg Reward (100) = -25038.21, Epsilon = 0.327, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1122: Reward = -1049.00, Avg Reward (100) = -25047.98, Epsilon = 0.327, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1123: Reward = -12446.80, Avg Reward (100) = -24468.48, Epsilon = 0.326, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1124: Reward = -42434.22, Avg Reward (100) = -24317.42, Epsilon = 0.326, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -42434.22, Border Penalty: -35150.87, Obstacle Penalty: -50.00
Episode 1125: Reward = -1049.00, Avg Reward (100) = -24455.23, Epsilon = 0.325, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1126: Reward = -25228.52, Avg Reward (100) = -24460.94, Epsilon = 0.324, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1127: Reward = -1098.00, Avg Reward (100) = -24358.23, Epsilon = 0.324, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1128: Reward = -1147.00, Avg Reward (100) = -24357.74, Epsilon = 0.323, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1129: Reward = -37833.70, Avg Reward (100) = -24363.42, Epsilon = 0.323, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37833.70, Border Penalty: -36129.36, Obstacle Penalty: -50.00
Episode 1130: Reward = -1147.00, Avg Reward (100) = -24731.76, Epsilon = 0.322, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1131: Reward = -1147.00, Avg Reward (100) = -24366.44, Epsilon = 0.321, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1132: Reward = -1394.00, Avg Reward (100) = -23975.60, Epsilon = 0.321, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1133: Reward = -35499.61, Avg Reward (100) = -23507.01, Epsilon = 0.320, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1134: Reward = -35499.61, Avg Reward (100) = -23339.25, Epsilon = 0.320, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1135: Reward = -12446.80, Avg Reward (100) = -23195.20, Epsilon = 0.319, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1136: Reward = -35499.61, Avg Reward (100) = -22841.18, Epsilon = 0.318, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1137: Reward = -63760.45, Avg Reward (100) = -22841.18, Epsilon = 0.318, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -63760.45, Border Penalty: -31940.89, Obstacle Penalty: -50.00
Episode 1138: Reward = -2156.56, Avg Reward (100) = -23464.85, Epsilon = 0.317, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 1139: Reward = -31625.50, Avg Reward (100) = -23476.41, Epsilon = 0.317, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -31625.50, Border Penalty: -32393.25, Obstacle Penalty: -50.00
Episode 1140: Reward = -28683.61, Avg Reward (100) = -23782.67, Epsilon = 0.316, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1141: Reward = -35499.61, Avg Reward (100) = -24058.52, Epsilon = 0.315, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1142: Reward = -28772.37, Avg Reward (100) = -24403.52, Epsilon = 0.315, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 1143: Reward = -1098.00, Avg Reward (100) = -24199.48, Epsilon = 0.314, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1144: Reward = -37669.33, Avg Reward (100) = -23812.33, Epsilon = 0.314, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1145: Reward = -31653.57, Avg Reward (100) = -23041.11, Epsilon = 0.313, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 1146: Reward = -35499.61, Avg Reward (100) = -23022.95, Epsilon = 0.312, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1147: Reward = -34238.00, Avg Reward (100) = -22841.43, Epsilon = 0.312, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -34238.00, Border Penalty: -34766.38, Obstacle Penalty: -50.00
Episode 1148: Reward = -35499.61, Avg Reward (100) = -23088.14, Epsilon = 0.311, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1149: Reward = -1049.00, Avg Reward (100) = -23433.14, Epsilon = 0.311, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1150: Reward = -35499.61, Avg Reward (100) = -23108.93, Epsilon = 0.310, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1151: Reward = -35499.61, Avg Reward (100) = -23129.23, Epsilon = 0.309, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1152: Reward = -1000.00, Avg Reward (100) = -23134.96, Epsilon = 0.309, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1153: Reward = -36726.20, Avg Reward (100) = -22757.57, Epsilon = 0.308, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36726.20, Border Penalty: -32739.82, Obstacle Penalty: -50.00
Episode 1154: Reward = -29220.94, Avg Reward (100) = -22728.77, Epsilon = 0.308, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29220.94, Border Penalty: -32231.25, Obstacle Penalty: -50.00
Episode 1155: Reward = -48745.93, Avg Reward (100) = -22481.66, Epsilon = 0.307, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48745.93, Border Penalty: -40097.11, Obstacle Penalty: -50.00
Episode 1156: Reward = -35499.61, Avg Reward (100) = -22959.12, Epsilon = 0.306, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1157: Reward = -1098.00, Avg Reward (100) = -23048.48, Epsilon = 0.306, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1158: Reward = -57983.46, Avg Reward (100) = -23049.46, Epsilon = 0.305, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57983.46, Border Penalty: -41230.57, Obstacle Penalty: -50.00
Episode 1159: Reward = -35499.61, Avg Reward (100) = -22979.45, Epsilon = 0.305, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1160: Reward = -29512.46, Avg Reward (100) = -23323.96, Epsilon = 0.304, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1161: Reward = -1147.00, Avg Reward (100) = -23284.38, Epsilon = 0.303, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1162: Reward = -3039.30, Avg Reward (100) = -23282.90, Epsilon = 0.303, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -3039.30, Border Penalty: -5606.63, Obstacle Penalty: -50.00
Episode 1163: Reward = -1245.00, Avg Reward (100) = -23299.34, Epsilon = 0.302, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1164: Reward = -34685.86, Avg Reward (100) = -23025.25, Epsilon = 0.302, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1165: Reward = -1196.00, Avg Reward (100) = -23361.62, Epsilon = 0.301, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1166: Reward = -1295.00, Avg Reward (100) = -22919.41, Epsilon = 0.300, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1167: Reward = -35499.61, Avg Reward (100) = -22636.12, Epsilon = 0.300, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1168: Reward = -49396.41, Avg Reward (100) = -22533.88, Epsilon = 0.299, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -49396.41, Border Penalty: -37333.04, Obstacle Penalty: -50.00
Episode 1169: Reward = -34685.86, Avg Reward (100) = -23017.35, Epsilon = 0.299, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1170: Reward = -1049.00, Avg Reward (100) = -23038.02, Epsilon = 0.298, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1171: Reward = -41554.36, Avg Reward (100) = -22670.51, Epsilon = 0.297, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -36818.37, Obstacle Penalty: -50.00
Episode 1172: Reward = -35499.61, Avg Reward (100) = -22739.19, Epsilon = 0.297, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1173: Reward = -1098.00, Avg Reward (100) = -23084.19, Epsilon = 0.296, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1174: Reward = -35499.61, Avg Reward (100) = -23084.68, Epsilon = 0.296, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1175: Reward = -1049.00, Avg Reward (100) = -23084.68, Epsilon = 0.295, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1176: Reward = -1049.00, Avg Reward (100) = -22767.54, Epsilon = 0.294, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1177: Reward = -35499.61, Avg Reward (100) = -22178.91, Epsilon = 0.294, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1178: Reward = -931.25, Avg Reward (100) = -22521.95, Epsilon = 0.293, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -931.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1179: Reward = -35295.52, Avg Reward (100) = -22520.77, Epsilon = 0.293, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34034.34, Obstacle Penalty: -50.00
Episode 1180: Reward = -58564.79, Avg Reward (100) = -22545.47, Epsilon = 0.292, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 1181: Reward = -1098.00, Avg Reward (100) = -22634.86, Epsilon = 0.291, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1182: Reward = -43263.20, Avg Reward (100) = -22633.39, Epsilon = 0.291, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1183: Reward = -1196.00, Avg Reward (100) = -23055.04, Epsilon = 0.290, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1184: Reward = -35499.61, Avg Reward (100) = -22784.17, Epsilon = 0.290, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1185: Reward = -27833.61, Avg Reward (100) = -22627.59, Epsilon = 0.289, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27833.61, Border Penalty: -31247.44, Obstacle Penalty: -50.00
Episode 1186: Reward = -35499.61, Avg Reward (100) = -22895.93, Epsilon = 0.288, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1187: Reward = -24736.72, Avg Reward (100) = -22815.01, Epsilon = 0.288, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -24736.72, Border Penalty: -30228.77, Obstacle Penalty: -50.00
Episode 1188: Reward = -59176.41, Avg Reward (100) = -23050.90, Epsilon = 0.287, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -32572.60, Obstacle Penalty: -50.00
Episode 1189: Reward = -1098.00, Avg Reward (100) = -23182.95, Epsilon = 0.287, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1190: Reward = -1098.00, Avg Reward (100) = -22797.87, Epsilon = 0.286, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1191: Reward = -32245.59, Avg Reward (100) = -22482.52, Epsilon = 0.285, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1192: Reward = -36089.25, Avg Reward (100) = -22372.35, Epsilon = 0.285, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1193: Reward = -1393.00, Avg Reward (100) = -22719.32, Epsilon = 0.284, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1194: Reward = -35499.61, Avg Reward (100) = -22312.22, Epsilon = 0.284, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1195: Reward = -35499.61, Avg Reward (100) = -22657.21, Epsilon = 0.283, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1196: Reward = -1098.00, Avg Reward (100) = -22687.22, Epsilon = 0.282, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1197: Reward = -37378.11, Avg Reward (100) = -22343.20, Epsilon = 0.282, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37378.11, Border Penalty: -31936.62, Obstacle Penalty: -50.00
Episode 1198: Reward = -37669.33, Avg Reward (100) = -22706.98, Epsilon = 0.281, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1199: Reward = -65325.95, Avg Reward (100) = -23071.72, Epsilon = 0.281, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 17, Reward Breakdown -> Delta_x Reward: -65325.95, Border Penalty: -41920.76, Obstacle Penalty: -50.00
Episode 1200: Reward = -33486.06, Avg Reward (100) = -23221.68, Epsilon = 0.280, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33486.06, Border Penalty: -31432.07, Obstacle Penalty: -50.00
Episode 1201: Reward = -1049.00, Avg Reward (100) = -23246.83, Epsilon = 0.279, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1202: Reward = -57983.46, Avg Reward (100) = -22814.99, Epsilon = 0.279, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57983.46, Border Penalty: -41230.57, Obstacle Penalty: -50.00
Episode 1203: Reward = -1000.00, Avg Reward (100) = -23142.54, Epsilon = 0.278, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1204: Reward = -1098.00, Avg Reward (100) = -22628.61, Epsilon = 0.278, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1205: Reward = -33701.04, Avg Reward (100) = -22627.14, Epsilon = 0.277, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1206: Reward = -28683.61, Avg Reward (100) = -22587.46, Epsilon = 0.276, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1207: Reward = -47439.38, Avg Reward (100) = -22519.30, Epsilon = 0.276, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 1208: Reward = -1049.00, Avg Reward (100) = -22985.85, Epsilon = 0.275, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1209: Reward = -37669.33, Avg Reward (100) = -22984.87, Epsilon = 0.275, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1210: Reward = -54629.56, Avg Reward (100) = -23351.56, Epsilon = 0.274, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54629.56, Border Penalty: -41837.55, Obstacle Penalty: -50.00
Episode 1211: Reward = -1000.00, Avg Reward (100) = -23542.86, Epsilon = 0.273, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1212: Reward = -33701.04, Avg Reward (100) = -23538.26, Epsilon = 0.273, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1213: Reward = -50685.33, Avg Reward (100) = -23865.27, Epsilon = 0.272, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50685.33, Border Penalty: -40573.34, Obstacle Penalty: -50.00
Episode 1214: Reward = -1147.00, Avg Reward (100) = -24359.18, Epsilon = 0.272, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1215: Reward = -1196.00, Avg Reward (100) = -24271.92, Epsilon = 0.271, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1216: Reward = -35499.61, Avg Reward (100) = -24130.86, Epsilon = 0.270, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1217: Reward = -28683.61, Avg Reward (100) = -23978.46, Epsilon = 0.270, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1218: Reward = -44147.51, Avg Reward (100) = -23995.53, Epsilon = 0.269, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44147.51, Border Penalty: -32410.62, Obstacle Penalty: -50.00
Episode 1219: Reward = -1098.00, Avg Reward (100) = -24425.05, Epsilon = 0.269, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1220: Reward = -29626.05, Avg Reward (100) = -24099.02, Epsilon = 0.268, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 1221: Reward = -49626.26, Avg Reward (100) = -24384.30, Epsilon = 0.267, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1222: Reward = -33469.53, Avg Reward (100) = -24545.87, Epsilon = 0.267, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1223: Reward = -1147.00, Avg Reward (100) = -24870.07, Epsilon = 0.266, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1224: Reward = -33701.04, Avg Reward (100) = -24757.07, Epsilon = 0.266, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1225: Reward = -35499.61, Avg Reward (100) = -24669.74, Epsilon = 0.265, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1226: Reward = -33469.53, Avg Reward (100) = -25014.25, Epsilon = 0.264, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1227: Reward = -1295.00, Avg Reward (100) = -25096.66, Epsilon = 0.264, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1228: Reward = -53296.27, Avg Reward (100) = -25098.63, Epsilon = 0.263, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -53296.27, Border Penalty: -41478.27, Obstacle Penalty: -50.00
Episode 1229: Reward = -42464.17, Avg Reward (100) = -25620.12, Epsilon = 0.263, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42464.17, Border Penalty: -34750.76, Obstacle Penalty: -50.00
Episode 1230: Reward = -33701.04, Avg Reward (100) = -25666.43, Epsilon = 0.262, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1231: Reward = -1196.00, Avg Reward (100) = -25991.97, Epsilon = 0.261, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1232: Reward = -33469.53, Avg Reward (100) = -25992.46, Epsilon = 0.261, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1233: Reward = -35499.61, Avg Reward (100) = -26313.21, Epsilon = 0.260, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1234: Reward = -29358.58, Avg Reward (100) = -26313.21, Epsilon = 0.260, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 1235: Reward = -36089.25, Avg Reward (100) = -26251.80, Epsilon = 0.259, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1236: Reward = -1049.00, Avg Reward (100) = -26488.23, Epsilon = 0.258, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1237: Reward = -1196.00, Avg Reward (100) = -26143.72, Epsilon = 0.258, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1238: Reward = -1147.00, Avg Reward (100) = -25518.08, Epsilon = 0.257, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1239: Reward = -1294.00, Avg Reward (100) = -25507.98, Epsilon = 0.257, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 1240: Reward = -39173.50, Avg Reward (100) = -25204.66, Epsilon = 0.256, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39173.50, Border Penalty: -35732.44, Obstacle Penalty: -50.00
Episode 1241: Reward = -1049.00, Avg Reward (100) = -25309.56, Epsilon = 0.255, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1242: Reward = -1049.00, Avg Reward (100) = -24965.06, Epsilon = 0.255, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1243: Reward = -34685.86, Avg Reward (100) = -24687.82, Epsilon = 0.254, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 1244: Reward = -1394.00, Avg Reward (100) = -25023.70, Epsilon = 0.254, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1245: Reward = -43968.81, Avg Reward (100) = -24660.95, Epsilon = 0.253, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43968.81, Border Penalty: -36640.77, Obstacle Penalty: -50.00
Episode 1246: Reward = -1049.00, Avg Reward (100) = -24784.10, Epsilon = 0.252, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1247: Reward = -37799.90, Avg Reward (100) = -24439.60, Epsilon = 0.252, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 1248: Reward = -1098.00, Avg Reward (100) = -24475.21, Epsilon = 0.251, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1249: Reward = -1098.00, Avg Reward (100) = -24131.20, Epsilon = 0.251, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1250: Reward = -59127.30, Avg Reward (100) = -24131.69, Epsilon = 0.250, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -59127.30, Border Penalty: -36104.90, Obstacle Penalty: -50.00
Episode 1251: Reward = -42166.28, Avg Reward (100) = -24367.97, Epsilon = 0.249, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42166.28, Border Penalty: -37401.79, Obstacle Penalty: -50.00
Episode 1252: Reward = -33701.04, Avg Reward (100) = -24434.63, Epsilon = 0.249, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1253: Reward = -1147.00, Avg Reward (100) = -24761.64, Epsilon = 0.248, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1254: Reward = -35756.20, Avg Reward (100) = -24405.85, Epsilon = 0.248, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -35756.20, Border Penalty: -32820.54, Obstacle Penalty: -50.00
Episode 1255: Reward = -54501.50, Avg Reward (100) = -24471.20, Epsilon = 0.247, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54501.50, Border Penalty: -40779.13, Obstacle Penalty: -50.00
Episode 1256: Reward = -28683.61, Avg Reward (100) = -24528.76, Epsilon = 0.246, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1257: Reward = -1098.00, Avg Reward (100) = -24460.60, Epsilon = 0.246, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1258: Reward = -28683.61, Avg Reward (100) = -24460.60, Epsilon = 0.245, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1259: Reward = -1147.00, Avg Reward (100) = -24167.60, Epsilon = 0.245, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1260: Reward = -1000.00, Avg Reward (100) = -23824.07, Epsilon = 0.244, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1261: Reward = -35499.61, Avg Reward (100) = -23538.95, Epsilon = 0.243, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1262: Reward = -43041.28, Avg Reward (100) = -23882.48, Epsilon = 0.243, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43041.28, Border Penalty: -35911.94, Obstacle Penalty: -50.00
Episode 1263: Reward = -1394.00, Avg Reward (100) = -24282.50, Epsilon = 0.242, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1264: Reward = -1000.00, Avg Reward (100) = -24283.99, Epsilon = 0.242, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1265: Reward = -1000.00, Avg Reward (100) = -23947.13, Epsilon = 0.241, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1266: Reward = -1147.00, Avg Reward (100) = -23945.17, Epsilon = 0.240, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1267: Reward = -1049.00, Avg Reward (100) = -23943.69, Epsilon = 0.240, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1268: Reward = -47266.13, Avg Reward (100) = -23599.18, Epsilon = 0.239, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47266.13, Border Penalty: -33507.87, Obstacle Penalty: -50.00
Episode 1269: Reward = -35499.61, Avg Reward (100) = -23577.88, Epsilon = 0.239, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1270: Reward = -32619.61, Avg Reward (100) = -23586.02, Epsilon = 0.238, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1271: Reward = -39409.45, Avg Reward (100) = -23901.72, Epsilon = 0.237, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39409.45, Border Penalty: -34826.64, Obstacle Penalty: -50.00
Episode 1272: Reward = -1000.00, Avg Reward (100) = -23880.27, Epsilon = 0.237, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1273: Reward = -27716.56, Avg Reward (100) = -23535.28, Epsilon = 0.236, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -27716.56, Border Penalty: -31132.37, Obstacle Penalty: -50.00
Episode 1274: Reward = -47848.55, Avg Reward (100) = -23801.46, Epsilon = 0.236, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1275: Reward = -1049.00, Avg Reward (100) = -23924.95, Epsilon = 0.235, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1276: Reward = -35499.61, Avg Reward (100) = -23924.95, Epsilon = 0.234, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1277: Reward = -29512.46, Avg Reward (100) = -24269.46, Epsilon = 0.234, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 1278: Reward = -1000.00, Avg Reward (100) = -24209.59, Epsilon = 0.233, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1279: Reward = -1000.00, Avg Reward (100) = -24210.27, Epsilon = 0.233, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1280: Reward = -35499.61, Avg Reward (100) = -23867.32, Epsilon = 0.232, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 1281: Reward = -35499.61, Avg Reward (100) = -23636.67, Epsilon = 0.231, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1282: Reward = -1147.00, Avg Reward (100) = -23980.68, Epsilon = 0.231, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1283: Reward = -36004.66, Avg Reward (100) = -23559.52, Epsilon = 0.230, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 1284: Reward = -32245.59, Avg Reward (100) = -23907.61, Epsilon = 0.230, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1285: Reward = -35499.61, Avg Reward (100) = -23875.07, Epsilon = 0.229, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1286: Reward = -40229.82, Avg Reward (100) = -23951.73, Epsilon = 0.228, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40229.82, Border Penalty: -36908.30, Obstacle Penalty: -50.00
Episode 1287: Reward = -26326.21, Avg Reward (100) = -23999.03, Epsilon = 0.228, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30324.92, Obstacle Penalty: -50.00
Episode 1288: Reward = -1098.00, Avg Reward (100) = -24014.92, Epsilon = 0.227, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1289: Reward = -1344.00, Avg Reward (100) = -23434.14, Epsilon = 0.227, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1290: Reward = -1049.00, Avg Reward (100) = -23436.60, Epsilon = 0.226, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1291: Reward = -54457.12, Avg Reward (100) = -23436.11, Epsilon = 0.225, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54457.12, Border Penalty: -41688.57, Obstacle Penalty: -50.00
Episode 1292: Reward = -61242.66, Avg Reward (100) = -23658.23, Epsilon = 0.225, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -37018.61, Obstacle Penalty: -50.00
Episode 1293: Reward = -1295.00, Avg Reward (100) = -23909.76, Epsilon = 0.224, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1294: Reward = -1049.00, Avg Reward (100) = -23908.78, Epsilon = 0.224, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1295: Reward = -1147.00, Avg Reward (100) = -23564.27, Epsilon = 0.223, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1296: Reward = -35499.61, Avg Reward (100) = -23220.75, Epsilon = 0.222, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1297: Reward = -32851.49, Avg Reward (100) = -23564.76, Epsilon = 0.222, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -32805.43, Obstacle Penalty: -50.00
Episode 1298: Reward = -1196.00, Avg Reward (100) = -23519.50, Epsilon = 0.221, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1299: Reward = -38414.23, Avg Reward (100) = -23154.76, Epsilon = 0.221, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -36175.60, Obstacle Penalty: -50.00
Episode 1300: Reward = -26061.91, Avg Reward (100) = -22885.65, Epsilon = 0.220, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26061.91, Border Penalty: -30748.40, Obstacle Penalty: -50.00
Episode 1301: Reward = -35499.61, Avg Reward (100) = -22811.41, Epsilon = 0.219, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1302: Reward = -36089.25, Avg Reward (100) = -23155.91, Epsilon = 0.219, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1303: Reward = -38791.47, Avg Reward (100) = -22936.97, Epsilon = 0.218, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -38791.47, Border Penalty: -34581.98, Obstacle Penalty: -50.00
Episode 1304: Reward = -29512.46, Avg Reward (100) = -23314.88, Epsilon = 0.218, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1305: Reward = -1196.00, Avg Reward (100) = -23599.03, Epsilon = 0.217, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1306: Reward = -47848.55, Avg Reward (100) = -23273.98, Epsilon = 0.216, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1307: Reward = -35499.61, Avg Reward (100) = -23465.63, Epsilon = 0.216, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1308: Reward = -35499.61, Avg Reward (100) = -23346.23, Epsilon = 0.215, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1309: Reward = -1147.00, Avg Reward (100) = -23690.74, Epsilon = 0.215, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1310: Reward = -34685.86, Avg Reward (100) = -23325.51, Epsilon = 0.214, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1311: Reward = -28683.61, Avg Reward (100) = -23126.08, Epsilon = 0.213, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1312: Reward = -31899.43, Avg Reward (100) = -23402.91, Epsilon = 0.213, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -31899.43, Border Penalty: -32444.46, Obstacle Penalty: -50.00
Episode 1313: Reward = -33701.04, Avg Reward (100) = -23384.90, Epsilon = 0.212, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1314: Reward = -27033.12, Avg Reward (100) = -23215.05, Epsilon = 0.212, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -27033.12, Border Penalty: -31473.43, Obstacle Penalty: -50.00
Episode 1315: Reward = -33469.53, Avg Reward (100) = -23473.91, Epsilon = 0.211, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1316: Reward = -29512.46, Avg Reward (100) = -23796.65, Epsilon = 0.210, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1317: Reward = -36089.25, Avg Reward (100) = -23736.78, Epsilon = 0.210, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1318: Reward = -39606.20, Avg Reward (100) = -23810.83, Epsilon = 0.209, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1319: Reward = -31163.36, Avg Reward (100) = -23765.42, Epsilon = 0.209, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31163.36, Border Penalty: -33115.60, Obstacle Penalty: -50.00
Episode 1320: Reward = -39369.19, Avg Reward (100) = -24066.07, Epsilon = 0.208, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -39369.19, Border Penalty: -37274.04, Obstacle Penalty: -50.00
Episode 1321: Reward = -1147.00, Avg Reward (100) = -24163.51, Epsilon = 0.207, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1322: Reward = -33701.04, Avg Reward (100) = -23678.71, Epsilon = 0.207, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -33409.77, Obstacle Penalty: -50.00
Episode 1323: Reward = -32720.85, Avg Reward (100) = -23681.03, Epsilon = 0.206, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -32720.85, Border Penalty: -33491.93, Obstacle Penalty: -50.00
Episode 1324: Reward = -28683.61, Avg Reward (100) = -23996.77, Epsilon = 0.206, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1325: Reward = -49626.26, Avg Reward (100) = -23946.59, Epsilon = 0.205, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1326: Reward = -35499.61, Avg Reward (100) = -24087.86, Epsilon = 0.204, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1327: Reward = -35499.61, Avg Reward (100) = -24108.16, Epsilon = 0.204, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1328: Reward = -33701.04, Avg Reward (100) = -24450.21, Epsilon = 0.203, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1329: Reward = -33469.53, Avg Reward (100) = -24254.25, Epsilon = 0.203, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1330: Reward = -33469.53, Avg Reward (100) = -24164.31, Epsilon = 0.202, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1331: Reward = -34164.73, Avg Reward (100) = -24161.99, Epsilon = 0.201, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 1332: Reward = -1295.00, Avg Reward (100) = -24491.68, Epsilon = 0.201, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1333: Reward = -37669.33, Avg Reward (100) = -24169.93, Epsilon = 0.200, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 1334: Reward = -1344.00, Avg Reward (100) = -24191.63, Epsilon = 0.200, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1335: Reward = -36089.25, Avg Reward (100) = -23911.49, Epsilon = 0.199, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1336: Reward = -35499.61, Avg Reward (100) = -23911.49, Epsilon = 0.198, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1337: Reward = -1295.00, Avg Reward (100) = -24255.99, Epsilon = 0.198, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1338: Reward = -35499.61, Avg Reward (100) = -24256.98, Epsilon = 0.197, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1339: Reward = -1000.00, Avg Reward (100) = -24600.51, Epsilon = 0.197, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1340: Reward = -27041.82, Avg Reward (100) = -24597.57, Epsilon = 0.196, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27041.82, Border Penalty: -30417.36, Obstacle Penalty: -50.00
Episode 1341: Reward = -35499.61, Avg Reward (100) = -24476.25, Epsilon = 0.195, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1342: Reward = -54799.21, Avg Reward (100) = -24820.76, Epsilon = 0.195, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54799.21, Border Penalty: -41940.29, Obstacle Penalty: -50.00
Episode 1343: Reward = -1196.00, Avg Reward (100) = -25358.26, Epsilon = 0.194, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1344: Reward = -43263.20, Avg Reward (100) = -25023.36, Epsilon = 0.194, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 1345: Reward = -1098.00, Avg Reward (100) = -25442.05, Epsilon = 0.193, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1346: Reward = -29626.05, Avg Reward (100) = -25013.34, Epsilon = 0.192, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 1347: Reward = -35499.61, Avg Reward (100) = -25299.12, Epsilon = 0.192, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1348: Reward = -33469.53, Avg Reward (100) = -25276.11, Epsilon = 0.191, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1349: Reward = -35499.61, Avg Reward (100) = -25599.83, Epsilon = 0.191, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1350: Reward = -1394.00, Avg Reward (100) = -25943.84, Epsilon = 0.190, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1351: Reward = -1049.00, Avg Reward (100) = -25366.51, Epsilon = 0.189, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1352: Reward = -35499.61, Avg Reward (100) = -24955.34, Epsilon = 0.189, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1353: Reward = -43902.06, Avg Reward (100) = -24973.32, Epsilon = 0.188, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 1354: Reward = -32245.59, Avg Reward (100) = -25400.87, Epsilon = 0.188, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1355: Reward = -37669.33, Avg Reward (100) = -25365.77, Epsilon = 0.187, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1356: Reward = -35499.61, Avg Reward (100) = -25197.45, Epsilon = 0.186, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1357: Reward = -51921.07, Avg Reward (100) = -25265.61, Epsilon = 0.186, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51921.07, Border Penalty: -39998.94, Obstacle Penalty: -50.00
Episode 1358: Reward = -35499.61, Avg Reward (100) = -25773.84, Epsilon = 0.185, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1359: Reward = -1000.00, Avg Reward (100) = -25842.00, Epsilon = 0.185, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1360: Reward = -12446.80, Avg Reward (100) = -25840.53, Epsilon = 0.184, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1361: Reward = -32245.59, Avg Reward (100) = -25954.99, Epsilon = 0.183, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1362: Reward = -49626.26, Avg Reward (100) = -25922.45, Epsilon = 0.183, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1363: Reward = -35499.61, Avg Reward (100) = -25988.30, Epsilon = 0.182, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1364: Reward = -35499.61, Avg Reward (100) = -26329.36, Epsilon = 0.182, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1365: Reward = -48772.41, Avg Reward (100) = -26674.36, Epsilon = 0.181, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48772.41, Border Penalty: -40113.36, Obstacle Penalty: -50.00
Episode 1366: Reward = -30549.19, Avg Reward (100) = -27152.08, Epsilon = 0.180, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30549.19, Border Penalty: -30639.42, Obstacle Penalty: -50.00
Episode 1367: Reward = -44507.68, Avg Reward (100) = -27446.10, Epsilon = 0.180, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 1368: Reward = -28683.61, Avg Reward (100) = -27880.69, Epsilon = 0.179, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1369: Reward = -35499.61, Avg Reward (100) = -27694.86, Epsilon = 0.179, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1370: Reward = -35499.61, Avg Reward (100) = -27694.86, Epsilon = 0.178, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1371: Reward = -1450.40, Avg Reward (100) = -27723.66, Epsilon = 0.177, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 1372: Reward = -59559.35, Avg Reward (100) = -27344.07, Epsilon = 0.177, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -59559.35, Border Penalty: -40456.77, Obstacle Penalty: -50.00
Episode 1373: Reward = -25228.52, Avg Reward (100) = -27929.67, Epsilon = 0.176, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1374: Reward = -1394.00, Avg Reward (100) = -27904.79, Epsilon = 0.176, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1375: Reward = -1147.00, Avg Reward (100) = -27440.24, Epsilon = 0.175, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1376: Reward = -1196.00, Avg Reward (100) = -27441.22, Epsilon = 0.174, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1377: Reward = -35499.61, Avg Reward (100) = -27098.18, Epsilon = 0.174, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1378: Reward = -35499.61, Avg Reward (100) = -27158.06, Epsilon = 0.173, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1379: Reward = -49176.10, Avg Reward (100) = -27503.05, Epsilon = 0.173, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1380: Reward = -32619.61, Avg Reward (100) = -27984.81, Epsilon = 0.172, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1381: Reward = -49626.26, Avg Reward (100) = -27956.01, Epsilon = 0.171, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 1382: Reward = -1394.00, Avg Reward (100) = -28097.28, Epsilon = 0.171, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1383: Reward = -1000.00, Avg Reward (100) = -28099.75, Epsilon = 0.170, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1384: Reward = -35499.61, Avg Reward (100) = -27749.70, Epsilon = 0.170, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1385: Reward = -1686.15, Avg Reward (100) = -27782.24, Epsilon = 0.169, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -1686.15, Border Penalty: -2143.31, Obstacle Penalty: -64.28
Episode 1386: Reward = -32235.76, Avg Reward (100) = -27444.11, Epsilon = 0.168, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 1387: Reward = -1000.00, Avg Reward (100) = -27364.17, Epsilon = 0.168, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1388: Reward = -35499.61, Avg Reward (100) = -27110.91, Epsilon = 0.167, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1389: Reward = -38625.36, Avg Reward (100) = -27454.92, Epsilon = 0.167, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38625.36, Border Penalty: -36583.92, Obstacle Penalty: -50.00
Episode 1390: Reward = -1098.00, Avg Reward (100) = -27827.74, Epsilon = 0.166, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1391: Reward = -35499.61, Avg Reward (100) = -27828.23, Epsilon = 0.165, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1392: Reward = -1252.40, Avg Reward (100) = -27638.65, Epsilon = 0.165, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1393: Reward = -25228.52, Avg Reward (100) = -27038.75, Epsilon = 0.164, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1394: Reward = -47477.73, Avg Reward (100) = -27278.08, Epsilon = 0.164, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47477.73, Border Penalty: -38905.30, Obstacle Penalty: -50.00
Episode 1395: Reward = -35499.61, Avg Reward (100) = -27742.37, Epsilon = 0.163, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1396: Reward = -25228.52, Avg Reward (100) = -28085.90, Epsilon = 0.162, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1397: Reward = -32619.61, Avg Reward (100) = -27983.19, Epsilon = 0.162, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1398: Reward = -35499.61, Avg Reward (100) = -27980.87, Epsilon = 0.161, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1399: Reward = -1295.00, Avg Reward (100) = -28323.90, Epsilon = 0.161, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1400: Reward = -35499.61, Avg Reward (100) = -27952.71, Epsilon = 0.160, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1401: Reward = -37403.42, Avg Reward (100) = -28047.09, Epsilon = 0.159, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -37403.42, Border Penalty: -36208.14, Obstacle Penalty: -50.00
Episode 1402: Reward = -1098.00, Avg Reward (100) = -28066.13, Epsilon = 0.159, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1403: Reward = -1147.00, Avg Reward (100) = -27716.21, Epsilon = 0.158, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1404: Reward = -1098.00, Avg Reward (100) = -27339.77, Epsilon = 0.158, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1405: Reward = -25228.52, Avg Reward (100) = -27055.62, Epsilon = 0.157, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1406: Reward = -35499.61, Avg Reward (100) = -27295.95, Epsilon = 0.156, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1407: Reward = -35499.61, Avg Reward (100) = -27172.46, Epsilon = 0.156, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1408: Reward = -35499.61, Avg Reward (100) = -27172.46, Epsilon = 0.155, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1409: Reward = -1196.00, Avg Reward (100) = -27172.46, Epsilon = 0.155, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1410: Reward = -1245.00, Avg Reward (100) = -27172.95, Epsilon = 0.154, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1411: Reward = -29879.41, Avg Reward (100) = -26838.54, Epsilon = 0.153, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -29879.41, Border Penalty: -31642.21, Obstacle Penalty: -50.00
Episode 1412: Reward = -35499.61, Avg Reward (100) = -26850.50, Epsilon = 0.153, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1413: Reward = -26943.44, Avg Reward (100) = -26886.50, Epsilon = 0.152, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26943.44, Border Penalty: -30802.15, Obstacle Penalty: -50.00
Episode 1414: Reward = -32815.85, Avg Reward (100) = -26818.93, Epsilon = 0.152, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 1415: Reward = -33701.04, Avg Reward (100) = -26876.75, Epsilon = 0.151, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1416: Reward = -30447.02, Avg Reward (100) = -26879.07, Epsilon = 0.150, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -32385.11, Obstacle Penalty: -50.00
Episode 1417: Reward = -35499.61, Avg Reward (100) = -26888.41, Epsilon = 0.150, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1418: Reward = -34685.86, Avg Reward (100) = -26882.52, Epsilon = 0.149, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 1419: Reward = -35499.61, Avg Reward (100) = -26833.31, Epsilon = 0.149, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1420: Reward = -35499.61, Avg Reward (100) = -26876.68, Epsilon = 0.148, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1421: Reward = -35499.61, Avg Reward (100) = -26837.98, Epsilon = 0.147, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1422: Reward = -35499.61, Avg Reward (100) = -27181.51, Epsilon = 0.147, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1423: Reward = -35499.61, Avg Reward (100) = -27199.49, Epsilon = 0.146, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1424: Reward = -21549.43, Avg Reward (100) = -27227.28, Epsilon = 0.146, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -21549.43, Border Penalty: -27427.83, Obstacle Penalty: -50.00
Episode 1425: Reward = -49626.26, Avg Reward (100) = -27155.94, Epsilon = 0.145, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1426: Reward = -1393.00, Avg Reward (100) = -27155.94, Epsilon = 0.144, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1427: Reward = -35499.61, Avg Reward (100) = -26814.87, Epsilon = 0.144, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1428: Reward = -35499.61, Avg Reward (100) = -26814.87, Epsilon = 0.143, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1429: Reward = -1147.00, Avg Reward (100) = -26832.86, Epsilon = 0.143, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1430: Reward = -54604.04, Avg Reward (100) = -26509.63, Epsilon = 0.142, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54604.04, Border Penalty: -41409.95, Obstacle Penalty: -50.00
Episode 1431: Reward = -35499.61, Avg Reward (100) = -26720.98, Epsilon = 0.141, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1432: Reward = -1000.00, Avg Reward (100) = -26734.33, Epsilon = 0.141, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1433: Reward = -34685.86, Avg Reward (100) = -26731.38, Epsilon = 0.140, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1434: Reward = -1000.00, Avg Reward (100) = -26701.54, Epsilon = 0.140, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1435: Reward = -1049.00, Avg Reward (100) = -26698.10, Epsilon = 0.139, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1436: Reward = -35499.61, Avg Reward (100) = -26347.70, Epsilon = 0.138, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1437: Reward = -35499.61, Avg Reward (100) = -26347.70, Epsilon = 0.138, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1438: Reward = -35499.61, Avg Reward (100) = -26689.74, Epsilon = 0.137, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1439: Reward = -35499.61, Avg Reward (100) = -26689.74, Epsilon = 0.137, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1440: Reward = -35499.61, Avg Reward (100) = -27034.74, Epsilon = 0.136, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1441: Reward = -1394.00, Avg Reward (100) = -27119.32, Epsilon = 0.135, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1442: Reward = -35499.61, Avg Reward (100) = -26778.26, Epsilon = 0.135, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1443: Reward = -64599.90, Avg Reward (100) = -26585.27, Epsilon = 0.134, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -64599.90, Border Penalty: -39729.39, Obstacle Penalty: -50.00
Episode 1444: Reward = -35499.61, Avg Reward (100) = -27219.31, Epsilon = 0.134, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1445: Reward = -35499.61, Avg Reward (100) = -27141.67, Epsilon = 0.133, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1446: Reward = -1098.00, Avg Reward (100) = -27485.69, Epsilon = 0.132, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1447: Reward = -35499.61, Avg Reward (100) = -27200.40, Epsilon = 0.132, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1448: Reward = -39606.20, Avg Reward (100) = -27200.40, Epsilon = 0.131, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1449: Reward = -29512.46, Avg Reward (100) = -27261.77, Epsilon = 0.131, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1450: Reward = -1196.00, Avg Reward (100) = -27201.90, Epsilon = 0.130, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1451: Reward = -53595.81, Avg Reward (100) = -27199.92, Epsilon = 0.129, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53595.81, Border Penalty: -41871.31, Obstacle Penalty: -50.00
Episode 1452: Reward = -35499.61, Avg Reward (100) = -27725.39, Epsilon = 0.129, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1453: Reward = -1147.00, Avg Reward (100) = -27725.39, Epsilon = 0.128, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1454: Reward = -1000.00, Avg Reward (100) = -27297.84, Epsilon = 0.128, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1455: Reward = -35499.61, Avg Reward (100) = -26985.38, Epsilon = 0.127, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1456: Reward = -1000.00, Avg Reward (100) = -26963.68, Epsilon = 0.126, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1457: Reward = -35499.61, Avg Reward (100) = -26618.69, Epsilon = 0.126, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1458: Reward = -35499.61, Avg Reward (100) = -26454.47, Epsilon = 0.125, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1459: Reward = -33701.04, Avg Reward (100) = -26454.47, Epsilon = 0.125, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -33286.29, Obstacle Penalty: -50.00
Episode 1460: Reward = -43263.20, Avg Reward (100) = -26781.48, Epsilon = 0.124, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1461: Reward = -1000.00, Avg Reward (100) = -27089.65, Epsilon = 0.123, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1462: Reward = -39645.35, Avg Reward (100) = -26777.19, Epsilon = 0.123, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39645.35, Border Penalty: -32136.45, Obstacle Penalty: -50.00
Episode 1463: Reward = -35499.61, Avg Reward (100) = -26677.38, Epsilon = 0.122, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1464: Reward = -36791.87, Avg Reward (100) = -26677.38, Epsilon = 0.122, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36791.87, Border Penalty: -35260.12, Obstacle Penalty: -50.00
Episode 1465: Reward = -35499.61, Avg Reward (100) = -26690.31, Epsilon = 0.121, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1466: Reward = -35499.61, Avg Reward (100) = -26557.58, Epsilon = 0.120, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1467: Reward = -32245.59, Avg Reward (100) = -26607.08, Epsilon = 0.120, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1468: Reward = -1196.00, Avg Reward (100) = -26484.46, Epsilon = 0.119, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1469: Reward = -35499.61, Avg Reward (100) = -26209.58, Epsilon = 0.119, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1470: Reward = -34685.86, Avg Reward (100) = -26209.58, Epsilon = 0.118, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 1471: Reward = -1147.00, Avg Reward (100) = -26201.45, Epsilon = 0.117, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1472: Reward = -28772.37, Avg Reward (100) = -26198.41, Epsilon = 0.117, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 1473: Reward = -49626.26, Avg Reward (100) = -25890.54, Epsilon = 0.116, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1474: Reward = -35499.61, Avg Reward (100) = -26134.52, Epsilon = 0.116, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1475: Reward = -35499.61, Avg Reward (100) = -26475.58, Epsilon = 0.115, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1476: Reward = -32245.59, Avg Reward (100) = -26819.10, Epsilon = 0.114, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1477: Reward = -35499.61, Avg Reward (100) = -27129.60, Epsilon = 0.114, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1478: Reward = -35499.61, Avg Reward (100) = -27129.60, Epsilon = 0.113, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1479: Reward = -1295.00, Avg Reward (100) = -27129.60, Epsilon = 0.113, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1480: Reward = -1394.00, Avg Reward (100) = -26650.79, Epsilon = 0.112, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1481: Reward = -28653.56, Avg Reward (100) = -26338.53, Epsilon = 0.111, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1482: Reward = -35499.61, Avg Reward (100) = -26128.80, Epsilon = 0.111, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1483: Reward = -1049.00, Avg Reward (100) = -26469.86, Epsilon = 0.110, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1484: Reward = -28683.61, Avg Reward (100) = -26470.35, Epsilon = 0.110, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1485: Reward = -35499.61, Avg Reward (100) = -26402.19, Epsilon = 0.109, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1486: Reward = -35499.61, Avg Reward (100) = -26740.33, Epsilon = 0.108, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1487: Reward = -28683.61, Avg Reward (100) = -26772.96, Epsilon = 0.108, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1488: Reward = -1000.00, Avg Reward (100) = -27049.80, Epsilon = 0.107, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1489: Reward = -37669.33, Avg Reward (100) = -26704.80, Epsilon = 0.107, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1490: Reward = -43263.20, Avg Reward (100) = -26695.24, Epsilon = 0.106, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1491: Reward = -35499.61, Avg Reward (100) = -27116.90, Epsilon = 0.105, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1492: Reward = -35499.61, Avg Reward (100) = -27116.90, Epsilon = 0.105, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1493: Reward = -33701.04, Avg Reward (100) = -27459.37, Epsilon = 0.104, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1494: Reward = -35499.61, Avg Reward (100) = -27544.09, Epsilon = 0.104, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1495: Reward = -28653.56, Avg Reward (100) = -27424.31, Epsilon = 0.103, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1496: Reward = -35499.61, Avg Reward (100) = -27355.85, Epsilon = 0.102, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1497: Reward = -35499.61, Avg Reward (100) = -27458.56, Epsilon = 0.102, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1498: Reward = -35499.61, Avg Reward (100) = -27487.36, Epsilon = 0.101, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1499: Reward = -35499.61, Avg Reward (100) = -27487.36, Epsilon = 0.101, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1500: Reward = -43263.20, Avg Reward (100) = -27829.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1501: Reward = -33469.53, Avg Reward (100) = -27907.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1502: Reward = -35499.61, Avg Reward (100) = -27867.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1503: Reward = -35499.61, Avg Reward (100) = -28211.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1504: Reward = -1196.00, Avg Reward (100) = -28555.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1505: Reward = -35499.61, Avg Reward (100) = -28556.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1506: Reward = -35499.61, Avg Reward (100) = -28658.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1507: Reward = -35499.61, Avg Reward (100) = -28658.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1508: Reward = -35499.61, Avg Reward (100) = -28658.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1509: Reward = -35499.61, Avg Reward (100) = -28658.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1510: Reward = -35499.61, Avg Reward (100) = -29001.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1511: Reward = -1147.00, Avg Reward (100) = -29344.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1512: Reward = -28653.56, Avg Reward (100) = -29057.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1513: Reward = -35499.61, Avg Reward (100) = -28988.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1514: Reward = -35499.61, Avg Reward (100) = -29074.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1515: Reward = -35499.61, Avg Reward (100) = -29101.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1516: Reward = -2172.03, Avg Reward (100) = -29119.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -2172.03, Border Penalty: -9738.44, Obstacle Penalty: -50.00
Episode 1517: Reward = -42504.46, Avg Reward (100) = -28836.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42504.46, Border Penalty: -37949.78, Obstacle Penalty: -50.00
Episode 1518: Reward = -35499.61, Avg Reward (100) = -28906.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1519: Reward = -35499.61, Avg Reward (100) = -28914.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1520: Reward = -35499.61, Avg Reward (100) = -28914.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1521: Reward = -1000.00, Avg Reward (100) = -28914.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1522: Reward = -35499.61, Avg Reward (100) = -28569.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1523: Reward = -34685.86, Avg Reward (100) = -28569.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1524: Reward = -1049.00, Avg Reward (100) = -28561.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1525: Reward = -35499.61, Avg Reward (100) = -28356.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1526: Reward = -35499.61, Avg Reward (100) = -28215.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1527: Reward = -1147.00, Avg Reward (100) = -28556.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1528: Reward = -32619.61, Avg Reward (100) = -28212.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1529: Reward = -1098.00, Avg Reward (100) = -28183.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1530: Reward = -1000.00, Avg Reward (100) = -28183.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1531: Reward = -25228.52, Avg Reward (100) = -27647.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1532: Reward = -35499.61, Avg Reward (100) = -27544.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1533: Reward = -35499.61, Avg Reward (100) = -27889.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1534: Reward = -35499.61, Avg Reward (100) = -27897.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1535: Reward = -32235.76, Avg Reward (100) = -28242.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 1536: Reward = -35499.61, Avg Reward (100) = -28554.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1537: Reward = -49929.11, Avg Reward (100) = -28554.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 1538: Reward = -32619.61, Avg Reward (100) = -28698.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1539: Reward = -35499.61, Avg Reward (100) = -28670.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1540: Reward = -35499.61, Avg Reward (100) = -28670.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1541: Reward = -35499.61, Avg Reward (100) = -28670.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1542: Reward = -35499.61, Avg Reward (100) = -29011.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1543: Reward = -35499.61, Avg Reward (100) = -29011.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1544: Reward = -35499.61, Avg Reward (100) = -28720.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1545: Reward = -1394.00, Avg Reward (100) = -28720.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1546: Reward = -35499.61, Avg Reward (100) = -28379.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 1547: Reward = -35499.61, Avg Reward (100) = -28723.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1548: Reward = -25228.52, Avg Reward (100) = -28723.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1549: Reward = -35499.61, Avg Reward (100) = -28579.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1550: Reward = -35499.61, Avg Reward (100) = -28639.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1551: Reward = -39606.20, Avg Reward (100) = -28982.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1552: Reward = -35499.61, Avg Reward (100) = -28842.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1553: Reward = -35499.61, Avg Reward (100) = -28842.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1554: Reward = -35499.61, Avg Reward (100) = -29185.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1555: Reward = -1295.00, Avg Reward (100) = -29530.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1556: Reward = -47848.55, Avg Reward (100) = -29188.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1557: Reward = -35499.61, Avg Reward (100) = -29657.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1558: Reward = -1049.00, Avg Reward (100) = -29657.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1559: Reward = -35499.61, Avg Reward (100) = -29312.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1560: Reward = -35499.61, Avg Reward (100) = -29330.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1561: Reward = -1394.00, Avg Reward (100) = -29253.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1562: Reward = -35499.61, Avg Reward (100) = -29257.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1563: Reward = -35499.61, Avg Reward (100) = -29215.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1564: Reward = -35499.61, Avg Reward (100) = -29215.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1565: Reward = -35499.61, Avg Reward (100) = -29202.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1566: Reward = -47848.55, Avg Reward (100) = -29202.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1567: Reward = -35499.61, Avg Reward (100) = -29326.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1568: Reward = -37669.33, Avg Reward (100) = -29358.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1569: Reward = -35499.61, Avg Reward (100) = -29723.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1570: Reward = -35499.61, Avg Reward (100) = -29723.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1571: Reward = -1147.00, Avg Reward (100) = -29731.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1572: Reward = -29512.46, Avg Reward (100) = -29731.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1573: Reward = -35499.61, Avg Reward (100) = -29739.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1574: Reward = -35499.61, Avg Reward (100) = -29597.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1575: Reward = -49176.10, Avg Reward (100) = -29597.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1576: Reward = -35499.61, Avg Reward (100) = -29734.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1577: Reward = -35499.61, Avg Reward (100) = -29767.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1578: Reward = -1000.00, Avg Reward (100) = -29767.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1579: Reward = -35499.61, Avg Reward (100) = -29422.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1580: Reward = -35499.61, Avg Reward (100) = -29764.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1581: Reward = -35499.61, Avg Reward (100) = -30105.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1582: Reward = -35499.61, Avg Reward (100) = -30173.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1583: Reward = -35499.61, Avg Reward (100) = -30173.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1584: Reward = -35499.61, Avg Reward (100) = -30518.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1585: Reward = -12446.80, Avg Reward (100) = -30586.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1586: Reward = -35499.61, Avg Reward (100) = -30355.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1587: Reward = -35499.61, Avg Reward (100) = -30355.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1588: Reward = -35499.61, Avg Reward (100) = -30423.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1589: Reward = -35499.61, Avg Reward (100) = -30768.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1590: Reward = -35499.61, Avg Reward (100) = -30747.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1591: Reward = -35499.61, Avg Reward (100) = -30669.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1592: Reward = -35499.61, Avg Reward (100) = -30669.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1593: Reward = -30549.19, Avg Reward (100) = -30669.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30549.19, Border Penalty: -30639.42, Obstacle Penalty: -50.00
Episode 1594: Reward = -35499.61, Avg Reward (100) = -30638.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1595: Reward = -35499.61, Avg Reward (100) = -30638.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1596: Reward = -35499.61, Avg Reward (100) = -30706.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1597: Reward = -35499.61, Avg Reward (100) = -30706.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1598: Reward = -1049.00, Avg Reward (100) = -30706.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1599: Reward = -35499.61, Avg Reward (100) = -30362.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1600: Reward = -35499.61, Avg Reward (100) = -30362.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1601: Reward = -25228.52, Avg Reward (100) = -30284.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1602: Reward = -35499.61, Avg Reward (100) = -30202.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1603: Reward = -35499.61, Avg Reward (100) = -30202.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1604: Reward = -35499.61, Avg Reward (100) = -30202.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1605: Reward = -35499.61, Avg Reward (100) = -30545.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1606: Reward = -25228.52, Avg Reward (100) = -30545.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1607: Reward = -35499.61, Avg Reward (100) = -30442.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1608: Reward = -35499.61, Avg Reward (100) = -30442.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1609: Reward = -42304.65, Avg Reward (100) = -30442.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 1610: Reward = -35499.61, Avg Reward (100) = -30510.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1611: Reward = -35499.61, Avg Reward (100) = -30510.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1612: Reward = -43902.06, Avg Reward (100) = -30853.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -37555.93, Obstacle Penalty: -50.00
Episode 1613: Reward = -35499.61, Avg Reward (100) = -31006.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1614: Reward = -1098.00, Avg Reward (100) = -31006.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1615: Reward = -35499.61, Avg Reward (100) = -30662.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1616: Reward = -1000.00, Avg Reward (100) = -30662.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1617: Reward = -35499.61, Avg Reward (100) = -30650.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1618: Reward = -28683.61, Avg Reward (100) = -30580.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1619: Reward = -35499.61, Avg Reward (100) = -30512.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1620: Reward = -35499.61, Avg Reward (100) = -30512.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1621: Reward = -1394.00, Avg Reward (100) = -30512.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1622: Reward = -1147.00, Avg Reward (100) = -30516.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1623: Reward = -35499.61, Avg Reward (100) = -30172.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1624: Reward = -35499.61, Avg Reward (100) = -30181.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1625: Reward = -1394.00, Avg Reward (100) = -30525.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1626: Reward = -64323.13, Avg Reward (100) = -30184.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -64323.13, Border Penalty: -35559.55, Obstacle Penalty: -50.00
Episode 1627: Reward = -1294.00, Avg Reward (100) = -30472.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1628: Reward = -35499.61, Avg Reward (100) = -30474.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1629: Reward = -1049.00, Avg Reward (100) = -30502.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1630: Reward = -35499.61, Avg Reward (100) = -30502.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1631: Reward = -35499.61, Avg Reward (100) = -30847.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1632: Reward = -35499.61, Avg Reward (100) = -30950.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1633: Reward = -35499.61, Avg Reward (100) = -30950.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1634: Reward = -35499.61, Avg Reward (100) = -30950.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1635: Reward = -35499.61, Avg Reward (100) = -30950.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1636: Reward = -33469.53, Avg Reward (100) = -30982.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1637: Reward = -35499.61, Avg Reward (100) = -30962.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1638: Reward = -1147.00, Avg Reward (100) = -30818.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1639: Reward = -35499.61, Avg Reward (100) = -30503.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1640: Reward = -25228.52, Avg Reward (100) = -30503.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1641: Reward = -35499.61, Avg Reward (100) = -30400.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1642: Reward = -1000.00, Avg Reward (100) = -30400.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1643: Reward = -35499.61, Avg Reward (100) = -30055.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1644: Reward = -35499.61, Avg Reward (100) = -30055.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1645: Reward = -37669.33, Avg Reward (100) = -30055.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1646: Reward = -35499.61, Avg Reward (100) = -30418.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1647: Reward = -35499.61, Avg Reward (100) = -30418.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1648: Reward = -35499.61, Avg Reward (100) = -30418.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1649: Reward = -1295.00, Avg Reward (100) = -30521.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1650: Reward = -47848.55, Avg Reward (100) = -30179.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1651: Reward = -35499.61, Avg Reward (100) = -30302.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1652: Reward = -49176.10, Avg Reward (100) = -30261.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1653: Reward = -35499.61, Avg Reward (100) = -30398.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1654: Reward = -35499.61, Avg Reward (100) = -30398.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1655: Reward = -35499.61, Avg Reward (100) = -30398.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1656: Reward = -58564.79, Avg Reward (100) = -30740.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 1657: Reward = -35499.61, Avg Reward (100) = -30847.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1658: Reward = -42112.30, Avg Reward (100) = -30847.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 1659: Reward = -1049.00, Avg Reward (100) = -31258.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1660: Reward = -35499.61, Avg Reward (100) = -30913.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1661: Reward = -35499.61, Avg Reward (100) = -30913.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1662: Reward = -35499.61, Avg Reward (100) = -31254.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1663: Reward = -35499.61, Avg Reward (100) = -31254.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1664: Reward = -35499.61, Avg Reward (100) = -31254.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1665: Reward = -1147.00, Avg Reward (100) = -31254.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1666: Reward = -35499.61, Avg Reward (100) = -30911.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1667: Reward = -35499.61, Avg Reward (100) = -30787.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1668: Reward = -35499.61, Avg Reward (100) = -30787.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1669: Reward = -35499.61, Avg Reward (100) = -30766.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1670: Reward = -12446.80, Avg Reward (100) = -30766.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1671: Reward = -35499.61, Avg Reward (100) = -30535.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1672: Reward = -35499.61, Avg Reward (100) = -30879.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1673: Reward = -29512.46, Avg Reward (100) = -30938.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1674: Reward = -49176.10, Avg Reward (100) = -30879.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1675: Reward = -35499.61, Avg Reward (100) = -31015.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1676: Reward = -35499.61, Avg Reward (100) = -30879.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1677: Reward = -32245.59, Avg Reward (100) = -30879.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1678: Reward = -35499.61, Avg Reward (100) = -30846.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1679: Reward = -35499.61, Avg Reward (100) = -31191.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1680: Reward = -35499.61, Avg Reward (100) = -31191.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1681: Reward = -33469.53, Avg Reward (100) = -31191.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1682: Reward = -35499.61, Avg Reward (100) = -31171.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1683: Reward = -35499.61, Avg Reward (100) = -31171.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1684: Reward = -1394.00, Avg Reward (100) = -31171.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1685: Reward = -12446.80, Avg Reward (100) = -30830.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1686: Reward = -12446.80, Avg Reward (100) = -30830.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1687: Reward = -1196.00, Avg Reward (100) = -30599.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1688: Reward = -35499.61, Avg Reward (100) = -30256.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1689: Reward = -38792.44, Avg Reward (100) = -30256.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 1690: Reward = -25228.52, Avg Reward (100) = -30289.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1691: Reward = -35499.61, Avg Reward (100) = -30186.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 1692: Reward = -35499.61, Avg Reward (100) = -30186.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1693: Reward = -35499.61, Avg Reward (100) = -30186.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1694: Reward = -35499.61, Avg Reward (100) = -30236.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1695: Reward = -35499.61, Avg Reward (100) = -30236.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1696: Reward = -28653.56, Avg Reward (100) = -30236.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1697: Reward = -35499.61, Avg Reward (100) = -30167.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1698: Reward = -35499.61, Avg Reward (100) = -30167.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1699: Reward = -35499.61, Avg Reward (100) = -30512.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1700: Reward = -35499.61, Avg Reward (100) = -30512.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1701: Reward = -1049.00, Avg Reward (100) = -30512.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1702: Reward = -1049.00, Avg Reward (100) = -30270.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1703: Reward = -35499.61, Avg Reward (100) = -29926.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1704: Reward = -1098.00, Avg Reward (100) = -29926.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1705: Reward = -35499.61, Avg Reward (100) = -29582.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1706: Reward = -41554.36, Avg Reward (100) = -29582.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 1707: Reward = -35499.61, Avg Reward (100) = -29745.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1708: Reward = -1098.00, Avg Reward (100) = -29745.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1709: Reward = -33469.53, Avg Reward (100) = -29401.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 1710: Reward = -48252.80, Avg Reward (100) = -29312.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 1711: Reward = -35499.61, Avg Reward (100) = -29440.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1712: Reward = -35499.61, Avg Reward (100) = -29440.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1713: Reward = -1049.00, Avg Reward (100) = -29356.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1714: Reward = -35499.61, Avg Reward (100) = -29011.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1715: Reward = -35499.61, Avg Reward (100) = -29355.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1716: Reward = -1147.00, Avg Reward (100) = -29355.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1717: Reward = -55155.70, Avg Reward (100) = -29357.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -55155.70, Border Penalty: -39717.51, Obstacle Penalty: -50.00
Episode 1718: Reward = -35499.61, Avg Reward (100) = -29554.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1719: Reward = -35499.61, Avg Reward (100) = -29622.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1720: Reward = -35499.61, Avg Reward (100) = -29622.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1721: Reward = -32245.59, Avg Reward (100) = -29622.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1722: Reward = -35499.61, Avg Reward (100) = -29930.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1723: Reward = -35499.61, Avg Reward (100) = -30274.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1724: Reward = -35499.61, Avg Reward (100) = -30274.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1725: Reward = -35499.61, Avg Reward (100) = -30274.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1726: Reward = -35499.61, Avg Reward (100) = -30615.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1727: Reward = -47054.80, Avg Reward (100) = -30327.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47054.80, Border Penalty: -37715.52, Obstacle Penalty: -50.00
Episode 1728: Reward = -35499.61, Avg Reward (100) = -30784.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1729: Reward = -33469.53, Avg Reward (100) = -30784.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 1730: Reward = -35499.61, Avg Reward (100) = -31108.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 1731: Reward = -35499.61, Avg Reward (100) = -31108.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1732: Reward = -35499.61, Avg Reward (100) = -31108.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1733: Reward = -35499.61, Avg Reward (100) = -31108.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1734: Reward = -32619.61, Avg Reward (100) = -31108.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1735: Reward = -1147.00, Avg Reward (100) = -31080.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1736: Reward = -35499.61, Avg Reward (100) = -30736.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1737: Reward = -35499.61, Avg Reward (100) = -30756.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1738: Reward = -35499.61, Avg Reward (100) = -30756.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1739: Reward = -48016.18, Avg Reward (100) = -31100.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48016.18, Border Penalty: -39202.87, Obstacle Penalty: -50.00
Episode 1740: Reward = -35499.61, Avg Reward (100) = -31225.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1741: Reward = -35499.61, Avg Reward (100) = -31328.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1742: Reward = -1394.00, Avg Reward (100) = -31328.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1743: Reward = -35499.61, Avg Reward (100) = -31332.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1744: Reward = -35499.61, Avg Reward (100) = -31332.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1745: Reward = -1147.00, Avg Reward (100) = -31332.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1746: Reward = -35499.61, Avg Reward (100) = -30966.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1747: Reward = -35499.61, Avg Reward (100) = -30966.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1748: Reward = -35499.61, Avg Reward (100) = -30966.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1749: Reward = -39606.20, Avg Reward (100) = -30966.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1750: Reward = -35499.61, Avg Reward (100) = -31350.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1751: Reward = -30665.53, Avg Reward (100) = -31226.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30665.53, Border Penalty: -33265.66, Obstacle Penalty: -50.00
Episode 1752: Reward = -1098.00, Avg Reward (100) = -31178.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1753: Reward = -28653.56, Avg Reward (100) = -30697.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1754: Reward = -35499.61, Avg Reward (100) = -30628.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1755: Reward = -47848.55, Avg Reward (100) = -30628.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1756: Reward = -35499.61, Avg Reward (100) = -30752.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1757: Reward = -1049.00, Avg Reward (100) = -30521.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1758: Reward = -35499.61, Avg Reward (100) = -30177.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1759: Reward = -39606.20, Avg Reward (100) = -30111.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1760: Reward = -39606.20, Avg Reward (100) = -30496.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1761: Reward = -35499.61, Avg Reward (100) = -30537.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1762: Reward = -35499.61, Avg Reward (100) = -30537.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1763: Reward = -1000.00, Avg Reward (100) = -30537.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1764: Reward = -35499.61, Avg Reward (100) = -30192.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1765: Reward = -34482.45, Avg Reward (100) = -30192.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 1766: Reward = -35499.61, Avg Reward (100) = -30526.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1767: Reward = -35499.61, Avg Reward (100) = -30526.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1768: Reward = -50498.83, Avg Reward (100) = -30526.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50498.83, Border Penalty: -40565.62, Obstacle Penalty: -50.00
Episode 1769: Reward = -35499.61, Avg Reward (100) = -30676.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1770: Reward = -39048.07, Avg Reward (100) = -30676.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -39048.07, Border Penalty: -36987.13, Obstacle Penalty: -50.00
Episode 1771: Reward = -1049.00, Avg Reward (100) = -30942.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1772: Reward = -1147.00, Avg Reward (100) = -30597.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1773: Reward = -41554.36, Avg Reward (100) = -30254.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 1774: Reward = -1049.00, Avg Reward (100) = -30374.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1775: Reward = -35499.61, Avg Reward (100) = -29893.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1776: Reward = -34927.46, Avg Reward (100) = -29893.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 1777: Reward = -34685.86, Avg Reward (100) = -29887.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1778: Reward = -35499.61, Avg Reward (100) = -29911.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1779: Reward = -34741.98, Avg Reward (100) = -29911.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 1780: Reward = -35499.61, Avg Reward (100) = -29904.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1781: Reward = -35499.61, Avg Reward (100) = -29904.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1782: Reward = -33701.04, Avg Reward (100) = -29924.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1783: Reward = -35499.61, Avg Reward (100) = -29906.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1784: Reward = -35499.61, Avg Reward (100) = -29906.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1785: Reward = -1394.00, Avg Reward (100) = -30247.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1786: Reward = -35499.61, Avg Reward (100) = -30137.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1787: Reward = -51880.45, Avg Reward (100) = -30367.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51880.45, Border Penalty: -41312.12, Obstacle Penalty: -50.00
Episode 1788: Reward = -1098.00, Avg Reward (100) = -30874.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1789: Reward = -26470.74, Avg Reward (100) = -30530.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 1790: Reward = -35499.61, Avg Reward (100) = -30407.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1791: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1792: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1793: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1794: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1795: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1796: Reward = -35499.61, Avg Reward (100) = -30510.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1797: Reward = -1393.00, Avg Reward (100) = -30578.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1798: Reward = -44507.68, Avg Reward (100) = -30237.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 1799: Reward = -28653.56, Avg Reward (100) = -30327.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1800: Reward = -35499.61, Avg Reward (100) = -30259.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1801: Reward = -25228.52, Avg Reward (100) = -30259.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1802: Reward = -35499.61, Avg Reward (100) = -30500.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1803: Reward = -35499.61, Avg Reward (100) = -30845.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1804: Reward = -35499.61, Avg Reward (100) = -30845.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1805: Reward = -1000.00, Avg Reward (100) = -31189.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1806: Reward = -35499.61, Avg Reward (100) = -30844.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1807: Reward = -1098.00, Avg Reward (100) = -30783.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1808: Reward = -35499.61, Avg Reward (100) = -30439.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1809: Reward = -35499.61, Avg Reward (100) = -30783.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 1810: Reward = -1049.00, Avg Reward (100) = -30804.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1811: Reward = -35499.61, Avg Reward (100) = -30332.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1812: Reward = -35499.61, Avg Reward (100) = -30332.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1813: Reward = -35499.61, Avg Reward (100) = -30332.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1814: Reward = -35499.61, Avg Reward (100) = -30676.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1815: Reward = -47848.55, Avg Reward (100) = -30676.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1816: Reward = -35499.61, Avg Reward (100) = -30800.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1817: Reward = -1295.00, Avg Reward (100) = -31143.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1818: Reward = -33701.04, Avg Reward (100) = -30605.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1819: Reward = -35499.61, Avg Reward (100) = -30587.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1820: Reward = -35499.61, Avg Reward (100) = -30587.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1821: Reward = -36089.25, Avg Reward (100) = -30587.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1822: Reward = -35499.61, Avg Reward (100) = -30625.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1823: Reward = -35499.61, Avg Reward (100) = -30625.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1824: Reward = -35499.61, Avg Reward (100) = -30625.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1825: Reward = -49626.26, Avg Reward (100) = -30625.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1826: Reward = -35499.61, Avg Reward (100) = -30766.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1827: Reward = -35499.61, Avg Reward (100) = -30766.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1828: Reward = -35499.61, Avg Reward (100) = -30651.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1829: Reward = -29512.46, Avg Reward (100) = -30651.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1830: Reward = -35499.61, Avg Reward (100) = -30611.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1831: Reward = -32245.59, Avg Reward (100) = -30611.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 1832: Reward = -36004.66, Avg Reward (100) = -30579.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 1833: Reward = -35499.61, Avg Reward (100) = -30584.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1834: Reward = -35499.61, Avg Reward (100) = -30584.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1835: Reward = -35499.61, Avg Reward (100) = -30612.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1836: Reward = -35499.61, Avg Reward (100) = -30956.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1837: Reward = -49626.26, Avg Reward (100) = -30956.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1838: Reward = -50011.42, Avg Reward (100) = -31097.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50011.42, Border Penalty: -38178.67, Obstacle Penalty: -50.00
Episode 1839: Reward = -28653.56, Avg Reward (100) = -31242.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1840: Reward = -1196.00, Avg Reward (100) = -31049.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1841: Reward = -35499.61, Avg Reward (100) = -30706.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1842: Reward = -35499.61, Avg Reward (100) = -30706.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1843: Reward = -35499.61, Avg Reward (100) = -31047.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1844: Reward = -35499.61, Avg Reward (100) = -31047.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1845: Reward = -35499.61, Avg Reward (100) = -31047.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1846: Reward = -35499.61, Avg Reward (100) = -31390.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1847: Reward = -54280.34, Avg Reward (100) = -31390.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54280.34, Border Penalty: -41966.66, Obstacle Penalty: -50.00
Episode 1848: Reward = -35499.61, Avg Reward (100) = -31578.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1849: Reward = -29626.05, Avg Reward (100) = -31578.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 1850: Reward = -49626.26, Avg Reward (100) = -31478.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1851: Reward = -35499.61, Avg Reward (100) = -31620.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1852: Reward = -49626.26, Avg Reward (100) = -31668.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1853: Reward = -35499.61, Avg Reward (100) = -32153.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1854: Reward = -35499.61, Avg Reward (100) = -32222.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1855: Reward = -35499.61, Avg Reward (100) = -32222.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1856: Reward = -35499.61, Avg Reward (100) = -32098.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1857: Reward = -35499.61, Avg Reward (100) = -32098.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1858: Reward = -1147.00, Avg Reward (100) = -32443.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1859: Reward = -35499.61, Avg Reward (100) = -32099.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1860: Reward = -33701.04, Avg Reward (100) = -32058.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1861: Reward = -35499.61, Avg Reward (100) = -31999.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1862: Reward = -35499.61, Avg Reward (100) = -31999.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1863: Reward = -29512.46, Avg Reward (100) = -31999.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1864: Reward = -1196.00, Avg Reward (100) = -32284.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1865: Reward = -35499.61, Avg Reward (100) = -31941.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1866: Reward = -49176.10, Avg Reward (100) = -31951.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1867: Reward = -35499.61, Avg Reward (100) = -32088.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1868: Reward = -35499.61, Avg Reward (100) = -32088.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1869: Reward = -35499.61, Avg Reward (100) = -31938.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1870: Reward = -35499.61, Avg Reward (100) = -31938.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1871: Reward = -35499.61, Avg Reward (100) = -31903.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1872: Reward = -35499.61, Avg Reward (100) = -32247.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1873: Reward = -35499.61, Avg Reward (100) = -32591.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1874: Reward = -28653.56, Avg Reward (100) = -32530.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1875: Reward = -32619.61, Avg Reward (100) = -32806.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1876: Reward = -35499.61, Avg Reward (100) = -32777.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1877: Reward = -35499.61, Avg Reward (100) = -32783.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1878: Reward = -43263.20, Avg Reward (100) = -32791.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1879: Reward = -35499.61, Avg Reward (100) = -32869.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1880: Reward = -1295.00, Avg Reward (100) = -32876.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1881: Reward = -35499.61, Avg Reward (100) = -32534.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1882: Reward = -1394.00, Avg Reward (100) = -32534.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1883: Reward = -49176.10, Avg Reward (100) = -32211.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1884: Reward = -43263.20, Avg Reward (100) = -32348.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1885: Reward = -35499.61, Avg Reward (100) = -32426.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1886: Reward = -35499.61, Avg Reward (100) = -32767.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1887: Reward = -35499.61, Avg Reward (100) = -32767.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1888: Reward = -35499.61, Avg Reward (100) = -32603.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1889: Reward = -35499.61, Avg Reward (100) = -32947.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1890: Reward = -35499.61, Avg Reward (100) = -33037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1891: Reward = -35499.61, Avg Reward (100) = -33037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1892: Reward = -35499.61, Avg Reward (100) = -33037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1893: Reward = -29512.46, Avg Reward (100) = -33037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1894: Reward = -29512.46, Avg Reward (100) = -32977.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 1895: Reward = -1000.00, Avg Reward (100) = -32917.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1896: Reward = -35499.61, Avg Reward (100) = -32572.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1897: Reward = -35499.61, Avg Reward (100) = -32572.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1898: Reward = -35499.61, Avg Reward (100) = -32914.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1899: Reward = -35499.61, Avg Reward (100) = -32823.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1900: Reward = -39606.20, Avg Reward (100) = -32892.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1901: Reward = -28653.56, Avg Reward (100) = -32933.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 1902: Reward = -12446.80, Avg Reward (100) = -32967.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1903: Reward = -35499.61, Avg Reward (100) = -32737.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1904: Reward = -31735.80, Avg Reward (100) = -32737.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31735.80, Border Penalty: -32997.37, Obstacle Penalty: -50.00
Episode 1905: Reward = -1147.00, Avg Reward (100) = -32699.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1906: Reward = -32235.76, Avg Reward (100) = -32701.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 1907: Reward = -35499.61, Avg Reward (100) = -32668.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1908: Reward = -1394.00, Avg Reward (100) = -33012.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1909: Reward = -1000.00, Avg Reward (100) = -32671.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1910: Reward = -1098.00, Avg Reward (100) = -32326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1911: Reward = -35499.61, Avg Reward (100) = -32326.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1912: Reward = -35499.61, Avg Reward (100) = -32326.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1913: Reward = -35499.61, Avg Reward (100) = -32326.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1914: Reward = -1196.00, Avg Reward (100) = -32326.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 1915: Reward = -1000.00, Avg Reward (100) = -31983.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1916: Reward = -35499.61, Avg Reward (100) = -31515.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1917: Reward = -47848.55, Avg Reward (100) = -31515.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 1918: Reward = -35499.61, Avg Reward (100) = -31980.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1919: Reward = -1000.00, Avg Reward (100) = -31998.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1920: Reward = -35499.61, Avg Reward (100) = -31653.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1921: Reward = -35499.61, Avg Reward (100) = -31653.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1922: Reward = -33701.04, Avg Reward (100) = -31647.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1923: Reward = -35499.61, Avg Reward (100) = -31629.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1924: Reward = -35499.61, Avg Reward (100) = -31629.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1925: Reward = -34685.86, Avg Reward (100) = -31629.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1926: Reward = -49176.10, Avg Reward (100) = -31480.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 1927: Reward = -1000.00, Avg Reward (100) = -31617.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1928: Reward = -37669.33, Avg Reward (100) = -31272.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1929: Reward = -32619.61, Avg Reward (100) = -31294.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 1930: Reward = -37669.33, Avg Reward (100) = -31325.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 1931: Reward = -35499.61, Avg Reward (100) = -31346.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1932: Reward = -35499.61, Avg Reward (100) = -31379.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1933: Reward = -34685.86, Avg Reward (100) = -31374.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1934: Reward = -35499.61, Avg Reward (100) = -31366.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1935: Reward = -35499.61, Avg Reward (100) = -31366.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1936: Reward = -35499.61, Avg Reward (100) = -31366.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1937: Reward = -35499.61, Avg Reward (100) = -31366.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1938: Reward = -34685.86, Avg Reward (100) = -31224.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1939: Reward = -1295.00, Avg Reward (100) = -31071.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1940: Reward = -32632.70, Avg Reward (100) = -30798.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 1941: Reward = -35499.61, Avg Reward (100) = -31112.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1942: Reward = -35499.61, Avg Reward (100) = -31112.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1943: Reward = -35499.61, Avg Reward (100) = -31112.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1944: Reward = -12446.80, Avg Reward (100) = -31112.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 1945: Reward = -35499.61, Avg Reward (100) = -30881.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1946: Reward = -35499.61, Avg Reward (100) = -30881.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1947: Reward = -1098.00, Avg Reward (100) = -30881.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 1948: Reward = -35499.61, Avg Reward (100) = -30350.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1949: Reward = -35499.61, Avg Reward (100) = -30350.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1950: Reward = -35499.61, Avg Reward (100) = -30408.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1951: Reward = -35499.61, Avg Reward (100) = -30267.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1952: Reward = -33701.04, Avg Reward (100) = -30267.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1953: Reward = -35499.61, Avg Reward (100) = -30108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1954: Reward = -35499.61, Avg Reward (100) = -30108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1955: Reward = -35499.61, Avg Reward (100) = -30108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1956: Reward = -35499.61, Avg Reward (100) = -30108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1957: Reward = -32281.14, Avg Reward (100) = -30108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32281.14, Border Penalty: -34088.48, Obstacle Penalty: -50.00
Episode 1958: Reward = -39606.20, Avg Reward (100) = -30076.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 1959: Reward = -27448.15, Avg Reward (100) = -30460.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -27448.15, Border Penalty: -31698.05, Obstacle Penalty: -50.00
Episode 1960: Reward = -43263.20, Avg Reward (100) = -30380.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1961: Reward = -1394.00, Avg Reward (100) = -30475.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1962: Reward = -30257.34, Avg Reward (100) = -30134.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30257.34, Border Penalty: -32861.68, Obstacle Penalty: -50.00
Episode 1963: Reward = -35499.61, Avg Reward (100) = -30082.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1964: Reward = -35499.61, Avg Reward (100) = -30142.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1965: Reward = -35499.61, Avg Reward (100) = -30485.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1966: Reward = -35499.61, Avg Reward (100) = -30485.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1967: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1968: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1969: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1970: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1971: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1972: Reward = -35499.61, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1973: Reward = -46577.49, Avg Reward (100) = -30348.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46577.49, Border Penalty: -37305.84, Obstacle Penalty: -50.00
Episode 1974: Reward = -36089.25, Avg Reward (100) = -30459.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 1975: Reward = -1394.00, Avg Reward (100) = -30533.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 1976: Reward = -35499.61, Avg Reward (100) = -30221.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1977: Reward = -43263.20, Avg Reward (100) = -30221.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 1978: Reward = -35499.61, Avg Reward (100) = -30298.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1979: Reward = -54036.93, Avg Reward (100) = -30221.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 1980: Reward = -35499.61, Avg Reward (100) = -30406.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1981: Reward = -40817.24, Avg Reward (100) = -30748.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40817.24, Border Penalty: -36530.08, Obstacle Penalty: -50.00
Episode 1982: Reward = -35499.61, Avg Reward (100) = -30801.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1983: Reward = -33701.04, Avg Reward (100) = -31142.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 1984: Reward = -1295.00, Avg Reward (100) = -30988.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1985: Reward = -35499.61, Avg Reward (100) = -30568.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1986: Reward = -34685.86, Avg Reward (100) = -30568.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 1987: Reward = -35499.61, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1988: Reward = -35499.61, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1989: Reward = -35499.61, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1990: Reward = -35499.61, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1991: Reward = -35499.61, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 1992: Reward = -33378.53, Avg Reward (100) = -30560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 1993: Reward = -49626.26, Avg Reward (100) = -30539.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 1994: Reward = -25228.52, Avg Reward (100) = -30740.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 1995: Reward = -1295.00, Avg Reward (100) = -30697.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 1996: Reward = -35499.61, Avg Reward (100) = -30700.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1997: Reward = -35499.61, Avg Reward (100) = -30700.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1998: Reward = -35499.61, Avg Reward (100) = -30700.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 1999: Reward = -35499.61, Avg Reward (100) = -30700.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2000: Reward = -1000.00, Avg Reward (100) = -30700.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2001: Reward = -1049.00, Avg Reward (100) = -30314.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2002: Reward = -35499.61, Avg Reward (100) = -30038.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2003: Reward = -35499.61, Avg Reward (100) = -30268.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2004: Reward = -35499.61, Avg Reward (100) = -30268.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2005: Reward = -35499.61, Avg Reward (100) = -30306.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2006: Reward = -35499.61, Avg Reward (100) = -30650.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2007: Reward = -49626.26, Avg Reward (100) = -30682.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2008: Reward = -47848.55, Avg Reward (100) = -30823.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2009: Reward = -43569.45, Avg Reward (100) = -31288.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43569.45, Border Penalty: -37743.09, Obstacle Penalty: -50.00
Episode 2010: Reward = -43263.20, Avg Reward (100) = -31714.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2011: Reward = -26787.09, Avg Reward (100) = -32135.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 2012: Reward = -35499.61, Avg Reward (100) = -32048.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2013: Reward = -39606.20, Avg Reward (100) = -32048.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2014: Reward = -35499.61, Avg Reward (100) = -32089.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2015: Reward = -35499.61, Avg Reward (100) = -32432.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2016: Reward = -35499.61, Avg Reward (100) = -32777.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2017: Reward = -35499.61, Avg Reward (100) = -32777.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2018: Reward = -35499.61, Avg Reward (100) = -32654.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2019: Reward = -35499.61, Avg Reward (100) = -32654.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2020: Reward = -35499.61, Avg Reward (100) = -32999.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2021: Reward = -43263.20, Avg Reward (100) = -32999.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2022: Reward = -12446.80, Avg Reward (100) = -33076.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2023: Reward = -50738.76, Avg Reward (100) = -32864.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50738.76, Border Penalty: -40478.38, Obstacle Penalty: -50.00
Episode 2024: Reward = -35499.61, Avg Reward (100) = -33016.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2025: Reward = -35499.61, Avg Reward (100) = -33016.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2026: Reward = -35499.61, Avg Reward (100) = -33024.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2027: Reward = -28653.56, Avg Reward (100) = -32888.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2028: Reward = -35499.61, Avg Reward (100) = -33164.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2029: Reward = -35499.61, Avg Reward (100) = -33143.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2030: Reward = -36089.25, Avg Reward (100) = -33171.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 2031: Reward = -1147.00, Avg Reward (100) = -33156.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2032: Reward = -1394.00, Avg Reward (100) = -32812.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2033: Reward = -35499.61, Avg Reward (100) = -32471.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2034: Reward = -1394.00, Avg Reward (100) = -32479.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2035: Reward = -35499.61, Avg Reward (100) = -32138.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2036: Reward = -33701.04, Avg Reward (100) = -32138.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2037: Reward = -1098.00, Avg Reward (100) = -32120.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2038: Reward = -35499.61, Avg Reward (100) = -31776.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2039: Reward = -35499.61, Avg Reward (100) = -31784.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2040: Reward = -35499.61, Avg Reward (100) = -32126.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2041: Reward = -33469.53, Avg Reward (100) = -32155.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2042: Reward = -35499.61, Avg Reward (100) = -32135.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2043: Reward = -35499.61, Avg Reward (100) = -32135.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2044: Reward = -35499.61, Avg Reward (100) = -32135.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2045: Reward = -35499.61, Avg Reward (100) = -32365.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2046: Reward = -35499.61, Avg Reward (100) = -32365.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2047: Reward = -35499.61, Avg Reward (100) = -32365.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2048: Reward = -35499.61, Avg Reward (100) = -32709.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2049: Reward = -49176.10, Avg Reward (100) = -32709.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2050: Reward = -39606.20, Avg Reward (100) = -32846.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 2051: Reward = -35499.61, Avg Reward (100) = -32887.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2052: Reward = -1049.00, Avg Reward (100) = -32887.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2053: Reward = -35499.61, Avg Reward (100) = -32560.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2054: Reward = -32245.59, Avg Reward (100) = -32560.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2055: Reward = -25228.52, Avg Reward (100) = -32528.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2056: Reward = -35499.61, Avg Reward (100) = -32425.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2057: Reward = -35499.61, Avg Reward (100) = -32425.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2058: Reward = -35499.61, Avg Reward (100) = -32457.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2059: Reward = -35499.61, Avg Reward (100) = -32416.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2060: Reward = -35499.61, Avg Reward (100) = -32497.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2061: Reward = -28683.61, Avg Reward (100) = -32419.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2062: Reward = -1147.00, Avg Reward (100) = -32692.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2063: Reward = -47848.55, Avg Reward (100) = -32401.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2064: Reward = -35499.61, Avg Reward (100) = -32524.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2065: Reward = -1049.00, Avg Reward (100) = -32524.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2066: Reward = -35499.61, Avg Reward (100) = -32180.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2067: Reward = -35499.61, Avg Reward (100) = -32180.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2068: Reward = -12446.80, Avg Reward (100) = -32180.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2069: Reward = -35499.61, Avg Reward (100) = -31949.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2070: Reward = -35499.61, Avg Reward (100) = -31949.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2071: Reward = -1196.00, Avg Reward (100) = -31949.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2072: Reward = -33469.53, Avg Reward (100) = -31606.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2073: Reward = -32619.61, Avg Reward (100) = -31586.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2074: Reward = -35499.61, Avg Reward (100) = -31446.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2075: Reward = -33701.04, Avg Reward (100) = -31441.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2076: Reward = -35499.61, Avg Reward (100) = -31764.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2077: Reward = -35499.61, Avg Reward (100) = -31764.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2078: Reward = -35499.61, Avg Reward (100) = -31686.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2079: Reward = -35499.61, Avg Reward (100) = -31686.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2080: Reward = -35499.61, Avg Reward (100) = -31501.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2081: Reward = -35499.61, Avg Reward (100) = -31501.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2082: Reward = -39606.20, Avg Reward (100) = -31447.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2083: Reward = -25228.52, Avg Reward (100) = -31489.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2084: Reward = -1000.00, Avg Reward (100) = -31404.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2085: Reward = -35499.61, Avg Reward (100) = -31401.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2086: Reward = -35499.61, Avg Reward (100) = -31401.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2087: Reward = -1295.00, Avg Reward (100) = -31409.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2088: Reward = -35499.61, Avg Reward (100) = -31067.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2089: Reward = -35499.61, Avg Reward (100) = -31067.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2090: Reward = -49626.26, Avg Reward (100) = -31067.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2091: Reward = -1098.00, Avg Reward (100) = -31208.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2092: Reward = -32245.59, Avg Reward (100) = -30864.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2093: Reward = -1049.00, Avg Reward (100) = -30853.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2094: Reward = -1295.00, Avg Reward (100) = -30367.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2095: Reward = -34685.86, Avg Reward (100) = -30128.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2096: Reward = -1000.00, Avg Reward (100) = -30462.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2097: Reward = -35499.61, Avg Reward (100) = -30117.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2098: Reward = -35499.61, Avg Reward (100) = -30117.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2099: Reward = -35499.61, Avg Reward (100) = -30117.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2100: Reward = -1196.00, Avg Reward (100) = -30117.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2101: Reward = -39606.20, Avg Reward (100) = -30119.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2102: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2103: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2104: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2105: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2106: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2107: Reward = -35499.61, Avg Reward (100) = -30504.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2108: Reward = -1196.00, Avg Reward (100) = -30363.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2109: Reward = -36004.66, Avg Reward (100) = -29896.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35049.13, Obstacle Penalty: -50.00
Episode 2110: Reward = -35499.61, Avg Reward (100) = -29821.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2111: Reward = -27492.00, Avg Reward (100) = -29743.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 2112: Reward = -34685.86, Avg Reward (100) = -29750.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2113: Reward = -35499.61, Avg Reward (100) = -29742.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2114: Reward = -35499.61, Avg Reward (100) = -29701.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2115: Reward = -1196.00, Avg Reward (100) = -29701.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2116: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2117: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2118: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2119: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2120: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2121: Reward = -35499.61, Avg Reward (100) = -29358.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2122: Reward = -28683.61, Avg Reward (100) = -29280.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2123: Reward = -35499.61, Avg Reward (100) = -29443.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2124: Reward = -1000.00, Avg Reward (100) = -29290.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2125: Reward = -1098.00, Avg Reward (100) = -28945.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2126: Reward = -35499.61, Avg Reward (100) = -28601.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2127: Reward = -35499.61, Avg Reward (100) = -28601.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2128: Reward = -31735.80, Avg Reward (100) = -28670.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31735.80, Border Penalty: -33598.23, Obstacle Penalty: -50.00
Episode 2129: Reward = -35499.61, Avg Reward (100) = -28632.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2130: Reward = -1295.00, Avg Reward (100) = -28632.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2131: Reward = -32619.61, Avg Reward (100) = -28284.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2132: Reward = -35499.61, Avg Reward (100) = -28599.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2133: Reward = -35499.61, Avg Reward (100) = -28940.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2134: Reward = -35499.61, Avg Reward (100) = -28940.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2135: Reward = -35499.61, Avg Reward (100) = -29281.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2136: Reward = -1295.00, Avg Reward (100) = -29281.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2137: Reward = -35499.61, Avg Reward (100) = -28957.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2138: Reward = -35499.61, Avg Reward (100) = -29301.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2139: Reward = -36022.43, Avg Reward (100) = -29301.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 2140: Reward = -1245.00, Avg Reward (100) = -29306.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2141: Reward = -35499.61, Avg Reward (100) = -28964.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2142: Reward = -28772.37, Avg Reward (100) = -28984.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 2143: Reward = -35499.61, Avg Reward (100) = -28917.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2144: Reward = -35499.61, Avg Reward (100) = -28917.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2145: Reward = -35499.61, Avg Reward (100) = -28917.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2146: Reward = -1394.00, Avg Reward (100) = -28917.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2147: Reward = -35499.61, Avg Reward (100) = -28576.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2148: Reward = -35499.61, Avg Reward (100) = -28576.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2149: Reward = -35499.61, Avg Reward (100) = -28576.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2150: Reward = -47848.55, Avg Reward (100) = -28439.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2151: Reward = -49176.10, Avg Reward (100) = -28521.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2152: Reward = -36089.25, Avg Reward (100) = -28658.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2153: Reward = -35499.61, Avg Reward (100) = -29008.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2154: Reward = -35499.61, Avg Reward (100) = -29008.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2155: Reward = -49176.10, Avg Reward (100) = -29041.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2156: Reward = -1196.00, Avg Reward (100) = -29280.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2157: Reward = -39606.20, Avg Reward (100) = -28937.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2158: Reward = -35499.61, Avg Reward (100) = -28978.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2159: Reward = -33701.04, Avg Reward (100) = -28978.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2160: Reward = -48044.60, Avg Reward (100) = -28961.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 2161: Reward = -35499.61, Avg Reward (100) = -29086.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2162: Reward = -27702.15, Avg Reward (100) = -29154.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27702.15, Border Penalty: -30554.88, Obstacle Penalty: -50.00
Episode 2163: Reward = -1394.00, Avg Reward (100) = -29420.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2164: Reward = -59645.17, Avg Reward (100) = -28955.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 2165: Reward = -35499.61, Avg Reward (100) = -29197.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2166: Reward = -49176.10, Avg Reward (100) = -29541.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2167: Reward = -47848.55, Avg Reward (100) = -29678.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2168: Reward = -35499.61, Avg Reward (100) = -29801.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2169: Reward = -43263.20, Avg Reward (100) = -30032.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2170: Reward = -35499.61, Avg Reward (100) = -30109.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2171: Reward = -37669.33, Avg Reward (100) = -30109.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2172: Reward = -35499.61, Avg Reward (100) = -30474.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2173: Reward = -51639.54, Avg Reward (100) = -30495.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51639.54, Border Penalty: -40925.70, Obstacle Penalty: -50.00
Episode 2174: Reward = -12769.82, Avg Reward (100) = -30685.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -12769.82, Border Penalty: -22136.90, Obstacle Penalty: -50.00
Episode 2175: Reward = -34685.86, Avg Reward (100) = -30457.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2176: Reward = -35499.61, Avg Reward (100) = -30467.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2177: Reward = -1000.00, Avg Reward (100) = -30467.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2178: Reward = -35499.61, Avg Reward (100) = -30122.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2179: Reward = -1147.00, Avg Reward (100) = -30122.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2180: Reward = -33701.04, Avg Reward (100) = -29779.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2181: Reward = -36089.25, Avg Reward (100) = -29761.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2182: Reward = -35499.61, Avg Reward (100) = -29767.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2183: Reward = -35499.61, Avg Reward (100) = -29726.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2184: Reward = -35499.61, Avg Reward (100) = -29828.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2185: Reward = -35499.61, Avg Reward (100) = -30173.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2186: Reward = -1049.00, Avg Reward (100) = -30173.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2187: Reward = -35499.61, Avg Reward (100) = -29829.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2188: Reward = -35499.61, Avg Reward (100) = -30171.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2189: Reward = -1049.00, Avg Reward (100) = -30171.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2190: Reward = -36089.25, Avg Reward (100) = -29826.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2191: Reward = -35499.61, Avg Reward (100) = -29691.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2192: Reward = -35499.61, Avg Reward (100) = -30035.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2193: Reward = -35499.61, Avg Reward (100) = -30068.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2194: Reward = -1196.00, Avg Reward (100) = -30412.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2195: Reward = -35499.61, Avg Reward (100) = -30411.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2196: Reward = -34685.86, Avg Reward (100) = -30419.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2197: Reward = -36089.25, Avg Reward (100) = -30756.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2198: Reward = -1295.00, Avg Reward (100) = -30762.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2199: Reward = -35499.61, Avg Reward (100) = -30420.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2200: Reward = -34685.86, Avg Reward (100) = -30420.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2201: Reward = -35499.61, Avg Reward (100) = -30755.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2202: Reward = -43802.69, Avg Reward (100) = -30714.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 2203: Reward = -54061.77, Avg Reward (100) = -30797.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54061.77, Border Penalty: -41464.82, Obstacle Penalty: -50.00
Episode 2204: Reward = -35499.61, Avg Reward (100) = -30982.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2205: Reward = -35499.61, Avg Reward (100) = -30982.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2206: Reward = -39606.20, Avg Reward (100) = -30982.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2207: Reward = -25228.52, Avg Reward (100) = -31023.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2208: Reward = -42504.46, Avg Reward (100) = -30921.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42504.46, Border Penalty: -37949.78, Obstacle Penalty: -50.00
Episode 2209: Reward = -32245.59, Avg Reward (100) = -31334.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2210: Reward = -32619.61, Avg Reward (100) = -31296.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2211: Reward = -35499.61, Avg Reward (100) = -31267.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2212: Reward = -30056.79, Avg Reward (100) = -31348.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -33036.80, Obstacle Penalty: -50.00
Episode 2213: Reward = -35499.61, Avg Reward (100) = -31301.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2214: Reward = -37669.33, Avg Reward (100) = -31301.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2215: Reward = -1098.00, Avg Reward (100) = -31323.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2216: Reward = -35499.61, Avg Reward (100) = -31322.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2217: Reward = -1196.00, Avg Reward (100) = -31322.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2218: Reward = -32245.59, Avg Reward (100) = -30979.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2219: Reward = -1098.00, Avg Reward (100) = -30946.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2220: Reward = -35499.61, Avg Reward (100) = -30602.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2221: Reward = -35499.61, Avg Reward (100) = -30602.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2222: Reward = -35499.61, Avg Reward (100) = -30602.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2223: Reward = -35499.61, Avg Reward (100) = -30670.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2224: Reward = -35499.61, Avg Reward (100) = -30670.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2225: Reward = -35499.61, Avg Reward (100) = -31015.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2226: Reward = -35499.61, Avg Reward (100) = -31360.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2227: Reward = -35499.61, Avg Reward (100) = -31360.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2228: Reward = -35499.61, Avg Reward (100) = -31360.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2229: Reward = -35499.61, Avg Reward (100) = -31397.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2230: Reward = -1049.00, Avg Reward (100) = -31397.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2231: Reward = -34685.86, Avg Reward (100) = -31395.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2232: Reward = -29410.78, Avg Reward (100) = -31415.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -29410.78, Border Penalty: -31281.70, Obstacle Penalty: -50.00
Episode 2233: Reward = -48772.41, Avg Reward (100) = -31354.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48772.41, Border Penalty: -40113.36, Obstacle Penalty: -50.00
Episode 2234: Reward = -35499.61, Avg Reward (100) = -31487.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2235: Reward = -35499.61, Avg Reward (100) = -31487.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2236: Reward = -35499.61, Avg Reward (100) = -31487.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2237: Reward = -33701.04, Avg Reward (100) = -31829.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2238: Reward = -36089.25, Avg Reward (100) = -31811.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2239: Reward = -35499.61, Avg Reward (100) = -31817.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2240: Reward = -35499.61, Avg Reward (100) = -31812.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2241: Reward = -33486.06, Avg Reward (100) = -32154.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33486.06, Border Penalty: -34346.12, Obstacle Penalty: -50.00
Episode 2242: Reward = -37669.33, Avg Reward (100) = -32134.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2243: Reward = -35499.61, Avg Reward (100) = -32223.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2244: Reward = -1000.00, Avg Reward (100) = -32223.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2245: Reward = -35499.61, Avg Reward (100) = -31878.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2246: Reward = -38636.47, Avg Reward (100) = -31878.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 2247: Reward = -40411.33, Avg Reward (100) = -32251.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 2248: Reward = -43263.20, Avg Reward (100) = -32300.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2249: Reward = -35499.61, Avg Reward (100) = -32377.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2250: Reward = -1196.00, Avg Reward (100) = -32377.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2251: Reward = -47848.55, Avg Reward (100) = -31911.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2252: Reward = -39606.20, Avg Reward (100) = -31898.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2253: Reward = -35499.61, Avg Reward (100) = -31933.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2254: Reward = -35499.61, Avg Reward (100) = -31933.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2255: Reward = -35499.61, Avg Reward (100) = -31933.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2256: Reward = -47848.55, Avg Reward (100) = -31796.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2257: Reward = -49176.10, Avg Reward (100) = -32263.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2258: Reward = -26326.21, Avg Reward (100) = -32358.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 2259: Reward = -35499.61, Avg Reward (100) = -32267.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2260: Reward = -35499.61, Avg Reward (100) = -32285.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2261: Reward = -35499.61, Avg Reward (100) = -32159.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2262: Reward = -1049.00, Avg Reward (100) = -32159.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2263: Reward = -1049.00, Avg Reward (100) = -31893.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2264: Reward = -1147.00, Avg Reward (100) = -31889.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2265: Reward = -35499.61, Avg Reward (100) = -31304.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2266: Reward = -35499.61, Avg Reward (100) = -31304.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2267: Reward = -36089.25, Avg Reward (100) = -31167.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2268: Reward = -35499.61, Avg Reward (100) = -31050.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2269: Reward = -49626.26, Avg Reward (100) = -31050.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2270: Reward = -35499.61, Avg Reward (100) = -31113.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2271: Reward = -35499.61, Avg Reward (100) = -31113.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2272: Reward = -35499.61, Avg Reward (100) = -31092.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2273: Reward = -35499.61, Avg Reward (100) = -31092.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2274: Reward = -1294.00, Avg Reward (100) = -30930.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2275: Reward = -35499.61, Avg Reward (100) = -30816.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2276: Reward = -35499.61, Avg Reward (100) = -30824.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2277: Reward = -1394.00, Avg Reward (100) = -30824.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2278: Reward = -34685.86, Avg Reward (100) = -30828.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2279: Reward = -28683.61, Avg Reward (100) = -30820.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2280: Reward = -35499.61, Avg Reward (100) = -31095.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2281: Reward = -35499.61, Avg Reward (100) = -31113.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2282: Reward = -35499.61, Avg Reward (100) = -31107.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2283: Reward = -35499.61, Avg Reward (100) = -31107.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2284: Reward = -1098.00, Avg Reward (100) = -31107.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2285: Reward = -1394.00, Avg Reward (100) = -30763.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2286: Reward = -32245.59, Avg Reward (100) = -30422.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2287: Reward = -39606.20, Avg Reward (100) = -30734.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2288: Reward = -37669.33, Avg Reward (100) = -30775.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2289: Reward = -35499.61, Avg Reward (100) = -30797.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2290: Reward = -35499.61, Avg Reward (100) = -31141.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2291: Reward = -30392.74, Avg Reward (100) = -31135.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 2292: Reward = -38432.03, Avg Reward (100) = -31084.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -38432.03, Border Penalty: -36581.93, Obstacle Penalty: -50.00
Episode 2293: Reward = -35499.61, Avg Reward (100) = -31113.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2294: Reward = -35499.61, Avg Reward (100) = -31113.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2295: Reward = -49626.26, Avg Reward (100) = -31457.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2296: Reward = -49176.10, Avg Reward (100) = -31598.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2297: Reward = -35499.61, Avg Reward (100) = -31743.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2298: Reward = -49176.10, Avg Reward (100) = -31737.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2299: Reward = -35499.61, Avg Reward (100) = -32216.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2300: Reward = -35499.61, Avg Reward (100) = -32216.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2301: Reward = -43263.20, Avg Reward (100) = -32224.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2302: Reward = -42304.65, Avg Reward (100) = -32301.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -33999.73, Obstacle Penalty: -50.00
Episode 2303: Reward = -35499.61, Avg Reward (100) = -32286.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2304: Reward = -35499.61, Avg Reward (100) = -32101.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2305: Reward = -35499.61, Avg Reward (100) = -32101.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2306: Reward = -35499.61, Avg Reward (100) = -32101.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2307: Reward = -35499.61, Avg Reward (100) = -32060.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2308: Reward = -28653.56, Avg Reward (100) = -32162.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2309: Reward = -49626.26, Avg Reward (100) = -32024.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2310: Reward = -35499.61, Avg Reward (100) = -32198.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2311: Reward = -35499.61, Avg Reward (100) = -32227.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2312: Reward = -35499.61, Avg Reward (100) = -32227.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2313: Reward = -26326.21, Avg Reward (100) = -32281.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 2314: Reward = -37669.33, Avg Reward (100) = -32189.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 2315: Reward = -1196.00, Avg Reward (100) = -32189.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2316: Reward = -1245.00, Avg Reward (100) = -32190.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2317: Reward = -32619.61, Avg Reward (100) = -31848.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2318: Reward = -35499.61, Avg Reward (100) = -32162.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2319: Reward = -35499.61, Avg Reward (100) = -32194.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2320: Reward = -33701.04, Avg Reward (100) = -32538.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2321: Reward = -1098.00, Avg Reward (100) = -32520.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2322: Reward = -28653.56, Avg Reward (100) = -32176.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2323: Reward = -1049.00, Avg Reward (100) = -32108.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2324: Reward = -35499.61, Avg Reward (100) = -31763.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2325: Reward = -1147.00, Avg Reward (100) = -31763.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2326: Reward = -35499.61, Avg Reward (100) = -31420.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2327: Reward = -35499.61, Avg Reward (100) = -31420.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2328: Reward = -35499.61, Avg Reward (100) = -31420.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2329: Reward = -32273.18, Avg Reward (100) = -31420.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -32273.18, Border Penalty: -32486.29, Obstacle Penalty: -50.00
Episode 2330: Reward = -35499.61, Avg Reward (100) = -31388.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2331: Reward = -25468.63, Avg Reward (100) = -31732.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 2332: Reward = -35499.61, Avg Reward (100) = -31640.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2333: Reward = -35499.61, Avg Reward (100) = -31701.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2334: Reward = -35499.61, Avg Reward (100) = -31568.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2335: Reward = -1433.40, Avg Reward (100) = -31568.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1433.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2336: Reward = -35499.61, Avg Reward (100) = -31228.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2337: Reward = -35499.61, Avg Reward (100) = -31228.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2338: Reward = -35499.61, Avg Reward (100) = -31245.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2339: Reward = -47848.55, Avg Reward (100) = -31240.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2340: Reward = -29512.46, Avg Reward (100) = -31363.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2341: Reward = -35499.61, Avg Reward (100) = -31303.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2342: Reward = -35499.61, Avg Reward (100) = -31323.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2343: Reward = -1295.00, Avg Reward (100) = -31302.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2344: Reward = -1147.00, Avg Reward (100) = -30960.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2345: Reward = -35499.61, Avg Reward (100) = -30961.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2346: Reward = -35499.61, Avg Reward (100) = -30961.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2347: Reward = -25228.52, Avg Reward (100) = -30930.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2348: Reward = -44651.33, Avg Reward (100) = -30778.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44651.33, Border Penalty: -35761.28, Obstacle Penalty: -50.00
Episode 2349: Reward = -35499.61, Avg Reward (100) = -30792.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2350: Reward = -39606.20, Avg Reward (100) = -30792.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2351: Reward = -35499.61, Avg Reward (100) = -31176.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2352: Reward = -52942.15, Avg Reward (100) = -31052.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 16, Reward Breakdown -> Delta_x Reward: -52942.15, Border Penalty: -41194.85, Obstacle Penalty: -50.00
Episode 2353: Reward = -1196.00, Avg Reward (100) = -31186.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2354: Reward = -35499.61, Avg Reward (100) = -30843.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2355: Reward = -35499.61, Avg Reward (100) = -30843.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2356: Reward = -35499.61, Avg Reward (100) = -30843.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2357: Reward = -1196.00, Avg Reward (100) = -30719.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2358: Reward = -35499.61, Avg Reward (100) = -30239.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2359: Reward = -35499.61, Avg Reward (100) = -30331.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2360: Reward = -33469.53, Avg Reward (100) = -30331.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2361: Reward = -35499.61, Avg Reward (100) = -30311.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2362: Reward = -37669.33, Avg Reward (100) = -30311.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -35743.02, Obstacle Penalty: -50.00
Episode 2363: Reward = -47848.55, Avg Reward (100) = -30677.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2364: Reward = -35499.61, Avg Reward (100) = -31145.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2365: Reward = -37669.33, Avg Reward (100) = -31489.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2366: Reward = -35499.61, Avg Reward (100) = -31510.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2367: Reward = -35499.61, Avg Reward (100) = -31510.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2368: Reward = -49176.10, Avg Reward (100) = -31504.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2369: Reward = -35499.61, Avg Reward (100) = -31641.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2370: Reward = -35499.61, Avg Reward (100) = -31500.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2371: Reward = -35499.61, Avg Reward (100) = -31500.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2372: Reward = -35499.61, Avg Reward (100) = -31500.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2373: Reward = -1295.00, Avg Reward (100) = -31500.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2374: Reward = -35499.61, Avg Reward (100) = -31158.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2375: Reward = -43263.20, Avg Reward (100) = -31500.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2376: Reward = -1196.00, Avg Reward (100) = -31578.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2377: Reward = -35499.61, Avg Reward (100) = -31234.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2378: Reward = -35499.61, Avg Reward (100) = -31576.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2379: Reward = -35499.61, Avg Reward (100) = -31584.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2380: Reward = -1049.00, Avg Reward (100) = -31652.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2381: Reward = -35499.61, Avg Reward (100) = -31307.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2382: Reward = -39606.20, Avg Reward (100) = -31307.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2383: Reward = -30416.69, Avg Reward (100) = -31348.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30416.69, Border Penalty: -33691.42, Obstacle Penalty: -50.00
Episode 2384: Reward = -49176.10, Avg Reward (100) = -31298.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2385: Reward = -1147.00, Avg Reward (100) = -31778.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2386: Reward = -35499.61, Avg Reward (100) = -31776.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2387: Reward = -35499.61, Avg Reward (100) = -31808.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2388: Reward = -1295.00, Avg Reward (100) = -31767.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2389: Reward = -35499.61, Avg Reward (100) = -31404.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2390: Reward = -1098.00, Avg Reward (100) = -31404.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2391: Reward = -35499.61, Avg Reward (100) = -31060.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2392: Reward = -38728.16, Avg Reward (100) = -31111.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38728.16, Border Penalty: -35051.43, Obstacle Penalty: -50.00
Episode 2393: Reward = -35499.61, Avg Reward (100) = -31114.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2394: Reward = -35499.61, Avg Reward (100) = -31114.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2395: Reward = -53955.87, Avg Reward (100) = -31114.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 2396: Reward = -35499.61, Avg Reward (100) = -31157.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2397: Reward = -28683.61, Avg Reward (100) = -31020.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2398: Reward = -35499.61, Avg Reward (100) = -30952.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2399: Reward = -35499.61, Avg Reward (100) = -30815.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2400: Reward = -1049.00, Avg Reward (100) = -30815.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2401: Reward = -9048.28, Avg Reward (100) = -30471.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -9048.28, Border Penalty: -18608.47, Obstacle Penalty: -50.00
Episode 2402: Reward = -55418.84, Avg Reward (100) = -30129.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -55418.84, Border Penalty: -39411.00, Obstacle Penalty: -50.00
Episode 2403: Reward = -43263.20, Avg Reward (100) = -30260.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2404: Reward = -35499.61, Avg Reward (100) = -30337.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2405: Reward = -35499.61, Avg Reward (100) = -30337.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2406: Reward = -37669.33, Avg Reward (100) = -30337.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2407: Reward = -35499.61, Avg Reward (100) = -30359.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2408: Reward = -35499.61, Avg Reward (100) = -30359.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2409: Reward = -35499.61, Avg Reward (100) = -30427.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2410: Reward = -35499.61, Avg Reward (100) = -30286.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2411: Reward = -35499.61, Avg Reward (100) = -30286.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2412: Reward = -35499.61, Avg Reward (100) = -30286.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2413: Reward = -39606.20, Avg Reward (100) = -30286.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2414: Reward = -35499.61, Avg Reward (100) = -30419.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2415: Reward = -1245.00, Avg Reward (100) = -30397.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2416: Reward = -35499.61, Avg Reward (100) = -30398.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2417: Reward = -35499.61, Avg Reward (100) = -30740.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2418: Reward = -35499.61, Avg Reward (100) = -30769.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2419: Reward = -32245.59, Avg Reward (100) = -30769.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2420: Reward = -1147.00, Avg Reward (100) = -30737.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2421: Reward = -35499.61, Avg Reward (100) = -30411.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2422: Reward = -35499.61, Avg Reward (100) = -30755.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2423: Reward = -12446.80, Avg Reward (100) = -30824.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2424: Reward = -33469.53, Avg Reward (100) = -30938.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2425: Reward = -36122.48, Avg Reward (100) = -30917.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36122.48, Border Penalty: -32749.10, Obstacle Penalty: -50.00
Episode 2426: Reward = -36089.25, Avg Reward (100) = -31267.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2427: Reward = -34927.46, Avg Reward (100) = -31273.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 2428: Reward = -35499.61, Avg Reward (100) = -31267.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2429: Reward = -35499.61, Avg Reward (100) = -31267.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2430: Reward = -1196.00, Avg Reward (100) = -31299.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2431: Reward = -1295.00, Avg Reward (100) = -30956.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2432: Reward = -35499.61, Avg Reward (100) = -30715.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2433: Reward = -35499.61, Avg Reward (100) = -30715.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2434: Reward = -35499.61, Avg Reward (100) = -30715.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2435: Reward = -29512.46, Avg Reward (100) = -30715.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2436: Reward = -1049.00, Avg Reward (100) = -30995.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2437: Reward = -35499.61, Avg Reward (100) = -30651.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2438: Reward = -46653.19, Avg Reward (100) = -30651.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 2439: Reward = -41835.16, Avg Reward (100) = -30762.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41835.16, Border Penalty: -35537.73, Obstacle Penalty: -50.00
Episode 2440: Reward = -1000.00, Avg Reward (100) = -30702.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2441: Reward = -35368.76, Avg Reward (100) = -30417.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -35368.76, Border Penalty: -34840.38, Obstacle Penalty: -50.00
Episode 2442: Reward = -35499.61, Avg Reward (100) = -30416.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2443: Reward = -1147.00, Avg Reward (100) = -30416.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2444: Reward = -35499.61, Avg Reward (100) = -30414.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2445: Reward = -1295.00, Avg Reward (100) = -30758.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2446: Reward = -43263.20, Avg Reward (100) = -30416.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2447: Reward = -49626.26, Avg Reward (100) = -30494.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2448: Reward = -35499.61, Avg Reward (100) = -30738.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2449: Reward = -35499.61, Avg Reward (100) = -30646.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2450: Reward = -59645.17, Avg Reward (100) = -30646.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 2451: Reward = -35499.61, Avg Reward (100) = -30846.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2452: Reward = -35499.61, Avg Reward (100) = -30846.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2453: Reward = -35499.61, Avg Reward (100) = -30672.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2454: Reward = -35499.61, Avg Reward (100) = -31015.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2455: Reward = -32245.59, Avg Reward (100) = -31015.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2456: Reward = -35499.61, Avg Reward (100) = -30982.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2457: Reward = -35499.61, Avg Reward (100) = -30982.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2458: Reward = -1196.00, Avg Reward (100) = -31326.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2459: Reward = -39606.20, Avg Reward (100) = -30982.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 2460: Reward = -35499.61, Avg Reward (100) = -31024.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2461: Reward = -28653.56, Avg Reward (100) = -31044.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2462: Reward = -35499.61, Avg Reward (100) = -30975.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2463: Reward = -35499.61, Avg Reward (100) = -30954.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2464: Reward = -35499.61, Avg Reward (100) = -30830.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2465: Reward = -29512.46, Avg Reward (100) = -30830.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2466: Reward = -35499.61, Avg Reward (100) = -30749.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2467: Reward = -35499.61, Avg Reward (100) = -30749.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2468: Reward = -35499.61, Avg Reward (100) = -30749.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2469: Reward = -35499.61, Avg Reward (100) = -30612.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2470: Reward = -35499.61, Avg Reward (100) = -30612.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2471: Reward = -1098.00, Avg Reward (100) = -30612.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2472: Reward = -35499.61, Avg Reward (100) = -30268.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2473: Reward = -28683.61, Avg Reward (100) = -30268.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2474: Reward = -28653.56, Avg Reward (100) = -30542.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2475: Reward = -28683.61, Avg Reward (100) = -30473.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2476: Reward = -47848.55, Avg Reward (100) = -30327.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2477: Reward = -35499.61, Avg Reward (100) = -30794.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2478: Reward = -35499.61, Avg Reward (100) = -30794.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2479: Reward = -35499.61, Avg Reward (100) = -30794.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2480: Reward = -35499.61, Avg Reward (100) = -30794.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2481: Reward = -1049.00, Avg Reward (100) = -31139.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2482: Reward = -35499.61, Avg Reward (100) = -30794.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2483: Reward = -49626.26, Avg Reward (100) = -30753.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2484: Reward = -35499.61, Avg Reward (100) = -30945.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2485: Reward = -1245.00, Avg Reward (100) = -30808.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2486: Reward = -35499.61, Avg Reward (100) = -30809.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2487: Reward = -35499.61, Avg Reward (100) = -30809.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2488: Reward = -1196.00, Avg Reward (100) = -30809.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2489: Reward = -35499.61, Avg Reward (100) = -30808.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2490: Reward = -42222.60, Avg Reward (100) = -30808.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42222.60, Border Penalty: -32085.55, Obstacle Penalty: -50.00
Episode 2491: Reward = -35499.61, Avg Reward (100) = -31220.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2492: Reward = -35499.61, Avg Reward (100) = -31220.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2493: Reward = -35499.61, Avg Reward (100) = -31187.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2494: Reward = -35499.61, Avg Reward (100) = -31187.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2495: Reward = -35499.61, Avg Reward (100) = -31187.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2496: Reward = -43177.43, Avg Reward (100) = -31003.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43177.43, Border Penalty: -37310.73, Obstacle Penalty: -50.00
Episode 2497: Reward = -36089.25, Avg Reward (100) = -31079.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2498: Reward = -35499.61, Avg Reward (100) = -31153.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2499: Reward = -35499.61, Avg Reward (100) = -31153.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2500: Reward = -43263.20, Avg Reward (100) = -31153.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2501: Reward = -64293.52, Avg Reward (100) = -31576.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -64293.52, Border Penalty: -37520.21, Obstacle Penalty: -50.00
Episode 2502: Reward = -35499.61, Avg Reward (100) = -32128.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2503: Reward = -35499.61, Avg Reward (100) = -31929.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2504: Reward = -35499.61, Avg Reward (100) = -31851.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2505: Reward = -1394.00, Avg Reward (100) = -31851.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2506: Reward = -35499.61, Avg Reward (100) = -31510.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2507: Reward = -1394.00, Avg Reward (100) = -31489.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2508: Reward = -35499.61, Avg Reward (100) = -31147.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2509: Reward = -49176.10, Avg Reward (100) = -31147.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2510: Reward = -47848.55, Avg Reward (100) = -31284.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2511: Reward = -35499.61, Avg Reward (100) = -31408.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2512: Reward = -35499.61, Avg Reward (100) = -31408.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2513: Reward = -35499.61, Avg Reward (100) = -31408.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2514: Reward = -49929.11, Avg Reward (100) = -31367.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 2515: Reward = -47848.55, Avg Reward (100) = -31511.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2516: Reward = -35499.61, Avg Reward (100) = -31977.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2517: Reward = -35499.61, Avg Reward (100) = -31977.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2518: Reward = -35499.61, Avg Reward (100) = -31977.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2519: Reward = -35499.61, Avg Reward (100) = -31977.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2520: Reward = -35499.61, Avg Reward (100) = -32010.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2521: Reward = -35499.61, Avg Reward (100) = -32353.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2522: Reward = -1295.00, Avg Reward (100) = -32353.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2523: Reward = -35499.61, Avg Reward (100) = -32011.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2524: Reward = -35499.61, Avg Reward (100) = -32242.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2525: Reward = -28653.56, Avg Reward (100) = -32262.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2526: Reward = -39606.20, Avg Reward (100) = -32187.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2527: Reward = -49176.10, Avg Reward (100) = -32222.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2528: Reward = -1394.00, Avg Reward (100) = -32365.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2529: Reward = -35499.61, Avg Reward (100) = -32024.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2530: Reward = -42112.30, Avg Reward (100) = -32024.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 2531: Reward = -35499.61, Avg Reward (100) = -32433.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2532: Reward = -33469.53, Avg Reward (100) = -32775.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2533: Reward = -1049.00, Avg Reward (100) = -32755.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2534: Reward = -35499.61, Avg Reward (100) = -32410.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2535: Reward = -35499.61, Avg Reward (100) = -32410.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2536: Reward = -12446.80, Avg Reward (100) = -32470.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2537: Reward = -43263.20, Avg Reward (100) = -32584.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2538: Reward = -35499.61, Avg Reward (100) = -32662.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2539: Reward = -29512.46, Avg Reward (100) = -32550.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2540: Reward = -35499.61, Avg Reward (100) = -32427.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2541: Reward = -1049.00, Avg Reward (100) = -32772.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2542: Reward = -1147.00, Avg Reward (100) = -32429.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2543: Reward = -1394.00, Avg Reward (100) = -32085.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2544: Reward = -1098.00, Avg Reward (100) = -32088.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2545: Reward = -1147.00, Avg Reward (100) = -31744.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2546: Reward = -37669.33, Avg Reward (100) = -31742.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2547: Reward = -34685.86, Avg Reward (100) = -31686.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2548: Reward = -35499.61, Avg Reward (100) = -31537.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2549: Reward = -35499.61, Avg Reward (100) = -31537.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2550: Reward = -35499.61, Avg Reward (100) = -31537.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2551: Reward = -35499.61, Avg Reward (100) = -31295.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2552: Reward = -43263.20, Avg Reward (100) = -31295.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 2553: Reward = -43569.45, Avg Reward (100) = -31373.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43569.45, Border Penalty: -37743.09, Obstacle Penalty: -50.00
Episode 2554: Reward = -29626.05, Avg Reward (100) = -31454.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 2555: Reward = -35499.61, Avg Reward (100) = -31395.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2556: Reward = -25228.52, Avg Reward (100) = -31427.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2557: Reward = -35499.61, Avg Reward (100) = -31325.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2558: Reward = -35499.61, Avg Reward (100) = -31325.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2559: Reward = -35499.61, Avg Reward (100) = -31668.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2560: Reward = -1196.00, Avg Reward (100) = -31627.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2561: Reward = -35499.61, Avg Reward (100) = -31284.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2562: Reward = -25228.52, Avg Reward (100) = -31352.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2563: Reward = -35499.61, Avg Reward (100) = -31249.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2564: Reward = -35499.61, Avg Reward (100) = -31249.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2565: Reward = -35499.61, Avg Reward (100) = -31249.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2566: Reward = -35499.61, Avg Reward (100) = -31309.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2567: Reward = -35499.61, Avg Reward (100) = -31309.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2568: Reward = -35499.61, Avg Reward (100) = -31309.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2569: Reward = -35499.61, Avg Reward (100) = -31309.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2570: Reward = -53615.70, Avg Reward (100) = -31309.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -41236.93, Obstacle Penalty: -50.00
Episode 2571: Reward = -25228.52, Avg Reward (100) = -31490.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2572: Reward = -36089.25, Avg Reward (100) = -31732.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2573: Reward = -35499.61, Avg Reward (100) = -31738.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2574: Reward = -49626.26, Avg Reward (100) = -31806.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2575: Reward = -35499.61, Avg Reward (100) = -32016.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2576: Reward = -35499.61, Avg Reward (100) = -32084.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2577: Reward = -1196.00, Avg Reward (100) = -31960.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2578: Reward = -35499.61, Avg Reward (100) = -31617.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2579: Reward = -1098.00, Avg Reward (100) = -31617.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2580: Reward = -35499.61, Avg Reward (100) = -31273.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2581: Reward = -35499.61, Avg Reward (100) = -31273.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2582: Reward = -48116.97, Avg Reward (100) = -31618.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 2583: Reward = -35499.61, Avg Reward (100) = -31744.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2584: Reward = -1000.00, Avg Reward (100) = -31603.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2585: Reward = -47257.10, Avg Reward (100) = -31258.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47257.10, Border Penalty: -39370.42, Obstacle Penalty: -50.00
Episode 2586: Reward = -35499.61, Avg Reward (100) = -31718.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2587: Reward = -35499.61, Avg Reward (100) = -31718.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2588: Reward = -46305.80, Avg Reward (100) = -31718.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46305.80, Border Penalty: -37626.48, Obstacle Penalty: -50.00
Episode 2589: Reward = -1147.00, Avg Reward (100) = -32169.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2590: Reward = -35499.61, Avg Reward (100) = -31825.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2591: Reward = -35499.61, Avg Reward (100) = -31758.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2592: Reward = -28683.61, Avg Reward (100) = -31758.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2593: Reward = -1296.78, Avg Reward (100) = -31690.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2594: Reward = -35499.61, Avg Reward (100) = -31348.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2595: Reward = -35499.61, Avg Reward (100) = -31348.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2596: Reward = -32245.59, Avg Reward (100) = -31348.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2597: Reward = -1393.00, Avg Reward (100) = -31239.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2598: Reward = -33382.70, Avg Reward (100) = -30892.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33382.70, Border Penalty: -34178.79, Obstacle Penalty: -50.00
Episode 2599: Reward = -35499.61, Avg Reward (100) = -30870.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2600: Reward = -35499.61, Avg Reward (100) = -30870.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2601: Reward = -35499.61, Avg Reward (100) = -30793.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2602: Reward = -35499.61, Avg Reward (100) = -30505.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2603: Reward = -35499.61, Avg Reward (100) = -30505.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2604: Reward = -35499.61, Avg Reward (100) = -30505.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2605: Reward = -35499.61, Avg Reward (100) = -30505.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2606: Reward = -1196.00, Avg Reward (100) = -30846.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2607: Reward = -35499.61, Avg Reward (100) = -30503.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2608: Reward = -35499.61, Avg Reward (100) = -30844.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2609: Reward = -1196.00, Avg Reward (100) = -30844.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2610: Reward = -34685.86, Avg Reward (100) = -30364.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2611: Reward = -35499.61, Avg Reward (100) = -30232.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2612: Reward = -35499.61, Avg Reward (100) = -30232.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2613: Reward = -37669.33, Avg Reward (100) = -30232.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2614: Reward = -32619.61, Avg Reward (100) = -30254.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2615: Reward = -28653.56, Avg Reward (100) = -30081.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2616: Reward = -35499.61, Avg Reward (100) = -29889.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2617: Reward = -32619.61, Avg Reward (100) = -29889.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2618: Reward = -28653.56, Avg Reward (100) = -29860.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2619: Reward = -1098.00, Avg Reward (100) = -29792.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2620: Reward = -39606.20, Avg Reward (100) = -29448.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -33795.82, Obstacle Penalty: -50.00
Episode 2621: Reward = -1295.00, Avg Reward (100) = -29489.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2622: Reward = -35499.61, Avg Reward (100) = -29147.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2623: Reward = -35499.61, Avg Reward (100) = -29489.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2624: Reward = -35499.61, Avg Reward (100) = -29489.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2625: Reward = -43263.20, Avg Reward (100) = -29489.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -35267.92, Obstacle Penalty: -50.00
Episode 2626: Reward = -35499.61, Avg Reward (100) = -29635.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2627: Reward = -37669.33, Avg Reward (100) = -29594.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2628: Reward = -35499.61, Avg Reward (100) = -29479.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2629: Reward = -1147.00, Avg Reward (100) = -29820.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2630: Reward = -35499.61, Avg Reward (100) = -29476.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2631: Reward = -33701.04, Avg Reward (100) = -29410.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2632: Reward = -32619.61, Avg Reward (100) = -29392.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2633: Reward = -1394.00, Avg Reward (100) = -29384.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2634: Reward = -35499.61, Avg Reward (100) = -29387.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2635: Reward = -35499.61, Avg Reward (100) = -29387.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2636: Reward = -35499.61, Avg Reward (100) = -29387.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2637: Reward = -35499.61, Avg Reward (100) = -29618.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2638: Reward = -1295.00, Avg Reward (100) = -29540.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2639: Reward = -35499.61, Avg Reward (100) = -29198.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2640: Reward = -32245.59, Avg Reward (100) = -29258.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2641: Reward = -35499.61, Avg Reward (100) = -29225.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2642: Reward = -35499.61, Avg Reward (100) = -29570.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2643: Reward = -35499.61, Avg Reward (100) = -29913.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2644: Reward = -35499.61, Avg Reward (100) = -30255.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2645: Reward = -12446.80, Avg Reward (100) = -30599.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2646: Reward = -35499.61, Avg Reward (100) = -30712.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2647: Reward = -1245.00, Avg Reward (100) = -30690.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2648: Reward = -35499.61, Avg Reward (100) = -30355.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2649: Reward = -49176.10, Avg Reward (100) = -30355.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2650: Reward = -35499.61, Avg Reward (100) = -30492.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2651: Reward = -35499.61, Avg Reward (100) = -30492.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2652: Reward = -28683.61, Avg Reward (100) = -30492.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2653: Reward = -35499.61, Avg Reward (100) = -30346.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2654: Reward = -35499.61, Avg Reward (100) = -30266.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2655: Reward = -25228.52, Avg Reward (100) = -30324.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2656: Reward = -28683.61, Avg Reward (100) = -30222.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2657: Reward = -1295.00, Avg Reward (100) = -30256.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2658: Reward = -35499.61, Avg Reward (100) = -29914.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2659: Reward = -35499.61, Avg Reward (100) = -29914.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2660: Reward = -35499.61, Avg Reward (100) = -29914.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2661: Reward = -28653.56, Avg Reward (100) = -30257.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2662: Reward = -35499.61, Avg Reward (100) = -30189.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2663: Reward = -35499.61, Avg Reward (100) = -30291.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2664: Reward = -35499.61, Avg Reward (100) = -30291.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2665: Reward = -35499.61, Avg Reward (100) = -30291.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2666: Reward = -35499.61, Avg Reward (100) = -30291.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2667: Reward = -49176.10, Avg Reward (100) = -30291.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2668: Reward = -35499.61, Avg Reward (100) = -30428.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2669: Reward = -33378.53, Avg Reward (100) = -30428.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 2670: Reward = -36089.25, Avg Reward (100) = -30407.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2671: Reward = -35499.61, Avg Reward (100) = -30232.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2672: Reward = -35499.61, Avg Reward (100) = -30335.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2673: Reward = -34345.81, Avg Reward (100) = -30329.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34345.81, Border Penalty: -35118.36, Obstacle Penalty: -50.00
Episode 2674: Reward = -28683.61, Avg Reward (100) = -30317.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2675: Reward = -1098.00, Avg Reward (100) = -30108.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2676: Reward = -33701.04, Avg Reward (100) = -29764.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2677: Reward = -35499.61, Avg Reward (100) = -29746.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2678: Reward = -1196.00, Avg Reward (100) = -30089.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2679: Reward = -35499.61, Avg Reward (100) = -29746.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2680: Reward = -35499.61, Avg Reward (100) = -30090.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2681: Reward = -35499.61, Avg Reward (100) = -30090.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2682: Reward = -1394.00, Avg Reward (100) = -30090.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2683: Reward = -43263.20, Avg Reward (100) = -29622.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2684: Reward = -35499.61, Avg Reward (100) = -29700.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2685: Reward = -35499.61, Avg Reward (100) = -30045.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2686: Reward = -35499.61, Avg Reward (100) = -29927.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2687: Reward = -35499.61, Avg Reward (100) = -29927.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2688: Reward = -35499.61, Avg Reward (100) = -29927.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2689: Reward = -32245.59, Avg Reward (100) = -29819.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2690: Reward = -35499.61, Avg Reward (100) = -30130.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2691: Reward = -54604.04, Avg Reward (100) = -30130.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54604.04, Border Penalty: -41409.95, Obstacle Penalty: -50.00
Episode 2692: Reward = -33701.04, Avg Reward (100) = -30321.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2693: Reward = -35499.61, Avg Reward (100) = -30372.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2694: Reward = -35499.61, Avg Reward (100) = -30714.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2695: Reward = -29512.46, Avg Reward (100) = -30714.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2696: Reward = -35499.61, Avg Reward (100) = -30654.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2697: Reward = -35499.61, Avg Reward (100) = -30686.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2698: Reward = -1196.00, Avg Reward (100) = -31027.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2699: Reward = -35499.61, Avg Reward (100) = -30706.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2700: Reward = -35499.61, Avg Reward (100) = -30706.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2701: Reward = -35499.61, Avg Reward (100) = -30706.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2702: Reward = -35499.61, Avg Reward (100) = -30706.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2703: Reward = -1098.00, Avg Reward (100) = -30706.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2704: Reward = -32619.61, Avg Reward (100) = -30361.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2705: Reward = -35499.61, Avg Reward (100) = -30333.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2706: Reward = -1147.00, Avg Reward (100) = -30333.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2707: Reward = -29512.46, Avg Reward (100) = -30332.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2708: Reward = -35499.61, Avg Reward (100) = -30272.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2709: Reward = -35499.61, Avg Reward (100) = -30272.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2710: Reward = -54036.93, Avg Reward (100) = -30615.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 2711: Reward = -28653.56, Avg Reward (100) = -30809.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2712: Reward = -12446.80, Avg Reward (100) = -30740.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2713: Reward = -35499.61, Avg Reward (100) = -30510.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2714: Reward = -54870.38, Avg Reward (100) = -30488.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -54870.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 2715: Reward = -48772.41, Avg Reward (100) = -30711.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48772.41, Border Penalty: -39513.14, Obstacle Penalty: -50.00
Episode 2716: Reward = -1049.00, Avg Reward (100) = -30912.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2717: Reward = -35499.61, Avg Reward (100) = -30567.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2718: Reward = -28683.61, Avg Reward (100) = -30596.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2719: Reward = -36089.25, Avg Reward (100) = -30596.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2720: Reward = -35499.61, Avg Reward (100) = -30946.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2721: Reward = -35499.61, Avg Reward (100) = -30905.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2722: Reward = -35499.61, Avg Reward (100) = -31247.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2723: Reward = -1098.00, Avg Reward (100) = -31247.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2724: Reward = -32619.61, Avg Reward (100) = -30903.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2725: Reward = -35499.61, Avg Reward (100) = -30875.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2726: Reward = -35499.61, Avg Reward (100) = -30797.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2727: Reward = -35499.61, Avg Reward (100) = -30797.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2728: Reward = -1295.00, Avg Reward (100) = -30775.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2729: Reward = -1394.00, Avg Reward (100) = -30433.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2730: Reward = -28653.56, Avg Reward (100) = -30436.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2731: Reward = -35499.61, Avg Reward (100) = -30367.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2732: Reward = -35499.61, Avg Reward (100) = -30385.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2733: Reward = -35499.61, Avg Reward (100) = -30414.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2734: Reward = -35499.61, Avg Reward (100) = -30755.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2735: Reward = -28653.56, Avg Reward (100) = -30755.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2736: Reward = -35499.61, Avg Reward (100) = -30687.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2737: Reward = -26326.21, Avg Reward (100) = -30687.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 2738: Reward = -35499.61, Avg Reward (100) = -30595.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2739: Reward = -47848.55, Avg Reward (100) = -30937.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2740: Reward = -43263.20, Avg Reward (100) = -31060.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2741: Reward = -43263.20, Avg Reward (100) = -31171.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 2742: Reward = -35499.61, Avg Reward (100) = -31248.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2743: Reward = -35499.61, Avg Reward (100) = -31248.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2744: Reward = -35499.61, Avg Reward (100) = -31248.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2745: Reward = -49626.26, Avg Reward (100) = -31248.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2746: Reward = -48803.55, Avg Reward (100) = -31620.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48803.55, Border Penalty: -40077.88, Obstacle Penalty: -50.00
Episode 2747: Reward = -32245.59, Avg Reward (100) = -31753.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2748: Reward = -35499.61, Avg Reward (100) = -32063.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2749: Reward = -1196.00, Avg Reward (100) = -32063.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2750: Reward = -34685.86, Avg Reward (100) = -31583.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2751: Reward = -35499.61, Avg Reward (100) = -31575.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2752: Reward = -35499.61, Avg Reward (100) = -31575.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2753: Reward = -31653.57, Avg Reward (100) = -31643.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 2754: Reward = -35499.61, Avg Reward (100) = -31605.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2755: Reward = -41554.36, Avg Reward (100) = -31605.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 2756: Reward = -35499.61, Avg Reward (100) = -31768.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2757: Reward = -35499.61, Avg Reward (100) = -31836.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2758: Reward = -29512.46, Avg Reward (100) = -32178.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2759: Reward = -35499.61, Avg Reward (100) = -32118.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2760: Reward = -35499.61, Avg Reward (100) = -32118.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2761: Reward = -1196.00, Avg Reward (100) = -32118.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2762: Reward = -42304.65, Avg Reward (100) = -31844.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 2763: Reward = -1394.00, Avg Reward (100) = -31912.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2764: Reward = -35499.61, Avg Reward (100) = -31571.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2765: Reward = -35499.61, Avg Reward (100) = -31571.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2766: Reward = -35499.61, Avg Reward (100) = -31571.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2767: Reward = -35499.61, Avg Reward (100) = -31571.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2768: Reward = -49719.75, Avg Reward (100) = -31434.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49719.75, Border Penalty: -38279.55, Obstacle Penalty: -50.00
Episode 2769: Reward = -39606.20, Avg Reward (100) = -31576.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2770: Reward = -28653.56, Avg Reward (100) = -31639.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2771: Reward = -35499.61, Avg Reward (100) = -31564.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2772: Reward = -25228.52, Avg Reward (100) = -31564.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2773: Reward = -1000.00, Avg Reward (100) = -31461.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2774: Reward = -1049.00, Avg Reward (100) = -31128.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2775: Reward = -35499.61, Avg Reward (100) = -30852.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2776: Reward = -35499.61, Avg Reward (100) = -31196.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2777: Reward = -35499.61, Avg Reward (100) = -31214.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2778: Reward = -52315.20, Avg Reward (100) = -31214.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 2779: Reward = -1196.00, Avg Reward (100) = -31725.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2780: Reward = -43263.20, Avg Reward (100) = -31382.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 2781: Reward = -1147.00, Avg Reward (100) = -31459.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2782: Reward = -32619.61, Avg Reward (100) = -31116.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2783: Reward = -35499.61, Avg Reward (100) = -31428.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2784: Reward = -47848.55, Avg Reward (100) = -31351.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2785: Reward = -35499.61, Avg Reward (100) = -31474.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2786: Reward = -35499.61, Avg Reward (100) = -31474.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2787: Reward = -35499.61, Avg Reward (100) = -31474.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2788: Reward = -42363.56, Avg Reward (100) = -31474.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 2789: Reward = -35499.61, Avg Reward (100) = -31543.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2790: Reward = -35499.61, Avg Reward (100) = -31575.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2791: Reward = -35499.61, Avg Reward (100) = -31575.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2792: Reward = -28653.56, Avg Reward (100) = -31384.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2793: Reward = -35499.61, Avg Reward (100) = -31334.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2794: Reward = -1295.00, Avg Reward (100) = -31334.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2795: Reward = -35499.61, Avg Reward (100) = -30992.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2796: Reward = -1098.00, Avg Reward (100) = -31052.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2797: Reward = -35499.61, Avg Reward (100) = -30707.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2798: Reward = -35499.61, Avg Reward (100) = -30707.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2799: Reward = -35499.61, Avg Reward (100) = -31051.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2800: Reward = -1000.00, Avg Reward (100) = -31051.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2801: Reward = -1295.00, Avg Reward (100) = -30706.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2802: Reward = -35499.61, Avg Reward (100) = -30363.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2803: Reward = -28772.37, Avg Reward (100) = -30363.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 2804: Reward = -1000.00, Avg Reward (100) = -30640.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2805: Reward = -35499.61, Avg Reward (100) = -30324.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2806: Reward = -35499.61, Avg Reward (100) = -30324.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2807: Reward = -34685.86, Avg Reward (100) = -30668.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2808: Reward = -35499.61, Avg Reward (100) = -30719.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2809: Reward = -35499.61, Avg Reward (100) = -30719.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2810: Reward = -28653.56, Avg Reward (100) = -30719.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2811: Reward = -35499.61, Avg Reward (100) = -30465.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2812: Reward = -32619.61, Avg Reward (100) = -30534.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2813: Reward = -35499.61, Avg Reward (100) = -30736.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2814: Reward = -35499.61, Avg Reward (100) = -30736.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2815: Reward = -49626.26, Avg Reward (100) = -30542.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2816: Reward = -35499.61, Avg Reward (100) = -30550.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2817: Reward = -1000.00, Avg Reward (100) = -30895.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2818: Reward = -28683.61, Avg Reward (100) = -30550.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2819: Reward = -35499.61, Avg Reward (100) = -30550.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2820: Reward = -48044.60, Avg Reward (100) = -30544.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 2821: Reward = -49176.10, Avg Reward (100) = -30670.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2822: Reward = -35499.61, Avg Reward (100) = -30806.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2823: Reward = -1098.00, Avg Reward (100) = -30806.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2824: Reward = -35499.61, Avg Reward (100) = -30806.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2825: Reward = -49176.10, Avg Reward (100) = -30835.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2826: Reward = -33469.53, Avg Reward (100) = -30972.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2827: Reward = -30056.79, Avg Reward (100) = -30952.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -30142.54, Obstacle Penalty: -50.00
Episode 2828: Reward = -49626.26, Avg Reward (100) = -30897.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2829: Reward = -53454.27, Avg Reward (100) = -31380.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53454.27, Border Penalty: -41200.47, Obstacle Penalty: -50.00
Episode 2830: Reward = -35499.61, Avg Reward (100) = -31901.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2831: Reward = -35499.61, Avg Reward (100) = -31970.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2832: Reward = -35499.61, Avg Reward (100) = -31970.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2833: Reward = -35499.61, Avg Reward (100) = -31970.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2834: Reward = -35499.61, Avg Reward (100) = -31970.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2835: Reward = -35499.61, Avg Reward (100) = -31970.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2836: Reward = -35499.61, Avg Reward (100) = -32038.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2837: Reward = -53615.70, Avg Reward (100) = -32038.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -41236.93, Obstacle Penalty: -50.00
Episode 2838: Reward = -36089.25, Avg Reward (100) = -32311.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2839: Reward = -1393.00, Avg Reward (100) = -32317.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2840: Reward = -1000.00, Avg Reward (100) = -31852.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2841: Reward = -44957.91, Avg Reward (100) = -31430.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44957.91, Border Penalty: -38477.29, Obstacle Penalty: -50.00
Episode 2842: Reward = -35499.61, Avg Reward (100) = -31447.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2843: Reward = -34685.86, Avg Reward (100) = -31447.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2844: Reward = -32619.61, Avg Reward (100) = -31438.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2845: Reward = -28653.56, Avg Reward (100) = -31410.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2846: Reward = -1098.00, Avg Reward (100) = -31200.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2847: Reward = -35499.61, Avg Reward (100) = -30723.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2848: Reward = -12446.80, Avg Reward (100) = -30755.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 2849: Reward = -35499.61, Avg Reward (100) = -30525.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2850: Reward = -35499.61, Avg Reward (100) = -30868.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2851: Reward = -35499.61, Avg Reward (100) = -30876.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2852: Reward = -1049.00, Avg Reward (100) = -30876.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2853: Reward = -43263.20, Avg Reward (100) = -30531.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2854: Reward = -25228.52, Avg Reward (100) = -30648.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2855: Reward = -35499.61, Avg Reward (100) = -30545.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2856: Reward = -32245.59, Avg Reward (100) = -30484.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2857: Reward = -34685.86, Avg Reward (100) = -30452.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2858: Reward = -33701.04, Avg Reward (100) = -30444.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2859: Reward = -39606.20, Avg Reward (100) = -30486.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2860: Reward = -35499.61, Avg Reward (100) = -30527.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2861: Reward = -35499.61, Avg Reward (100) = -30527.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2862: Reward = -1147.00, Avg Reward (100) = -30870.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2863: Reward = -35499.61, Avg Reward (100) = -30458.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2864: Reward = -1295.00, Avg Reward (100) = -30799.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 2865: Reward = -35499.61, Avg Reward (100) = -30457.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2866: Reward = -35499.61, Avg Reward (100) = -30457.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2867: Reward = -35499.61, Avg Reward (100) = -30457.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2868: Reward = -43263.20, Avg Reward (100) = -30457.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2869: Reward = -35499.61, Avg Reward (100) = -30393.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2870: Reward = -1098.00, Avg Reward (100) = -30351.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2871: Reward = -29512.46, Avg Reward (100) = -30076.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2872: Reward = -1147.00, Avg Reward (100) = -30016.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2873: Reward = -35499.61, Avg Reward (100) = -29775.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2874: Reward = -33701.04, Avg Reward (100) = -30120.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2875: Reward = -35499.61, Avg Reward (100) = -30447.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2876: Reward = -43263.20, Avg Reward (100) = -30447.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2877: Reward = -1049.00, Avg Reward (100) = -30524.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2878: Reward = -1394.00, Avg Reward (100) = -30180.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2879: Reward = -47130.15, Avg Reward (100) = -29671.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47130.15, Border Penalty: -39456.06, Obstacle Penalty: -50.00
Episode 2880: Reward = -1394.00, Avg Reward (100) = -30130.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2881: Reward = -35499.61, Avg Reward (100) = -29711.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2882: Reward = -35499.61, Avg Reward (100) = -30055.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2883: Reward = -37799.90, Avg Reward (100) = -30084.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 2884: Reward = -35499.61, Avg Reward (100) = -30107.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2885: Reward = -35499.61, Avg Reward (100) = -29983.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2886: Reward = -35499.61, Avg Reward (100) = -29983.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2887: Reward = -28653.56, Avg Reward (100) = -29983.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2888: Reward = -49176.10, Avg Reward (100) = -29915.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2889: Reward = -35499.61, Avg Reward (100) = -29983.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2890: Reward = -35499.61, Avg Reward (100) = -29983.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2891: Reward = -1049.00, Avg Reward (100) = -29983.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2892: Reward = -35499.61, Avg Reward (100) = -29638.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2893: Reward = -35499.61, Avg Reward (100) = -29707.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2894: Reward = -1000.00, Avg Reward (100) = -29707.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2895: Reward = -35499.61, Avg Reward (100) = -29704.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2896: Reward = -39606.20, Avg Reward (100) = -29704.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 2897: Reward = -35499.61, Avg Reward (100) = -30089.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2898: Reward = -35499.61, Avg Reward (100) = -30089.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2899: Reward = -34685.86, Avg Reward (100) = -30089.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2900: Reward = -33701.04, Avg Reward (100) = -30081.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2901: Reward = -28653.56, Avg Reward (100) = -30408.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2902: Reward = -30392.74, Avg Reward (100) = -30681.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 2903: Reward = -25468.63, Avg Reward (100) = -30630.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 2904: Reward = -35499.61, Avg Reward (100) = -30597.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2905: Reward = -35499.61, Avg Reward (100) = -30942.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2906: Reward = -1049.00, Avg Reward (100) = -30942.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2907: Reward = -35499.61, Avg Reward (100) = -30598.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2908: Reward = -32235.76, Avg Reward (100) = -30606.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33367.27, Obstacle Penalty: -50.00
Episode 2909: Reward = -35499.61, Avg Reward (100) = -30573.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2910: Reward = -35499.61, Avg Reward (100) = -30573.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2911: Reward = -28653.56, Avg Reward (100) = -30642.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 2912: Reward = -47848.55, Avg Reward (100) = -30573.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 2913: Reward = -35499.61, Avg Reward (100) = -30726.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2914: Reward = -35499.61, Avg Reward (100) = -30726.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2915: Reward = -29512.46, Avg Reward (100) = -30726.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2916: Reward = -32245.59, Avg Reward (100) = -30524.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2917: Reward = -35499.61, Avg Reward (100) = -30492.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2918: Reward = -35499.61, Avg Reward (100) = -30837.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2919: Reward = -35499.61, Avg Reward (100) = -30905.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2920: Reward = -5390.43, Avg Reward (100) = -30905.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -5390.43, Border Penalty: -12900.05, Obstacle Penalty: -50.00
Episode 2921: Reward = -39606.20, Avg Reward (100) = -30478.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 2922: Reward = -37669.33, Avg Reward (100) = -30383.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 2923: Reward = -35499.61, Avg Reward (100) = -30404.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2924: Reward = -35499.61, Avg Reward (100) = -30748.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2925: Reward = -49176.10, Avg Reward (100) = -30748.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2926: Reward = -34685.86, Avg Reward (100) = -30748.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 2927: Reward = -35499.61, Avg Reward (100) = -30761.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2928: Reward = -29512.46, Avg Reward (100) = -30815.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2929: Reward = -1098.00, Avg Reward (100) = -30614.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2930: Reward = -35499.61, Avg Reward (100) = -30090.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2931: Reward = -35499.61, Avg Reward (100) = -30090.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2932: Reward = -35499.61, Avg Reward (100) = -30090.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2933: Reward = -49176.10, Avg Reward (100) = -30090.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2934: Reward = -32245.59, Avg Reward (100) = -30227.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2935: Reward = -39671.98, Avg Reward (100) = -30195.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 2936: Reward = -35499.61, Avg Reward (100) = -30236.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2937: Reward = -35499.61, Avg Reward (100) = -30236.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2938: Reward = -1147.00, Avg Reward (100) = -30055.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2939: Reward = -1147.00, Avg Reward (100) = -29706.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2940: Reward = -35499.61, Avg Reward (100) = -29703.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2941: Reward = -35499.61, Avg Reward (100) = -30048.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2942: Reward = -43263.20, Avg Reward (100) = -29954.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2943: Reward = -34685.86, Avg Reward (100) = -30031.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 2944: Reward = -35499.61, Avg Reward (100) = -30031.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2945: Reward = -32245.59, Avg Reward (100) = -30060.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 2946: Reward = -35499.61, Avg Reward (100) = -30096.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2947: Reward = -35499.61, Avg Reward (100) = -30440.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2948: Reward = -33701.04, Avg Reward (100) = -30440.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2949: Reward = -1394.00, Avg Reward (100) = -30653.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2950: Reward = -1147.00, Avg Reward (100) = -30312.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2951: Reward = -35499.61, Avg Reward (100) = -29968.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2952: Reward = -34345.81, Avg Reward (100) = -29968.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34345.81, Border Penalty: -35118.36, Obstacle Penalty: -50.00
Episode 2953: Reward = -33469.53, Avg Reward (100) = -30301.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 2954: Reward = -35499.61, Avg Reward (100) = -30203.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2955: Reward = -35499.61, Avg Reward (100) = -30306.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2956: Reward = -35499.61, Avg Reward (100) = -30306.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2957: Reward = -35499.61, Avg Reward (100) = -30338.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2958: Reward = -36089.25, Avg Reward (100) = -30346.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 2959: Reward = -35499.61, Avg Reward (100) = -30370.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2960: Reward = -35499.61, Avg Reward (100) = -30329.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2961: Reward = -29512.46, Avg Reward (100) = -30329.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2962: Reward = -35499.61, Avg Reward (100) = -30269.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2963: Reward = -35499.61, Avg Reward (100) = -30613.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2964: Reward = -1196.00, Avg Reward (100) = -30613.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 2965: Reward = -32619.61, Avg Reward (100) = -30612.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 2966: Reward = -25468.63, Avg Reward (100) = -30583.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 2967: Reward = -35499.61, Avg Reward (100) = -30483.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 2968: Reward = -29512.46, Avg Reward (100) = -30483.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2969: Reward = -35499.61, Avg Reward (100) = -30345.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2970: Reward = -1000.00, Avg Reward (100) = -30345.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2971: Reward = -35499.61, Avg Reward (100) = -30344.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2972: Reward = -35499.61, Avg Reward (100) = -30404.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2973: Reward = -12769.82, Avg Reward (100) = -30748.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -12769.82, Border Penalty: -22136.90, Obstacle Penalty: -50.00
Episode 2974: Reward = -1394.00, Avg Reward (100) = -30520.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 2975: Reward = -35499.61, Avg Reward (100) = -30197.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2976: Reward = -52585.18, Avg Reward (100) = -30197.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 2977: Reward = -33701.04, Avg Reward (100) = -30291.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 2978: Reward = -35499.61, Avg Reward (100) = -30617.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2979: Reward = -49626.26, Avg Reward (100) = -30958.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 2980: Reward = -35499.61, Avg Reward (100) = -30983.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2981: Reward = -49176.10, Avg Reward (100) = -31324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 2982: Reward = -35499.61, Avg Reward (100) = -31461.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2983: Reward = -35499.61, Avg Reward (100) = -31461.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2984: Reward = -30619.04, Avg Reward (100) = -31438.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30619.04, Border Penalty: -32490.02, Obstacle Penalty: -50.00
Episode 2985: Reward = -43263.20, Avg Reward (100) = -31389.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 2986: Reward = -35499.61, Avg Reward (100) = -31467.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2987: Reward = -35499.61, Avg Reward (100) = -31467.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2988: Reward = -35499.61, Avg Reward (100) = -31535.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2989: Reward = -29512.46, Avg Reward (100) = -31398.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 2990: Reward = -47848.55, Avg Reward (100) = -31339.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -36300.06, Obstacle Penalty: -50.00
Episode 2991: Reward = -35499.61, Avg Reward (100) = -31462.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2992: Reward = -1049.00, Avg Reward (100) = -31807.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 2993: Reward = -35499.61, Avg Reward (100) = -31462.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2994: Reward = -24654.29, Avg Reward (100) = -31462.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -24654.29, Border Penalty: -30086.89, Obstacle Penalty: -50.00
Episode 2995: Reward = -35499.61, Avg Reward (100) = -31699.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2996: Reward = -35499.61, Avg Reward (100) = -31699.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 2997: Reward = -25228.52, Avg Reward (100) = -31658.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 2998: Reward = -35499.61, Avg Reward (100) = -31555.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 2999: Reward = -35499.61, Avg Reward (100) = -31555.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3000: Reward = -1296.78, Avg Reward (100) = -31563.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3001: Reward = -1098.00, Avg Reward (100) = -31239.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3002: Reward = -1000.00, Avg Reward (100) = -30963.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3003: Reward = -44651.33, Avg Reward (100) = -30669.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44651.33, Border Penalty: -38718.66, Obstacle Penalty: -50.00
Episode 3004: Reward = -35499.61, Avg Reward (100) = -30861.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3005: Reward = -1000.00, Avg Reward (100) = -30861.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3006: Reward = -35499.61, Avg Reward (100) = -30516.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3007: Reward = -35499.61, Avg Reward (100) = -30861.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3008: Reward = -35499.61, Avg Reward (100) = -30861.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3009: Reward = -35499.61, Avg Reward (100) = -30893.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3010: Reward = -35499.61, Avg Reward (100) = -30893.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3011: Reward = -25869.03, Avg Reward (100) = -30893.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -25869.03, Border Penalty: -30119.32, Obstacle Penalty: -50.00
Episode 3012: Reward = -35499.61, Avg Reward (100) = -30866.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3013: Reward = -35499.61, Avg Reward (100) = -30742.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3014: Reward = -47402.59, Avg Reward (100) = -30742.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47402.59, Border Penalty: -38808.54, Obstacle Penalty: -50.00
Episode 3015: Reward = -35499.61, Avg Reward (100) = -30861.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3016: Reward = -33701.04, Avg Reward (100) = -30921.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3017: Reward = -35499.61, Avg Reward (100) = -30936.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3018: Reward = -35499.61, Avg Reward (100) = -30936.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3019: Reward = -35499.61, Avg Reward (100) = -30936.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3020: Reward = -35499.61, Avg Reward (100) = -30936.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3021: Reward = -1049.00, Avg Reward (100) = -31237.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3022: Reward = -35499.61, Avg Reward (100) = -30851.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3023: Reward = -35116.24, Avg Reward (100) = -30829.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -35116.24, Border Penalty: -33867.79, Obstacle Penalty: -50.00
Episode 3024: Reward = -35499.61, Avg Reward (100) = -30826.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3025: Reward = -37669.33, Avg Reward (100) = -30826.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3026: Reward = -35499.61, Avg Reward (100) = -30710.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3027: Reward = -1049.00, Avg Reward (100) = -30719.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3028: Reward = -35499.61, Avg Reward (100) = -30374.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3029: Reward = -12446.80, Avg Reward (100) = -30434.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3030: Reward = -32245.59, Avg Reward (100) = -30547.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3031: Reward = -1196.00, Avg Reward (100) = -30515.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3032: Reward = -48252.80, Avg Reward (100) = -30172.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 3033: Reward = -32619.61, Avg Reward (100) = -30299.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3034: Reward = -35499.61, Avg Reward (100) = -30134.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3035: Reward = -28683.61, Avg Reward (100) = -30166.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3036: Reward = -32245.59, Avg Reward (100) = -30056.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3037: Reward = -35499.61, Avg Reward (100) = -30024.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3038: Reward = -29512.46, Avg Reward (100) = -30024.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3039: Reward = -32675.73, Avg Reward (100) = -30308.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32675.73, Border Penalty: -30294.06, Obstacle Penalty: -50.00
Episode 3040: Reward = -43263.20, Avg Reward (100) = -30623.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 3041: Reward = -1196.00, Avg Reward (100) = -30701.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3042: Reward = -35499.61, Avg Reward (100) = -30357.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3043: Reward = -1049.00, Avg Reward (100) = -30280.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3044: Reward = -35499.61, Avg Reward (100) = -29943.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3045: Reward = -29946.84, Avg Reward (100) = -29943.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -29946.84, Border Penalty: -33033.02, Obstacle Penalty: -50.00
Episode 3046: Reward = -28683.61, Avg Reward (100) = -29920.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3047: Reward = -1196.00, Avg Reward (100) = -29852.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3048: Reward = -35499.61, Avg Reward (100) = -29509.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3049: Reward = -35499.61, Avg Reward (100) = -29527.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3050: Reward = -35499.61, Avg Reward (100) = -29868.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3051: Reward = -35499.61, Avg Reward (100) = -30212.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3052: Reward = -33701.04, Avg Reward (100) = -30212.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3053: Reward = -35499.61, Avg Reward (100) = -30205.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3054: Reward = -1049.00, Avg Reward (100) = -30226.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3055: Reward = -37669.33, Avg Reward (100) = -29881.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3056: Reward = -25228.52, Avg Reward (100) = -29903.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3057: Reward = -29512.46, Avg Reward (100) = -29800.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3058: Reward = -35499.61, Avg Reward (100) = -29740.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3059: Reward = -35499.61, Avg Reward (100) = -29734.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3060: Reward = -35499.61, Avg Reward (100) = -29734.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3061: Reward = -35499.61, Avg Reward (100) = -29734.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3062: Reward = -35499.61, Avg Reward (100) = -29794.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3063: Reward = -1196.00, Avg Reward (100) = -29794.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3064: Reward = -35499.61, Avg Reward (100) = -29451.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3065: Reward = -35499.61, Avg Reward (100) = -29794.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3066: Reward = -43263.20, Avg Reward (100) = -29823.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3067: Reward = -1295.00, Avg Reward (100) = -30001.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3068: Reward = -35499.61, Avg Reward (100) = -29659.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3069: Reward = -33469.53, Avg Reward (100) = -29719.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3070: Reward = -1049.00, Avg Reward (100) = -29699.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3071: Reward = -1295.00, Avg Reward (100) = -29699.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3072: Reward = -1000.00, Avg Reward (100) = -29357.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3073: Reward = -35499.61, Avg Reward (100) = -29012.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3074: Reward = -1394.00, Avg Reward (100) = -29239.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3075: Reward = -35499.61, Avg Reward (100) = -29239.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3076: Reward = -53075.23, Avg Reward (100) = -29239.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -41137.98, Obstacle Penalty: -50.00
Episode 3077: Reward = -35499.61, Avg Reward (100) = -29244.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3078: Reward = -1049.00, Avg Reward (100) = -29262.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3079: Reward = -39606.20, Avg Reward (100) = -28918.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3080: Reward = -29512.46, Avg Reward (100) = -28818.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3081: Reward = -35499.61, Avg Reward (100) = -28758.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3082: Reward = -35499.61, Avg Reward (100) = -28621.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3083: Reward = -29512.46, Avg Reward (100) = -28621.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3084: Reward = -37669.33, Avg Reward (100) = -28561.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3085: Reward = -36089.25, Avg Reward (100) = -28631.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3086: Reward = -35499.61, Avg Reward (100) = -28560.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3087: Reward = -55155.70, Avg Reward (100) = -28560.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -55155.70, Border Penalty: -39717.51, Obstacle Penalty: -50.00
Episode 3088: Reward = -35499.61, Avg Reward (100) = -28756.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3089: Reward = -35499.61, Avg Reward (100) = -28756.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3090: Reward = -49176.10, Avg Reward (100) = -28816.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3091: Reward = -35499.61, Avg Reward (100) = -28829.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3092: Reward = -35499.61, Avg Reward (100) = -28829.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3093: Reward = -32245.59, Avg Reward (100) = -29174.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 3094: Reward = -1394.00, Avg Reward (100) = -29141.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3095: Reward = -35499.61, Avg Reward (100) = -28909.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3096: Reward = -35499.61, Avg Reward (100) = -28909.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3097: Reward = -12446.80, Avg Reward (100) = -28909.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3098: Reward = -49626.26, Avg Reward (100) = -28781.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3099: Reward = -35499.61, Avg Reward (100) = -28922.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3100: Reward = -36089.25, Avg Reward (100) = -28922.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3101: Reward = -28683.61, Avg Reward (100) = -29270.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3102: Reward = -35499.61, Avg Reward (100) = -29546.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3103: Reward = -35499.61, Avg Reward (100) = -29891.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3104: Reward = -33378.53, Avg Reward (100) = -29800.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 3105: Reward = -1394.00, Avg Reward (100) = -29778.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3106: Reward = -33469.53, Avg Reward (100) = -29782.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3107: Reward = -1049.00, Avg Reward (100) = -29762.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3108: Reward = -35499.61, Avg Reward (100) = -29417.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3109: Reward = -47848.55, Avg Reward (100) = -29417.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3110: Reward = -35499.61, Avg Reward (100) = -29541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3111: Reward = -35499.61, Avg Reward (100) = -29541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3112: Reward = -34685.86, Avg Reward (100) = -29637.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3113: Reward = -39135.41, Avg Reward (100) = -29629.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36090.25, Obstacle Penalty: -50.00
Episode 3114: Reward = -35499.61, Avg Reward (100) = -29665.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3115: Reward = -35499.61, Avg Reward (100) = -29546.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3116: Reward = -43263.20, Avg Reward (100) = -29546.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -35267.92, Obstacle Penalty: -50.00
Episode 3117: Reward = -43263.20, Avg Reward (100) = -29642.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3118: Reward = -1196.00, Avg Reward (100) = -29720.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3119: Reward = -35499.61, Avg Reward (100) = -29377.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3120: Reward = -35499.61, Avg Reward (100) = -29377.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3121: Reward = -32245.59, Avg Reward (100) = -29377.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3122: Reward = -35499.61, Avg Reward (100) = -29689.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3123: Reward = -54280.34, Avg Reward (100) = -29689.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54280.34, Border Penalty: -41966.66, Obstacle Penalty: -50.00
Episode 3124: Reward = -29512.46, Avg Reward (100) = -29880.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3125: Reward = -28683.61, Avg Reward (100) = -29820.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -29464.60, Obstacle Penalty: -50.00
Episode 3126: Reward = -49176.10, Avg Reward (100) = -29731.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3127: Reward = -35499.61, Avg Reward (100) = -29867.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3128: Reward = -33701.04, Avg Reward (100) = -30212.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3129: Reward = -35499.61, Avg Reward (100) = -30194.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3130: Reward = -35499.61, Avg Reward (100) = -30424.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3131: Reward = -35499.61, Avg Reward (100) = -30457.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3132: Reward = -35499.61, Avg Reward (100) = -30800.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3133: Reward = -35499.61, Avg Reward (100) = -30672.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3134: Reward = -35499.61, Avg Reward (100) = -30701.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3135: Reward = -49176.10, Avg Reward (100) = -30701.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 3136: Reward = -1295.00, Avg Reward (100) = -30906.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3137: Reward = -32619.61, Avg Reward (100) = -30597.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3138: Reward = -49626.26, Avg Reward (100) = -30568.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3139: Reward = -35499.61, Avg Reward (100) = -30769.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3140: Reward = -35499.61, Avg Reward (100) = -30797.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3141: Reward = -35499.61, Avg Reward (100) = -30720.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3142: Reward = -35499.61, Avg Reward (100) = -31063.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3143: Reward = -35499.61, Avg Reward (100) = -31063.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3144: Reward = -35499.61, Avg Reward (100) = -31407.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3145: Reward = -25228.52, Avg Reward (100) = -31407.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3146: Reward = -35499.61, Avg Reward (100) = -31360.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3147: Reward = -39606.20, Avg Reward (100) = -31428.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3148: Reward = -35499.61, Avg Reward (100) = -31812.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3149: Reward = -35499.61, Avg Reward (100) = -31812.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3150: Reward = -1000.00, Avg Reward (100) = -31812.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3151: Reward = -49176.10, Avg Reward (100) = -31467.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3152: Reward = -35499.61, Avg Reward (100) = -31604.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3153: Reward = -35499.61, Avg Reward (100) = -31622.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3154: Reward = -1245.00, Avg Reward (100) = -31622.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3155: Reward = -34685.86, Avg Reward (100) = -31624.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3156: Reward = -35499.61, Avg Reward (100) = -31594.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3157: Reward = -35499.61, Avg Reward (100) = -31697.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3158: Reward = -35499.61, Avg Reward (100) = -31757.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3159: Reward = -43263.20, Avg Reward (100) = -31757.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3160: Reward = -35499.61, Avg Reward (100) = -31834.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3161: Reward = -35499.61, Avg Reward (100) = -31834.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3162: Reward = -28683.61, Avg Reward (100) = -31834.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3163: Reward = -39606.20, Avg Reward (100) = -31766.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3164: Reward = -35499.61, Avg Reward (100) = -32150.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3165: Reward = -35499.61, Avg Reward (100) = -32150.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3166: Reward = -30246.10, Avg Reward (100) = -32150.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -30246.10, Border Penalty: -32822.25, Obstacle Penalty: -50.00
Episode 3167: Reward = -1098.00, Avg Reward (100) = -32020.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3168: Reward = -35499.61, Avg Reward (100) = -32018.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3169: Reward = -32619.61, Avg Reward (100) = -32018.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3170: Reward = -35499.61, Avg Reward (100) = -32010.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3171: Reward = -35499.61, Avg Reward (100) = -32354.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3172: Reward = -35499.61, Avg Reward (100) = -32696.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3173: Reward = -35499.61, Avg Reward (100) = -33041.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3174: Reward = -32619.61, Avg Reward (100) = -33041.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3175: Reward = -35499.61, Avg Reward (100) = -33353.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3176: Reward = -35499.61, Avg Reward (100) = -33353.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3177: Reward = -35499.61, Avg Reward (100) = -33178.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3178: Reward = -35499.61, Avg Reward (100) = -33178.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3179: Reward = -35499.61, Avg Reward (100) = -33522.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3180: Reward = -35499.61, Avg Reward (100) = -33481.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3181: Reward = -47914.45, Avg Reward (100) = -33541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 3182: Reward = -44618.20, Avg Reward (100) = -33665.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -44618.20, Border Penalty: -38251.55, Obstacle Penalty: -50.00
Episode 3183: Reward = -32619.61, Avg Reward (100) = -33756.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 3184: Reward = -35499.61, Avg Reward (100) = -33787.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3185: Reward = -35499.61, Avg Reward (100) = -33766.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3186: Reward = -25539.05, Avg Reward (100) = -33760.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -25539.05, Border Penalty: -30186.28, Obstacle Penalty: -50.00
Episode 3187: Reward = -35499.61, Avg Reward (100) = -33660.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3188: Reward = -35499.61, Avg Reward (100) = -33464.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3189: Reward = -35499.61, Avg Reward (100) = -33464.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3190: Reward = -35499.61, Avg Reward (100) = -33464.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3191: Reward = -1049.00, Avg Reward (100) = -33327.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3192: Reward = -1394.00, Avg Reward (100) = -32982.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3193: Reward = -35499.61, Avg Reward (100) = -32641.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3194: Reward = -35499.61, Avg Reward (100) = -32674.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3195: Reward = -33701.04, Avg Reward (100) = -33015.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3196: Reward = -35499.61, Avg Reward (100) = -32997.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3197: Reward = -37669.33, Avg Reward (100) = -32997.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3198: Reward = -35499.61, Avg Reward (100) = -33249.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3199: Reward = -28653.56, Avg Reward (100) = -33108.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3200: Reward = -32619.61, Avg Reward (100) = -33039.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3201: Reward = -48252.80, Avg Reward (100) = -33005.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 3202: Reward = -35499.61, Avg Reward (100) = -33200.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3203: Reward = -35499.61, Avg Reward (100) = -33200.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3204: Reward = -35499.61, Avg Reward (100) = -33200.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3205: Reward = -35499.61, Avg Reward (100) = -33222.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3206: Reward = -35499.61, Avg Reward (100) = -33563.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3207: Reward = -35499.61, Avg Reward (100) = -33583.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3208: Reward = -39216.62, Avg Reward (100) = -33927.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39216.62, Border Penalty: -32994.85, Obstacle Penalty: -50.00
Episode 3209: Reward = -1049.00, Avg Reward (100) = -33965.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3210: Reward = -35499.61, Avg Reward (100) = -33497.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3211: Reward = -12446.80, Avg Reward (100) = -33497.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3212: Reward = -35499.61, Avg Reward (100) = -33266.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3213: Reward = -32245.59, Avg Reward (100) = -33274.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3214: Reward = -43263.20, Avg Reward (100) = -33205.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 3215: Reward = -1098.00, Avg Reward (100) = -33283.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3216: Reward = -36089.25, Avg Reward (100) = -32939.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3217: Reward = -33469.53, Avg Reward (100) = -32867.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3218: Reward = -33701.04, Avg Reward (100) = -32769.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3219: Reward = -28683.61, Avg Reward (100) = -33094.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3220: Reward = -35499.61, Avg Reward (100) = -33026.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3221: Reward = -35499.61, Avg Reward (100) = -33026.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3222: Reward = -35499.61, Avg Reward (100) = -33059.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3223: Reward = -35499.61, Avg Reward (100) = -33059.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3224: Reward = -1196.00, Avg Reward (100) = -32871.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3225: Reward = -34685.86, Avg Reward (100) = -32588.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3226: Reward = -35499.61, Avg Reward (100) = -32648.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3227: Reward = -35499.61, Avg Reward (100) = -32511.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3228: Reward = -35499.61, Avg Reward (100) = -32511.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3229: Reward = -37833.70, Avg Reward (100) = -32529.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37833.70, Border Penalty: -36129.36, Obstacle Penalty: -50.00
Episode 3230: Reward = -35499.61, Avg Reward (100) = -32552.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3231: Reward = -35499.61, Avg Reward (100) = -32552.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3232: Reward = -35499.61, Avg Reward (100) = -32552.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3233: Reward = -35499.61, Avg Reward (100) = -32552.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3234: Reward = -12446.80, Avg Reward (100) = -32552.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3235: Reward = -35499.61, Avg Reward (100) = -32322.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3236: Reward = -32245.59, Avg Reward (100) = -32185.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3237: Reward = -1196.00, Avg Reward (100) = -32495.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3238: Reward = -35499.61, Avg Reward (100) = -32180.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3239: Reward = -32619.61, Avg Reward (100) = -32039.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3240: Reward = -35499.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3241: Reward = -35499.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3242: Reward = -35499.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3243: Reward = -35499.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3244: Reward = -35499.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3245: Reward = -28683.61, Avg Reward (100) = -32010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3246: Reward = -1098.00, Avg Reward (100) = -32045.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3247: Reward = -35499.61, Avg Reward (100) = -31701.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3248: Reward = -1295.00, Avg Reward (100) = -31660.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3249: Reward = -35499.61, Avg Reward (100) = -31318.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3250: Reward = -1049.00, Avg Reward (100) = -31318.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3251: Reward = -49176.10, Avg Reward (100) = -31318.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3252: Reward = -32619.61, Avg Reward (100) = -31318.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3253: Reward = -35499.61, Avg Reward (100) = -31289.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3254: Reward = -35499.61, Avg Reward (100) = -31289.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3255: Reward = -1049.00, Avg Reward (100) = -31632.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3256: Reward = -49174.12, Avg Reward (100) = -31296.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 3257: Reward = -33646.16, Avg Reward (100) = -31432.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -33646.16, Border Penalty: -32930.10, Obstacle Penalty: -50.00
Episode 3258: Reward = -35499.61, Avg Reward (100) = -31414.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3259: Reward = -35499.61, Avg Reward (100) = -31414.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3260: Reward = -32619.61, Avg Reward (100) = -31336.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3261: Reward = -35499.61, Avg Reward (100) = -31307.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3262: Reward = -35499.61, Avg Reward (100) = -31307.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3263: Reward = -42504.46, Avg Reward (100) = -31375.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42504.46, Border Penalty: -37949.78, Obstacle Penalty: -50.00
Episode 3264: Reward = -1049.00, Avg Reward (100) = -31404.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3265: Reward = -35499.61, Avg Reward (100) = -31060.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3266: Reward = -35499.61, Avg Reward (100) = -31060.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3267: Reward = -35499.61, Avg Reward (100) = -31112.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3268: Reward = -12446.80, Avg Reward (100) = -31456.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3269: Reward = -35499.61, Avg Reward (100) = -31226.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3270: Reward = -12446.80, Avg Reward (100) = -31255.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3271: Reward = -35499.61, Avg Reward (100) = -31024.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3272: Reward = -35499.61, Avg Reward (100) = -31024.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3273: Reward = -35499.61, Avg Reward (100) = -31024.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3274: Reward = -28653.56, Avg Reward (100) = -31024.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3275: Reward = -35499.61, Avg Reward (100) = -30985.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3276: Reward = -33701.04, Avg Reward (100) = -30985.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3277: Reward = -1295.00, Avg Reward (100) = -30967.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3278: Reward = -35499.61, Avg Reward (100) = -30625.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3279: Reward = -35499.61, Avg Reward (100) = -30625.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3280: Reward = -35499.61, Avg Reward (100) = -30625.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3281: Reward = -33701.04, Avg Reward (100) = -30625.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3282: Reward = -35499.61, Avg Reward (100) = -30482.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3283: Reward = -1394.00, Avg Reward (100) = -30391.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3284: Reward = -35499.61, Avg Reward (100) = -30079.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3285: Reward = -35499.61, Avg Reward (100) = -30079.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3286: Reward = -34685.86, Avg Reward (100) = -30079.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 3287: Reward = -1394.00, Avg Reward (100) = -30170.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3288: Reward = -35499.61, Avg Reward (100) = -29829.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3289: Reward = -35499.61, Avg Reward (100) = -29829.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3290: Reward = -34482.45, Avg Reward (100) = -29829.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 3291: Reward = -35499.61, Avg Reward (100) = -29819.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3292: Reward = -35499.61, Avg Reward (100) = -30164.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3293: Reward = -35499.61, Avg Reward (100) = -30505.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3294: Reward = -47848.55, Avg Reward (100) = -30505.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3295: Reward = -1098.00, Avg Reward (100) = -30628.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3296: Reward = -35499.61, Avg Reward (100) = -30302.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3297: Reward = -35499.61, Avg Reward (100) = -30302.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3298: Reward = -35499.61, Avg Reward (100) = -30281.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3299: Reward = -12446.80, Avg Reward (100) = -30281.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3300: Reward = -1000.00, Avg Reward (100) = -30118.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3301: Reward = -1000.00, Avg Reward (100) = -29802.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3302: Reward = -35499.61, Avg Reward (100) = -29330.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3303: Reward = -2156.56, Avg Reward (100) = -29330.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 3304: Reward = -35499.61, Avg Reward (100) = -28996.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3305: Reward = -35499.61, Avg Reward (100) = -28996.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3306: Reward = -35499.61, Avg Reward (100) = -28996.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3307: Reward = -1098.00, Avg Reward (100) = -28996.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3308: Reward = -35499.61, Avg Reward (100) = -28652.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3309: Reward = -35499.61, Avg Reward (100) = -28615.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3310: Reward = -35499.61, Avg Reward (100) = -28960.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3311: Reward = -35499.61, Avg Reward (100) = -28960.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3312: Reward = -35499.61, Avg Reward (100) = -29190.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3313: Reward = -35499.61, Avg Reward (100) = -29190.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3314: Reward = -1196.00, Avg Reward (100) = -29223.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3315: Reward = -35499.61, Avg Reward (100) = -28802.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3316: Reward = -35499.61, Avg Reward (100) = -29146.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3317: Reward = -33469.53, Avg Reward (100) = -29140.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3318: Reward = -35499.61, Avg Reward (100) = -29140.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3319: Reward = -48949.36, Avg Reward (100) = -29158.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -48949.36, Border Penalty: -40380.79, Obstacle Penalty: -50.00
Episode 3320: Reward = -12446.80, Avg Reward (100) = -29361.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3321: Reward = -35499.61, Avg Reward (100) = -29130.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3322: Reward = -1196.00, Avg Reward (100) = -29130.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3323: Reward = -35499.61, Avg Reward (100) = -28787.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3324: Reward = -39606.20, Avg Reward (100) = -28787.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3325: Reward = -35499.61, Avg Reward (100) = -29171.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3326: Reward = -35499.61, Avg Reward (100) = -29179.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3327: Reward = -33701.04, Avg Reward (100) = -29179.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3328: Reward = -12446.80, Avg Reward (100) = -29161.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3329: Reward = -35499.61, Avg Reward (100) = -28931.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3330: Reward = -35499.61, Avg Reward (100) = -28908.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3331: Reward = -35499.61, Avg Reward (100) = -28908.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3332: Reward = -35499.61, Avg Reward (100) = -28908.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3333: Reward = -35499.61, Avg Reward (100) = -28908.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3334: Reward = -1295.00, Avg Reward (100) = -28908.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3335: Reward = -35499.61, Avg Reward (100) = -28796.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3336: Reward = -30063.90, Avg Reward (100) = -28796.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30063.90, Border Penalty: -32903.33, Obstacle Penalty: -50.00
Episode 3337: Reward = -1049.00, Avg Reward (100) = -28774.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3338: Reward = -1049.00, Avg Reward (100) = -28773.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3339: Reward = -47848.55, Avg Reward (100) = -28428.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3340: Reward = -33469.53, Avg Reward (100) = -28581.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3341: Reward = -35499.61, Avg Reward (100) = -28560.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3342: Reward = -35499.61, Avg Reward (100) = -28560.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3343: Reward = -35499.61, Avg Reward (100) = -28560.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3344: Reward = -35499.61, Avg Reward (100) = -28560.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3345: Reward = -35499.61, Avg Reward (100) = -28560.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3346: Reward = -29512.46, Avg Reward (100) = -28628.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3347: Reward = -35499.61, Avg Reward (100) = -28913.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3348: Reward = -35499.61, Avg Reward (100) = -28913.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3349: Reward = -54238.48, Avg Reward (100) = -29255.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54238.48, Border Penalty: -40171.28, Obstacle Penalty: -50.00
Episode 3350: Reward = -35499.61, Avg Reward (100) = -29442.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3351: Reward = -35499.61, Avg Reward (100) = -29787.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3352: Reward = -49176.10, Avg Reward (100) = -29650.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3353: Reward = -1147.00, Avg Reward (100) = -29815.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3354: Reward = -1049.00, Avg Reward (100) = -29472.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3355: Reward = -36089.25, Avg Reward (100) = -29127.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3356: Reward = -35499.61, Avg Reward (100) = -29478.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3357: Reward = -35499.61, Avg Reward (100) = -29341.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3358: Reward = -1098.00, Avg Reward (100) = -29359.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3359: Reward = -33469.53, Avg Reward (100) = -29015.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3360: Reward = -35499.61, Avg Reward (100) = -28995.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3361: Reward = -1000.00, Avg Reward (100) = -29024.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3362: Reward = -43263.20, Avg Reward (100) = -28679.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3363: Reward = -35499.61, Avg Reward (100) = -28757.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3364: Reward = -28772.37, Avg Reward (100) = -28687.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 3365: Reward = -29512.46, Avg Reward (100) = -28964.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3366: Reward = -1295.00, Avg Reward (100) = -28904.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3367: Reward = -12446.80, Avg Reward (100) = -28562.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3368: Reward = -35499.61, Avg Reward (100) = -28331.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3369: Reward = -35499.61, Avg Reward (100) = -28562.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3370: Reward = -1098.00, Avg Reward (100) = -28562.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3371: Reward = -35499.61, Avg Reward (100) = -28448.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3372: Reward = -29512.46, Avg Reward (100) = -28448.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3373: Reward = -35499.61, Avg Reward (100) = -28389.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3374: Reward = -35499.61, Avg Reward (100) = -28389.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3375: Reward = -35499.61, Avg Reward (100) = -28457.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3376: Reward = -49626.26, Avg Reward (100) = -28457.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3377: Reward = -35499.61, Avg Reward (100) = -28616.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3378: Reward = -35499.61, Avg Reward (100) = -28958.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3379: Reward = -47848.55, Avg Reward (100) = -28958.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3380: Reward = -27866.99, Avg Reward (100) = -29082.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -27866.99, Border Penalty: -31603.49, Obstacle Penalty: -50.00
Episode 3381: Reward = -35499.61, Avg Reward (100) = -29005.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3382: Reward = -35499.61, Avg Reward (100) = -29023.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3383: Reward = -1196.00, Avg Reward (100) = -29023.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3384: Reward = -43569.45, Avg Reward (100) = -29021.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43569.45, Border Penalty: -37743.09, Obstacle Penalty: -50.00
Episode 3385: Reward = -32619.61, Avg Reward (100) = -29102.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3386: Reward = -36089.25, Avg Reward (100) = -29073.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 3387: Reward = -29512.46, Avg Reward (100) = -29087.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3388: Reward = -1000.00, Avg Reward (100) = -29369.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3389: Reward = -35499.61, Avg Reward (100) = -29024.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3390: Reward = -1196.00, Avg Reward (100) = -29024.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3391: Reward = -47848.55, Avg Reward (100) = -28691.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3392: Reward = -32245.59, Avg Reward (100) = -28814.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3393: Reward = -32245.59, Avg Reward (100) = -28782.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3394: Reward = -32245.59, Avg Reward (100) = -28749.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3395: Reward = -35499.61, Avg Reward (100) = -28593.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3396: Reward = -35499.61, Avg Reward (100) = -28937.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3397: Reward = -32940.72, Avg Reward (100) = -28937.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32940.72, Border Penalty: -32866.37, Obstacle Penalty: -50.00
Episode 3398: Reward = -35499.61, Avg Reward (100) = -28911.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3399: Reward = -37669.33, Avg Reward (100) = -28911.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3400: Reward = -35499.61, Avg Reward (100) = -29164.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3401: Reward = -12446.80, Avg Reward (100) = -29509.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3402: Reward = -35499.61, Avg Reward (100) = -29623.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3403: Reward = -1196.00, Avg Reward (100) = -29623.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3404: Reward = -35499.61, Avg Reward (100) = -29614.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3405: Reward = -39606.20, Avg Reward (100) = -29614.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3406: Reward = -1394.00, Avg Reward (100) = -29655.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3407: Reward = -35499.61, Avg Reward (100) = -29314.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3408: Reward = -35499.61, Avg Reward (100) = -29658.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3409: Reward = -35499.61, Avg Reward (100) = -29658.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3410: Reward = -1098.00, Avg Reward (100) = -29658.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3411: Reward = -33469.53, Avg Reward (100) = -29314.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3412: Reward = -35499.61, Avg Reward (100) = -29293.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3413: Reward = -35499.61, Avg Reward (100) = -29293.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3414: Reward = -35499.61, Avg Reward (100) = -29293.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3415: Reward = -59176.41, Avg Reward (100) = -29636.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -34852.61, Obstacle Penalty: -50.00
Episode 3416: Reward = -52172.23, Avg Reward (100) = -29873.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52172.23, Border Penalty: -36624.57, Obstacle Penalty: -50.00
Episode 3417: Reward = -36089.25, Avg Reward (100) = -30040.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3418: Reward = -35499.61, Avg Reward (100) = -30066.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3419: Reward = -1049.00, Avg Reward (100) = -30066.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3420: Reward = -35499.61, Avg Reward (100) = -29587.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3421: Reward = -1147.00, Avg Reward (100) = -29818.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3422: Reward = -49176.10, Avg Reward (100) = -29474.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3423: Reward = -35499.61, Avg Reward (100) = -29954.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3424: Reward = -47914.45, Avg Reward (100) = -29954.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 3425: Reward = -35499.61, Avg Reward (100) = -30037.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3426: Reward = -33469.53, Avg Reward (100) = -30037.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3427: Reward = -53615.70, Avg Reward (100) = -30017.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -41236.93, Obstacle Penalty: -50.00
Episode 3428: Reward = -49626.26, Avg Reward (100) = -30216.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3429: Reward = -35499.61, Avg Reward (100) = -30588.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3430: Reward = -35499.61, Avg Reward (100) = -30588.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3431: Reward = -25228.52, Avg Reward (100) = -30588.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3432: Reward = -1000.00, Avg Reward (100) = -30485.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3433: Reward = -1098.00, Avg Reward (100) = -30140.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3434: Reward = -35499.61, Avg Reward (100) = -29796.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3435: Reward = -35499.61, Avg Reward (100) = -30138.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3436: Reward = -35499.61, Avg Reward (100) = -30138.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3437: Reward = -35499.61, Avg Reward (100) = -30192.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3438: Reward = -35499.61, Avg Reward (100) = -30537.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3439: Reward = -35499.61, Avg Reward (100) = -30881.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3440: Reward = -35499.61, Avg Reward (100) = -30758.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3441: Reward = -35499.61, Avg Reward (100) = -30778.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3442: Reward = -35499.61, Avg Reward (100) = -30778.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3443: Reward = -47848.55, Avg Reward (100) = -30778.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3444: Reward = -35499.61, Avg Reward (100) = -30902.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3445: Reward = -25228.52, Avg Reward (100) = -30902.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3446: Reward = -43263.20, Avg Reward (100) = -30799.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3447: Reward = -35499.61, Avg Reward (100) = -30936.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3448: Reward = -35499.61, Avg Reward (100) = -30936.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3449: Reward = -35499.61, Avg Reward (100) = -30936.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3450: Reward = -35499.61, Avg Reward (100) = -30749.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3451: Reward = -36089.25, Avg Reward (100) = -30749.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3452: Reward = -24832.48, Avg Reward (100) = -30755.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -24832.48, Border Penalty: -30321.71, Obstacle Penalty: -50.00
Episode 3453: Reward = -38414.23, Avg Reward (100) = -30511.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -36175.60, Obstacle Penalty: -50.00
Episode 3454: Reward = -31555.25, Avg Reward (100) = -30884.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -31555.25, Border Penalty: -33490.29, Obstacle Penalty: -50.00
Episode 3455: Reward = -35499.61, Avg Reward (100) = -31189.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3456: Reward = -1000.00, Avg Reward (100) = -31183.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3457: Reward = -35499.61, Avg Reward (100) = -30838.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3458: Reward = -1196.00, Avg Reward (100) = -30838.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3459: Reward = -1000.00, Avg Reward (100) = -30839.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3460: Reward = -35499.61, Avg Reward (100) = -30515.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3461: Reward = -1147.00, Avg Reward (100) = -30515.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3462: Reward = -32632.70, Avg Reward (100) = -30516.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 3463: Reward = -35499.61, Avg Reward (100) = -30410.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3464: Reward = -35499.61, Avg Reward (100) = -30410.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3465: Reward = -35499.61, Avg Reward (100) = -30477.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3466: Reward = -12446.80, Avg Reward (100) = -30537.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3467: Reward = -35499.61, Avg Reward (100) = -30648.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3468: Reward = -35499.61, Avg Reward (100) = -30879.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3469: Reward = -12446.80, Avg Reward (100) = -30879.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3470: Reward = -35499.61, Avg Reward (100) = -30648.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3471: Reward = -36089.25, Avg Reward (100) = -30992.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 3472: Reward = -35499.61, Avg Reward (100) = -30998.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3473: Reward = -1196.00, Avg Reward (100) = -31058.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3474: Reward = -35499.61, Avg Reward (100) = -30715.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3475: Reward = -35499.61, Avg Reward (100) = -30715.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3476: Reward = -35499.61, Avg Reward (100) = -30715.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3477: Reward = -1295.00, Avg Reward (100) = -30574.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3478: Reward = -1098.00, Avg Reward (100) = -30232.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3479: Reward = -35499.61, Avg Reward (100) = -29888.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3480: Reward = -35499.61, Avg Reward (100) = -29764.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3481: Reward = -32245.59, Avg Reward (100) = -29841.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3482: Reward = -48567.86, Avg Reward (100) = -29808.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 3483: Reward = -43263.20, Avg Reward (100) = -29939.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3484: Reward = -35499.61, Avg Reward (100) = -30359.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3485: Reward = -28683.61, Avg Reward (100) = -30279.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3486: Reward = -32619.61, Avg Reward (100) = -30239.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3487: Reward = -35499.61, Avg Reward (100) = -30205.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3488: Reward = -28683.61, Avg Reward (100) = -30265.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3489: Reward = -33469.53, Avg Reward (100) = -30541.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3490: Reward = -35499.61, Avg Reward (100) = -30521.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3491: Reward = -35499.61, Avg Reward (100) = -30864.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3492: Reward = -35499.61, Avg Reward (100) = -30741.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3493: Reward = -35499.61, Avg Reward (100) = -30773.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3494: Reward = -35499.61, Avg Reward (100) = -30806.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3495: Reward = -1000.00, Avg Reward (100) = -30838.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3496: Reward = -33469.53, Avg Reward (100) = -30493.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3497: Reward = -35499.61, Avg Reward (100) = -30473.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3498: Reward = -1000.00, Avg Reward (100) = -30499.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3499: Reward = -35499.61, Avg Reward (100) = -30154.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3500: Reward = -35499.61, Avg Reward (100) = -30132.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3501: Reward = -28683.61, Avg Reward (100) = -30132.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3502: Reward = -35499.61, Avg Reward (100) = -30294.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3503: Reward = -43263.20, Avg Reward (100) = -30294.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 3504: Reward = -36089.25, Avg Reward (100) = -30715.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3505: Reward = -35499.61, Avg Reward (100) = -30721.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3506: Reward = -35499.61, Avg Reward (100) = -30680.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3507: Reward = -35499.61, Avg Reward (100) = -31021.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3508: Reward = -35499.61, Avg Reward (100) = -31021.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3509: Reward = -32675.73, Avg Reward (100) = -31021.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32675.73, Border Penalty: -30294.06, Obstacle Penalty: -50.00
Episode 3510: Reward = -37669.33, Avg Reward (100) = -30993.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3511: Reward = -35499.61, Avg Reward (100) = -31358.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3512: Reward = -35499.61, Avg Reward (100) = -31379.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3513: Reward = -35499.61, Avg Reward (100) = -31379.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3514: Reward = -32619.61, Avg Reward (100) = -31379.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3515: Reward = -35499.61, Avg Reward (100) = -31350.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3516: Reward = -33701.04, Avg Reward (100) = -31113.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3517: Reward = -35499.61, Avg Reward (100) = -30928.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3518: Reward = -1442.00, Avg Reward (100) = -30922.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1442.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3519: Reward = -39606.20, Avg Reward (100) = -30582.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3520: Reward = -35499.61, Avg Reward (100) = -30967.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3521: Reward = -43263.20, Avg Reward (100) = -30967.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3522: Reward = -35499.61, Avg Reward (100) = -31389.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3523: Reward = -1000.00, Avg Reward (100) = -31252.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3524: Reward = -35499.61, Avg Reward (100) = -30907.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3525: Reward = -52585.18, Avg Reward (100) = -30783.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 3526: Reward = -53264.24, Avg Reward (100) = -30953.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -53264.24, Border Penalty: -40635.22, Obstacle Penalty: -50.00
Episode 3527: Reward = -36089.25, Avg Reward (100) = -31151.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3528: Reward = -35499.61, Avg Reward (100) = -30976.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3529: Reward = -36726.20, Avg Reward (100) = -30835.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36726.20, Border Penalty: -32739.82, Obstacle Penalty: -50.00
Episode 3530: Reward = -35499.61, Avg Reward (100) = -30847.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3531: Reward = -1394.00, Avg Reward (100) = -30847.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3532: Reward = -1000.00, Avg Reward (100) = -30609.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3533: Reward = -33469.53, Avg Reward (100) = -30609.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3534: Reward = -37669.33, Avg Reward (100) = -30933.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3535: Reward = -35499.61, Avg Reward (100) = -30954.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3536: Reward = -35499.61, Avg Reward (100) = -30954.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3537: Reward = -35499.61, Avg Reward (100) = -30954.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3538: Reward = -1147.00, Avg Reward (100) = -30954.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3539: Reward = -32619.61, Avg Reward (100) = -30611.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3540: Reward = -35499.61, Avg Reward (100) = -30582.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3541: Reward = -35499.61, Avg Reward (100) = -30582.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3542: Reward = -35499.61, Avg Reward (100) = -30582.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3543: Reward = -35499.61, Avg Reward (100) = -30582.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3544: Reward = -35499.61, Avg Reward (100) = -30458.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3545: Reward = -35499.61, Avg Reward (100) = -30458.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3546: Reward = -42113.29, Avg Reward (100) = -30561.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42113.29, Border Penalty: -35930.51, Obstacle Penalty: -50.00
Episode 3547: Reward = -49176.10, Avg Reward (100) = -30550.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3548: Reward = -35499.61, Avg Reward (100) = -30686.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3549: Reward = -1049.00, Avg Reward (100) = -30686.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3550: Reward = -35499.61, Avg Reward (100) = -30342.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3551: Reward = -1098.00, Avg Reward (100) = -30342.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3552: Reward = -35499.61, Avg Reward (100) = -29992.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3553: Reward = -1098.00, Avg Reward (100) = -30099.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3554: Reward = -29512.46, Avg Reward (100) = -29725.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3555: Reward = -35499.61, Avg Reward (100) = -29705.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3556: Reward = -35499.61, Avg Reward (100) = -29705.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3557: Reward = -26326.21, Avg Reward (100) = -30050.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 3558: Reward = -1049.00, Avg Reward (100) = -29958.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3559: Reward = -35499.61, Avg Reward (100) = -29957.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3560: Reward = -35499.61, Avg Reward (100) = -30302.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3561: Reward = -38636.47, Avg Reward (100) = -30302.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 3562: Reward = -35499.61, Avg Reward (100) = -30677.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3563: Reward = -30650.91, Avg Reward (100) = -30705.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30650.91, Border Penalty: -32829.87, Obstacle Penalty: -50.00
Episode 3564: Reward = -37669.33, Avg Reward (100) = -30657.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3565: Reward = -35499.61, Avg Reward (100) = -30679.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3566: Reward = -35499.61, Avg Reward (100) = -30679.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3567: Reward = -28198.29, Avg Reward (100) = -30909.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31316.97, Obstacle Penalty: -50.00
Episode 3568: Reward = -35499.61, Avg Reward (100) = -30836.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3569: Reward = -39606.20, Avg Reward (100) = -30836.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3570: Reward = -35499.61, Avg Reward (100) = -31108.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3571: Reward = -35499.61, Avg Reward (100) = -31108.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3572: Reward = -35499.61, Avg Reward (100) = -31102.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3573: Reward = -1147.00, Avg Reward (100) = -31102.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3574: Reward = -35499.61, Avg Reward (100) = -31101.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3575: Reward = -35499.61, Avg Reward (100) = -31101.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3576: Reward = -35499.61, Avg Reward (100) = -31101.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3577: Reward = -41554.36, Avg Reward (100) = -31101.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 3578: Reward = -28683.61, Avg Reward (100) = -31504.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3579: Reward = -35499.61, Avg Reward (100) = -31780.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3580: Reward = -35499.61, Avg Reward (100) = -31780.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3581: Reward = -35499.61, Avg Reward (100) = -31780.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3582: Reward = -35499.61, Avg Reward (100) = -31812.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3583: Reward = -35499.61, Avg Reward (100) = -31682.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3584: Reward = -35499.61, Avg Reward (100) = -31604.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3585: Reward = -35499.61, Avg Reward (100) = -31604.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3586: Reward = -35499.61, Avg Reward (100) = -31672.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3587: Reward = -35499.61, Avg Reward (100) = -31701.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3588: Reward = -35499.61, Avg Reward (100) = -31701.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3589: Reward = -47848.55, Avg Reward (100) = -31769.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3590: Reward = -37295.09, Avg Reward (100) = -31913.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37295.09, Border Penalty: -36380.75, Obstacle Penalty: -50.00
Episode 3591: Reward = -25228.52, Avg Reward (100) = -31931.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3592: Reward = -25228.52, Avg Reward (100) = -31828.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3593: Reward = -35499.61, Avg Reward (100) = -31725.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3594: Reward = -35499.61, Avg Reward (100) = -31725.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3595: Reward = -35499.61, Avg Reward (100) = -31725.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3596: Reward = -35499.61, Avg Reward (100) = -32070.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3597: Reward = -35499.61, Avg Reward (100) = -32091.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3598: Reward = -36089.25, Avg Reward (100) = -32091.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3599: Reward = -1049.00, Avg Reward (100) = -32442.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3600: Reward = -1000.00, Avg Reward (100) = -32097.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3601: Reward = -35499.61, Avg Reward (100) = -31752.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3602: Reward = -34685.86, Avg Reward (100) = -31820.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3603: Reward = -33701.04, Avg Reward (100) = -31812.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3604: Reward = -35499.61, Avg Reward (100) = -31717.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3605: Reward = -35499.61, Avg Reward (100) = -31711.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3606: Reward = -35499.61, Avg Reward (100) = -31711.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3607: Reward = -37669.33, Avg Reward (100) = -31711.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3608: Reward = -1049.00, Avg Reward (100) = -31732.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3609: Reward = -43263.20, Avg Reward (100) = -31388.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3610: Reward = -35499.61, Avg Reward (100) = -31494.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3611: Reward = -49626.26, Avg Reward (100) = -31472.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3612: Reward = -1147.00, Avg Reward (100) = -31613.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3613: Reward = -35499.61, Avg Reward (100) = -31270.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3614: Reward = -1000.00, Avg Reward (100) = -31270.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3615: Reward = -1147.00, Avg Reward (100) = -30954.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3616: Reward = -28653.56, Avg Reward (100) = -30610.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3617: Reward = -35499.61, Avg Reward (100) = -30560.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3618: Reward = -35499.61, Avg Reward (100) = -30560.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3619: Reward = -35499.61, Avg Reward (100) = -30900.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3620: Reward = -35499.61, Avg Reward (100) = -30859.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3621: Reward = -35499.61, Avg Reward (100) = -30859.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3622: Reward = -1098.00, Avg Reward (100) = -30781.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3623: Reward = -29512.46, Avg Reward (100) = -30437.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3624: Reward = -35499.61, Avg Reward (100) = -30723.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3625: Reward = -35499.61, Avg Reward (100) = -30723.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3626: Reward = -35499.61, Avg Reward (100) = -30552.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3627: Reward = -34685.86, Avg Reward (100) = -30374.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3628: Reward = -35499.61, Avg Reward (100) = -30360.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3629: Reward = -35499.61, Avg Reward (100) = -30360.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3630: Reward = -35499.61, Avg Reward (100) = -30348.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3631: Reward = -35499.61, Avg Reward (100) = -30348.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3632: Reward = -33469.53, Avg Reward (100) = -30689.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3633: Reward = -37669.33, Avg Reward (100) = -31013.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3634: Reward = -35499.61, Avg Reward (100) = -31055.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3635: Reward = -47848.55, Avg Reward (100) = -31034.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3636: Reward = -36089.25, Avg Reward (100) = -31157.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3637: Reward = -35499.61, Avg Reward (100) = -31163.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3638: Reward = -36089.25, Avg Reward (100) = -31163.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3639: Reward = -35499.61, Avg Reward (100) = -31513.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3640: Reward = -35499.61, Avg Reward (100) = -31541.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3641: Reward = -1098.00, Avg Reward (100) = -31541.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3642: Reward = -35499.61, Avg Reward (100) = -31197.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3643: Reward = -35499.61, Avg Reward (100) = -31197.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3644: Reward = -39671.98, Avg Reward (100) = -31197.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 3645: Reward = -35499.61, Avg Reward (100) = -31239.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3646: Reward = -49176.10, Avg Reward (100) = -31239.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3647: Reward = -35499.61, Avg Reward (100) = -31310.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3648: Reward = -49176.10, Avg Reward (100) = -31173.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3649: Reward = -35499.61, Avg Reward (100) = -31310.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3650: Reward = -35499.61, Avg Reward (100) = -31654.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3651: Reward = -39606.20, Avg Reward (100) = -31654.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3652: Reward = -1196.00, Avg Reward (100) = -32039.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3653: Reward = -35499.61, Avg Reward (100) = -31696.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3654: Reward = -35499.61, Avg Reward (100) = -32040.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3655: Reward = -35499.61, Avg Reward (100) = -32100.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3656: Reward = -35499.61, Avg Reward (100) = -32100.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3657: Reward = -43263.20, Avg Reward (100) = -32100.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3658: Reward = -35499.61, Avg Reward (100) = -32270.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3659: Reward = -35499.61, Avg Reward (100) = -32614.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3660: Reward = -36089.25, Avg Reward (100) = -32614.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3661: Reward = -12446.80, Avg Reward (100) = -32620.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3662: Reward = -35499.61, Avg Reward (100) = -32358.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3663: Reward = -35499.61, Avg Reward (100) = -32358.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3664: Reward = -34685.86, Avg Reward (100) = -32407.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3665: Reward = -35499.61, Avg Reward (100) = -32377.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3666: Reward = -35499.61, Avg Reward (100) = -32377.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3667: Reward = -35499.61, Avg Reward (100) = -32377.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3668: Reward = -1196.00, Avg Reward (100) = -32450.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3669: Reward = -35499.61, Avg Reward (100) = -32107.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3670: Reward = -1394.00, Avg Reward (100) = -32066.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3671: Reward = -35499.61, Avg Reward (100) = -31725.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3672: Reward = -32851.49, Avg Reward (100) = -31725.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 3673: Reward = -34685.86, Avg Reward (100) = -31698.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3674: Reward = -35499.61, Avg Reward (100) = -32033.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3675: Reward = -1196.00, Avg Reward (100) = -32033.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3676: Reward = -39606.20, Avg Reward (100) = -31690.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3677: Reward = -35499.61, Avg Reward (100) = -31731.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3678: Reward = -35499.61, Avg Reward (100) = -31671.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3679: Reward = -35499.61, Avg Reward (100) = -31739.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3680: Reward = -1098.00, Avg Reward (100) = -31739.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3681: Reward = -35499.61, Avg Reward (100) = -31395.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3682: Reward = -35499.61, Avg Reward (100) = -31395.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3683: Reward = -35499.61, Avg Reward (100) = -31395.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3684: Reward = -33701.04, Avg Reward (100) = -31395.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3685: Reward = -32245.59, Avg Reward (100) = -31377.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3686: Reward = -28653.56, Avg Reward (100) = -31345.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3687: Reward = -29358.58, Avg Reward (100) = -31276.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 3688: Reward = -20619.50, Avg Reward (100) = -31215.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -20619.50, Border Penalty: -25851.06, Obstacle Penalty: -50.00
Episode 3689: Reward = -35295.52, Avg Reward (100) = -31066.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34034.34, Obstacle Penalty: -50.00
Episode 3690: Reward = -1000.00, Avg Reward (100) = -30940.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3691: Reward = -35499.61, Avg Reward (100) = -30577.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3692: Reward = -35499.61, Avg Reward (100) = -30680.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3693: Reward = -1049.00, Avg Reward (100) = -30783.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3694: Reward = -28683.61, Avg Reward (100) = -30438.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3695: Reward = -25228.52, Avg Reward (100) = -30370.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3696: Reward = -35499.61, Avg Reward (100) = -30267.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3697: Reward = -35499.61, Avg Reward (100) = -30267.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3698: Reward = -35499.61, Avg Reward (100) = -30267.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3699: Reward = -37102.93, Avg Reward (100) = -30262.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37102.93, Border Penalty: -34449.38, Obstacle Penalty: -50.00
Episode 3700: Reward = -1147.00, Avg Reward (100) = -30622.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3701: Reward = -35499.61, Avg Reward (100) = -30624.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3702: Reward = -35499.61, Avg Reward (100) = -30624.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3703: Reward = -30092.93, Avg Reward (100) = -30632.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30092.93, Border Penalty: -31776.74, Obstacle Penalty: -50.00
Episode 3704: Reward = -35499.61, Avg Reward (100) = -30596.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3705: Reward = -1196.00, Avg Reward (100) = -30596.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3706: Reward = -35499.61, Avg Reward (100) = -30253.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3707: Reward = -1098.00, Avg Reward (100) = -30253.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3708: Reward = -33469.53, Avg Reward (100) = -29887.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3709: Reward = -1394.00, Avg Reward (100) = -30211.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3710: Reward = -35499.61, Avg Reward (100) = -29792.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3711: Reward = -1394.00, Avg Reward (100) = -29792.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3712: Reward = -35499.61, Avg Reward (100) = -29310.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3713: Reward = -35499.61, Avg Reward (100) = -29654.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3714: Reward = -39606.20, Avg Reward (100) = -29654.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3715: Reward = -35499.61, Avg Reward (100) = -30040.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3716: Reward = -35499.61, Avg Reward (100) = -30383.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3717: Reward = -35499.61, Avg Reward (100) = -30452.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3718: Reward = -1295.00, Avg Reward (100) = -30452.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3719: Reward = -35499.61, Avg Reward (100) = -30110.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3720: Reward = -35499.61, Avg Reward (100) = -30110.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3721: Reward = -35499.61, Avg Reward (100) = -30110.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3722: Reward = -35499.61, Avg Reward (100) = -30110.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3723: Reward = -1000.00, Avg Reward (100) = -30454.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3724: Reward = -28683.61, Avg Reward (100) = -30168.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3725: Reward = -35499.61, Avg Reward (100) = -30100.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3726: Reward = -35499.61, Avg Reward (100) = -30100.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3727: Reward = -28653.56, Avg Reward (100) = -30100.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3728: Reward = -35499.61, Avg Reward (100) = -30040.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3729: Reward = -1394.00, Avg Reward (100) = -30040.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3730: Reward = -1294.00, Avg Reward (100) = -29699.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 3731: Reward = -49626.26, Avg Reward (100) = -29357.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3732: Reward = -1147.00, Avg Reward (100) = -29498.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3733: Reward = -35499.61, Avg Reward (100) = -29175.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3734: Reward = -35499.61, Avg Reward (100) = -29153.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3735: Reward = -1049.00, Avg Reward (100) = -29153.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3736: Reward = -1295.00, Avg Reward (100) = -28685.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3737: Reward = -35499.61, Avg Reward (100) = -28337.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3738: Reward = -34927.46, Avg Reward (100) = -28337.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 3739: Reward = -35499.61, Avg Reward (100) = -28326.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3740: Reward = -35499.61, Avg Reward (100) = -28326.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3741: Reward = -35499.61, Avg Reward (100) = -28326.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3742: Reward = -35499.61, Avg Reward (100) = -28670.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3743: Reward = -43263.20, Avg Reward (100) = -28670.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 3744: Reward = -47848.55, Avg Reward (100) = -28747.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3745: Reward = -35499.61, Avg Reward (100) = -28829.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3746: Reward = -35499.61, Avg Reward (100) = -28829.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3747: Reward = -35499.61, Avg Reward (100) = -28692.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3748: Reward = -35499.61, Avg Reward (100) = -28692.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3749: Reward = -35499.61, Avg Reward (100) = -28556.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3750: Reward = -32619.61, Avg Reward (100) = -28556.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3751: Reward = -35499.61, Avg Reward (100) = -28527.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3752: Reward = -35499.61, Avg Reward (100) = -28486.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3753: Reward = -1394.00, Avg Reward (100) = -28829.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3754: Reward = -35499.61, Avg Reward (100) = -28488.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3755: Reward = -33469.53, Avg Reward (100) = -28488.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3756: Reward = -47848.55, Avg Reward (100) = -28467.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -36300.06, Obstacle Penalty: -50.00
Episode 3757: Reward = -35499.61, Avg Reward (100) = -28591.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3758: Reward = -35499.61, Avg Reward (100) = -28513.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3759: Reward = -35499.61, Avg Reward (100) = -28513.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3760: Reward = -35499.61, Avg Reward (100) = -28513.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3761: Reward = -35499.61, Avg Reward (100) = -28507.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3762: Reward = -1147.00, Avg Reward (100) = -28738.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3763: Reward = -33701.04, Avg Reward (100) = -28394.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3764: Reward = -35499.61, Avg Reward (100) = -28376.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3765: Reward = -1000.00, Avg Reward (100) = -28384.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3766: Reward = -1147.00, Avg Reward (100) = -28039.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3767: Reward = -34685.86, Avg Reward (100) = -27696.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 3768: Reward = -47848.55, Avg Reward (100) = -27688.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3769: Reward = -35499.61, Avg Reward (100) = -28154.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3770: Reward = -1098.00, Avg Reward (100) = -28154.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3771: Reward = -47848.55, Avg Reward (100) = -28151.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3772: Reward = -35499.61, Avg Reward (100) = -28275.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3773: Reward = -35499.61, Avg Reward (100) = -28301.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3774: Reward = -45723.38, Avg Reward (100) = -28309.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -45723.38, Border Penalty: -38065.23, Obstacle Penalty: -50.00
Episode 3775: Reward = -35499.61, Avg Reward (100) = -28412.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3776: Reward = -35499.61, Avg Reward (100) = -28755.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3777: Reward = -1098.00, Avg Reward (100) = -28714.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3778: Reward = -37669.33, Avg Reward (100) = -28370.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3779: Reward = -43263.20, Avg Reward (100) = -28391.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3780: Reward = -36089.25, Avg Reward (100) = -28469.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3781: Reward = -45417.44, Avg Reward (100) = -28819.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45417.44, Border Penalty: -37990.87, Obstacle Penalty: -50.00
Episode 3782: Reward = -33469.53, Avg Reward (100) = -28918.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3783: Reward = -35499.61, Avg Reward (100) = -28898.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3784: Reward = -35499.61, Avg Reward (100) = -28898.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3785: Reward = -35499.61, Avg Reward (100) = -28916.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3786: Reward = -40817.24, Avg Reward (100) = -28948.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40817.24, Border Penalty: -36530.08, Obstacle Penalty: -50.00
Episode 3787: Reward = -35499.61, Avg Reward (100) = -29070.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3788: Reward = -35499.61, Avg Reward (100) = -29131.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3789: Reward = -35499.61, Avg Reward (100) = -29280.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3790: Reward = -35499.61, Avg Reward (100) = -29282.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3791: Reward = -1196.00, Avg Reward (100) = -29627.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3792: Reward = -35499.61, Avg Reward (100) = -29284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3793: Reward = -1196.00, Avg Reward (100) = -29284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3794: Reward = -35499.61, Avg Reward (100) = -29286.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3795: Reward = -35499.61, Avg Reward (100) = -29354.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3796: Reward = -35499.61, Avg Reward (100) = -29457.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3797: Reward = -35499.61, Avg Reward (100) = -29457.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3798: Reward = -57674.50, Avg Reward (100) = -29457.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -57674.50, Border Penalty: -41170.21, Obstacle Penalty: -50.00
Episode 3799: Reward = -49626.26, Avg Reward (100) = -29678.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3800: Reward = -38414.23, Avg Reward (100) = -29804.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -33257.42, Obstacle Penalty: -50.00
Episode 3801: Reward = -35499.61, Avg Reward (100) = -30176.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3802: Reward = -35499.61, Avg Reward (100) = -30176.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3803: Reward = -35499.61, Avg Reward (100) = -30176.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3804: Reward = -17777.35, Avg Reward (100) = -30230.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -17777.35, Border Penalty: -24485.94, Obstacle Penalty: -50.00
Episode 3805: Reward = -35499.61, Avg Reward (100) = -30053.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3806: Reward = -33469.53, Avg Reward (100) = -30396.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3807: Reward = -35499.61, Avg Reward (100) = -30376.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3808: Reward = -1196.00, Avg Reward (100) = -30720.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3809: Reward = -29512.46, Avg Reward (100) = -30397.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3810: Reward = -37669.33, Avg Reward (100) = -30678.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3811: Reward = -1000.00, Avg Reward (100) = -30700.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3812: Reward = -1295.00, Avg Reward (100) = -30696.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3813: Reward = -1049.00, Avg Reward (100) = -30354.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3814: Reward = -35499.61, Avg Reward (100) = -30009.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3815: Reward = -43591.77, Avg Reward (100) = -29968.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43591.77, Border Penalty: -38351.20, Obstacle Penalty: -50.00
Episode 3816: Reward = -35499.61, Avg Reward (100) = -30049.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3817: Reward = -35499.61, Avg Reward (100) = -30049.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3818: Reward = -28683.61, Avg Reward (100) = -30049.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3819: Reward = -35499.61, Avg Reward (100) = -30323.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3820: Reward = -35499.61, Avg Reward (100) = -30323.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3821: Reward = -35499.61, Avg Reward (100) = -30323.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3822: Reward = -35499.61, Avg Reward (100) = -30323.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3823: Reward = -35499.61, Avg Reward (100) = -30323.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3824: Reward = -35499.61, Avg Reward (100) = -30668.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3825: Reward = -43263.20, Avg Reward (100) = -30736.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3826: Reward = -29512.46, Avg Reward (100) = -30814.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 3827: Reward = -28683.61, Avg Reward (100) = -30754.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3828: Reward = -32245.59, Avg Reward (100) = -30754.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3829: Reward = -35499.61, Avg Reward (100) = -30722.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3830: Reward = -53334.41, Avg Reward (100) = -31063.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 3831: Reward = -1000.00, Avg Reward (100) = -31583.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3832: Reward = -35499.61, Avg Reward (100) = -31097.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 3833: Reward = -1098.00, Avg Reward (100) = -31441.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3834: Reward = -35499.61, Avg Reward (100) = -31097.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3835: Reward = -33701.04, Avg Reward (100) = -31097.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3836: Reward = -35499.61, Avg Reward (100) = -31423.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3837: Reward = -35499.61, Avg Reward (100) = -31765.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3838: Reward = -35499.61, Avg Reward (100) = -31765.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3839: Reward = -35499.61, Avg Reward (100) = -31771.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3840: Reward = -35499.61, Avg Reward (100) = -31771.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3841: Reward = -35499.61, Avg Reward (100) = -31771.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3842: Reward = -33701.04, Avg Reward (100) = -31771.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3843: Reward = -1394.00, Avg Reward (100) = -31753.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3844: Reward = -12446.80, Avg Reward (100) = -31334.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 3845: Reward = -1394.00, Avg Reward (100) = -30980.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3846: Reward = -35499.61, Avg Reward (100) = -30639.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3847: Reward = -35499.61, Avg Reward (100) = -30639.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3848: Reward = -35499.61, Avg Reward (100) = -30639.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3849: Reward = -35499.61, Avg Reward (100) = -30639.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3850: Reward = -47848.55, Avg Reward (100) = -30639.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3851: Reward = -42363.56, Avg Reward (100) = -30791.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 3852: Reward = -32245.59, Avg Reward (100) = -30860.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3853: Reward = -35499.61, Avg Reward (100) = -30827.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3854: Reward = -1147.00, Avg Reward (100) = -31169.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3855: Reward = -1196.00, Avg Reward (100) = -30825.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3856: Reward = -39606.20, Avg Reward (100) = -30502.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3857: Reward = -35499.61, Avg Reward (100) = -30420.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3858: Reward = -35499.61, Avg Reward (100) = -30420.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3859: Reward = -35499.61, Avg Reward (100) = -30420.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3860: Reward = -1098.00, Avg Reward (100) = -30420.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3861: Reward = -1394.00, Avg Reward (100) = -30076.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3862: Reward = -32245.59, Avg Reward (100) = -29735.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3863: Reward = -35499.61, Avg Reward (100) = -30046.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3864: Reward = -35499.61, Avg Reward (100) = -30064.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3865: Reward = -35499.61, Avg Reward (100) = -30064.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3866: Reward = -32245.59, Avg Reward (100) = -30409.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3867: Reward = -1147.00, Avg Reward (100) = -30720.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3868: Reward = -49626.26, Avg Reward (100) = -30384.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 3869: Reward = -35499.61, Avg Reward (100) = -30402.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3870: Reward = -35499.61, Avg Reward (100) = -30402.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3871: Reward = -35499.61, Avg Reward (100) = -30746.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3872: Reward = -35499.61, Avg Reward (100) = -30623.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3873: Reward = -35499.61, Avg Reward (100) = -30623.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3874: Reward = -1049.00, Avg Reward (100) = -30623.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3875: Reward = -35499.61, Avg Reward (100) = -30176.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3876: Reward = -35499.61, Avg Reward (100) = -30176.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3877: Reward = -35499.61, Avg Reward (100) = -30176.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3878: Reward = -1147.00, Avg Reward (100) = -30520.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3879: Reward = -26470.74, Avg Reward (100) = -30155.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 3880: Reward = -39135.41, Avg Reward (100) = -29987.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36959.92, Obstacle Penalty: -50.00
Episode 3881: Reward = -35499.61, Avg Reward (100) = -30017.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3882: Reward = -35499.61, Avg Reward (100) = -29918.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3883: Reward = -33701.04, Avg Reward (100) = -29938.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3884: Reward = -32619.61, Avg Reward (100) = -29920.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3885: Reward = -35499.61, Avg Reward (100) = -29892.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3886: Reward = -35499.61, Avg Reward (100) = -29892.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3887: Reward = -35499.61, Avg Reward (100) = -29838.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3888: Reward = -39606.20, Avg Reward (100) = -29838.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3889: Reward = -47848.55, Avg Reward (100) = -29879.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 3890: Reward = -35499.61, Avg Reward (100) = -30003.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3891: Reward = -1098.00, Avg Reward (100) = -30003.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3892: Reward = -35499.61, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3893: Reward = -1196.00, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3894: Reward = -35499.61, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3895: Reward = -35499.61, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3896: Reward = -35499.61, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3897: Reward = -35499.61, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3898: Reward = -49176.10, Avg Reward (100) = -30002.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3899: Reward = -28683.61, Avg Reward (100) = -29917.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 3900: Reward = -43263.20, Avg Reward (100) = -29708.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 3901: Reward = -1196.00, Avg Reward (100) = -29756.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3902: Reward = -48016.18, Avg Reward (100) = -29413.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48016.18, Border Penalty: -39202.87, Obstacle Penalty: -50.00
Episode 3903: Reward = -35499.61, Avg Reward (100) = -29538.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3904: Reward = -35499.61, Avg Reward (100) = -29538.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3905: Reward = -35499.61, Avg Reward (100) = -29715.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3906: Reward = -37669.33, Avg Reward (100) = -29715.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3907: Reward = -35499.61, Avg Reward (100) = -29757.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3908: Reward = -35499.61, Avg Reward (100) = -29757.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3909: Reward = -35499.61, Avg Reward (100) = -30100.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3910: Reward = -35499.61, Avg Reward (100) = -30160.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3911: Reward = -35499.61, Avg Reward (100) = -30139.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3912: Reward = -35499.61, Avg Reward (100) = -30484.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3913: Reward = -1000.00, Avg Reward (100) = -30826.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3914: Reward = -35499.61, Avg Reward (100) = -30825.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3915: Reward = -30619.04, Avg Reward (100) = -30825.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30619.04, Border Penalty: -32490.02, Obstacle Penalty: -50.00
Episode 3916: Reward = -35499.61, Avg Reward (100) = -30695.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3917: Reward = -35499.61, Avg Reward (100) = -30695.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3918: Reward = -1196.00, Avg Reward (100) = -30695.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3919: Reward = -35499.61, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3920: Reward = -35499.61, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3921: Reward = -35499.61, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3922: Reward = -35499.61, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3923: Reward = -35499.61, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3924: Reward = -49929.11, Avg Reward (100) = -30421.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 3925: Reward = -35499.61, Avg Reward (100) = -30565.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3926: Reward = -53053.43, Avg Reward (100) = -30487.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -53053.43, Border Penalty: -39554.56, Obstacle Penalty: -50.00
Episode 3927: Reward = -35468.23, Avg Reward (100) = -30723.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35468.23, Border Penalty: -35365.46, Obstacle Penalty: -50.00
Episode 3928: Reward = -25228.52, Avg Reward (100) = -30790.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3929: Reward = -34236.08, Avg Reward (100) = -30720.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -34470.76, Obstacle Penalty: -50.00
Episode 3930: Reward = -35499.61, Avg Reward (100) = -30708.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3931: Reward = -28653.56, Avg Reward (100) = -30529.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 3932: Reward = -35499.61, Avg Reward (100) = -30806.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3933: Reward = -35499.61, Avg Reward (100) = -30806.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3934: Reward = -1147.00, Avg Reward (100) = -31150.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3935: Reward = -25228.52, Avg Reward (100) = -30806.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 3936: Reward = -28653.56, Avg Reward (100) = -30722.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3937: Reward = -1196.00, Avg Reward (100) = -30653.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 3938: Reward = -35499.61, Avg Reward (100) = -30310.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3939: Reward = -35499.61, Avg Reward (100) = -30310.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3940: Reward = -1147.00, Avg Reward (100) = -30310.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3941: Reward = -1295.00, Avg Reward (100) = -29967.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3942: Reward = -35499.61, Avg Reward (100) = -29625.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3943: Reward = -33469.53, Avg Reward (100) = -29643.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3944: Reward = -35499.61, Avg Reward (100) = -29963.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3945: Reward = -35499.61, Avg Reward (100) = -30194.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3946: Reward = -35499.61, Avg Reward (100) = -30535.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3947: Reward = -1394.00, Avg Reward (100) = -30535.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3948: Reward = -1394.00, Avg Reward (100) = -30194.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 3949: Reward = -35499.61, Avg Reward (100) = -29853.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3950: Reward = -35499.61, Avg Reward (100) = -29853.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3951: Reward = -35499.61, Avg Reward (100) = -29729.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3952: Reward = -35499.61, Avg Reward (100) = -29661.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3953: Reward = -35499.61, Avg Reward (100) = -29693.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3954: Reward = -35499.61, Avg Reward (100) = -29693.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3955: Reward = -35499.61, Avg Reward (100) = -30037.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3956: Reward = -35499.61, Avg Reward (100) = -30380.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3957: Reward = -1147.00, Avg Reward (100) = -30339.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3958: Reward = -35499.61, Avg Reward (100) = -29995.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3959: Reward = -35499.61, Avg Reward (100) = -29995.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3960: Reward = -35499.61, Avg Reward (100) = -29995.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3961: Reward = -35499.61, Avg Reward (100) = -30339.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3962: Reward = -36089.25, Avg Reward (100) = -30680.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 3963: Reward = -35499.61, Avg Reward (100) = -30719.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3964: Reward = -1000.00, Avg Reward (100) = -30719.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3965: Reward = -44051.76, Avg Reward (100) = -30374.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -44051.76, Border Penalty: -38320.71, Obstacle Penalty: -50.00
Episode 3966: Reward = -35499.61, Avg Reward (100) = -30459.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3967: Reward = -35499.61, Avg Reward (100) = -30492.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3968: Reward = -35499.61, Avg Reward (100) = -30835.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3969: Reward = -35499.61, Avg Reward (100) = -30694.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3970: Reward = -35499.61, Avg Reward (100) = -30694.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3971: Reward = -1098.00, Avg Reward (100) = -30694.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3972: Reward = -35499.61, Avg Reward (100) = -30350.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 3973: Reward = -32245.59, Avg Reward (100) = -30350.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 3974: Reward = -35499.61, Avg Reward (100) = -30317.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3975: Reward = -53962.77, Avg Reward (100) = -30662.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53962.77, Border Penalty: -39528.81, Obstacle Penalty: -50.00
Episode 3976: Reward = -35499.61, Avg Reward (100) = -30847.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3977: Reward = -35499.61, Avg Reward (100) = -30847.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3978: Reward = -28653.56, Avg Reward (100) = -30847.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3979: Reward = -35499.61, Avg Reward (100) = -31122.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3980: Reward = -35499.61, Avg Reward (100) = -31212.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3981: Reward = -33701.04, Avg Reward (100) = -31176.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 3982: Reward = -28653.56, Avg Reward (100) = -31158.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 3983: Reward = -1295.00, Avg Reward (100) = -31089.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 3984: Reward = -37669.33, Avg Reward (100) = -30765.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 3985: Reward = -39606.20, Avg Reward (100) = -30816.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 3986: Reward = -1000.00, Avg Reward (100) = -30857.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 3987: Reward = -303.39, Avg Reward (100) = -30512.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -303.39, Border Penalty: -628.96, Obstacle Penalty: -89.52
Episode 3988: Reward = -33469.53, Avg Reward (100) = -30160.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 3989: Reward = -35499.61, Avg Reward (100) = -30098.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3990: Reward = -49176.10, Avg Reward (100) = -29975.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 3991: Reward = -35499.61, Avg Reward (100) = -30112.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3992: Reward = -35499.61, Avg Reward (100) = -30456.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3993: Reward = -35499.61, Avg Reward (100) = -30456.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3994: Reward = -35499.61, Avg Reward (100) = -30799.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3995: Reward = -35499.61, Avg Reward (100) = -30799.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3996: Reward = -35499.61, Avg Reward (100) = -30799.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3997: Reward = -35499.61, Avg Reward (100) = -30799.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3998: Reward = -35499.61, Avg Reward (100) = -30799.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 3999: Reward = -12446.80, Avg Reward (100) = -30662.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4000: Reward = -36004.66, Avg Reward (100) = -30499.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 4001: Reward = -39606.20, Avg Reward (100) = -30427.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4002: Reward = -35499.61, Avg Reward (100) = -30811.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4003: Reward = -32619.61, Avg Reward (100) = -30686.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4004: Reward = -35499.61, Avg Reward (100) = -30657.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4005: Reward = -1147.00, Avg Reward (100) = -30657.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4006: Reward = -35499.61, Avg Reward (100) = -30314.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4007: Reward = -35499.61, Avg Reward (100) = -30292.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4008: Reward = -1147.00, Avg Reward (100) = -30292.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4009: Reward = -35499.61, Avg Reward (100) = -29948.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4010: Reward = -1049.00, Avg Reward (100) = -29948.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4011: Reward = -35499.61, Avg Reward (100) = -29604.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4012: Reward = -35499.61, Avg Reward (100) = -29604.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4013: Reward = -37669.33, Avg Reward (100) = -29604.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4014: Reward = -35499.61, Avg Reward (100) = -29970.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4015: Reward = -34685.86, Avg Reward (100) = -29970.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4016: Reward = -35499.61, Avg Reward (100) = -30011.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4017: Reward = -35499.61, Avg Reward (100) = -30011.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4018: Reward = -28653.56, Avg Reward (100) = -30011.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4019: Reward = -35499.61, Avg Reward (100) = -30286.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4020: Reward = -49626.26, Avg Reward (100) = -30286.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4021: Reward = -35499.61, Avg Reward (100) = -30427.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4022: Reward = -35499.61, Avg Reward (100) = -30427.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4023: Reward = -35499.61, Avg Reward (100) = -30427.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4024: Reward = -49626.26, Avg Reward (100) = -30427.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4025: Reward = -35499.61, Avg Reward (100) = -30424.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4026: Reward = -35499.61, Avg Reward (100) = -30424.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4027: Reward = -1000.00, Avg Reward (100) = -30248.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4028: Reward = -35499.61, Avg Reward (100) = -29904.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4029: Reward = -35499.61, Avg Reward (100) = -30006.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4030: Reward = -1294.00, Avg Reward (100) = -30019.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 4031: Reward = -1049.00, Avg Reward (100) = -29677.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4032: Reward = -1196.00, Avg Reward (100) = -29401.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4033: Reward = -35499.61, Avg Reward (100) = -29058.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4034: Reward = -35499.61, Avg Reward (100) = -29058.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4035: Reward = -1296.78, Avg Reward (100) = -29401.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4036: Reward = -35499.61, Avg Reward (100) = -29162.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4037: Reward = -35499.61, Avg Reward (100) = -29231.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4038: Reward = -49176.10, Avg Reward (100) = -29574.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4039: Reward = -35499.61, Avg Reward (100) = -29710.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4040: Reward = -35499.61, Avg Reward (100) = -29710.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4041: Reward = -35499.61, Avg Reward (100) = -30054.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4042: Reward = -1196.00, Avg Reward (100) = -30396.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4043: Reward = -32245.59, Avg Reward (100) = -30053.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4044: Reward = -35499.61, Avg Reward (100) = -30041.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4045: Reward = -35499.61, Avg Reward (100) = -30041.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4046: Reward = -36089.25, Avg Reward (100) = -30041.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4047: Reward = -34685.86, Avg Reward (100) = -30047.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4048: Reward = -35499.61, Avg Reward (100) = -30380.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4049: Reward = -35499.61, Avg Reward (100) = -30721.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4050: Reward = -35499.61, Avg Reward (100) = -30721.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4051: Reward = -35499.61, Avg Reward (100) = -30721.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4052: Reward = -47848.55, Avg Reward (100) = -30721.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4053: Reward = -35499.61, Avg Reward (100) = -30844.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4054: Reward = -35499.61, Avg Reward (100) = -30844.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4055: Reward = -36089.25, Avg Reward (100) = -30844.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4056: Reward = -28653.56, Avg Reward (100) = -30850.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4057: Reward = -28683.61, Avg Reward (100) = -30782.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4058: Reward = -35499.61, Avg Reward (100) = -31057.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4059: Reward = -35499.61, Avg Reward (100) = -31057.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4060: Reward = -1147.00, Avg Reward (100) = -31057.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4061: Reward = -35499.61, Avg Reward (100) = -30713.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4062: Reward = -1295.00, Avg Reward (100) = -30713.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4063: Reward = -30447.02, Avg Reward (100) = -30365.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -32385.11, Obstacle Penalty: -50.00
Episode 4064: Reward = -35499.61, Avg Reward (100) = -30315.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4065: Reward = -35499.61, Avg Reward (100) = -30660.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4066: Reward = -26326.21, Avg Reward (100) = -30574.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 4067: Reward = -1394.00, Avg Reward (100) = -30483.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4068: Reward = -35499.61, Avg Reward (100) = -30142.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4069: Reward = -35499.61, Avg Reward (100) = -30142.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4070: Reward = -1295.00, Avg Reward (100) = -30142.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4071: Reward = -35499.61, Avg Reward (100) = -29800.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4072: Reward = -43263.20, Avg Reward (100) = -30144.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4073: Reward = -35499.61, Avg Reward (100) = -30221.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4074: Reward = -35499.61, Avg Reward (100) = -30254.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4075: Reward = -32619.61, Avg Reward (100) = -30254.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4076: Reward = -35499.61, Avg Reward (100) = -30040.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4077: Reward = -35499.61, Avg Reward (100) = -30040.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4078: Reward = -35499.61, Avg Reward (100) = -30040.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4079: Reward = -35499.61, Avg Reward (100) = -30109.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4080: Reward = -29512.46, Avg Reward (100) = -30109.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4081: Reward = -35499.61, Avg Reward (100) = -30049.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4082: Reward = -29512.46, Avg Reward (100) = -30067.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4083: Reward = -35499.61, Avg Reward (100) = -30075.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4084: Reward = -1049.00, Avg Reward (100) = -30417.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4085: Reward = -35499.61, Avg Reward (100) = -30051.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4086: Reward = -44187.07, Avg Reward (100) = -30010.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -44187.07, Border Penalty: -33400.95, Obstacle Penalty: -50.00
Episode 4087: Reward = -49626.26, Avg Reward (100) = -30442.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4088: Reward = -25228.52, Avg Reward (100) = -30935.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4089: Reward = -35499.61, Avg Reward (100) = -30853.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4090: Reward = -47848.55, Avg Reward (100) = -30853.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4091: Reward = -49174.12, Avg Reward (100) = -30840.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 4092: Reward = -35499.61, Avg Reward (100) = -30976.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4093: Reward = -32619.61, Avg Reward (100) = -30976.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4094: Reward = -35499.61, Avg Reward (100) = -30948.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4095: Reward = -1147.00, Avg Reward (100) = -30948.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4096: Reward = -47848.55, Avg Reward (100) = -30604.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4097: Reward = -54261.02, Avg Reward (100) = -30728.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54261.02, Border Penalty: -40768.21, Obstacle Penalty: -50.00
Episode 4098: Reward = -33701.04, Avg Reward (100) = -30915.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4099: Reward = -35499.61, Avg Reward (100) = -30897.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4100: Reward = -1147.00, Avg Reward (100) = -31128.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4101: Reward = -35499.61, Avg Reward (100) = -30779.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4102: Reward = -35499.61, Avg Reward (100) = -30738.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4103: Reward = -35499.61, Avg Reward (100) = -30738.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4104: Reward = -35499.61, Avg Reward (100) = -30767.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4105: Reward = -35499.61, Avg Reward (100) = -30767.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4106: Reward = -1049.00, Avg Reward (100) = -31110.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4107: Reward = -1000.00, Avg Reward (100) = -30766.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4108: Reward = -35499.61, Avg Reward (100) = -30421.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4109: Reward = -29512.46, Avg Reward (100) = -30764.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4110: Reward = -49176.10, Avg Reward (100) = -30705.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4111: Reward = -35499.61, Avg Reward (100) = -31186.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4112: Reward = -35499.61, Avg Reward (100) = -31186.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4113: Reward = -25228.52, Avg Reward (100) = -31186.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4114: Reward = -35499.61, Avg Reward (100) = -31061.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4115: Reward = -35499.61, Avg Reward (100) = -31061.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4116: Reward = -32619.61, Avg Reward (100) = -31070.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4117: Reward = -35499.61, Avg Reward (100) = -31041.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4118: Reward = -35499.61, Avg Reward (100) = -31041.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4119: Reward = -35499.61, Avg Reward (100) = -31109.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4120: Reward = -35499.61, Avg Reward (100) = -31109.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4121: Reward = -1394.00, Avg Reward (100) = -30968.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4122: Reward = -35499.61, Avg Reward (100) = -30627.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4123: Reward = -49626.26, Avg Reward (100) = -30627.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4124: Reward = -39606.20, Avg Reward (100) = -30768.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -33795.82, Obstacle Penalty: -50.00
Episode 4125: Reward = -35499.61, Avg Reward (100) = -30668.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4126: Reward = -35499.61, Avg Reward (100) = -30668.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4127: Reward = -35499.61, Avg Reward (100) = -30668.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4128: Reward = -1000.00, Avg Reward (100) = -31013.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4129: Reward = -35499.61, Avg Reward (100) = -30668.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4130: Reward = -28653.56, Avg Reward (100) = -30668.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4131: Reward = -43263.20, Avg Reward (100) = -30942.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4132: Reward = -35499.61, Avg Reward (100) = -31364.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4133: Reward = -35499.61, Avg Reward (100) = -31707.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4134: Reward = -35499.61, Avg Reward (100) = -31707.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4135: Reward = -35499.61, Avg Reward (100) = -31707.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4136: Reward = -35499.61, Avg Reward (100) = -32049.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4137: Reward = -35499.61, Avg Reward (100) = -32049.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4138: Reward = -35499.61, Avg Reward (100) = -32049.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4139: Reward = -35499.61, Avg Reward (100) = -31912.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4140: Reward = -35499.61, Avg Reward (100) = -31912.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4141: Reward = -35499.61, Avg Reward (100) = -31912.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4142: Reward = -35499.61, Avg Reward (100) = -31912.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4143: Reward = -49174.12, Avg Reward (100) = -32255.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 4144: Reward = -42651.70, Avg Reward (100) = -32424.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -36315.46, Obstacle Penalty: -50.00
Episode 4145: Reward = -1049.00, Avg Reward (100) = -32496.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4146: Reward = -25228.52, Avg Reward (100) = -32151.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4147: Reward = -35499.61, Avg Reward (100) = -32043.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4148: Reward = -34685.86, Avg Reward (100) = -32051.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4149: Reward = -35499.61, Avg Reward (100) = -32043.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4150: Reward = -12446.80, Avg Reward (100) = -32043.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4151: Reward = -31653.57, Avg Reward (100) = -31812.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 4152: Reward = -35499.61, Avg Reward (100) = -31774.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4153: Reward = -1147.00, Avg Reward (100) = -31650.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4154: Reward = -36089.25, Avg Reward (100) = -31307.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4155: Reward = -5472.60, Avg Reward (100) = -31313.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -5472.60, Border Penalty: -15256.44, Obstacle Penalty: -50.00
Episode 4156: Reward = -35499.61, Avg Reward (100) = -31006.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4157: Reward = -35499.61, Avg Reward (100) = -31075.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4158: Reward = -35499.61, Avg Reward (100) = -31143.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4159: Reward = -35499.61, Avg Reward (100) = -31143.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4160: Reward = -35499.61, Avg Reward (100) = -31143.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4161: Reward = -1394.00, Avg Reward (100) = -31487.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4162: Reward = -47848.55, Avg Reward (100) = -31146.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4163: Reward = -35499.61, Avg Reward (100) = -31611.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4164: Reward = -1295.00, Avg Reward (100) = -31662.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4165: Reward = -35499.61, Avg Reward (100) = -31320.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4166: Reward = -35499.61, Avg Reward (100) = -31320.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4167: Reward = -35499.61, Avg Reward (100) = -31411.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4168: Reward = -1295.00, Avg Reward (100) = -31752.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4169: Reward = -35499.61, Avg Reward (100) = -31410.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4170: Reward = -35499.61, Avg Reward (100) = -31410.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4171: Reward = -35499.61, Avg Reward (100) = -31752.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4172: Reward = -1098.00, Avg Reward (100) = -31752.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4173: Reward = -35499.61, Avg Reward (100) = -31331.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4174: Reward = -49626.26, Avg Reward (100) = -31331.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4175: Reward = -12446.80, Avg Reward (100) = -31472.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4176: Reward = -35499.61, Avg Reward (100) = -31270.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4177: Reward = -35499.61, Avg Reward (100) = -31270.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4178: Reward = -12446.80, Avg Reward (100) = -31270.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4179: Reward = -35499.61, Avg Reward (100) = -31040.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4180: Reward = -35499.61, Avg Reward (100) = -31040.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4181: Reward = -39671.98, Avg Reward (100) = -31100.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 4182: Reward = -35499.61, Avg Reward (100) = -31141.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4183: Reward = -25228.52, Avg Reward (100) = -31201.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4184: Reward = -35499.61, Avg Reward (100) = -31098.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4185: Reward = -35499.61, Avg Reward (100) = -31443.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4186: Reward = -35499.61, Avg Reward (100) = -31443.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4187: Reward = -35499.61, Avg Reward (100) = -31356.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4188: Reward = -1049.00, Avg Reward (100) = -31215.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4189: Reward = -40817.24, Avg Reward (100) = -30973.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40817.24, Border Penalty: -36530.08, Obstacle Penalty: -50.00
Episode 4190: Reward = -35499.61, Avg Reward (100) = -31026.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4191: Reward = -35499.61, Avg Reward (100) = -30903.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4192: Reward = -35499.61, Avg Reward (100) = -30766.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4193: Reward = -42464.98, Avg Reward (100) = -30766.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -42464.98, Border Penalty: -37928.99, Obstacle Penalty: -50.00
Episode 4194: Reward = -35499.61, Avg Reward (100) = -30864.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4195: Reward = -34685.86, Avg Reward (100) = -30864.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 4196: Reward = -25228.52, Avg Reward (100) = -31200.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4197: Reward = -41656.72, Avg Reward (100) = -30974.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41656.72, Border Penalty: -35485.22, Obstacle Penalty: -50.00
Episode 4198: Reward = -35499.61, Avg Reward (100) = -30848.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4199: Reward = -35499.61, Avg Reward (100) = -30866.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4200: Reward = -35499.61, Avg Reward (100) = -30866.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4201: Reward = -35499.61, Avg Reward (100) = -31209.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4202: Reward = -35499.61, Avg Reward (100) = -31209.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4203: Reward = -35499.61, Avg Reward (100) = -31209.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4204: Reward = -1394.00, Avg Reward (100) = -31209.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4205: Reward = -35499.61, Avg Reward (100) = -30868.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4206: Reward = -1049.00, Avg Reward (100) = -30868.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4207: Reward = -35499.61, Avg Reward (100) = -30868.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4208: Reward = -35499.61, Avg Reward (100) = -31213.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4209: Reward = -35499.61, Avg Reward (100) = -31213.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4210: Reward = -35499.61, Avg Reward (100) = -31273.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4211: Reward = -25228.52, Avg Reward (100) = -31136.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4212: Reward = -35499.61, Avg Reward (100) = -31033.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4213: Reward = -35499.61, Avg Reward (100) = -31033.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4214: Reward = -1147.00, Avg Reward (100) = -31136.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4215: Reward = -12446.80, Avg Reward (100) = -30793.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4216: Reward = -25228.52, Avg Reward (100) = -30562.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4217: Reward = -35499.61, Avg Reward (100) = -30488.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4218: Reward = -47477.73, Avg Reward (100) = -30488.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47477.73, Border Penalty: -38905.30, Obstacle Penalty: -50.00
Episode 4219: Reward = -1000.00, Avg Reward (100) = -30608.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4220: Reward = -35499.61, Avg Reward (100) = -30263.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4221: Reward = -35499.61, Avg Reward (100) = -30263.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4222: Reward = -35499.61, Avg Reward (100) = -30604.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4223: Reward = -49626.26, Avg Reward (100) = -30604.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4224: Reward = -35499.61, Avg Reward (100) = -30604.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4225: Reward = -1394.00, Avg Reward (100) = -30563.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4226: Reward = -35499.61, Avg Reward (100) = -30222.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4227: Reward = -35499.61, Avg Reward (100) = -30222.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4228: Reward = -1098.00, Avg Reward (100) = -30222.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4229: Reward = -35499.61, Avg Reward (100) = -30223.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4230: Reward = -1252.40, Avg Reward (100) = -30223.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4231: Reward = -35499.61, Avg Reward (100) = -29949.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4232: Reward = -35499.61, Avg Reward (100) = -29871.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4233: Reward = -35499.61, Avg Reward (100) = -29871.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4234: Reward = -42363.56, Avg Reward (100) = -29871.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 4235: Reward = -1295.00, Avg Reward (100) = -29940.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4236: Reward = -34685.86, Avg Reward (100) = -29598.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4237: Reward = -35499.61, Avg Reward (100) = -29590.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4238: Reward = -35499.61, Avg Reward (100) = -29590.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4239: Reward = -36089.25, Avg Reward (100) = -29590.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4240: Reward = -35499.61, Avg Reward (100) = -29596.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4241: Reward = -1049.00, Avg Reward (100) = -29596.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4242: Reward = -35499.61, Avg Reward (100) = -29251.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4243: Reward = -35499.61, Avg Reward (100) = -29251.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4244: Reward = -1196.00, Avg Reward (100) = -29114.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4245: Reward = -1098.00, Avg Reward (100) = -28700.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4246: Reward = -35499.61, Avg Reward (100) = -28700.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4247: Reward = -1147.00, Avg Reward (100) = -28803.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4248: Reward = -33469.53, Avg Reward (100) = -28459.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4249: Reward = -35499.61, Avg Reward (100) = -28447.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4250: Reward = -39606.20, Avg Reward (100) = -28447.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4251: Reward = -35499.61, Avg Reward (100) = -28719.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4252: Reward = -35499.61, Avg Reward (100) = -28757.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4253: Reward = -35499.61, Avg Reward (100) = -28757.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4254: Reward = -35499.61, Avg Reward (100) = -29101.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4255: Reward = -35499.61, Avg Reward (100) = -29095.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4256: Reward = -35499.61, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4257: Reward = -1394.00, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4258: Reward = -1147.00, Avg Reward (100) = -29054.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4259: Reward = -33469.53, Avg Reward (100) = -28711.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4260: Reward = -35499.61, Avg Reward (100) = -28690.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4261: Reward = -35499.61, Avg Reward (100) = -28690.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4262: Reward = -1394.00, Avg Reward (100) = -29031.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4263: Reward = -35499.61, Avg Reward (100) = -28567.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4264: Reward = -32619.61, Avg Reward (100) = -28567.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4265: Reward = -47439.38, Avg Reward (100) = -28880.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 4266: Reward = -35499.61, Avg Reward (100) = -28999.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4267: Reward = -1049.00, Avg Reward (100) = -28999.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4268: Reward = -35499.61, Avg Reward (100) = -28655.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4269: Reward = -41280.90, Avg Reward (100) = -28997.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 4270: Reward = -49176.10, Avg Reward (100) = -29055.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4271: Reward = -12446.80, Avg Reward (100) = -29192.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4272: Reward = -35499.61, Avg Reward (100) = -28961.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4273: Reward = -35499.61, Avg Reward (100) = -29305.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4274: Reward = -1394.00, Avg Reward (100) = -29305.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4275: Reward = -35499.61, Avg Reward (100) = -28823.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4276: Reward = -1098.00, Avg Reward (100) = -29053.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4277: Reward = -35499.61, Avg Reward (100) = -28709.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4278: Reward = -35499.61, Avg Reward (100) = -28709.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4279: Reward = -34685.86, Avg Reward (100) = -28940.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4280: Reward = -35499.61, Avg Reward (100) = -28932.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4281: Reward = -35499.61, Avg Reward (100) = -28932.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4282: Reward = -49176.10, Avg Reward (100) = -28890.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -37163.81, Obstacle Penalty: -50.00
Episode 4283: Reward = -35499.61, Avg Reward (100) = -29027.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4284: Reward = -25228.52, Avg Reward (100) = -29129.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4285: Reward = -51639.54, Avg Reward (100) = -29027.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51639.54, Border Penalty: -40925.70, Obstacle Penalty: -50.00
Episode 4286: Reward = -35499.61, Avg Reward (100) = -29188.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4287: Reward = -35499.61, Avg Reward (100) = -29188.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4288: Reward = -35499.61, Avg Reward (100) = -29188.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4289: Reward = -28653.56, Avg Reward (100) = -29533.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4290: Reward = -35499.61, Avg Reward (100) = -29411.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4291: Reward = -35499.61, Avg Reward (100) = -29411.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4292: Reward = -12446.80, Avg Reward (100) = -29411.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4293: Reward = -5390.43, Avg Reward (100) = -29180.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -5390.43, Border Penalty: -12900.05, Obstacle Penalty: -50.00
Episode 4294: Reward = -1295.00, Avg Reward (100) = -28810.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4295: Reward = -35499.61, Avg Reward (100) = -28468.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4296: Reward = -35499.61, Avg Reward (100) = -28476.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4297: Reward = -35499.61, Avg Reward (100) = -28579.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4298: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4299: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4300: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4301: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4302: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4303: Reward = -35499.61, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4304: Reward = -28653.56, Avg Reward (100) = -28517.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4305: Reward = -35499.61, Avg Reward (100) = -28790.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4306: Reward = -35499.61, Avg Reward (100) = -28790.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4307: Reward = -35499.61, Avg Reward (100) = -29134.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4308: Reward = -35499.61, Avg Reward (100) = -29134.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4309: Reward = -35499.61, Avg Reward (100) = -29134.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4310: Reward = -35499.61, Avg Reward (100) = -29134.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4311: Reward = -35499.61, Avg Reward (100) = -29134.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4312: Reward = -35499.61, Avg Reward (100) = -29237.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4313: Reward = -47848.55, Avg Reward (100) = -29237.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4314: Reward = -35499.61, Avg Reward (100) = -29360.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4315: Reward = -35499.61, Avg Reward (100) = -29704.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4316: Reward = -46653.19, Avg Reward (100) = -29934.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 4317: Reward = -37669.33, Avg Reward (100) = -30149.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4318: Reward = -35499.61, Avg Reward (100) = -30170.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4319: Reward = -1394.00, Avg Reward (100) = -30050.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4320: Reward = -1245.00, Avg Reward (100) = -30054.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4321: Reward = -34685.86, Avg Reward (100) = -29712.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4322: Reward = -32619.61, Avg Reward (100) = -29704.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4323: Reward = -49176.10, Avg Reward (100) = -29675.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4324: Reward = -29512.46, Avg Reward (100) = -29670.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4325: Reward = -35499.61, Avg Reward (100) = -29611.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4326: Reward = -33469.53, Avg Reward (100) = -29952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4327: Reward = -35499.61, Avg Reward (100) = -29931.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4328: Reward = -35499.61, Avg Reward (100) = -29931.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4329: Reward = -35499.61, Avg Reward (100) = -30275.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4330: Reward = -39606.20, Avg Reward (100) = -30275.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4331: Reward = -35499.61, Avg Reward (100) = -30659.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4332: Reward = -35499.61, Avg Reward (100) = -30659.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4333: Reward = -35499.61, Avg Reward (100) = -30659.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4334: Reward = -30056.79, Avg Reward (100) = -30659.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -33036.80, Obstacle Penalty: -50.00
Episode 4335: Reward = -40411.33, Avg Reward (100) = -30536.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 4336: Reward = -35499.61, Avg Reward (100) = -30927.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4337: Reward = -39606.20, Avg Reward (100) = -30935.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4338: Reward = -35499.61, Avg Reward (100) = -30976.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4339: Reward = -35499.61, Avg Reward (100) = -30976.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4340: Reward = -1098.00, Avg Reward (100) = -30970.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4341: Reward = -34745.03, Avg Reward (100) = -30626.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34745.03, Border Penalty: -32351.37, Obstacle Penalty: -50.00
Episode 4342: Reward = -32619.61, Avg Reward (100) = -30963.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4343: Reward = -48116.97, Avg Reward (100) = -30934.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -36853.81, Obstacle Penalty: -50.00
Episode 4344: Reward = -35499.61, Avg Reward (100) = -31061.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4345: Reward = -52333.05, Avg Reward (100) = -31404.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40617.02, Obstacle Penalty: -50.00
Episode 4346: Reward = -35499.61, Avg Reward (100) = -31916.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4347: Reward = -1098.00, Avg Reward (100) = -31916.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4348: Reward = -1394.00, Avg Reward (100) = -31915.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4349: Reward = -12446.80, Avg Reward (100) = -31595.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4350: Reward = -35499.61, Avg Reward (100) = -31364.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4351: Reward = -35499.61, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4352: Reward = -35499.61, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4353: Reward = -35499.61, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4354: Reward = -35499.61, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4355: Reward = -35499.61, Avg Reward (100) = -31323.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4356: Reward = -35499.61, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4357: Reward = -34685.86, Avg Reward (100) = -31323.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4358: Reward = -35499.61, Avg Reward (100) = -31656.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4359: Reward = -37669.33, Avg Reward (100) = -32000.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 4360: Reward = -47439.38, Avg Reward (100) = -32042.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -38679.39, Obstacle Penalty: -50.00
Episode 4361: Reward = -34685.86, Avg Reward (100) = -32161.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4362: Reward = -28683.61, Avg Reward (100) = -32153.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4363: Reward = -35499.61, Avg Reward (100) = -32426.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4364: Reward = -28653.56, Avg Reward (100) = -32426.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4365: Reward = -49176.10, Avg Reward (100) = -32386.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4366: Reward = -35499.61, Avg Reward (100) = -32403.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4367: Reward = -1295.00, Avg Reward (100) = -32403.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4368: Reward = -1196.00, Avg Reward (100) = -32406.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4369: Reward = -35499.61, Avg Reward (100) = -32063.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4370: Reward = -35499.61, Avg Reward (100) = -32005.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4371: Reward = -37669.33, Avg Reward (100) = -31868.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4372: Reward = -35499.61, Avg Reward (100) = -32120.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4373: Reward = -1000.00, Avg Reward (100) = -32120.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4374: Reward = -34236.08, Avg Reward (100) = -31775.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -34470.76, Obstacle Penalty: -50.00
Episode 4375: Reward = -1000.00, Avg Reward (100) = -32104.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4376: Reward = -35499.61, Avg Reward (100) = -31759.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4377: Reward = -35499.61, Avg Reward (100) = -32103.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4378: Reward = -35499.61, Avg Reward (100) = -32103.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4379: Reward = -12446.80, Avg Reward (100) = -32103.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4380: Reward = -35499.61, Avg Reward (100) = -31881.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4381: Reward = -37669.33, Avg Reward (100) = -31881.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4382: Reward = -35499.61, Avg Reward (100) = -31902.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4383: Reward = -35499.61, Avg Reward (100) = -31765.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4384: Reward = -28683.61, Avg Reward (100) = -31765.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4385: Reward = -1196.00, Avg Reward (100) = -31800.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4386: Reward = -35499.61, Avg Reward (100) = -31296.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4387: Reward = -35499.61, Avg Reward (100) = -31296.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4388: Reward = -35499.61, Avg Reward (100) = -31296.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4389: Reward = -35499.61, Avg Reward (100) = -31296.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4390: Reward = -47914.45, Avg Reward (100) = -31364.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 4391: Reward = -35499.61, Avg Reward (100) = -31488.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4392: Reward = -35499.61, Avg Reward (100) = -31488.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4393: Reward = -35499.61, Avg Reward (100) = -31719.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4394: Reward = -35499.61, Avg Reward (100) = -32020.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4395: Reward = -43263.20, Avg Reward (100) = -32362.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4396: Reward = -35499.61, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4397: Reward = -35499.61, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4398: Reward = -35499.61, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4399: Reward = -35499.61, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4400: Reward = -35499.61, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4401: Reward = -25228.52, Avg Reward (100) = -32440.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4402: Reward = -33469.53, Avg Reward (100) = -32337.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4403: Reward = -35499.61, Avg Reward (100) = -32316.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4404: Reward = -36089.25, Avg Reward (100) = -32316.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4405: Reward = -35499.61, Avg Reward (100) = -32391.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4406: Reward = -38036.20, Avg Reward (100) = -32391.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38036.20, Border Penalty: -35931.23, Obstacle Penalty: -50.00
Episode 4407: Reward = -35499.61, Avg Reward (100) = -32416.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4408: Reward = -35499.61, Avg Reward (100) = -32416.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4409: Reward = -29358.58, Avg Reward (100) = -32416.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 4410: Reward = -35499.61, Avg Reward (100) = -32355.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4411: Reward = -1147.00, Avg Reward (100) = -32355.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4412: Reward = -30416.69, Avg Reward (100) = -32011.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30416.69, Border Penalty: -33691.42, Obstacle Penalty: -50.00
Episode 4413: Reward = -49176.10, Avg Reward (100) = -31960.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4414: Reward = -35499.61, Avg Reward (100) = -31974.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4415: Reward = -49176.10, Avg Reward (100) = -31974.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4416: Reward = -35499.61, Avg Reward (100) = -32110.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4417: Reward = -32619.61, Avg Reward (100) = -31999.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4418: Reward = -1196.00, Avg Reward (100) = -31948.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4419: Reward = -35499.61, Avg Reward (100) = -31605.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4420: Reward = -34685.86, Avg Reward (100) = -31946.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4421: Reward = -35499.61, Avg Reward (100) = -32281.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4422: Reward = -12446.80, Avg Reward (100) = -32289.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4423: Reward = -1000.00, Avg Reward (100) = -32087.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4424: Reward = -35499.61, Avg Reward (100) = -31606.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4425: Reward = -32245.59, Avg Reward (100) = -31665.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4426: Reward = -35499.61, Avg Reward (100) = -31633.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4427: Reward = -35499.61, Avg Reward (100) = -31653.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4428: Reward = -47848.55, Avg Reward (100) = -31653.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4429: Reward = -35499.61, Avg Reward (100) = -31777.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4430: Reward = -36089.25, Avg Reward (100) = -31777.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4431: Reward = -27052.21, Avg Reward (100) = -31741.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27052.21, Border Penalty: -31213.36, Obstacle Penalty: -50.00
Episode 4432: Reward = -35499.61, Avg Reward (100) = -31657.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4433: Reward = -49626.26, Avg Reward (100) = -31657.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4434: Reward = -1098.00, Avg Reward (100) = -31798.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4435: Reward = -35499.61, Avg Reward (100) = -31509.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4436: Reward = -39671.98, Avg Reward (100) = -31460.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 4437: Reward = -35499.61, Avg Reward (100) = -31501.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4438: Reward = -35499.61, Avg Reward (100) = -31460.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4439: Reward = -35499.61, Avg Reward (100) = -31460.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4440: Reward = -1000.00, Avg Reward (100) = -31460.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4441: Reward = -35499.61, Avg Reward (100) = -31459.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4442: Reward = -1196.00, Avg Reward (100) = -31467.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4443: Reward = -28653.56, Avg Reward (100) = -31153.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4444: Reward = -32245.59, Avg Reward (100) = -30958.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4445: Reward = -35499.61, Avg Reward (100) = -30925.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4446: Reward = -35499.61, Avg Reward (100) = -30757.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4447: Reward = -35499.61, Avg Reward (100) = -30757.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4448: Reward = -35499.61, Avg Reward (100) = -31101.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4449: Reward = -35499.61, Avg Reward (100) = -31442.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4450: Reward = -49176.10, Avg Reward (100) = -31673.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 4451: Reward = -35499.61, Avg Reward (100) = -31809.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4452: Reward = -39606.20, Avg Reward (100) = -31809.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4453: Reward = -35499.61, Avg Reward (100) = -31850.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4454: Reward = -35499.61, Avg Reward (100) = -31850.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4455: Reward = -1147.00, Avg Reward (100) = -31850.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4456: Reward = -35499.61, Avg Reward (100) = -31507.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4457: Reward = -1196.00, Avg Reward (100) = -31507.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4458: Reward = -46107.05, Avg Reward (100) = -31172.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46107.05, Border Penalty: -37684.10, Obstacle Penalty: -50.00
Episode 4459: Reward = -47914.45, Avg Reward (100) = -31278.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 4460: Reward = -28683.61, Avg Reward (100) = -31381.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4461: Reward = -48116.97, Avg Reward (100) = -31193.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 4462: Reward = -35499.61, Avg Reward (100) = -31327.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4463: Reward = -49626.26, Avg Reward (100) = -31395.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4464: Reward = -54870.38, Avg Reward (100) = -31537.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -54870.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 4465: Reward = -35499.61, Avg Reward (100) = -31799.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4466: Reward = -43902.06, Avg Reward (100) = -31662.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 4467: Reward = -35499.61, Avg Reward (100) = -31746.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4468: Reward = -33701.04, Avg Reward (100) = -32088.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4469: Reward = -35499.61, Avg Reward (100) = -32413.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4470: Reward = -35499.61, Avg Reward (100) = -32413.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4471: Reward = -47848.55, Avg Reward (100) = -32413.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 4472: Reward = -35499.61, Avg Reward (100) = -32515.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4473: Reward = -35499.61, Avg Reward (100) = -32515.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4474: Reward = -35499.61, Avg Reward (100) = -32860.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4475: Reward = -25228.52, Avg Reward (100) = -32873.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4476: Reward = -28683.61, Avg Reward (100) = -33115.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4477: Reward = -1245.00, Avg Reward (100) = -33047.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4478: Reward = -35499.61, Avg Reward (100) = -32704.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4479: Reward = -43263.20, Avg Reward (100) = -32704.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4480: Reward = -39606.20, Avg Reward (100) = -33012.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4481: Reward = -31163.36, Avg Reward (100) = -33054.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31163.36, Border Penalty: -33115.60, Obstacle Penalty: -50.00
Episode 4482: Reward = -25228.52, Avg Reward (100) = -32988.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4483: Reward = -35499.61, Avg Reward (100) = -32886.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4484: Reward = -29512.46, Avg Reward (100) = -32886.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4485: Reward = -35499.61, Avg Reward (100) = -32894.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4486: Reward = -35499.61, Avg Reward (100) = -33237.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4487: Reward = -35499.61, Avg Reward (100) = -33237.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4488: Reward = -35499.61, Avg Reward (100) = -33237.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4489: Reward = -30392.74, Avg Reward (100) = -33237.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 4490: Reward = -35499.61, Avg Reward (100) = -33186.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4491: Reward = -48252.80, Avg Reward (100) = -33062.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38090.98, Obstacle Penalty: -50.00
Episode 4492: Reward = -35499.61, Avg Reward (100) = -33189.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4493: Reward = -1049.00, Avg Reward (100) = -33189.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4494: Reward = -35499.61, Avg Reward (100) = -32845.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4495: Reward = -35499.61, Avg Reward (100) = -32845.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4496: Reward = -47848.55, Avg Reward (100) = -32767.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 4497: Reward = -1098.00, Avg Reward (100) = -32891.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4498: Reward = -1394.00, Avg Reward (100) = -32547.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4499: Reward = -43263.20, Avg Reward (100) = -32206.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4500: Reward = -35499.61, Avg Reward (100) = -32283.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4501: Reward = -12446.80, Avg Reward (100) = -32283.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4502: Reward = -32632.70, Avg Reward (100) = -32155.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 4503: Reward = -37669.33, Avg Reward (100) = -32147.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4504: Reward = -35499.61, Avg Reward (100) = -32169.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4505: Reward = -1196.00, Avg Reward (100) = -32163.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4506: Reward = -35499.61, Avg Reward (100) = -31820.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4507: Reward = -35499.61, Avg Reward (100) = -31795.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4508: Reward = -37669.33, Avg Reward (100) = -31795.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4509: Reward = -35499.61, Avg Reward (100) = -31816.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4510: Reward = -35499.61, Avg Reward (100) = -31878.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4511: Reward = -35499.61, Avg Reward (100) = -31878.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4512: Reward = -34685.86, Avg Reward (100) = -32221.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4513: Reward = -35499.61, Avg Reward (100) = -32264.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4514: Reward = -35499.61, Avg Reward (100) = -32127.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4515: Reward = -49626.26, Avg Reward (100) = -32127.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4516: Reward = -25228.52, Avg Reward (100) = -32132.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4517: Reward = -1147.00, Avg Reward (100) = -32029.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4518: Reward = -35499.61, Avg Reward (100) = -31714.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4519: Reward = -35499.61, Avg Reward (100) = -32057.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4520: Reward = -34685.86, Avg Reward (100) = -32057.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4521: Reward = -35499.61, Avg Reward (100) = -32057.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4522: Reward = -49626.26, Avg Reward (100) = -32057.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4523: Reward = -1394.00, Avg Reward (100) = -32429.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4524: Reward = -35499.61, Avg Reward (100) = -32433.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4525: Reward = -35499.61, Avg Reward (100) = -32433.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4526: Reward = -35499.61, Avg Reward (100) = -32465.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4527: Reward = -35499.61, Avg Reward (100) = -32465.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4528: Reward = -35499.61, Avg Reward (100) = -32465.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4529: Reward = -43263.20, Avg Reward (100) = -32342.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4530: Reward = -33469.53, Avg Reward (100) = -32420.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4531: Reward = -35499.61, Avg Reward (100) = -32393.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4532: Reward = -32245.59, Avg Reward (100) = -32478.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 4533: Reward = -35499.61, Avg Reward (100) = -32445.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4534: Reward = -28653.56, Avg Reward (100) = -32304.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4535: Reward = -29512.46, Avg Reward (100) = -32580.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 4536: Reward = -46242.48, Avg Reward (100) = -32520.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -36037.65, Obstacle Penalty: -50.00
Episode 4537: Reward = -28882.62, Avg Reward (100) = -32585.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28882.62, Border Penalty: -32371.81, Obstacle Penalty: -50.00
Episode 4538: Reward = -35499.61, Avg Reward (100) = -32519.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4539: Reward = -25228.52, Avg Reward (100) = -32519.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4540: Reward = -32619.61, Avg Reward (100) = -32417.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4541: Reward = -1098.00, Avg Reward (100) = -32733.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4542: Reward = -35499.61, Avg Reward (100) = -32389.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4543: Reward = -47848.55, Avg Reward (100) = -32732.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4544: Reward = -35499.61, Avg Reward (100) = -32924.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4545: Reward = -1049.00, Avg Reward (100) = -32956.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4546: Reward = -1393.00, Avg Reward (100) = -32612.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4547: Reward = -50968.57, Avg Reward (100) = -32271.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -40121.91, Obstacle Penalty: -50.00
Episode 4548: Reward = -35499.61, Avg Reward (100) = -32425.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4549: Reward = -35499.61, Avg Reward (100) = -32425.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4550: Reward = -35499.61, Avg Reward (100) = -32425.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4551: Reward = -35499.61, Avg Reward (100) = -32289.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4552: Reward = -35499.61, Avg Reward (100) = -32289.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4553: Reward = -35499.61, Avg Reward (100) = -32248.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4554: Reward = -30619.04, Avg Reward (100) = -32248.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30619.04, Border Penalty: -32490.02, Obstacle Penalty: -50.00
Episode 4555: Reward = -28653.56, Avg Reward (100) = -32199.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4556: Reward = -35499.61, Avg Reward (100) = -32474.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4557: Reward = -35499.61, Avg Reward (100) = -32474.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4558: Reward = -1196.00, Avg Reward (100) = -32817.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4559: Reward = -49176.10, Avg Reward (100) = -32368.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4560: Reward = -1000.00, Avg Reward (100) = -32380.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4561: Reward = -1147.00, Avg Reward (100) = -32104.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4562: Reward = -35499.61, Avg Reward (100) = -31634.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4563: Reward = -35499.61, Avg Reward (100) = -31634.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4564: Reward = -35499.61, Avg Reward (100) = -31493.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4565: Reward = -35499.61, Avg Reward (100) = -31299.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4566: Reward = -35499.61, Avg Reward (100) = -31299.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4567: Reward = -35499.61, Avg Reward (100) = -31215.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4568: Reward = -35499.61, Avg Reward (100) = -31215.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4569: Reward = -35499.61, Avg Reward (100) = -31233.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4570: Reward = -36089.25, Avg Reward (100) = -31233.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4571: Reward = -43263.20, Avg Reward (100) = -31239.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4572: Reward = -33701.04, Avg Reward (100) = -31193.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4573: Reward = -35499.61, Avg Reward (100) = -31175.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4574: Reward = -35499.61, Avg Reward (100) = -31175.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4575: Reward = -1295.00, Avg Reward (100) = -31175.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4576: Reward = -35499.61, Avg Reward (100) = -30936.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4577: Reward = -35499.61, Avg Reward (100) = -31004.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4578: Reward = -35499.61, Avg Reward (100) = -31346.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4579: Reward = -34685.86, Avg Reward (100) = -31346.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4580: Reward = -35499.61, Avg Reward (100) = -31260.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4581: Reward = -35499.61, Avg Reward (100) = -31219.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4582: Reward = -35499.61, Avg Reward (100) = -31263.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4583: Reward = -35499.61, Avg Reward (100) = -31365.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4584: Reward = -35499.61, Avg Reward (100) = -31365.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4585: Reward = -25228.52, Avg Reward (100) = -31425.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4586: Reward = -35499.61, Avg Reward (100) = -31323.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4587: Reward = -35499.61, Avg Reward (100) = -31323.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4588: Reward = -35499.61, Avg Reward (100) = -31323.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4589: Reward = -35499.61, Avg Reward (100) = -31323.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4590: Reward = -31625.50, Avg Reward (100) = -31374.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -31625.50, Border Penalty: -32993.25, Obstacle Penalty: -50.00
Episode 4591: Reward = -25228.52, Avg Reward (100) = -31335.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4592: Reward = -35499.61, Avg Reward (100) = -31105.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4593: Reward = -35499.61, Avg Reward (100) = -31105.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4594: Reward = -35499.61, Avg Reward (100) = -31449.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4595: Reward = -35499.61, Avg Reward (100) = -31449.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4596: Reward = -32245.59, Avg Reward (100) = -31449.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4597: Reward = -34685.86, Avg Reward (100) = -31293.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4598: Reward = -12446.80, Avg Reward (100) = -31629.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4599: Reward = -46968.27, Avg Reward (100) = -31740.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46968.27, Border Penalty: -39241.64, Obstacle Penalty: -50.00
Episode 4600: Reward = -1394.00, Avg Reward (100) = -31777.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4601: Reward = -1147.00, Avg Reward (100) = -31436.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4602: Reward = -35499.61, Avg Reward (100) = -31323.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4603: Reward = -28683.61, Avg Reward (100) = -31351.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4604: Reward = -32619.61, Avg Reward (100) = -31261.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4605: Reward = -35499.61, Avg Reward (100) = -31233.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4606: Reward = -1098.00, Avg Reward (100) = -31576.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4607: Reward = -35499.61, Avg Reward (100) = -31232.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4608: Reward = -47848.55, Avg Reward (100) = -31232.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4609: Reward = -29512.46, Avg Reward (100) = -31333.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4610: Reward = -1098.00, Avg Reward (100) = -31274.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4611: Reward = -20619.50, Avg Reward (100) = -30930.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -20619.50, Border Penalty: -25851.06, Obstacle Penalty: -50.00
Episode 4612: Reward = -35499.61, Avg Reward (100) = -30781.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4613: Reward = -35499.61, Avg Reward (100) = -30789.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4614: Reward = -35499.61, Avg Reward (100) = -30789.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4615: Reward = -35499.61, Avg Reward (100) = -30789.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4616: Reward = -35499.61, Avg Reward (100) = -30648.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4617: Reward = -35499.61, Avg Reward (100) = -30750.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4618: Reward = -32619.61, Avg Reward (100) = -31094.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4619: Reward = -47848.55, Avg Reward (100) = -31065.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4620: Reward = -35499.61, Avg Reward (100) = -31189.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4621: Reward = -35499.61, Avg Reward (100) = -31197.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4622: Reward = -32612.87, Avg Reward (100) = -31197.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 4623: Reward = -1295.00, Avg Reward (100) = -31027.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4624: Reward = -33701.04, Avg Reward (100) = -31026.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4625: Reward = -26914.26, Avg Reward (100) = -31008.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26914.26, Border Penalty: -31408.38, Obstacle Penalty: -50.00
Episode 4626: Reward = -35499.61, Avg Reward (100) = -30922.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4627: Reward = -49176.10, Avg Reward (100) = -30922.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4628: Reward = -35499.61, Avg Reward (100) = -31058.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4629: Reward = -49626.26, Avg Reward (100) = -31058.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4630: Reward = -35499.61, Avg Reward (100) = -31122.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4631: Reward = -33701.04, Avg Reward (100) = -31142.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4632: Reward = -35499.61, Avg Reward (100) = -31124.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4633: Reward = -35499.61, Avg Reward (100) = -31157.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4634: Reward = -1196.00, Avg Reward (100) = -31157.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4635: Reward = -35499.61, Avg Reward (100) = -30882.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4636: Reward = -37669.33, Avg Reward (100) = -30942.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4637: Reward = -33701.04, Avg Reward (100) = -30857.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4638: Reward = -32619.61, Avg Reward (100) = -30905.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4639: Reward = -35499.61, Avg Reward (100) = -30876.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4640: Reward = -35499.61, Avg Reward (100) = -30979.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4641: Reward = -33701.04, Avg Reward (100) = -31007.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4642: Reward = -35499.61, Avg Reward (100) = -31333.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4643: Reward = -28198.29, Avg Reward (100) = -31333.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 4644: Reward = -35499.61, Avg Reward (100) = -31137.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4645: Reward = -35499.61, Avg Reward (100) = -31137.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4646: Reward = -1147.00, Avg Reward (100) = -31481.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4647: Reward = -36089.25, Avg Reward (100) = -31479.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4648: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4649: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4650: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4651: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4652: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4653: Reward = -35499.61, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4654: Reward = -40817.24, Avg Reward (100) = -31330.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40817.24, Border Penalty: -35385.96, Obstacle Penalty: -50.00
Episode 4655: Reward = -35499.61, Avg Reward (100) = -31432.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4656: Reward = -35499.61, Avg Reward (100) = -31501.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4657: Reward = -35499.61, Avg Reward (100) = -31501.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4658: Reward = -35499.61, Avg Reward (100) = -31501.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4659: Reward = -26943.44, Avg Reward (100) = -31844.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26943.44, Border Penalty: -31417.73, Obstacle Penalty: -50.00
Episode 4660: Reward = -35499.61, Avg Reward (100) = -31621.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4661: Reward = -35499.61, Avg Reward (100) = -31966.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4662: Reward = -1000.00, Avg Reward (100) = -32310.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4663: Reward = -1147.00, Avg Reward (100) = -31965.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4664: Reward = -35499.61, Avg Reward (100) = -31621.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4665: Reward = -35499.61, Avg Reward (100) = -31621.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4666: Reward = -34685.86, Avg Reward (100) = -31621.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4667: Reward = -36089.25, Avg Reward (100) = -31613.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4668: Reward = -32619.61, Avg Reward (100) = -31619.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4669: Reward = -24832.48, Avg Reward (100) = -31590.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -24832.48, Border Penalty: -30321.71, Obstacle Penalty: -50.00
Episode 4670: Reward = -1295.00, Avg Reward (100) = -31484.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4671: Reward = -1147.00, Avg Reward (100) = -31136.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4672: Reward = -1394.00, Avg Reward (100) = -30715.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4673: Reward = -35499.61, Avg Reward (100) = -30391.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4674: Reward = -33469.53, Avg Reward (100) = -30391.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4675: Reward = -35499.61, Avg Reward (100) = -30371.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4676: Reward = -1049.00, Avg Reward (100) = -30713.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4677: Reward = -35499.61, Avg Reward (100) = -30369.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4678: Reward = -35499.61, Avg Reward (100) = -30369.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4679: Reward = -35499.61, Avg Reward (100) = -30369.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4680: Reward = -35499.61, Avg Reward (100) = -30377.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4681: Reward = -33378.53, Avg Reward (100) = -30377.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 4682: Reward = -35499.61, Avg Reward (100) = -30356.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4683: Reward = -35499.61, Avg Reward (100) = -30356.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4684: Reward = -35499.61, Avg Reward (100) = -30356.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4685: Reward = -35499.61, Avg Reward (100) = -30356.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4686: Reward = -1394.00, Avg Reward (100) = -30458.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4687: Reward = -36089.25, Avg Reward (100) = -30117.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4688: Reward = -35499.61, Avg Reward (100) = -30123.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4689: Reward = -12446.80, Avg Reward (100) = -30123.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4690: Reward = -35499.61, Avg Reward (100) = -29893.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4691: Reward = -35499.61, Avg Reward (100) = -29931.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4692: Reward = -35499.61, Avg Reward (100) = -30034.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4693: Reward = -35499.61, Avg Reward (100) = -30034.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4694: Reward = -35499.61, Avg Reward (100) = -30034.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4695: Reward = -45558.54, Avg Reward (100) = -30034.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -45558.54, Border Penalty: -38557.82, Obstacle Penalty: -50.00
Episode 4696: Reward = -35499.61, Avg Reward (100) = -30135.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4697: Reward = -35499.61, Avg Reward (100) = -30167.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4698: Reward = -35499.61, Avg Reward (100) = -30175.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4699: Reward = -12446.80, Avg Reward (100) = -30406.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4700: Reward = -35499.61, Avg Reward (100) = -30061.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4701: Reward = -1049.00, Avg Reward (100) = -30402.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4702: Reward = -31735.80, Avg Reward (100) = -30401.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31735.80, Border Penalty: -33598.23, Obstacle Penalty: -50.00
Episode 4703: Reward = -35499.61, Avg Reward (100) = -30363.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4704: Reward = -35499.61, Avg Reward (100) = -30431.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4705: Reward = -32245.59, Avg Reward (100) = -30460.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 4706: Reward = -32619.61, Avg Reward (100) = -30428.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4707: Reward = -30447.02, Avg Reward (100) = -30743.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -32385.11, Obstacle Penalty: -50.00
Episode 4708: Reward = -28683.61, Avg Reward (100) = -30692.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4709: Reward = -1049.00, Avg Reward (100) = -30501.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4710: Reward = -43802.69, Avg Reward (100) = -30216.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 4711: Reward = -36089.25, Avg Reward (100) = -30643.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4712: Reward = -35499.61, Avg Reward (100) = -30798.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4713: Reward = -34685.86, Avg Reward (100) = -30798.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4714: Reward = -35499.61, Avg Reward (100) = -30790.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4715: Reward = -35499.61, Avg Reward (100) = -30790.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4716: Reward = -35499.61, Avg Reward (100) = -30790.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4717: Reward = -35499.61, Avg Reward (100) = -30790.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4718: Reward = -35499.61, Avg Reward (100) = -30790.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4719: Reward = -35499.61, Avg Reward (100) = -30818.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4720: Reward = -1295.00, Avg Reward (100) = -30695.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4721: Reward = -35499.61, Avg Reward (100) = -30353.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4722: Reward = -47848.55, Avg Reward (100) = -30353.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4723: Reward = -35499.61, Avg Reward (100) = -30505.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4724: Reward = -35499.61, Avg Reward (100) = -30847.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4725: Reward = -35499.61, Avg Reward (100) = -30865.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4726: Reward = -1000.00, Avg Reward (100) = -30951.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4727: Reward = -35499.61, Avg Reward (100) = -30606.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4728: Reward = -33469.53, Avg Reward (100) = -30469.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4729: Reward = -28653.56, Avg Reward (100) = -30449.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4730: Reward = -35499.61, Avg Reward (100) = -30239.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4731: Reward = -33701.04, Avg Reward (100) = -30239.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4732: Reward = -49126.76, Avg Reward (100) = -30239.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49126.76, Border Penalty: -37589.07, Obstacle Penalty: -50.00
Episode 4733: Reward = -1147.00, Avg Reward (100) = -30376.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4734: Reward = -35499.61, Avg Reward (100) = -30032.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4735: Reward = -35499.61, Avg Reward (100) = -30375.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4736: Reward = -35499.61, Avg Reward (100) = -30375.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4737: Reward = -35499.61, Avg Reward (100) = -30353.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4738: Reward = -35499.61, Avg Reward (100) = -30371.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4739: Reward = -35499.61, Avg Reward (100) = -30400.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4740: Reward = -36089.25, Avg Reward (100) = -30400.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 4741: Reward = -34482.45, Avg Reward (100) = -30406.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 4742: Reward = -35499.61, Avg Reward (100) = -30414.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4743: Reward = -35499.61, Avg Reward (100) = -30414.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4744: Reward = -28653.56, Avg Reward (100) = -30487.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4745: Reward = -35499.61, Avg Reward (100) = -30418.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4746: Reward = -12446.80, Avg Reward (100) = -30418.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4747: Reward = -43263.20, Avg Reward (100) = -30531.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4748: Reward = -1443.00, Avg Reward (100) = -30603.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1443.00, Border Penalty: -5276.28, Obstacle Penalty: -50.00
Episode 4749: Reward = -1394.00, Avg Reward (100) = -30263.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4750: Reward = -1147.00, Avg Reward (100) = -29922.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4751: Reward = -35499.61, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4752: Reward = -35499.61, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4753: Reward = -35499.61, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4754: Reward = -1098.00, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4755: Reward = -32619.61, Avg Reward (100) = -29181.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4756: Reward = -35499.61, Avg Reward (100) = -29152.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4757: Reward = -35499.61, Avg Reward (100) = -29152.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4758: Reward = -35499.61, Avg Reward (100) = -29152.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4759: Reward = -35499.61, Avg Reward (100) = -29152.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4760: Reward = -35499.61, Avg Reward (100) = -29238.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4761: Reward = -1393.00, Avg Reward (100) = -29238.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4762: Reward = -35499.61, Avg Reward (100) = -28897.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4763: Reward = -1098.00, Avg Reward (100) = -29242.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4764: Reward = -35499.61, Avg Reward (100) = -29241.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4765: Reward = -39606.20, Avg Reward (100) = -29241.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4766: Reward = -49626.26, Avg Reward (100) = -29282.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4767: Reward = -1147.00, Avg Reward (100) = -29431.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4768: Reward = -1394.00, Avg Reward (100) = -29082.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4769: Reward = -35499.61, Avg Reward (100) = -28770.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4770: Reward = -47848.55, Avg Reward (100) = -28876.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4771: Reward = -29512.46, Avg Reward (100) = -29342.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4772: Reward = -35499.61, Avg Reward (100) = -29626.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4773: Reward = -1049.00, Avg Reward (100) = -29967.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4774: Reward = -25228.52, Avg Reward (100) = -29622.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4775: Reward = -35499.61, Avg Reward (100) = -29540.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4776: Reward = -1049.00, Avg Reward (100) = -29540.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4777: Reward = -1196.00, Avg Reward (100) = -29540.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4778: Reward = -1394.00, Avg Reward (100) = -29197.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4779: Reward = -35499.61, Avg Reward (100) = -28856.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4780: Reward = -35499.61, Avg Reward (100) = -28856.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4781: Reward = -34685.86, Avg Reward (100) = -28856.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4782: Reward = -35499.61, Avg Reward (100) = -28869.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4783: Reward = -12446.80, Avg Reward (100) = -28869.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4784: Reward = -47848.55, Avg Reward (100) = -28638.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4785: Reward = -35499.61, Avg Reward (100) = -28762.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4786: Reward = -35499.61, Avg Reward (100) = -28762.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4787: Reward = -49626.26, Avg Reward (100) = -29103.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4788: Reward = -49626.26, Avg Reward (100) = -29238.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4789: Reward = -35499.61, Avg Reward (100) = -29379.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4790: Reward = -35499.61, Avg Reward (100) = -29610.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4791: Reward = -1147.00, Avg Reward (100) = -29610.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4792: Reward = -48849.18, Avg Reward (100) = -29266.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48849.18, Border Penalty: -37797.46, Obstacle Penalty: -50.00
Episode 4793: Reward = -25228.52, Avg Reward (100) = -29400.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4794: Reward = -28985.54, Avg Reward (100) = -29297.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28985.54, Border Penalty: -31642.03, Obstacle Penalty: -50.00
Episode 4795: Reward = -37664.73, Avg Reward (100) = -29232.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37664.73, Border Penalty: -34269.04, Obstacle Penalty: -50.00
Episode 4796: Reward = -35499.61, Avg Reward (100) = -29153.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4797: Reward = -1049.00, Avg Reward (100) = -29153.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4798: Reward = -35499.61, Avg Reward (100) = -28809.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4799: Reward = -35499.61, Avg Reward (100) = -28809.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4800: Reward = -28683.61, Avg Reward (100) = -29039.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4801: Reward = -28683.61, Avg Reward (100) = -28971.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4802: Reward = -35499.61, Avg Reward (100) = -29247.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4803: Reward = -1000.00, Avg Reward (100) = -29285.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4804: Reward = -35499.61, Avg Reward (100) = -28940.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4805: Reward = -35499.61, Avg Reward (100) = -28940.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4806: Reward = -1492.00, Avg Reward (100) = -28973.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -3180.03, Obstacle Penalty: -50.00
Episode 4807: Reward = -12446.80, Avg Reward (100) = -28661.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4808: Reward = -1049.00, Avg Reward (100) = -28481.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4809: Reward = -35499.61, Avg Reward (100) = -28205.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4810: Reward = -34685.86, Avg Reward (100) = -28549.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4811: Reward = -1000.00, Avg Reward (100) = -28458.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4812: Reward = -35499.61, Avg Reward (100) = -28107.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4813: Reward = -35499.61, Avg Reward (100) = -28107.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4814: Reward = -35499.61, Avg Reward (100) = -28115.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4815: Reward = -35499.61, Avg Reward (100) = -28115.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4816: Reward = -1147.00, Avg Reward (100) = -28115.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4817: Reward = -35499.61, Avg Reward (100) = -27772.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4818: Reward = -35499.61, Avg Reward (100) = -27772.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4819: Reward = -35499.61, Avg Reward (100) = -27772.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4820: Reward = -35499.61, Avg Reward (100) = -27772.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4821: Reward = -29512.46, Avg Reward (100) = -28114.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4822: Reward = -1295.00, Avg Reward (100) = -28054.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4823: Reward = -35499.61, Avg Reward (100) = -27589.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4824: Reward = -35499.61, Avg Reward (100) = -27589.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4825: Reward = -35499.61, Avg Reward (100) = -27589.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4826: Reward = -35499.61, Avg Reward (100) = -27589.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4827: Reward = -35499.61, Avg Reward (100) = -27934.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4828: Reward = -35499.61, Avg Reward (100) = -27934.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4829: Reward = -45265.96, Avg Reward (100) = -27954.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45265.96, Border Penalty: -38474.69, Obstacle Penalty: -50.00
Episode 4830: Reward = -1147.00, Avg Reward (100) = -28120.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4831: Reward = -28683.61, Avg Reward (100) = -27777.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4832: Reward = -35499.61, Avg Reward (100) = -27726.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4833: Reward = -35499.61, Avg Reward (100) = -27590.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4834: Reward = -34236.08, Avg Reward (100) = -27934.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -34470.76, Obstacle Penalty: -50.00
Episode 4835: Reward = -35499.61, Avg Reward (100) = -27921.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4836: Reward = -35499.61, Avg Reward (100) = -27921.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4837: Reward = -35499.61, Avg Reward (100) = -27921.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4838: Reward = -34685.86, Avg Reward (100) = -27921.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4839: Reward = -33701.04, Avg Reward (100) = -27913.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4840: Reward = -35499.61, Avg Reward (100) = -27895.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4841: Reward = -1049.00, Avg Reward (100) = -27889.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4842: Reward = -35499.61, Avg Reward (100) = -27555.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4843: Reward = -36089.25, Avg Reward (100) = -27555.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4844: Reward = -35499.61, Avg Reward (100) = -27560.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4845: Reward = -32245.59, Avg Reward (100) = -27629.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4846: Reward = -1049.00, Avg Reward (100) = -27596.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4847: Reward = -35499.61, Avg Reward (100) = -27482.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4848: Reward = -35499.61, Avg Reward (100) = -27405.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4849: Reward = -35499.61, Avg Reward (100) = -27745.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4850: Reward = -35499.61, Avg Reward (100) = -28086.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4851: Reward = -28653.56, Avg Reward (100) = -28430.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4852: Reward = -35499.61, Avg Reward (100) = -28361.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4853: Reward = -45723.38, Avg Reward (100) = -28361.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -45723.38, Border Penalty: -38065.23, Obstacle Penalty: -50.00
Episode 4854: Reward = -35499.61, Avg Reward (100) = -28464.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4855: Reward = -35499.61, Avg Reward (100) = -28808.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4856: Reward = -35499.61, Avg Reward (100) = -28837.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4857: Reward = -39606.20, Avg Reward (100) = -28837.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4858: Reward = -54036.93, Avg Reward (100) = -28878.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 4859: Reward = -32245.59, Avg Reward (100) = -29063.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 4860: Reward = -33701.04, Avg Reward (100) = -29030.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4861: Reward = -35499.61, Avg Reward (100) = -29012.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4862: Reward = -1196.00, Avg Reward (100) = -29354.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4863: Reward = -35499.61, Avg Reward (100) = -29010.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4864: Reward = -34685.86, Avg Reward (100) = -29354.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4865: Reward = -1098.00, Avg Reward (100) = -29346.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4866: Reward = -35499.61, Avg Reward (100) = -28961.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4867: Reward = -35499.61, Avg Reward (100) = -28820.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4868: Reward = -35499.61, Avg Reward (100) = -29164.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4869: Reward = -35499.61, Avg Reward (100) = -29505.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4870: Reward = -47848.55, Avg Reward (100) = -29505.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 4871: Reward = -35499.61, Avg Reward (100) = -29505.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4872: Reward = -35499.61, Avg Reward (100) = -29564.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4873: Reward = -35499.61, Avg Reward (100) = -29564.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4874: Reward = -35499.61, Avg Reward (100) = -29909.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4875: Reward = -34685.86, Avg Reward (100) = -30012.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4876: Reward = -35499.61, Avg Reward (100) = -30004.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4877: Reward = -12446.80, Avg Reward (100) = -30348.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4878: Reward = -39606.20, Avg Reward (100) = -30461.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4879: Reward = -35499.61, Avg Reward (100) = -30843.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4880: Reward = -35499.61, Avg Reward (100) = -30843.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4881: Reward = -35499.61, Avg Reward (100) = -30843.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4882: Reward = -35499.61, Avg Reward (100) = -30851.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4883: Reward = -35499.61, Avg Reward (100) = -30851.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4884: Reward = -35499.61, Avg Reward (100) = -31081.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4885: Reward = -1000.00, Avg Reward (100) = -30958.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4886: Reward = -35499.61, Avg Reward (100) = -30613.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4887: Reward = -32619.61, Avg Reward (100) = -30613.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4888: Reward = -1196.00, Avg Reward (100) = -30443.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4889: Reward = -35499.61, Avg Reward (100) = -29958.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4890: Reward = -1147.00, Avg Reward (100) = -29958.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4891: Reward = -36089.25, Avg Reward (100) = -29615.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4892: Reward = -35499.61, Avg Reward (100) = -29964.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4893: Reward = -1147.00, Avg Reward (100) = -29831.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4894: Reward = -12446.80, Avg Reward (100) = -29590.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 4895: Reward = -35499.61, Avg Reward (100) = -29425.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 4896: Reward = -1196.00, Avg Reward (100) = -29403.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4897: Reward = -35499.61, Avg Reward (100) = -29060.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4898: Reward = -35499.61, Avg Reward (100) = -29405.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4899: Reward = -49626.26, Avg Reward (100) = -29405.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4900: Reward = -34685.86, Avg Reward (100) = -29546.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4901: Reward = -25228.52, Avg Reward (100) = -29606.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4902: Reward = -35499.61, Avg Reward (100) = -29571.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4903: Reward = -1147.00, Avg Reward (100) = -29571.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4904: Reward = -35499.61, Avg Reward (100) = -29573.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4905: Reward = -34345.81, Avg Reward (100) = -29573.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34345.81, Border Penalty: -34495.49, Obstacle Penalty: -50.00
Episode 4906: Reward = -35499.61, Avg Reward (100) = -29561.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4907: Reward = -43263.20, Avg Reward (100) = -29901.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4908: Reward = -35499.61, Avg Reward (100) = -30209.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4909: Reward = -61242.66, Avg Reward (100) = -30554.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -39298.61, Obstacle Penalty: -50.00
Episode 4910: Reward = -35499.61, Avg Reward (100) = -30811.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4911: Reward = -35499.61, Avg Reward (100) = -30819.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4912: Reward = -1147.00, Avg Reward (100) = -31164.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4913: Reward = -35499.61, Avg Reward (100) = -30821.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4914: Reward = -25228.52, Avg Reward (100) = -30821.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4915: Reward = -49626.26, Avg Reward (100) = -30718.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 4916: Reward = -35499.61, Avg Reward (100) = -30860.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4917: Reward = -44507.68, Avg Reward (100) = -31203.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 4918: Reward = -33701.04, Avg Reward (100) = -31293.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4919: Reward = -35499.61, Avg Reward (100) = -31275.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4920: Reward = -35499.61, Avg Reward (100) = -31275.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4921: Reward = -35499.61, Avg Reward (100) = -31275.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4922: Reward = -1147.00, Avg Reward (100) = -31335.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4923: Reward = -35499.61, Avg Reward (100) = -31334.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4924: Reward = -35499.61, Avg Reward (100) = -31334.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4925: Reward = -35499.61, Avg Reward (100) = -31334.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4926: Reward = -1147.00, Avg Reward (100) = -31334.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4927: Reward = -37669.33, Avg Reward (100) = -30990.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4928: Reward = -35499.61, Avg Reward (100) = -31012.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4929: Reward = -35499.61, Avg Reward (100) = -31012.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4930: Reward = -28653.56, Avg Reward (100) = -30914.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4931: Reward = -29512.46, Avg Reward (100) = -31189.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4932: Reward = -36089.25, Avg Reward (100) = -31197.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 4933: Reward = -49176.10, Avg Reward (100) = -31203.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 4934: Reward = -35499.61, Avg Reward (100) = -31340.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4935: Reward = -35499.61, Avg Reward (100) = -31353.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4936: Reward = -35499.61, Avg Reward (100) = -31353.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4937: Reward = -1098.00, Avg Reward (100) = -31353.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4938: Reward = -35499.61, Avg Reward (100) = -31009.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4939: Reward = -35499.61, Avg Reward (100) = -31017.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4940: Reward = -35499.61, Avg Reward (100) = -31035.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4941: Reward = -35499.61, Avg Reward (100) = -31035.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4942: Reward = -33469.53, Avg Reward (100) = -31379.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 4943: Reward = -35499.61, Avg Reward (100) = -31359.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4944: Reward = -1394.00, Avg Reward (100) = -31353.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 4945: Reward = -37669.33, Avg Reward (100) = -31012.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -35743.02, Obstacle Penalty: -50.00
Episode 4946: Reward = -33701.04, Avg Reward (100) = -31066.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 4947: Reward = -39606.20, Avg Reward (100) = -31393.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4948: Reward = -34685.86, Avg Reward (100) = -31434.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4949: Reward = -29512.46, Avg Reward (100) = -31426.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 4950: Reward = -1098.00, Avg Reward (100) = -31366.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4951: Reward = -35499.61, Avg Reward (100) = -31022.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4952: Reward = -34685.86, Avg Reward (100) = -31090.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 4953: Reward = -35499.61, Avg Reward (100) = -31082.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4954: Reward = -35499.61, Avg Reward (100) = -30980.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4955: Reward = -35499.61, Avg Reward (100) = -30980.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 4956: Reward = -1000.00, Avg Reward (100) = -30980.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4957: Reward = -35499.61, Avg Reward (100) = -30635.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4958: Reward = -37669.33, Avg Reward (100) = -30594.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 4959: Reward = -35499.61, Avg Reward (100) = -30430.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4960: Reward = -35499.61, Avg Reward (100) = -30463.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4961: Reward = -28653.56, Avg Reward (100) = -30481.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 4962: Reward = -35499.61, Avg Reward (100) = -30412.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4963: Reward = -1049.00, Avg Reward (100) = -30755.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4964: Reward = -32612.87, Avg Reward (100) = -30411.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 4965: Reward = -35499.61, Avg Reward (100) = -30390.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4966: Reward = -35499.61, Avg Reward (100) = -30734.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4967: Reward = -1098.00, Avg Reward (100) = -30734.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4968: Reward = -1147.00, Avg Reward (100) = -30390.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4969: Reward = -35499.61, Avg Reward (100) = -30047.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4970: Reward = -35499.61, Avg Reward (100) = -30047.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4971: Reward = -1196.00, Avg Reward (100) = -29923.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 4972: Reward = -43263.20, Avg Reward (100) = -29580.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4973: Reward = -35499.61, Avg Reward (100) = -29658.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4974: Reward = -1147.00, Avg Reward (100) = -29658.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4975: Reward = -1394.00, Avg Reward (100) = -29314.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4976: Reward = -1394.00, Avg Reward (100) = -28981.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 4977: Reward = -35499.61, Avg Reward (100) = -28640.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4978: Reward = -1098.00, Avg Reward (100) = -28871.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4979: Reward = -35499.61, Avg Reward (100) = -28486.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4980: Reward = -39606.20, Avg Reward (100) = -28486.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4981: Reward = -1295.00, Avg Reward (100) = -28527.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 4982: Reward = -35499.61, Avg Reward (100) = -28185.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4983: Reward = -35499.61, Avg Reward (100) = -28185.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4984: Reward = -35499.61, Avg Reward (100) = -28185.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4985: Reward = -39606.20, Avg Reward (100) = -28185.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4986: Reward = -35499.61, Avg Reward (100) = -28571.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4987: Reward = -39606.20, Avg Reward (100) = -28571.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 4988: Reward = -32245.59, Avg Reward (100) = -28641.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 4989: Reward = -35499.61, Avg Reward (100) = -28951.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4990: Reward = -43263.20, Avg Reward (100) = -28951.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 4991: Reward = -35499.61, Avg Reward (100) = -29372.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4992: Reward = -28683.61, Avg Reward (100) = -29366.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 4993: Reward = -25228.52, Avg Reward (100) = -29298.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 4994: Reward = -35499.61, Avg Reward (100) = -29539.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4995: Reward = -35499.61, Avg Reward (100) = -29769.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4996: Reward = -1000.00, Avg Reward (100) = -29769.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 4997: Reward = -35499.61, Avg Reward (100) = -29768.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4998: Reward = -35499.61, Avg Reward (100) = -29768.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 4999: Reward = -34685.86, Avg Reward (100) = -29768.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5000: Reward = -35499.61, Avg Reward (100) = -29618.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5001: Reward = -35499.61, Avg Reward (100) = -29626.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5002: Reward = -35499.61, Avg Reward (100) = -29729.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5003: Reward = -35499.61, Avg Reward (100) = -29729.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5004: Reward = -35499.61, Avg Reward (100) = -30072.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5005: Reward = -47848.55, Avg Reward (100) = -30072.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5006: Reward = -35499.61, Avg Reward (100) = -30208.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5007: Reward = -1098.00, Avg Reward (100) = -30208.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5008: Reward = -35499.61, Avg Reward (100) = -29786.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5009: Reward = -36089.25, Avg Reward (100) = -29786.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5010: Reward = -35499.61, Avg Reward (100) = -29534.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5011: Reward = -35499.61, Avg Reward (100) = -29534.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5012: Reward = -35499.61, Avg Reward (100) = -29534.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5013: Reward = -35499.61, Avg Reward (100) = -29878.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5014: Reward = -25228.52, Avg Reward (100) = -29878.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5015: Reward = -35499.61, Avg Reward (100) = -29878.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5016: Reward = -26470.74, Avg Reward (100) = -29737.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 5017: Reward = -25228.52, Avg Reward (100) = -29646.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5018: Reward = -1000.00, Avg Reward (100) = -29454.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5019: Reward = -35499.61, Avg Reward (100) = -29127.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5020: Reward = -49626.26, Avg Reward (100) = -29127.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5021: Reward = -39606.20, Avg Reward (100) = -29268.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5022: Reward = -35499.61, Avg Reward (100) = -29309.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5023: Reward = -35499.61, Avg Reward (100) = -29652.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5024: Reward = -33469.53, Avg Reward (100) = -29652.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5025: Reward = -35499.61, Avg Reward (100) = -29632.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5026: Reward = -32619.61, Avg Reward (100) = -29632.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5027: Reward = -35499.61, Avg Reward (100) = -29947.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5028: Reward = -35499.61, Avg Reward (100) = -29925.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5029: Reward = -35499.61, Avg Reward (100) = -29925.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5030: Reward = -35499.61, Avg Reward (100) = -29925.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5031: Reward = -24832.48, Avg Reward (100) = -29994.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -24832.48, Border Penalty: -30321.71, Obstacle Penalty: -50.00
Episode 5032: Reward = -35499.61, Avg Reward (100) = -29947.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5033: Reward = -49626.26, Avg Reward (100) = -29941.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5034: Reward = -35499.61, Avg Reward (100) = -29945.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5035: Reward = -47848.55, Avg Reward (100) = -29945.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5036: Reward = -35499.61, Avg Reward (100) = -30069.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5037: Reward = -1295.00, Avg Reward (100) = -30069.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5038: Reward = -30651.53, Avg Reward (100) = -30071.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30651.53, Border Penalty: -32266.32, Obstacle Penalty: -50.00
Episode 5039: Reward = -41554.36, Avg Reward (100) = -30022.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 5040: Reward = -39770.79, Avg Reward (100) = -30083.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -39770.79, Border Penalty: -36915.96, Obstacle Penalty: -50.00
Episode 5041: Reward = -1098.00, Avg Reward (100) = -30126.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5042: Reward = -1245.00, Avg Reward (100) = -29782.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5043: Reward = -35499.61, Avg Reward (100) = -29459.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5044: Reward = -1295.00, Avg Reward (100) = -29459.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5045: Reward = -35499.61, Avg Reward (100) = -29458.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5046: Reward = -35499.61, Avg Reward (100) = -29437.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5047: Reward = -35499.61, Avg Reward (100) = -29455.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5048: Reward = -35499.61, Avg Reward (100) = -29414.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5049: Reward = -35499.61, Avg Reward (100) = -29422.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5050: Reward = -35499.61, Avg Reward (100) = -29482.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5051: Reward = -65103.65, Avg Reward (100) = -29826.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -65103.65, Border Penalty: -41707.10, Obstacle Penalty: -50.00
Episode 5052: Reward = -35499.61, Avg Reward (100) = -30122.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5053: Reward = -1000.00, Avg Reward (100) = -30130.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5054: Reward = -1394.00, Avg Reward (100) = -29785.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5055: Reward = -1295.00, Avg Reward (100) = -29444.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5056: Reward = -35499.61, Avg Reward (100) = -29102.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5057: Reward = -34685.86, Avg Reward (100) = -29447.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5058: Reward = -1049.00, Avg Reward (100) = -29439.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5059: Reward = -32619.61, Avg Reward (100) = -29072.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5060: Reward = -35499.61, Avg Reward (100) = -29044.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5061: Reward = -50968.57, Avg Reward (100) = -29044.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -39473.87, Obstacle Penalty: -50.00
Episode 5062: Reward = -1098.00, Avg Reward (100) = -29267.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5063: Reward = -1147.00, Avg Reward (100) = -28923.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5064: Reward = -36022.43, Avg Reward (100) = -28924.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 5065: Reward = -34685.86, Avg Reward (100) = -28958.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5066: Reward = -35499.61, Avg Reward (100) = -28950.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5067: Reward = -47848.55, Avg Reward (100) = -28950.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5068: Reward = -39606.20, Avg Reward (100) = -29417.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5069: Reward = -35499.61, Avg Reward (100) = -29802.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5070: Reward = -48849.18, Avg Reward (100) = -29802.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48849.18, Border Penalty: -35937.59, Obstacle Penalty: -50.00
Episode 5071: Reward = -35499.61, Avg Reward (100) = -29935.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5072: Reward = -35499.61, Avg Reward (100) = -30278.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5073: Reward = -35499.61, Avg Reward (100) = -30201.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5074: Reward = -35499.61, Avg Reward (100) = -30201.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5075: Reward = -35499.61, Avg Reward (100) = -30544.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5076: Reward = -1196.00, Avg Reward (100) = -30885.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5077: Reward = -29512.46, Avg Reward (100) = -30883.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5078: Reward = -35499.61, Avg Reward (100) = -30823.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5079: Reward = -1196.00, Avg Reward (100) = -31167.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5080: Reward = -35499.61, Avg Reward (100) = -30824.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5081: Reward = -33469.53, Avg Reward (100) = -30783.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5082: Reward = -34685.86, Avg Reward (100) = -31105.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5083: Reward = -35499.61, Avg Reward (100) = -31097.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5084: Reward = -35499.61, Avg Reward (100) = -31097.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5085: Reward = -35499.61, Avg Reward (100) = -31097.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5086: Reward = -39606.20, Avg Reward (100) = -31056.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5087: Reward = -35499.61, Avg Reward (100) = -31097.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5088: Reward = -47848.55, Avg Reward (100) = -31056.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5089: Reward = -1049.00, Avg Reward (100) = -31212.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5090: Reward = -28683.61, Avg Reward (100) = -30867.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5091: Reward = -1295.00, Avg Reward (100) = -30722.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5092: Reward = -26470.74, Avg Reward (100) = -30379.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 5093: Reward = -35499.61, Avg Reward (100) = -30357.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5094: Reward = -37669.33, Avg Reward (100) = -30460.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 5095: Reward = -33996.79, Avg Reward (100) = -30482.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33996.79, Border Penalty: -34775.92, Obstacle Penalty: -50.00
Episode 5096: Reward = -35499.61, Avg Reward (100) = -30467.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5097: Reward = -33469.53, Avg Reward (100) = -30812.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5098: Reward = -32245.59, Avg Reward (100) = -30791.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5099: Reward = -35499.61, Avg Reward (100) = -30759.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5100: Reward = -35499.61, Avg Reward (100) = -30767.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5101: Reward = -28653.56, Avg Reward (100) = -30767.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 5102: Reward = -35499.61, Avg Reward (100) = -30699.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5103: Reward = -2156.56, Avg Reward (100) = -30699.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 5104: Reward = -35499.61, Avg Reward (100) = -30365.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5105: Reward = -35499.61, Avg Reward (100) = -30365.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5106: Reward = -1049.00, Avg Reward (100) = -30242.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5107: Reward = -35499.61, Avg Reward (100) = -29897.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5108: Reward = -29512.46, Avg Reward (100) = -30241.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 5109: Reward = -47848.55, Avg Reward (100) = -30181.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5110: Reward = -35499.61, Avg Reward (100) = -30299.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5111: Reward = -35499.61, Avg Reward (100) = -30299.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5112: Reward = -47848.55, Avg Reward (100) = -30299.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5113: Reward = -1049.00, Avg Reward (100) = -30422.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5114: Reward = -35499.61, Avg Reward (100) = -30078.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5115: Reward = -35499.61, Avg Reward (100) = -30181.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5116: Reward = -35499.61, Avg Reward (100) = -30181.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5117: Reward = -35499.61, Avg Reward (100) = -30271.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5118: Reward = -35499.61, Avg Reward (100) = -30374.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5119: Reward = -28683.61, Avg Reward (100) = -30719.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5120: Reward = -29512.46, Avg Reward (100) = -30650.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5121: Reward = -35499.61, Avg Reward (100) = -30449.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5122: Reward = -35499.61, Avg Reward (100) = -30408.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5123: Reward = -35499.61, Avg Reward (100) = -30408.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5124: Reward = -1394.00, Avg Reward (100) = -30408.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5125: Reward = -35499.61, Avg Reward (100) = -30087.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5126: Reward = -35499.61, Avg Reward (100) = -30087.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5127: Reward = -35499.61, Avg Reward (100) = -30116.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5128: Reward = -35499.61, Avg Reward (100) = -30116.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5129: Reward = -1049.00, Avg Reward (100) = -30116.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5130: Reward = -1000.00, Avg Reward (100) = -29772.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5131: Reward = -48567.86, Avg Reward (100) = -29427.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 5132: Reward = -35499.61, Avg Reward (100) = -29664.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5133: Reward = -25228.52, Avg Reward (100) = -29664.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5134: Reward = -49285.73, Avg Reward (100) = -29420.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49285.73, Border Penalty: -40370.16, Obstacle Penalty: -50.00
Episode 5135: Reward = -35499.61, Avg Reward (100) = -29558.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5136: Reward = -36089.25, Avg Reward (100) = -29434.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5137: Reward = -35499.61, Avg Reward (100) = -29440.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5138: Reward = -1049.00, Avg Reward (100) = -29782.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5139: Reward = -35499.61, Avg Reward (100) = -29486.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5140: Reward = -35499.61, Avg Reward (100) = -29426.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5141: Reward = -35499.61, Avg Reward (100) = -29383.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5142: Reward = -32619.61, Avg Reward (100) = -29727.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5143: Reward = -1295.00, Avg Reward (100) = -30041.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5144: Reward = -43263.20, Avg Reward (100) = -29699.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -35267.92, Obstacle Penalty: -50.00
Episode 5145: Reward = -32245.59, Avg Reward (100) = -30119.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5146: Reward = -35499.61, Avg Reward (100) = -30086.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5147: Reward = -35499.61, Avg Reward (100) = -30086.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5148: Reward = -1000.00, Avg Reward (100) = -30086.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5149: Reward = -32619.61, Avg Reward (100) = -29741.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5150: Reward = -36224.14, Avg Reward (100) = -29712.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36224.14, Border Penalty: -34054.01, Obstacle Penalty: -50.00
Episode 5151: Reward = -52270.10, Avg Reward (100) = -29719.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 5152: Reward = -45485.92, Avg Reward (100) = -29591.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38982.36, Obstacle Penalty: -50.00
Episode 5153: Reward = -35499.61, Avg Reward (100) = -29691.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5154: Reward = -52333.05, Avg Reward (100) = -30036.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40617.02, Obstacle Penalty: -50.00
Episode 5155: Reward = -35499.61, Avg Reward (100) = -30545.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5156: Reward = -35499.61, Avg Reward (100) = -30887.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5157: Reward = -35499.61, Avg Reward (100) = -30887.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5158: Reward = -35499.61, Avg Reward (100) = -30896.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5159: Reward = -52585.18, Avg Reward (100) = -31240.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 5160: Reward = -28683.61, Avg Reward (100) = -31440.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5161: Reward = -25228.52, Avg Reward (100) = -31372.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5162: Reward = -35499.61, Avg Reward (100) = -31114.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5163: Reward = -35499.61, Avg Reward (100) = -31458.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5164: Reward = -1098.00, Avg Reward (100) = -31802.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5165: Reward = -35499.61, Avg Reward (100) = -31452.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5166: Reward = -35499.61, Avg Reward (100) = -31461.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5167: Reward = -1394.00, Avg Reward (100) = -31461.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5168: Reward = -28653.56, Avg Reward (100) = -30996.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5169: Reward = -35499.61, Avg Reward (100) = -30886.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5170: Reward = -35499.61, Avg Reward (100) = -30886.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5171: Reward = -35499.61, Avg Reward (100) = -30753.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5172: Reward = -35499.61, Avg Reward (100) = -30753.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5173: Reward = -35499.61, Avg Reward (100) = -30753.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5174: Reward = -35499.61, Avg Reward (100) = -30753.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5175: Reward = -12446.80, Avg Reward (100) = -30753.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5176: Reward = -35499.61, Avg Reward (100) = -30522.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5177: Reward = -1000.00, Avg Reward (100) = -30866.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5178: Reward = -35499.61, Avg Reward (100) = -30580.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5179: Reward = -35499.61, Avg Reward (100) = -30580.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5180: Reward = -48116.97, Avg Reward (100) = -30923.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 5181: Reward = -32619.61, Avg Reward (100) = -31050.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5182: Reward = -35499.61, Avg Reward (100) = -31041.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5183: Reward = -32619.61, Avg Reward (100) = -31049.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5184: Reward = -35499.61, Avg Reward (100) = -31020.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5185: Reward = -29512.46, Avg Reward (100) = -31020.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5186: Reward = -39606.20, Avg Reward (100) = -30961.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5187: Reward = -36089.25, Avg Reward (100) = -30961.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5188: Reward = -32619.61, Avg Reward (100) = -30966.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5189: Reward = -1394.00, Avg Reward (100) = -30814.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5190: Reward = -35499.61, Avg Reward (100) = -30818.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5191: Reward = -35499.61, Avg Reward (100) = -30886.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5192: Reward = -35499.61, Avg Reward (100) = -31228.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5193: Reward = -25228.52, Avg Reward (100) = -31318.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5194: Reward = -35499.61, Avg Reward (100) = -31215.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5195: Reward = -33469.53, Avg Reward (100) = -31194.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 5196: Reward = -35499.61, Avg Reward (100) = -31188.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5197: Reward = -35499.61, Avg Reward (100) = -31188.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5198: Reward = -1147.00, Avg Reward (100) = -31209.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5199: Reward = -1394.00, Avg Reward (100) = -30898.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5200: Reward = -1049.00, Avg Reward (100) = -30557.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5201: Reward = -32815.85, Avg Reward (100) = -30212.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 5202: Reward = -35499.61, Avg Reward (100) = -30254.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5203: Reward = -35499.61, Avg Reward (100) = -30254.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5204: Reward = -35499.61, Avg Reward (100) = -30587.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5205: Reward = -35499.61, Avg Reward (100) = -30587.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5206: Reward = -35499.61, Avg Reward (100) = -30587.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5207: Reward = -35499.61, Avg Reward (100) = -30932.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5208: Reward = -35499.61, Avg Reward (100) = -30932.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5209: Reward = -1196.00, Avg Reward (100) = -30992.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5210: Reward = -28683.61, Avg Reward (100) = -30525.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5211: Reward = -35499.61, Avg Reward (100) = -30457.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5212: Reward = -47848.55, Avg Reward (100) = -30457.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5213: Reward = -1295.00, Avg Reward (100) = -30457.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5214: Reward = -35499.61, Avg Reward (100) = -30459.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5215: Reward = -35499.61, Avg Reward (100) = -30459.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5216: Reward = -35499.61, Avg Reward (100) = -30459.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5217: Reward = -52416.78, Avg Reward (100) = -30459.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52416.78, Border Penalty: -38942.04, Obstacle Penalty: -50.00
Episode 5218: Reward = -35499.61, Avg Reward (100) = -30629.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5219: Reward = -35499.61, Avg Reward (100) = -30629.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5220: Reward = -39751.02, Avg Reward (100) = -30697.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39751.02, Border Penalty: -35863.75, Obstacle Penalty: -50.00
Episode 5221: Reward = -35499.61, Avg Reward (100) = -30799.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5222: Reward = -35499.61, Avg Reward (100) = -30799.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5223: Reward = -1196.00, Avg Reward (100) = -30799.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5224: Reward = -48044.60, Avg Reward (100) = -30456.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 5225: Reward = -35499.61, Avg Reward (100) = -30923.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5226: Reward = -35499.61, Avg Reward (100) = -30923.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5227: Reward = -35499.61, Avg Reward (100) = -30923.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5228: Reward = -1394.00, Avg Reward (100) = -30923.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5229: Reward = -35499.61, Avg Reward (100) = -30582.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5230: Reward = -55917.21, Avg Reward (100) = -30926.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 5231: Reward = -32499.04, Avg Reward (100) = -31475.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32499.04, Border Penalty: -32458.42, Obstacle Penalty: -50.00
Episode 5232: Reward = -37185.15, Avg Reward (100) = -31315.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37185.15, Border Penalty: -36230.21, Obstacle Penalty: -50.00
Episode 5233: Reward = -35499.61, Avg Reward (100) = -31331.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5234: Reward = -27492.00, Avg Reward (100) = -31434.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 5235: Reward = -1147.00, Avg Reward (100) = -31216.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5236: Reward = -35499.61, Avg Reward (100) = -30873.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5237: Reward = -35499.61, Avg Reward (100) = -30867.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5238: Reward = -35499.61, Avg Reward (100) = -30867.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5239: Reward = -35499.61, Avg Reward (100) = -31211.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5240: Reward = -35499.61, Avg Reward (100) = -31211.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5241: Reward = -35499.61, Avg Reward (100) = -31211.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5242: Reward = -1000.00, Avg Reward (100) = -31211.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5243: Reward = -35499.61, Avg Reward (100) = -30895.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5244: Reward = -1147.00, Avg Reward (100) = -31237.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5245: Reward = -33555.72, Avg Reward (100) = -30816.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -33555.72, Border Penalty: -32939.09, Obstacle Penalty: -50.00
Episode 5246: Reward = -35499.61, Avg Reward (100) = -30829.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5247: Reward = -35499.61, Avg Reward (100) = -30829.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5248: Reward = -35499.61, Avg Reward (100) = -30829.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5249: Reward = -35499.61, Avg Reward (100) = -31174.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5250: Reward = -36089.25, Avg Reward (100) = -31203.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 5251: Reward = -35499.61, Avg Reward (100) = -31201.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5252: Reward = -34685.86, Avg Reward (100) = -31034.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5253: Reward = -28653.56, Avg Reward (100) = -30926.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5254: Reward = -35499.61, Avg Reward (100) = -30857.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5255: Reward = -1295.00, Avg Reward (100) = -30689.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5256: Reward = -35499.61, Avg Reward (100) = -30347.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5257: Reward = -1147.00, Avg Reward (100) = -30347.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5258: Reward = -29358.58, Avg Reward (100) = -30003.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 5259: Reward = -32619.61, Avg Reward (100) = -29942.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5260: Reward = -35499.61, Avg Reward (100) = -29742.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5261: Reward = -43263.20, Avg Reward (100) = -29810.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5262: Reward = -33469.53, Avg Reward (100) = -29991.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5263: Reward = -35499.61, Avg Reward (100) = -29971.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5264: Reward = -39671.98, Avg Reward (100) = -29971.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -36458.51, Obstacle Penalty: -50.00
Episode 5265: Reward = -33701.04, Avg Reward (100) = -30356.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5266: Reward = -46305.80, Avg Reward (100) = -30338.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46305.80, Border Penalty: -37626.48, Obstacle Penalty: -50.00
Episode 5267: Reward = -35499.61, Avg Reward (100) = -30446.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5268: Reward = -35499.61, Avg Reward (100) = -30787.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5269: Reward = -35499.61, Avg Reward (100) = -30856.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5270: Reward = -36089.25, Avg Reward (100) = -30856.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5271: Reward = -47848.55, Avg Reward (100) = -30862.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5272: Reward = -1000.00, Avg Reward (100) = -30985.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5273: Reward = -1196.00, Avg Reward (100) = -30640.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5274: Reward = -1394.00, Avg Reward (100) = -30297.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5275: Reward = -12446.80, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5276: Reward = -35499.61, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5277: Reward = -1000.00, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5278: Reward = -35499.61, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5279: Reward = -35499.61, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5280: Reward = -35499.61, Avg Reward (100) = -29956.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5281: Reward = -35499.61, Avg Reward (100) = -29830.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5282: Reward = -35499.61, Avg Reward (100) = -29859.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5283: Reward = -35499.61, Avg Reward (100) = -29859.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5284: Reward = -35499.61, Avg Reward (100) = -29888.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5285: Reward = -35499.61, Avg Reward (100) = -29888.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5286: Reward = -1000.00, Avg Reward (100) = -29947.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5287: Reward = -1394.00, Avg Reward (100) = -29561.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5288: Reward = -35499.61, Avg Reward (100) = -29214.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5289: Reward = -35499.61, Avg Reward (100) = -29243.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5290: Reward = -1295.00, Avg Reward (100) = -29584.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5291: Reward = -39135.41, Avg Reward (100) = -29242.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36959.92, Obstacle Penalty: -50.00
Episode 5292: Reward = -32245.59, Avg Reward (100) = -29279.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5293: Reward = -25228.52, Avg Reward (100) = -29246.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5294: Reward = -28683.61, Avg Reward (100) = -29246.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5295: Reward = -39784.20, Avg Reward (100) = -29178.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -39784.20, Border Penalty: -36768.43, Obstacle Penalty: -50.00
Episode 5296: Reward = -1196.00, Avg Reward (100) = -29241.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5297: Reward = -35499.61, Avg Reward (100) = -28898.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5298: Reward = -37669.33, Avg Reward (100) = -28898.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 5299: Reward = -35499.61, Avg Reward (100) = -29263.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5300: Reward = -35499.61, Avg Reward (100) = -29604.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5301: Reward = -58564.79, Avg Reward (100) = -29949.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 5302: Reward = -35499.61, Avg Reward (100) = -30206.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5303: Reward = -35499.61, Avg Reward (100) = -30206.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5304: Reward = -25751.89, Avg Reward (100) = -30206.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 5305: Reward = -35499.61, Avg Reward (100) = -30109.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5306: Reward = -35499.61, Avg Reward (100) = -30109.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5307: Reward = -28653.56, Avg Reward (100) = -30109.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 5308: Reward = -35499.61, Avg Reward (100) = -30040.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5309: Reward = -35499.61, Avg Reward (100) = -30040.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5310: Reward = -35499.61, Avg Reward (100) = -30383.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5311: Reward = -1344.00, Avg Reward (100) = -30452.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5312: Reward = -35499.61, Avg Reward (100) = -30110.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5313: Reward = -35499.61, Avg Reward (100) = -29987.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5314: Reward = -35499.61, Avg Reward (100) = -30329.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5315: Reward = -35499.61, Avg Reward (100) = -30329.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5316: Reward = -1196.00, Avg Reward (100) = -30329.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5317: Reward = -37295.09, Avg Reward (100) = -29986.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37295.09, Border Penalty: -33486.08, Obstacle Penalty: -50.00
Episode 5318: Reward = -35499.61, Avg Reward (100) = -29834.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5319: Reward = -33701.04, Avg Reward (100) = -29834.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5320: Reward = -1394.00, Avg Reward (100) = -29816.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5321: Reward = -35499.61, Avg Reward (100) = -29433.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5322: Reward = -35499.61, Avg Reward (100) = -29433.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5323: Reward = -37669.33, Avg Reward (100) = -29433.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 5324: Reward = -35499.61, Avg Reward (100) = -29797.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5325: Reward = -32245.59, Avg Reward (100) = -29672.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5326: Reward = -32245.59, Avg Reward (100) = -29639.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5327: Reward = -1098.00, Avg Reward (100) = -29607.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5328: Reward = -35499.61, Avg Reward (100) = -29263.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5329: Reward = -35499.61, Avg Reward (100) = -29604.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5330: Reward = -28653.56, Avg Reward (100) = -29604.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5331: Reward = -35499.61, Avg Reward (100) = -29331.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5332: Reward = -1049.00, Avg Reward (100) = -29361.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5333: Reward = -25228.52, Avg Reward (100) = -29000.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5334: Reward = -40716.65, Avg Reward (100) = -28897.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40716.65, Border Penalty: -36777.90, Obstacle Penalty: -50.00
Episode 5335: Reward = -28653.56, Avg Reward (100) = -29030.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5336: Reward = -35499.61, Avg Reward (100) = -29305.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5337: Reward = -35499.61, Avg Reward (100) = -29305.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5338: Reward = -39606.20, Avg Reward (100) = -29305.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5339: Reward = -12446.80, Avg Reward (100) = -29346.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5340: Reward = -35499.61, Avg Reward (100) = -29115.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5341: Reward = -32619.61, Avg Reward (100) = -29115.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5342: Reward = -35499.61, Avg Reward (100) = -29086.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5343: Reward = -34685.86, Avg Reward (100) = -29431.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5344: Reward = -35499.61, Avg Reward (100) = -29423.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5345: Reward = -1000.00, Avg Reward (100) = -29767.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5346: Reward = -35499.61, Avg Reward (100) = -29441.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5347: Reward = -35499.61, Avg Reward (100) = -29441.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5348: Reward = -1295.00, Avg Reward (100) = -29441.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5349: Reward = -35499.61, Avg Reward (100) = -29099.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5350: Reward = -1049.00, Avg Reward (100) = -29099.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5351: Reward = -35499.61, Avg Reward (100) = -28749.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5352: Reward = -43263.20, Avg Reward (100) = -28749.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5353: Reward = -1196.00, Avg Reward (100) = -28834.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5354: Reward = -32245.59, Avg Reward (100) = -28560.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5355: Reward = -35499.61, Avg Reward (100) = -28527.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5356: Reward = -35499.61, Avg Reward (100) = -28869.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5357: Reward = -34685.86, Avg Reward (100) = -28869.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5358: Reward = -35499.61, Avg Reward (100) = -29205.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5359: Reward = -35499.61, Avg Reward (100) = -29266.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5360: Reward = -35499.61, Avg Reward (100) = -29295.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5361: Reward = -35499.61, Avg Reward (100) = -29295.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5362: Reward = -1394.00, Avg Reward (100) = -29217.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5363: Reward = -35499.61, Avg Reward (100) = -28897.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5364: Reward = -29512.46, Avg Reward (100) = -28897.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 5365: Reward = -43263.20, Avg Reward (100) = -28795.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5366: Reward = -35499.61, Avg Reward (100) = -28891.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5367: Reward = -32245.59, Avg Reward (100) = -28783.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5368: Reward = -41656.72, Avg Reward (100) = -28750.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41656.72, Border Penalty: -35485.22, Obstacle Penalty: -50.00
Episode 5369: Reward = -35499.61, Avg Reward (100) = -28812.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5370: Reward = -35499.61, Avg Reward (100) = -28812.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5371: Reward = -32245.59, Avg Reward (100) = -28806.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5372: Reward = -43263.20, Avg Reward (100) = -28650.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5373: Reward = -35499.61, Avg Reward (100) = -29072.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5374: Reward = -35499.61, Avg Reward (100) = -29415.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5375: Reward = -28653.56, Avg Reward (100) = -29756.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5376: Reward = -1147.00, Avg Reward (100) = -29918.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5377: Reward = -35499.61, Avg Reward (100) = -29575.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5378: Reward = -35499.61, Avg Reward (100) = -29920.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5379: Reward = -32245.59, Avg Reward (100) = -29920.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5380: Reward = -35499.61, Avg Reward (100) = -29887.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5381: Reward = -1000.00, Avg Reward (100) = -29887.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5382: Reward = -35499.61, Avg Reward (100) = -29542.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5383: Reward = -34236.08, Avg Reward (100) = -29542.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -33359.23, Obstacle Penalty: -50.00
Episode 5384: Reward = -35499.61, Avg Reward (100) = -29530.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5385: Reward = -49626.26, Avg Reward (100) = -29530.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5386: Reward = -1049.00, Avg Reward (100) = -29671.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5387: Reward = -1049.00, Avg Reward (100) = -29672.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5388: Reward = -30056.79, Avg Reward (100) = -29668.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -33036.80, Obstacle Penalty: -50.00
Episode 5389: Reward = -1000.00, Avg Reward (100) = -29614.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5390: Reward = -1196.00, Avg Reward (100) = -29269.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5391: Reward = -35499.61, Avg Reward (100) = -29268.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5392: Reward = -35499.61, Avg Reward (100) = -29231.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5393: Reward = -35499.61, Avg Reward (100) = -29264.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5394: Reward = -35499.61, Avg Reward (100) = -29367.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5395: Reward = -35499.61, Avg Reward (100) = -29435.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5396: Reward = -35499.61, Avg Reward (100) = -29392.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5397: Reward = -35499.61, Avg Reward (100) = -29735.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5398: Reward = -35499.61, Avg Reward (100) = -29735.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5399: Reward = -35499.61, Avg Reward (100) = -29713.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5400: Reward = -35499.61, Avg Reward (100) = -29713.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5401: Reward = -1049.00, Avg Reward (100) = -29713.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5402: Reward = -32619.61, Avg Reward (100) = -29138.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5403: Reward = -35499.61, Avg Reward (100) = -29109.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5404: Reward = -1196.00, Avg Reward (100) = -29109.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5405: Reward = -1000.00, Avg Reward (100) = -28864.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5406: Reward = -35499.61, Avg Reward (100) = -28519.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5407: Reward = -35499.61, Avg Reward (100) = -28519.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5408: Reward = -35499.61, Avg Reward (100) = -28587.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5409: Reward = -35499.61, Avg Reward (100) = -28587.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5410: Reward = -34685.86, Avg Reward (100) = -28587.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5411: Reward = -35499.61, Avg Reward (100) = -28579.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5412: Reward = -47848.55, Avg Reward (100) = -28921.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 5413: Reward = -39606.20, Avg Reward (100) = -29044.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5414: Reward = -25228.52, Avg Reward (100) = -29085.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5415: Reward = -1147.00, Avg Reward (100) = -28982.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5416: Reward = -26787.09, Avg Reward (100) = -28639.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 5417: Reward = -35499.61, Avg Reward (100) = -28895.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5418: Reward = -35499.61, Avg Reward (100) = -28877.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5419: Reward = -35499.61, Avg Reward (100) = -28877.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5420: Reward = -1049.00, Avg Reward (100) = -28895.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5421: Reward = -35499.61, Avg Reward (100) = -28891.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5422: Reward = -35499.61, Avg Reward (100) = -28891.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5423: Reward = -35499.61, Avg Reward (100) = -28891.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5424: Reward = -35499.61, Avg Reward (100) = -28870.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5425: Reward = -28683.61, Avg Reward (100) = -28870.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5426: Reward = -36089.25, Avg Reward (100) = -28834.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5427: Reward = -35499.61, Avg Reward (100) = -28873.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5428: Reward = -35499.61, Avg Reward (100) = -29217.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5429: Reward = -1000.00, Avg Reward (100) = -29217.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5430: Reward = -35499.61, Avg Reward (100) = -28872.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5431: Reward = -35499.61, Avg Reward (100) = -28940.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5432: Reward = -1098.00, Avg Reward (100) = -28940.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5433: Reward = -35499.61, Avg Reward (100) = -28940.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5434: Reward = -35499.61, Avg Reward (100) = -29043.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5435: Reward = -1049.00, Avg Reward (100) = -28991.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5436: Reward = -49176.10, Avg Reward (100) = -28715.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5437: Reward = -35499.61, Avg Reward (100) = -28852.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5438: Reward = -36089.25, Avg Reward (100) = -28852.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5439: Reward = -49929.11, Avg Reward (100) = -28817.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 5440: Reward = -35499.61, Avg Reward (100) = -29191.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5441: Reward = -28653.56, Avg Reward (100) = -29191.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 5442: Reward = -39606.20, Avg Reward (100) = -29152.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5443: Reward = -42103.80, Avg Reward (100) = -29193.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42103.80, Border Penalty: -37936.77, Obstacle Penalty: -50.00
Episode 5444: Reward = -35499.61, Avg Reward (100) = -29267.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5445: Reward = -1049.00, Avg Reward (100) = -29267.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5446: Reward = -1245.00, Avg Reward (100) = -29267.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5447: Reward = -35499.61, Avg Reward (100) = -28925.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5448: Reward = -35499.61, Avg Reward (100) = -28925.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5449: Reward = -35499.61, Avg Reward (100) = -29267.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5450: Reward = -59698.96, Avg Reward (100) = -29267.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -59698.96, Border Penalty: -41177.89, Obstacle Penalty: -50.00
Episode 5451: Reward = -47848.55, Avg Reward (100) = -29853.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5452: Reward = -35499.61, Avg Reward (100) = -29977.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5453: Reward = -12446.80, Avg Reward (100) = -29899.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5454: Reward = -36499.46, Avg Reward (100) = -30012.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36499.46, Border Penalty: -35826.99, Obstacle Penalty: -50.00
Episode 5455: Reward = -35499.61, Avg Reward (100) = -30054.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5456: Reward = -35499.61, Avg Reward (100) = -30054.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5457: Reward = -35499.61, Avg Reward (100) = -30054.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5458: Reward = -35499.61, Avg Reward (100) = -30063.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5459: Reward = -35499.61, Avg Reward (100) = -30063.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5460: Reward = -35499.61, Avg Reward (100) = -30063.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5461: Reward = -35499.61, Avg Reward (100) = -30063.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5462: Reward = -35499.61, Avg Reward (100) = -30063.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5463: Reward = -37142.51, Avg Reward (100) = -30404.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37142.51, Border Penalty: -34556.38, Obstacle Penalty: -50.00
Episode 5464: Reward = -35295.52, Avg Reward (100) = -30420.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34781.11, Obstacle Penalty: -50.00
Episode 5465: Reward = -35499.61, Avg Reward (100) = -30478.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5466: Reward = -35499.61, Avg Reward (100) = -30400.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5467: Reward = -35499.61, Avg Reward (100) = -30400.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5468: Reward = -28683.61, Avg Reward (100) = -30433.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5469: Reward = -47848.55, Avg Reward (100) = -30303.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5470: Reward = -44524.86, Avg Reward (100) = -30426.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44524.86, Border Penalty: -38099.33, Obstacle Penalty: -50.00
Episode 5471: Reward = -35499.61, Avg Reward (100) = -30517.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5472: Reward = -35499.61, Avg Reward (100) = -30549.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5473: Reward = -35499.61, Avg Reward (100) = -30472.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5474: Reward = -35499.61, Avg Reward (100) = -30472.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5475: Reward = -1295.00, Avg Reward (100) = -30472.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5476: Reward = -37669.33, Avg Reward (100) = -30198.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -35743.02, Obstacle Penalty: -50.00
Episode 5477: Reward = -35499.61, Avg Reward (100) = -30563.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5478: Reward = -1098.00, Avg Reward (100) = -30563.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5479: Reward = -35499.61, Avg Reward (100) = -30219.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5480: Reward = -35499.61, Avg Reward (100) = -30252.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5481: Reward = -49176.10, Avg Reward (100) = -30252.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5482: Reward = -33701.04, Avg Reward (100) = -30734.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5483: Reward = -38924.96, Avg Reward (100) = -30716.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38924.96, Border Penalty: -36612.80, Obstacle Penalty: -50.00
Episode 5484: Reward = -35499.61, Avg Reward (100) = -30762.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5485: Reward = -39606.20, Avg Reward (100) = -30762.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5486: Reward = -39606.20, Avg Reward (100) = -30662.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5487: Reward = -35499.61, Avg Reward (100) = -31048.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5488: Reward = -1000.00, Avg Reward (100) = -31392.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5489: Reward = -35499.61, Avg Reward (100) = -31102.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5490: Reward = -35499.61, Avg Reward (100) = -31447.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5491: Reward = -35499.61, Avg Reward (100) = -31790.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5492: Reward = -35499.61, Avg Reward (100) = -31790.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5493: Reward = -35499.61, Avg Reward (100) = -31790.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5494: Reward = -49176.10, Avg Reward (100) = -31790.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5495: Reward = -35499.61, Avg Reward (100) = -31927.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5496: Reward = -1295.00, Avg Reward (100) = -31927.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5497: Reward = -35499.61, Avg Reward (100) = -31585.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5498: Reward = -35499.61, Avg Reward (100) = -31585.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5499: Reward = -47848.55, Avg Reward (100) = -31585.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5500: Reward = -1147.00, Avg Reward (100) = -31708.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5501: Reward = -49626.26, Avg Reward (100) = -31365.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5502: Reward = -52416.78, Avg Reward (100) = -31850.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52416.78, Border Penalty: -38942.04, Obstacle Penalty: -50.00
Episode 5503: Reward = -39606.20, Avg Reward (100) = -32048.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5504: Reward = -12446.80, Avg Reward (100) = -32089.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5505: Reward = -35499.61, Avg Reward (100) = -32202.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5506: Reward = -1147.00, Avg Reward (100) = -32547.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5507: Reward = -35499.61, Avg Reward (100) = -32203.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5508: Reward = -35499.61, Avg Reward (100) = -32203.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5509: Reward = -35499.61, Avg Reward (100) = -32203.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5510: Reward = -35499.61, Avg Reward (100) = -32203.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5511: Reward = -1245.00, Avg Reward (100) = -32211.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5512: Reward = -35499.61, Avg Reward (100) = -31869.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5513: Reward = -35499.61, Avg Reward (100) = -31745.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5514: Reward = -35499.61, Avg Reward (100) = -31704.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5515: Reward = -33701.04, Avg Reward (100) = -31807.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5516: Reward = -56422.21, Avg Reward (100) = -32133.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -56422.21, Border Penalty: -40121.59, Obstacle Penalty: -50.00
Episode 5517: Reward = -35499.61, Avg Reward (100) = -32429.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5518: Reward = -35499.61, Avg Reward (100) = -32429.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5519: Reward = -1098.00, Avg Reward (100) = -32429.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5520: Reward = -35499.61, Avg Reward (100) = -32085.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5521: Reward = -35499.61, Avg Reward (100) = -32429.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5522: Reward = -35499.61, Avg Reward (100) = -32429.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5523: Reward = -35499.61, Avg Reward (100) = -32429.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5524: Reward = -54061.77, Avg Reward (100) = -32429.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54061.77, Border Penalty: -41464.82, Obstacle Penalty: -50.00
Episode 5525: Reward = -35499.61, Avg Reward (100) = -32615.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5526: Reward = -35499.61, Avg Reward (100) = -32683.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5527: Reward = -35499.61, Avg Reward (100) = -32677.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5528: Reward = -35499.61, Avg Reward (100) = -32677.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5529: Reward = -35499.61, Avg Reward (100) = -32677.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5530: Reward = -35499.61, Avg Reward (100) = -33022.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5531: Reward = -38636.47, Avg Reward (100) = -33022.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 5532: Reward = -1049.00, Avg Reward (100) = -33054.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5533: Reward = -35499.61, Avg Reward (100) = -33053.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5534: Reward = -35499.61, Avg Reward (100) = -33053.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5535: Reward = -35499.61, Avg Reward (100) = -33053.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5536: Reward = -35499.61, Avg Reward (100) = -33398.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5537: Reward = -12446.80, Avg Reward (100) = -33261.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5538: Reward = -1295.00, Avg Reward (100) = -33030.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5539: Reward = -1098.00, Avg Reward (100) = -32682.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5540: Reward = -35499.61, Avg Reward (100) = -32194.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5541: Reward = -32619.61, Avg Reward (100) = -32194.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5542: Reward = -34685.86, Avg Reward (100) = -32234.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5543: Reward = -35499.61, Avg Reward (100) = -32185.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5544: Reward = -1000.00, Avg Reward (100) = -32119.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5545: Reward = -1049.00, Avg Reward (100) = -31774.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5546: Reward = -49176.10, Avg Reward (100) = -31774.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5547: Reward = -35499.61, Avg Reward (100) = -32253.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5548: Reward = -35499.61, Avg Reward (100) = -32253.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5549: Reward = -1000.00, Avg Reward (100) = -32253.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5550: Reward = -1098.00, Avg Reward (100) = -31908.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5551: Reward = -35499.61, Avg Reward (100) = -31322.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5552: Reward = -35499.61, Avg Reward (100) = -31198.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5553: Reward = -49285.73, Avg Reward (100) = -31198.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49285.73, Border Penalty: -40370.16, Obstacle Penalty: -50.00
Episode 5554: Reward = -35499.61, Avg Reward (100) = -31567.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5555: Reward = -1049.00, Avg Reward (100) = -31557.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5556: Reward = -1147.00, Avg Reward (100) = -31212.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5557: Reward = -1394.00, Avg Reward (100) = -30869.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5558: Reward = -35499.61, Avg Reward (100) = -30528.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5559: Reward = -47848.55, Avg Reward (100) = -30528.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5560: Reward = -29512.46, Avg Reward (100) = -30651.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5561: Reward = -43263.20, Avg Reward (100) = -30591.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5562: Reward = -35499.61, Avg Reward (100) = -30669.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5563: Reward = -35499.61, Avg Reward (100) = -30669.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5564: Reward = -1049.00, Avg Reward (100) = -30653.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5565: Reward = -49626.26, Avg Reward (100) = -30310.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5566: Reward = -1196.00, Avg Reward (100) = -30451.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5567: Reward = -35499.61, Avg Reward (100) = -30108.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5568: Reward = -35499.61, Avg Reward (100) = -30108.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5569: Reward = -35499.61, Avg Reward (100) = -30176.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5570: Reward = -34685.86, Avg Reward (100) = -30053.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5571: Reward = -35499.61, Avg Reward (100) = -29955.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5572: Reward = -43263.20, Avg Reward (100) = -29955.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 5573: Reward = -29512.46, Avg Reward (100) = -30032.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5574: Reward = -35499.61, Avg Reward (100) = -29972.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5575: Reward = -35499.61, Avg Reward (100) = -29972.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5576: Reward = -35499.61, Avg Reward (100) = -30314.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5577: Reward = -34685.86, Avg Reward (100) = -30293.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5578: Reward = -35499.61, Avg Reward (100) = -30285.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5579: Reward = -35499.61, Avg Reward (100) = -30629.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5580: Reward = -1147.00, Avg Reward (100) = -30629.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5581: Reward = -1098.00, Avg Reward (100) = -30285.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5582: Reward = -1098.00, Avg Reward (100) = -29804.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5583: Reward = -1394.00, Avg Reward (100) = -29478.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5584: Reward = -47848.55, Avg Reward (100) = -29103.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5585: Reward = -35499.61, Avg Reward (100) = -29226.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5586: Reward = -35499.61, Avg Reward (100) = -29185.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5587: Reward = -35499.61, Avg Reward (100) = -29144.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5588: Reward = -35499.61, Avg Reward (100) = -29144.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5589: Reward = -36089.25, Avg Reward (100) = -29489.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5590: Reward = -1049.00, Avg Reward (100) = -29495.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5591: Reward = -35499.61, Avg Reward (100) = -29151.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5592: Reward = -35499.61, Avg Reward (100) = -29151.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5593: Reward = -1196.00, Avg Reward (100) = -29151.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5594: Reward = -35499.61, Avg Reward (100) = -28808.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5595: Reward = -32619.61, Avg Reward (100) = -28671.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5596: Reward = -35499.61, Avg Reward (100) = -28642.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5597: Reward = -1196.00, Avg Reward (100) = -28984.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5598: Reward = -35499.61, Avg Reward (100) = -28641.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5599: Reward = -35499.61, Avg Reward (100) = -28641.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5600: Reward = -1147.00, Avg Reward (100) = -28518.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5601: Reward = -35499.61, Avg Reward (100) = -28518.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5602: Reward = -47848.55, Avg Reward (100) = -28376.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5603: Reward = -32619.61, Avg Reward (100) = -28331.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5604: Reward = -42868.59, Avg Reward (100) = -28261.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42868.59, Border Penalty: -32076.03, Obstacle Penalty: -50.00
Episode 5605: Reward = -32619.61, Avg Reward (100) = -28565.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5606: Reward = -35499.61, Avg Reward (100) = -28536.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5607: Reward = -39606.20, Avg Reward (100) = -28880.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5608: Reward = -33469.53, Avg Reward (100) = -28921.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5609: Reward = -34685.86, Avg Reward (100) = -28900.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5610: Reward = -35499.61, Avg Reward (100) = -28892.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5611: Reward = -33469.53, Avg Reward (100) = -28892.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5612: Reward = -35499.61, Avg Reward (100) = -29215.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5613: Reward = -33469.53, Avg Reward (100) = -29215.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5614: Reward = -36089.25, Avg Reward (100) = -29194.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5615: Reward = -35499.61, Avg Reward (100) = -29200.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5616: Reward = -35499.61, Avg Reward (100) = -29218.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5617: Reward = -35499.61, Avg Reward (100) = -29009.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5618: Reward = -33701.04, Avg Reward (100) = -29009.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5619: Reward = -33469.53, Avg Reward (100) = -28991.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5620: Reward = -1344.00, Avg Reward (100) = -29315.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5621: Reward = -35499.61, Avg Reward (100) = -28973.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5622: Reward = -35499.61, Avg Reward (100) = -28973.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5623: Reward = -35499.61, Avg Reward (100) = -28973.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5624: Reward = -35499.61, Avg Reward (100) = -28973.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5625: Reward = -37447.67, Avg Reward (100) = -28787.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37447.67, Border Penalty: -34347.61, Obstacle Penalty: -50.00
Episode 5626: Reward = -35499.61, Avg Reward (100) = -28807.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5627: Reward = -35499.61, Avg Reward (100) = -28807.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5628: Reward = -47848.55, Avg Reward (100) = -28807.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5629: Reward = -1000.00, Avg Reward (100) = -28930.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5630: Reward = -35499.61, Avg Reward (100) = -28585.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5631: Reward = -35499.61, Avg Reward (100) = -28585.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5632: Reward = -28683.61, Avg Reward (100) = -28554.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5633: Reward = -35499.61, Avg Reward (100) = -28830.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5634: Reward = -35499.61, Avg Reward (100) = -28830.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5635: Reward = -42112.30, Avg Reward (100) = -28830.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 5636: Reward = -36089.25, Avg Reward (100) = -28897.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5637: Reward = -48116.97, Avg Reward (100) = -28902.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 5638: Reward = -33701.04, Avg Reward (100) = -29259.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5639: Reward = -35499.61, Avg Reward (100) = -29583.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5640: Reward = -35499.61, Avg Reward (100) = -29927.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5641: Reward = -1394.00, Avg Reward (100) = -29927.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5642: Reward = -35499.61, Avg Reward (100) = -29615.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5643: Reward = -35499.61, Avg Reward (100) = -29623.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5644: Reward = -1049.00, Avg Reward (100) = -29623.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5645: Reward = -1196.00, Avg Reward (100) = -29624.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5646: Reward = -35499.61, Avg Reward (100) = -29625.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5647: Reward = -35499.61, Avg Reward (100) = -29488.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5648: Reward = -35499.61, Avg Reward (100) = -29488.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5649: Reward = -35499.61, Avg Reward (100) = -29488.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5650: Reward = -35499.61, Avg Reward (100) = -29833.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5651: Reward = -35499.61, Avg Reward (100) = -30177.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5652: Reward = -1000.00, Avg Reward (100) = -30177.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5653: Reward = -47914.45, Avg Reward (100) = -29832.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 5654: Reward = -12446.80, Avg Reward (100) = -29819.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5655: Reward = -35499.61, Avg Reward (100) = -29588.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5656: Reward = -35499.61, Avg Reward (100) = -29933.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5657: Reward = -35499.61, Avg Reward (100) = -30276.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5658: Reward = -35499.61, Avg Reward (100) = -30617.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5659: Reward = -35499.61, Avg Reward (100) = -30617.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5660: Reward = -1196.00, Avg Reward (100) = -30494.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5661: Reward = -1295.00, Avg Reward (100) = -30211.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5662: Reward = -32245.59, Avg Reward (100) = -29791.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5663: Reward = -1147.00, Avg Reward (100) = -29758.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5664: Reward = -35499.61, Avg Reward (100) = -29415.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5665: Reward = -35499.61, Avg Reward (100) = -29759.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5666: Reward = -35499.61, Avg Reward (100) = -29618.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5667: Reward = -35499.61, Avg Reward (100) = -29961.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5668: Reward = -35499.61, Avg Reward (100) = -29961.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5669: Reward = -28683.61, Avg Reward (100) = -29961.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5670: Reward = -49626.26, Avg Reward (100) = -29893.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 5671: Reward = -49929.11, Avg Reward (100) = -30042.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 5672: Reward = -35499.61, Avg Reward (100) = -30187.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5673: Reward = -1196.00, Avg Reward (100) = -30109.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5674: Reward = -35499.61, Avg Reward (100) = -29826.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5675: Reward = -47848.55, Avg Reward (100) = -29826.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5676: Reward = -35499.61, Avg Reward (100) = -29949.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5677: Reward = -36089.25, Avg Reward (100) = -29949.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5678: Reward = -49626.26, Avg Reward (100) = -29963.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5679: Reward = -35499.61, Avg Reward (100) = -30105.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5680: Reward = -35499.61, Avg Reward (100) = -30105.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5681: Reward = -1098.00, Avg Reward (100) = -30448.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5682: Reward = -35499.61, Avg Reward (100) = -30448.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5683: Reward = -35499.61, Avg Reward (100) = -30792.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5684: Reward = -32245.59, Avg Reward (100) = -31133.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5685: Reward = -35499.61, Avg Reward (100) = -30977.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5686: Reward = -35499.61, Avg Reward (100) = -30977.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5687: Reward = -35499.61, Avg Reward (100) = -30977.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5688: Reward = -35499.61, Avg Reward (100) = -30977.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5689: Reward = -1196.00, Avg Reward (100) = -30977.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5690: Reward = -35499.61, Avg Reward (100) = -30628.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5691: Reward = -38755.16, Avg Reward (100) = -30973.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38755.16, Border Penalty: -36817.61, Obstacle Penalty: -50.00
Episode 5692: Reward = -35499.61, Avg Reward (100) = -31005.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5693: Reward = -1394.00, Avg Reward (100) = -31005.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 5694: Reward = -49626.26, Avg Reward (100) = -31007.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5695: Reward = -1295.00, Avg Reward (100) = -31149.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5696: Reward = -39606.20, Avg Reward (100) = -30835.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5697: Reward = -29512.46, Avg Reward (100) = -30876.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5698: Reward = -35499.61, Avg Reward (100) = -31159.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5699: Reward = -35499.61, Avg Reward (100) = -31159.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5700: Reward = -36089.25, Avg Reward (100) = -31159.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5701: Reward = -1295.00, Avg Reward (100) = -31509.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5702: Reward = -35499.61, Avg Reward (100) = -31167.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5703: Reward = -35499.61, Avg Reward (100) = -31043.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5704: Reward = -1049.00, Avg Reward (100) = -31072.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5705: Reward = -39606.20, Avg Reward (100) = -30654.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5706: Reward = -28438.08, Avg Reward (100) = -30724.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -28438.08, Border Penalty: -30917.02, Obstacle Penalty: -50.00
Episode 5707: Reward = -49626.26, Avg Reward (100) = -30653.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5708: Reward = -33701.04, Avg Reward (100) = -30753.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5709: Reward = -34685.86, Avg Reward (100) = -30756.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5710: Reward = -35499.61, Avg Reward (100) = -30756.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5711: Reward = -33469.53, Avg Reward (100) = -30756.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5712: Reward = -48567.86, Avg Reward (100) = -30756.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 5713: Reward = -1147.00, Avg Reward (100) = -30886.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5714: Reward = -1049.00, Avg Reward (100) = -30563.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5715: Reward = -35499.61, Avg Reward (100) = -30213.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5716: Reward = -35499.61, Avg Reward (100) = -30213.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5717: Reward = -33469.53, Avg Reward (100) = -30213.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5718: Reward = -35499.61, Avg Reward (100) = -30192.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5719: Reward = -35499.61, Avg Reward (100) = -30210.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5720: Reward = -35499.61, Avg Reward (100) = -30231.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5721: Reward = -49176.10, Avg Reward (100) = -30572.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5722: Reward = -29512.46, Avg Reward (100) = -30709.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5723: Reward = -35499.61, Avg Reward (100) = -30649.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5724: Reward = -35499.61, Avg Reward (100) = -30649.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5725: Reward = -35499.61, Avg Reward (100) = -30649.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5726: Reward = -12446.80, Avg Reward (100) = -30630.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5727: Reward = -35499.61, Avg Reward (100) = -30399.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5728: Reward = -1049.00, Avg Reward (100) = -30399.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5729: Reward = -35499.61, Avg Reward (100) = -29931.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5730: Reward = -35499.61, Avg Reward (100) = -30276.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5731: Reward = -49626.26, Avg Reward (100) = -30276.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5732: Reward = -35499.61, Avg Reward (100) = -30417.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5733: Reward = -35499.61, Avg Reward (100) = -30486.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5734: Reward = -35499.61, Avg Reward (100) = -30486.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5735: Reward = -1049.00, Avg Reward (100) = -30486.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5736: Reward = -35499.61, Avg Reward (100) = -30075.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5737: Reward = -1196.00, Avg Reward (100) = -30069.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5738: Reward = -32619.61, Avg Reward (100) = -29600.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5739: Reward = -1049.00, Avg Reward (100) = -29589.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5740: Reward = -35499.61, Avg Reward (100) = -29245.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5741: Reward = -32619.61, Avg Reward (100) = -29245.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5742: Reward = -35499.61, Avg Reward (100) = -29557.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5743: Reward = -29512.46, Avg Reward (100) = -29557.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31446.35, Obstacle Penalty: -50.00
Episode 5744: Reward = -1196.00, Avg Reward (100) = -29497.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5745: Reward = -35499.61, Avg Reward (100) = -29498.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5746: Reward = -35499.61, Avg Reward (100) = -29841.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5747: Reward = -35499.61, Avg Reward (100) = -29841.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5748: Reward = -29512.46, Avg Reward (100) = -29841.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5749: Reward = -32245.59, Avg Reward (100) = -29782.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 5750: Reward = -1393.00, Avg Reward (100) = -29749.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5751: Reward = -49176.10, Avg Reward (100) = -29408.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5752: Reward = -35499.61, Avg Reward (100) = -29545.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5753: Reward = -35499.61, Avg Reward (100) = -29890.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5754: Reward = -35499.61, Avg Reward (100) = -29766.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5755: Reward = -35499.61, Avg Reward (100) = -29996.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5756: Reward = -35499.61, Avg Reward (100) = -29996.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5757: Reward = -39606.20, Avg Reward (100) = -29996.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5758: Reward = -35499.61, Avg Reward (100) = -30037.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5759: Reward = -36791.87, Avg Reward (100) = -30037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36791.87, Border Penalty: -35260.12, Obstacle Penalty: -50.00
Episode 5760: Reward = -35499.61, Avg Reward (100) = -30050.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5761: Reward = -1000.00, Avg Reward (100) = -30393.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5762: Reward = -1098.00, Avg Reward (100) = -30390.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5763: Reward = -35499.61, Avg Reward (100) = -30079.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5764: Reward = -35499.61, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5765: Reward = -35499.61, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5766: Reward = -35499.61, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5767: Reward = -35499.61, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5768: Reward = -35499.61, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5769: Reward = -36089.25, Avg Reward (100) = -30422.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5770: Reward = -35499.61, Avg Reward (100) = -30496.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5771: Reward = -35499.61, Avg Reward (100) = -30355.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5772: Reward = -35499.61, Avg Reward (100) = -30211.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5773: Reward = -49626.26, Avg Reward (100) = -30211.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5774: Reward = -35499.61, Avg Reward (100) = -30695.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5775: Reward = -35499.61, Avg Reward (100) = -30695.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5776: Reward = -35499.61, Avg Reward (100) = -30572.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5777: Reward = -42651.70, Avg Reward (100) = -30572.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -37572.03, Obstacle Penalty: -50.00
Episode 5778: Reward = -35499.61, Avg Reward (100) = -30637.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5779: Reward = -35499.61, Avg Reward (100) = -30496.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5780: Reward = -35499.61, Avg Reward (100) = -30496.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5781: Reward = -35499.61, Avg Reward (100) = -30496.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5782: Reward = -35499.61, Avg Reward (100) = -30840.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5783: Reward = -49176.10, Avg Reward (100) = -30840.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5784: Reward = -29220.94, Avg Reward (100) = -30977.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29220.94, Border Penalty: -31150.23, Obstacle Penalty: -50.00
Episode 5785: Reward = -29512.46, Avg Reward (100) = -30946.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5786: Reward = -1000.00, Avg Reward (100) = -30887.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5787: Reward = -25228.52, Avg Reward (100) = -30542.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5788: Reward = -1000.00, Avg Reward (100) = -30439.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5789: Reward = -35499.61, Avg Reward (100) = -30094.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5790: Reward = -35499.61, Avg Reward (100) = -30437.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5791: Reward = -35499.61, Avg Reward (100) = -30437.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5792: Reward = -52416.78, Avg Reward (100) = -30404.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52416.78, Border Penalty: -38942.04, Obstacle Penalty: -50.00
Episode 5793: Reward = -35499.61, Avg Reward (100) = -30574.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5794: Reward = -1295.00, Avg Reward (100) = -30915.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5795: Reward = -34685.86, Avg Reward (100) = -30431.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5796: Reward = -35499.61, Avg Reward (100) = -30765.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5797: Reward = -35499.61, Avg Reward (100) = -30724.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5798: Reward = -35499.61, Avg Reward (100) = -30784.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5799: Reward = -32619.61, Avg Reward (100) = -30784.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5800: Reward = -35499.61, Avg Reward (100) = -30755.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5801: Reward = -35499.61, Avg Reward (100) = -30749.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5802: Reward = -1196.00, Avg Reward (100) = -31091.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5803: Reward = -35499.61, Avg Reward (100) = -30748.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5804: Reward = -35499.61, Avg Reward (100) = -30748.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5805: Reward = -682.25, Avg Reward (100) = -31093.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -682.25, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5806: Reward = -29512.46, Avg Reward (100) = -30704.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5807: Reward = -35499.61, Avg Reward (100) = -30714.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5808: Reward = -36089.25, Avg Reward (100) = -30573.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5809: Reward = -47025.21, Avg Reward (100) = -30597.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 5810: Reward = -35499.61, Avg Reward (100) = -30720.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5811: Reward = -49626.26, Avg Reward (100) = -30720.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5812: Reward = -35499.61, Avg Reward (100) = -30882.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5813: Reward = -35499.61, Avg Reward (100) = -30751.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5814: Reward = -35499.61, Avg Reward (100) = -31095.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5815: Reward = -35499.61, Avg Reward (100) = -31439.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5816: Reward = -35499.61, Avg Reward (100) = -31439.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5817: Reward = -35499.61, Avg Reward (100) = -31439.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5818: Reward = -35499.61, Avg Reward (100) = -31460.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5819: Reward = -1000.00, Avg Reward (100) = -31460.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5820: Reward = -39606.20, Avg Reward (100) = -31115.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5821: Reward = -35499.61, Avg Reward (100) = -31156.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5822: Reward = -37669.33, Avg Reward (100) = -31019.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 5823: Reward = -27702.15, Avg Reward (100) = -31100.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27702.15, Border Penalty: -30554.88, Obstacle Penalty: -50.00
Episode 5824: Reward = -35499.61, Avg Reward (100) = -31022.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5825: Reward = -35499.61, Avg Reward (100) = -31022.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5826: Reward = -35499.61, Avg Reward (100) = -31022.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5827: Reward = -35499.61, Avg Reward (100) = -31253.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5828: Reward = -35499.61, Avg Reward (100) = -31253.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5829: Reward = -35499.61, Avg Reward (100) = -31597.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5830: Reward = -36089.25, Avg Reward (100) = -31597.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5831: Reward = -30392.74, Avg Reward (100) = -31603.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 5832: Reward = -35499.61, Avg Reward (100) = -31411.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5833: Reward = -33469.53, Avg Reward (100) = -31411.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5834: Reward = -35499.61, Avg Reward (100) = -31391.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5835: Reward = -35499.61, Avg Reward (100) = -31391.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5836: Reward = -25228.52, Avg Reward (100) = -31735.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 5837: Reward = -28683.61, Avg Reward (100) = -31633.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5838: Reward = -35499.61, Avg Reward (100) = -31907.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5839: Reward = -35499.61, Avg Reward (100) = -31936.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5840: Reward = -35499.61, Avg Reward (100) = -32281.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5841: Reward = -5472.60, Avg Reward (100) = -32281.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -5472.60, Border Penalty: -15256.44, Obstacle Penalty: -50.00
Episode 5842: Reward = -27921.09, Avg Reward (100) = -32009.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27921.09, Border Penalty: -31646.78, Obstacle Penalty: -50.00
Episode 5843: Reward = -35499.61, Avg Reward (100) = -31933.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5844: Reward = -35499.61, Avg Reward (100) = -31993.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5845: Reward = -1295.00, Avg Reward (100) = -32336.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5846: Reward = -35499.61, Avg Reward (100) = -31994.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5847: Reward = -35499.61, Avg Reward (100) = -31994.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5848: Reward = -33701.04, Avg Reward (100) = -31994.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5849: Reward = -1049.00, Avg Reward (100) = -32036.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5850: Reward = -35499.61, Avg Reward (100) = -31724.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5851: Reward = -32619.61, Avg Reward (100) = -32065.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5852: Reward = -32245.59, Avg Reward (100) = -31900.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 5853: Reward = -35499.61, Avg Reward (100) = -31867.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5854: Reward = -44507.68, Avg Reward (100) = -31867.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 5855: Reward = -35499.61, Avg Reward (100) = -31957.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5856: Reward = -35499.61, Avg Reward (100) = -31957.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5857: Reward = -35499.61, Avg Reward (100) = -31957.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5858: Reward = -35499.61, Avg Reward (100) = -31916.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5859: Reward = -35499.61, Avg Reward (100) = -31916.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5860: Reward = -1344.00, Avg Reward (100) = -31903.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5861: Reward = -35499.61, Avg Reward (100) = -31562.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5862: Reward = -35499.61, Avg Reward (100) = -31907.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5863: Reward = -35499.61, Avg Reward (100) = -32251.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5864: Reward = -35499.61, Avg Reward (100) = -32251.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5865: Reward = -35499.61, Avg Reward (100) = -32251.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5866: Reward = -47848.55, Avg Reward (100) = -32251.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5867: Reward = -28683.61, Avg Reward (100) = -32374.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5868: Reward = -50483.94, Avg Reward (100) = -32306.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50483.94, Border Penalty: -33380.38, Obstacle Penalty: -50.00
Episode 5869: Reward = -35499.61, Avg Reward (100) = -32456.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5870: Reward = -1049.00, Avg Reward (100) = -32450.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5871: Reward = -35499.61, Avg Reward (100) = -32106.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5872: Reward = -35499.61, Avg Reward (100) = -32106.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5873: Reward = -35499.61, Avg Reward (100) = -32106.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5874: Reward = -35499.61, Avg Reward (100) = -31964.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5875: Reward = -42470.29, Avg Reward (100) = -31964.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42470.29, Border Penalty: -37853.53, Obstacle Penalty: -50.00
Episode 5876: Reward = -35499.61, Avg Reward (100) = -32034.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5877: Reward = -35499.61, Avg Reward (100) = -32034.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5878: Reward = -35499.61, Avg Reward (100) = -31962.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5879: Reward = -35499.61, Avg Reward (100) = -31962.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5880: Reward = -1196.00, Avg Reward (100) = -31962.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5881: Reward = -35499.61, Avg Reward (100) = -31619.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5882: Reward = -48044.60, Avg Reward (100) = -31619.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 5883: Reward = -34685.86, Avg Reward (100) = -31745.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5884: Reward = -12446.80, Avg Reward (100) = -31600.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5885: Reward = -49626.26, Avg Reward (100) = -31432.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5886: Reward = -1147.00, Avg Reward (100) = -31633.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5887: Reward = -35499.61, Avg Reward (100) = -31635.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5888: Reward = -35499.61, Avg Reward (100) = -31738.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5889: Reward = -1000.00, Avg Reward (100) = -32083.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5890: Reward = -49626.26, Avg Reward (100) = -31738.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5891: Reward = -47848.55, Avg Reward (100) = -31879.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5892: Reward = -34685.86, Avg Reward (100) = -32002.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5893: Reward = -28683.61, Avg Reward (100) = -31825.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5894: Reward = -35499.61, Avg Reward (100) = -31757.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5895: Reward = -35499.61, Avg Reward (100) = -32099.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5896: Reward = -36089.25, Avg Reward (100) = -32107.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5897: Reward = -35499.61, Avg Reward (100) = -32113.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5898: Reward = -33701.04, Avg Reward (100) = -32113.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5899: Reward = -12446.80, Avg Reward (100) = -32095.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5900: Reward = -35499.61, Avg Reward (100) = -31893.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5901: Reward = -35499.61, Avg Reward (100) = -31893.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5902: Reward = -1295.00, Avg Reward (100) = -31893.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5903: Reward = -36089.25, Avg Reward (100) = -31894.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5904: Reward = -35499.61, Avg Reward (100) = -31900.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5905: Reward = -35499.61, Avg Reward (100) = -31900.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5906: Reward = -35499.61, Avg Reward (100) = -32248.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5907: Reward = -36089.25, Avg Reward (100) = -32308.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5908: Reward = -35499.61, Avg Reward (100) = -32314.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5909: Reward = -1196.00, Avg Reward (100) = -32308.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5910: Reward = -1049.00, Avg Reward (100) = -31850.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5911: Reward = -35499.61, Avg Reward (100) = -31505.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5912: Reward = -1049.00, Avg Reward (100) = -31364.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5913: Reward = -35499.61, Avg Reward (100) = -31020.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5914: Reward = -35499.61, Avg Reward (100) = -31020.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5915: Reward = -49626.26, Avg Reward (100) = -31020.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5916: Reward = -35499.61, Avg Reward (100) = -31161.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5917: Reward = -49176.10, Avg Reward (100) = -31161.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5918: Reward = -49176.10, Avg Reward (100) = -31298.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5919: Reward = -33469.53, Avg Reward (100) = -31434.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5920: Reward = -1147.00, Avg Reward (100) = -31759.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5921: Reward = -33701.04, Avg Reward (100) = -31374.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5922: Reward = -35499.61, Avg Reward (100) = -31356.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5923: Reward = -35499.61, Avg Reward (100) = -31335.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5924: Reward = -34685.86, Avg Reward (100) = -31413.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5925: Reward = -35499.61, Avg Reward (100) = -31405.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5926: Reward = -12446.80, Avg Reward (100) = -31405.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5927: Reward = -35499.61, Avg Reward (100) = -31174.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5928: Reward = -1000.00, Avg Reward (100) = -31174.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5929: Reward = -35499.61, Avg Reward (100) = -30829.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5930: Reward = -28683.61, Avg Reward (100) = -30829.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5931: Reward = -1295.00, Avg Reward (100) = -30755.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 5932: Reward = -37669.33, Avg Reward (100) = -30464.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 5933: Reward = -35499.61, Avg Reward (100) = -30486.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5934: Reward = -33701.04, Avg Reward (100) = -30506.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 5935: Reward = -29512.46, Avg Reward (100) = -30488.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 5936: Reward = -38636.47, Avg Reward (100) = -30428.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 5937: Reward = -35499.61, Avg Reward (100) = -30562.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5938: Reward = -35499.61, Avg Reward (100) = -30630.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5939: Reward = -36089.25, Avg Reward (100) = -30630.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 5940: Reward = -36089.25, Avg Reward (100) = -30636.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 5941: Reward = -35499.61, Avg Reward (100) = -30642.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5942: Reward = -1147.00, Avg Reward (100) = -30942.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5943: Reward = -35499.61, Avg Reward (100) = -30675.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5944: Reward = -35499.61, Avg Reward (100) = -30675.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5945: Reward = -32779.00, Avg Reward (100) = -30675.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32779.00, Border Penalty: -32732.43, Obstacle Penalty: -50.00
Episode 5946: Reward = -33469.53, Avg Reward (100) = -30990.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 5947: Reward = -28772.37, Avg Reward (100) = -30969.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 5948: Reward = -35499.61, Avg Reward (100) = -30902.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5949: Reward = -34685.86, Avg Reward (100) = -30920.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5950: Reward = -49176.10, Avg Reward (100) = -31256.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 5951: Reward = -35499.61, Avg Reward (100) = -31393.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5952: Reward = -35499.61, Avg Reward (100) = -31422.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5953: Reward = -35499.61, Avg Reward (100) = -31454.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5954: Reward = -35499.61, Avg Reward (100) = -31454.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5955: Reward = -35499.61, Avg Reward (100) = -31364.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5956: Reward = -35499.61, Avg Reward (100) = -31364.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5957: Reward = -35499.61, Avg Reward (100) = -31364.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5958: Reward = -49626.26, Avg Reward (100) = -31364.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5959: Reward = -35499.61, Avg Reward (100) = -31506.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5960: Reward = -30688.98, Avg Reward (100) = -31506.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30688.98, Border Penalty: -32284.13, Obstacle Penalty: -50.00
Episode 5961: Reward = -39606.20, Avg Reward (100) = -31799.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 5962: Reward = -35499.61, Avg Reward (100) = -31840.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5963: Reward = -35499.61, Avg Reward (100) = -31840.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5964: Reward = -35499.61, Avg Reward (100) = -31840.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5965: Reward = -35499.61, Avg Reward (100) = -31840.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5966: Reward = -35499.61, Avg Reward (100) = -31840.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5967: Reward = -1196.00, Avg Reward (100) = -31717.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5968: Reward = -35499.61, Avg Reward (100) = -31442.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5969: Reward = -35499.61, Avg Reward (100) = -31292.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5970: Reward = -1098.00, Avg Reward (100) = -31292.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5971: Reward = -1098.00, Avg Reward (100) = -31292.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5972: Reward = -47848.55, Avg Reward (100) = -30948.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 5973: Reward = -1098.00, Avg Reward (100) = -31072.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5974: Reward = -32779.00, Avg Reward (100) = -30728.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32779.00, Border Penalty: -32732.43, Obstacle Penalty: -50.00
Episode 5975: Reward = -35499.61, Avg Reward (100) = -30701.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5976: Reward = -35499.61, Avg Reward (100) = -30631.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5977: Reward = -35499.61, Avg Reward (100) = -30631.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5978: Reward = -1196.00, Avg Reward (100) = -30631.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 5979: Reward = -35499.61, Avg Reward (100) = -30288.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5980: Reward = -49626.26, Avg Reward (100) = -30288.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5981: Reward = -35116.24, Avg Reward (100) = -30772.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -35116.24, Border Penalty: -33867.79, Obstacle Penalty: -50.00
Episode 5982: Reward = -34685.86, Avg Reward (100) = -30768.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5983: Reward = -35499.61, Avg Reward (100) = -30635.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 5984: Reward = -32619.61, Avg Reward (100) = -30643.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 5985: Reward = -1147.00, Avg Reward (100) = -30845.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 5986: Reward = -35499.61, Avg Reward (100) = -30360.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5987: Reward = -35499.61, Avg Reward (100) = -30703.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 5988: Reward = -30392.74, Avg Reward (100) = -30703.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 5989: Reward = -35499.61, Avg Reward (100) = -30652.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5990: Reward = -35499.61, Avg Reward (100) = -30997.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5991: Reward = -12446.80, Avg Reward (100) = -30856.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5992: Reward = -35499.61, Avg Reward (100) = -30502.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5993: Reward = -34685.86, Avg Reward (100) = -30510.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 5994: Reward = -35499.61, Avg Reward (100) = -30570.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5995: Reward = -49626.26, Avg Reward (100) = -30570.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 5996: Reward = -12446.80, Avg Reward (100) = -30712.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 5997: Reward = -35499.61, Avg Reward (100) = -30475.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5998: Reward = -35499.61, Avg Reward (100) = -30475.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 5999: Reward = -35499.61, Avg Reward (100) = -30493.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6000: Reward = -1295.00, Avg Reward (100) = -30724.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6001: Reward = -1098.00, Avg Reward (100) = -30382.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6002: Reward = -49626.26, Avg Reward (100) = -30038.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6003: Reward = -35499.61, Avg Reward (100) = -30521.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6004: Reward = -25228.52, Avg Reward (100) = -30515.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6005: Reward = -35499.61, Avg Reward (100) = -30412.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6006: Reward = -35499.61, Avg Reward (100) = -30412.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6007: Reward = -1000.00, Avg Reward (100) = -30412.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6008: Reward = -49626.26, Avg Reward (100) = -30061.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6009: Reward = -43263.20, Avg Reward (100) = -30203.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6010: Reward = -35499.61, Avg Reward (100) = -30623.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6011: Reward = -35499.61, Avg Reward (100) = -30968.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6012: Reward = -1147.00, Avg Reward (100) = -30968.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6013: Reward = -1196.00, Avg Reward (100) = -30969.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6014: Reward = -35499.61, Avg Reward (100) = -30626.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6015: Reward = -37669.33, Avg Reward (100) = -30626.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6016: Reward = -1295.00, Avg Reward (100) = -30506.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6017: Reward = -1049.00, Avg Reward (100) = -30164.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6018: Reward = -35499.61, Avg Reward (100) = -29683.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6019: Reward = -35499.61, Avg Reward (100) = -29546.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6020: Reward = -35499.61, Avg Reward (100) = -29566.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6021: Reward = -35499.61, Avg Reward (100) = -29910.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6022: Reward = -39606.20, Avg Reward (100) = -29928.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6023: Reward = -29512.46, Avg Reward (100) = -29969.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6024: Reward = -35499.61, Avg Reward (100) = -29909.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6025: Reward = -43263.20, Avg Reward (100) = -29917.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6026: Reward = -35499.61, Avg Reward (100) = -29995.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6027: Reward = -35499.61, Avg Reward (100) = -30225.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6028: Reward = -54036.93, Avg Reward (100) = -30225.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 6029: Reward = -25228.52, Avg Reward (100) = -30756.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6030: Reward = -35499.61, Avg Reward (100) = -30653.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6031: Reward = -37256.08, Avg Reward (100) = -30721.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 6032: Reward = -35499.61, Avg Reward (100) = -31081.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6033: Reward = -1394.00, Avg Reward (100) = -31059.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6034: Reward = -1000.00, Avg Reward (100) = -30718.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6035: Reward = -35499.61, Avg Reward (100) = -30391.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6036: Reward = -48044.60, Avg Reward (100) = -30451.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 6037: Reward = -32619.61, Avg Reward (100) = -30545.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6038: Reward = -29512.46, Avg Reward (100) = -30516.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6039: Reward = -35499.61, Avg Reward (100) = -30456.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6040: Reward = -35499.61, Avg Reward (100) = -30450.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6041: Reward = -35499.61, Avg Reward (100) = -30445.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6042: Reward = -35499.61, Avg Reward (100) = -30445.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6043: Reward = -47848.55, Avg Reward (100) = -30788.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6044: Reward = -35499.61, Avg Reward (100) = -30912.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6045: Reward = -39606.20, Avg Reward (100) = -30912.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6046: Reward = -1000.00, Avg Reward (100) = -30980.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6047: Reward = -35499.61, Avg Reward (100) = -30655.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6048: Reward = -1098.00, Avg Reward (100) = -30722.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6049: Reward = -2156.56, Avg Reward (100) = -30378.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 6050: Reward = -37669.33, Avg Reward (100) = -30053.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -35743.02, Obstacle Penalty: -50.00
Episode 6051: Reward = -43902.06, Avg Reward (100) = -29938.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 6052: Reward = -35499.61, Avg Reward (100) = -30022.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6053: Reward = -33701.04, Avg Reward (100) = -30022.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6054: Reward = -35499.61, Avg Reward (100) = -30004.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6055: Reward = -39135.41, Avg Reward (100) = -30004.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36959.92, Obstacle Penalty: -50.00
Episode 6056: Reward = -1294.00, Avg Reward (100) = -30040.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6057: Reward = -53075.23, Avg Reward (100) = -29698.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -41137.98, Obstacle Penalty: -50.00
Episode 6058: Reward = -35499.61, Avg Reward (100) = -29874.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6059: Reward = -39606.20, Avg Reward (100) = -29733.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6060: Reward = -1098.00, Avg Reward (100) = -29774.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6061: Reward = -36022.43, Avg Reward (100) = -29478.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 6062: Reward = -35499.61, Avg Reward (100) = -29442.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6063: Reward = -35499.61, Avg Reward (100) = -29442.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6064: Reward = -48296.35, Avg Reward (100) = -29442.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -48296.35, Border Penalty: -39970.15, Obstacle Penalty: -50.00
Episode 6065: Reward = -43263.20, Avg Reward (100) = -29570.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6066: Reward = -25228.52, Avg Reward (100) = -29648.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6067: Reward = -35499.61, Avg Reward (100) = -29545.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6068: Reward = -34164.73, Avg Reward (100) = -29888.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 6069: Reward = -32619.61, Avg Reward (100) = -29875.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6070: Reward = -25468.63, Avg Reward (100) = -29846.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 6071: Reward = -47848.55, Avg Reward (100) = -30090.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6072: Reward = -35499.61, Avg Reward (100) = -30557.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6073: Reward = -1098.00, Avg Reward (100) = -30434.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6074: Reward = -12446.80, Avg Reward (100) = -30434.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6075: Reward = -35499.61, Avg Reward (100) = -30230.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6076: Reward = -35499.61, Avg Reward (100) = -30230.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6077: Reward = -35499.61, Avg Reward (100) = -30230.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6078: Reward = -35499.61, Avg Reward (100) = -30230.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6079: Reward = -1098.00, Avg Reward (100) = -30573.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6080: Reward = -29512.46, Avg Reward (100) = -30229.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6081: Reward = -34685.86, Avg Reward (100) = -30028.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6082: Reward = -12446.80, Avg Reward (100) = -30024.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6083: Reward = -35499.61, Avg Reward (100) = -29802.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6084: Reward = -28198.29, Avg Reward (100) = -29802.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 6085: Reward = -35499.61, Avg Reward (100) = -29757.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6086: Reward = -35499.61, Avg Reward (100) = -30101.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6087: Reward = -35499.61, Avg Reward (100) = -30101.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6088: Reward = -12446.80, Avg Reward (100) = -30101.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6089: Reward = -37669.33, Avg Reward (100) = -29921.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6090: Reward = -1196.00, Avg Reward (100) = -29943.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6091: Reward = -35499.61, Avg Reward (100) = -29600.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6092: Reward = -35499.61, Avg Reward (100) = -29831.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6093: Reward = -35499.61, Avg Reward (100) = -29831.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6094: Reward = -35499.61, Avg Reward (100) = -29839.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6095: Reward = -35499.61, Avg Reward (100) = -29839.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6096: Reward = -49626.26, Avg Reward (100) = -29697.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6097: Reward = -35499.61, Avg Reward (100) = -30069.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6098: Reward = -35499.61, Avg Reward (100) = -30069.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6099: Reward = -49626.26, Avg Reward (100) = -30069.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6100: Reward = -58564.79, Avg Reward (100) = -30211.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -35389.71, Obstacle Penalty: -50.00
Episode 6101: Reward = -35499.61, Avg Reward (100) = -30783.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6102: Reward = -36089.25, Avg Reward (100) = -31127.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6103: Reward = -35499.61, Avg Reward (100) = -30992.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6104: Reward = -35499.61, Avg Reward (100) = -30992.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6105: Reward = -35499.61, Avg Reward (100) = -31095.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6106: Reward = -35499.61, Avg Reward (100) = -31095.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6107: Reward = -35499.61, Avg Reward (100) = -31095.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6108: Reward = -29512.46, Avg Reward (100) = -31440.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6109: Reward = -49176.10, Avg Reward (100) = -31238.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6110: Reward = -1492.00, Avg Reward (100) = -31298.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 6111: Reward = -49626.26, Avg Reward (100) = -30958.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6112: Reward = -39606.20, Avg Reward (100) = -31099.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6113: Reward = -1295.00, Avg Reward (100) = -31483.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6114: Reward = -12446.80, Avg Reward (100) = -31484.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6115: Reward = -35499.61, Avg Reward (100) = -31254.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6116: Reward = -35499.61, Avg Reward (100) = -31232.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6117: Reward = -37669.33, Avg Reward (100) = -31574.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6118: Reward = -35499.61, Avg Reward (100) = -31940.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6119: Reward = -1394.00, Avg Reward (100) = -31940.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6120: Reward = -31163.36, Avg Reward (100) = -31599.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31163.36, Border Penalty: -33115.60, Obstacle Penalty: -50.00
Episode 6121: Reward = -35499.61, Avg Reward (100) = -31556.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6122: Reward = -1098.00, Avg Reward (100) = -31556.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6123: Reward = -49176.10, Avg Reward (100) = -31171.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6124: Reward = -35499.61, Avg Reward (100) = -31368.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6125: Reward = -35499.61, Avg Reward (100) = -31368.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6126: Reward = -49176.10, Avg Reward (100) = -31290.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6127: Reward = -1049.00, Avg Reward (100) = -31427.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6128: Reward = -1098.00, Avg Reward (100) = -31082.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6129: Reward = -12446.80, Avg Reward (100) = -30553.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6130: Reward = -38792.44, Avg Reward (100) = -30425.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 6131: Reward = -32245.59, Avg Reward (100) = -30458.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6132: Reward = -26943.44, Avg Reward (100) = -30408.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26943.44, Border Penalty: -31417.73, Obstacle Penalty: -50.00
Episode 6133: Reward = -35499.61, Avg Reward (100) = -30322.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6134: Reward = -25228.52, Avg Reward (100) = -30663.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6135: Reward = -35499.61, Avg Reward (100) = -30906.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6136: Reward = -35499.61, Avg Reward (100) = -30906.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6137: Reward = -34685.86, Avg Reward (100) = -30780.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6138: Reward = -1147.00, Avg Reward (100) = -30801.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6139: Reward = -35499.61, Avg Reward (100) = -30517.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6140: Reward = -35499.61, Avg Reward (100) = -30517.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6141: Reward = -1000.00, Avg Reward (100) = -30517.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6142: Reward = -1394.00, Avg Reward (100) = -30172.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6143: Reward = -1196.00, Avg Reward (100) = -29831.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6144: Reward = -29220.94, Avg Reward (100) = -29365.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29220.94, Border Penalty: -32231.25, Obstacle Penalty: -50.00
Episode 6145: Reward = -35499.61, Avg Reward (100) = -29302.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6146: Reward = -1295.00, Avg Reward (100) = -29261.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6147: Reward = -36089.25, Avg Reward (100) = -29264.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6148: Reward = -35499.61, Avg Reward (100) = -29270.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6149: Reward = -35499.61, Avg Reward (100) = -29614.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6150: Reward = -35499.61, Avg Reward (100) = -29947.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6151: Reward = -35499.61, Avg Reward (100) = -29925.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6152: Reward = -35499.61, Avg Reward (100) = -29841.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6153: Reward = -35499.61, Avg Reward (100) = -29841.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6154: Reward = -12446.80, Avg Reward (100) = -29859.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6155: Reward = -35499.61, Avg Reward (100) = -29629.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6156: Reward = -35499.61, Avg Reward (100) = -29592.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6157: Reward = -28683.61, Avg Reward (100) = -29934.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6158: Reward = -35499.61, Avg Reward (100) = -29690.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6159: Reward = -35499.61, Avg Reward (100) = -29690.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6160: Reward = -49176.10, Avg Reward (100) = -29649.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6161: Reward = -1147.00, Avg Reward (100) = -30130.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6162: Reward = -35499.61, Avg Reward (100) = -29781.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6163: Reward = -1000.00, Avg Reward (100) = -29781.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6164: Reward = -1000.00, Avg Reward (100) = -29436.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6165: Reward = -35499.61, Avg Reward (100) = -28963.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6166: Reward = -49626.26, Avg Reward (100) = -28886.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6167: Reward = -42113.29, Avg Reward (100) = -29130.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42113.29, Border Penalty: -35930.51, Obstacle Penalty: -50.00
Episode 6168: Reward = -35499.61, Avg Reward (100) = -29196.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6169: Reward = -25228.52, Avg Reward (100) = -29209.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6170: Reward = -35499.61, Avg Reward (100) = -29135.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6171: Reward = -44053.85, Avg Reward (100) = -29236.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44053.85, Border Penalty: -33891.44, Obstacle Penalty: -50.00
Episode 6172: Reward = -35499.61, Avg Reward (100) = -29198.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6173: Reward = -35499.61, Avg Reward (100) = -29198.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6174: Reward = -35499.61, Avg Reward (100) = -29542.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6175: Reward = -58806.38, Avg Reward (100) = -29772.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -58806.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 6176: Reward = -35499.61, Avg Reward (100) = -30005.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6177: Reward = -28653.56, Avg Reward (100) = -30005.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6178: Reward = -33469.53, Avg Reward (100) = -29937.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6179: Reward = -35499.61, Avg Reward (100) = -29917.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6180: Reward = -35499.61, Avg Reward (100) = -30261.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6181: Reward = -51579.35, Avg Reward (100) = -30320.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51579.35, Border Penalty: -40630.78, Obstacle Penalty: -50.00
Episode 6182: Reward = -35499.61, Avg Reward (100) = -30489.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6183: Reward = -35499.61, Avg Reward (100) = -30720.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6184: Reward = -35499.61, Avg Reward (100) = -30720.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6185: Reward = -35499.61, Avg Reward (100) = -30793.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6186: Reward = -35499.61, Avg Reward (100) = -30793.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6187: Reward = -28653.56, Avg Reward (100) = -30793.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6188: Reward = -1196.00, Avg Reward (100) = -30725.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6189: Reward = -35499.61, Avg Reward (100) = -30612.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6190: Reward = -35499.61, Avg Reward (100) = -30590.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6191: Reward = -35499.61, Avg Reward (100) = -30933.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6192: Reward = -35499.61, Avg Reward (100) = -30933.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6193: Reward = -1049.00, Avg Reward (100) = -30933.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6194: Reward = -31663.31, Avg Reward (100) = -30589.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -31663.31, Border Penalty: -32801.48, Obstacle Penalty: -50.00
Episode 6195: Reward = -35499.61, Avg Reward (100) = -30550.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6196: Reward = -35499.61, Avg Reward (100) = -30550.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6197: Reward = -35499.61, Avg Reward (100) = -30409.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6198: Reward = -35499.61, Avg Reward (100) = -30409.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6199: Reward = -40955.38, Avg Reward (100) = -30409.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 6200: Reward = -35499.61, Avg Reward (100) = -30322.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6201: Reward = -1049.00, Avg Reward (100) = -30092.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6202: Reward = -32619.61, Avg Reward (100) = -29747.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6203: Reward = -34685.86, Avg Reward (100) = -29713.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6204: Reward = -1196.00, Avg Reward (100) = -29705.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6205: Reward = -28653.56, Avg Reward (100) = -29361.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6206: Reward = -1394.00, Avg Reward (100) = -29293.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6207: Reward = -43263.20, Avg Reward (100) = -28952.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 6208: Reward = -39606.20, Avg Reward (100) = -29030.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6209: Reward = -32245.59, Avg Reward (100) = -29131.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6210: Reward = -35499.61, Avg Reward (100) = -28961.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6211: Reward = -35499.61, Avg Reward (100) = -29301.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6212: Reward = -47848.55, Avg Reward (100) = -29160.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 6213: Reward = -33168.98, Avg Reward (100) = -29242.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -33168.98, Border Penalty: -33715.99, Obstacle Penalty: -50.00
Episode 6214: Reward = -35499.61, Avg Reward (100) = -29561.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6215: Reward = -29512.46, Avg Reward (100) = -29792.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6216: Reward = -1196.00, Avg Reward (100) = -29732.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6217: Reward = -46746.27, Avg Reward (100) = -29389.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46746.27, Border Penalty: -36091.83, Obstacle Penalty: -50.00
Episode 6218: Reward = -35499.61, Avg Reward (100) = -29480.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6219: Reward = -35499.61, Avg Reward (100) = -29480.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6220: Reward = -35499.61, Avg Reward (100) = -29821.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6221: Reward = -35499.61, Avg Reward (100) = -29864.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6222: Reward = -35499.61, Avg Reward (100) = -29864.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6223: Reward = -28683.61, Avg Reward (100) = -30208.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6224: Reward = -35499.61, Avg Reward (100) = -30003.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6225: Reward = -35499.61, Avg Reward (100) = -30003.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6226: Reward = -1147.00, Avg Reward (100) = -30003.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6227: Reward = -28683.61, Avg Reward (100) = -29523.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6228: Reward = -48879.47, Avg Reward (100) = -29799.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48879.47, Border Penalty: -39589.61, Obstacle Penalty: -50.00
Episode 6229: Reward = -35499.61, Avg Reward (100) = -30277.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6230: Reward = -39606.20, Avg Reward (100) = -30507.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6231: Reward = -35499.61, Avg Reward (100) = -30516.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6232: Reward = -49176.10, Avg Reward (100) = -30548.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6233: Reward = -35499.61, Avg Reward (100) = -30770.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6234: Reward = -35499.61, Avg Reward (100) = -30770.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6235: Reward = -35499.61, Avg Reward (100) = -30873.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6236: Reward = -25228.52, Avg Reward (100) = -30873.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6237: Reward = -35499.61, Avg Reward (100) = -30770.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6238: Reward = -1049.00, Avg Reward (100) = -30779.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6239: Reward = -37669.33, Avg Reward (100) = -30778.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6240: Reward = -35499.61, Avg Reward (100) = -30799.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6241: Reward = -35499.61, Avg Reward (100) = -30799.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6242: Reward = -35499.61, Avg Reward (100) = -31144.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6243: Reward = -35499.61, Avg Reward (100) = -31485.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6244: Reward = -35499.61, Avg Reward (100) = -31828.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6245: Reward = -35499.61, Avg Reward (100) = -31891.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6246: Reward = -35499.61, Avg Reward (100) = -31891.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6247: Reward = -1394.00, Avg Reward (100) = -32233.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6248: Reward = -35499.61, Avg Reward (100) = -31886.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6249: Reward = -35499.61, Avg Reward (100) = -31886.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6250: Reward = -35499.61, Avg Reward (100) = -31886.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6251: Reward = -1147.00, Avg Reward (100) = -31886.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6252: Reward = -35499.61, Avg Reward (100) = -31543.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6253: Reward = -37669.33, Avg Reward (100) = -31543.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6254: Reward = -36089.25, Avg Reward (100) = -31564.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6255: Reward = -35499.61, Avg Reward (100) = -31801.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6256: Reward = -35499.61, Avg Reward (100) = -31801.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6257: Reward = -1000.00, Avg Reward (100) = -31801.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6258: Reward = -35499.61, Avg Reward (100) = -31524.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6259: Reward = -28683.61, Avg Reward (100) = -31524.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6260: Reward = -49176.10, Avg Reward (100) = -31456.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.45, Obstacle Penalty: -50.00
Episode 6261: Reward = -35499.61, Avg Reward (100) = -31456.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6262: Reward = -1196.00, Avg Reward (100) = -31799.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6263: Reward = -12446.80, Avg Reward (100) = -31456.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6264: Reward = -1147.00, Avg Reward (100) = -31571.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6265: Reward = -35499.61, Avg Reward (100) = -31572.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6266: Reward = -1394.00, Avg Reward (100) = -31572.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6267: Reward = -35499.61, Avg Reward (100) = -31090.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6268: Reward = -35499.61, Avg Reward (100) = -31024.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6269: Reward = -32619.61, Avg Reward (100) = -31024.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6270: Reward = -35499.61, Avg Reward (100) = -31098.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6271: Reward = -12446.80, Avg Reward (100) = -31098.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6272: Reward = -35499.61, Avg Reward (100) = -30782.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6273: Reward = -1147.00, Avg Reward (100) = -30782.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6274: Reward = -34719.54, Avg Reward (100) = -30438.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34719.54, Border Penalty: -34754.38, Obstacle Penalty: -50.00
Episode 6275: Reward = -1147.00, Avg Reward (100) = -30430.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6276: Reward = -29512.46, Avg Reward (100) = -29854.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6277: Reward = -36089.25, Avg Reward (100) = -29794.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 6278: Reward = -1000.00, Avg Reward (100) = -29868.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6279: Reward = -35499.61, Avg Reward (100) = -29544.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6280: Reward = -35499.61, Avg Reward (100) = -29544.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6281: Reward = -35499.61, Avg Reward (100) = -29544.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6282: Reward = -35499.61, Avg Reward (100) = -29383.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6283: Reward = -1049.00, Avg Reward (100) = -29383.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6284: Reward = -33469.53, Avg Reward (100) = -29038.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 6285: Reward = -42504.46, Avg Reward (100) = -29018.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42504.46, Border Penalty: -37949.78, Obstacle Penalty: -50.00
Episode 6286: Reward = -35499.61, Avg Reward (100) = -29088.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6287: Reward = -49176.10, Avg Reward (100) = -29088.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6288: Reward = -1000.00, Avg Reward (100) = -29293.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6289: Reward = -35499.61, Avg Reward (100) = -29291.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6290: Reward = -35499.61, Avg Reward (100) = -29291.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6291: Reward = -1147.00, Avg Reward (100) = -29291.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6292: Reward = -36089.25, Avg Reward (100) = -28948.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6293: Reward = -35499.61, Avg Reward (100) = -28954.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6294: Reward = -35499.61, Avg Reward (100) = -29298.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6295: Reward = -32245.59, Avg Reward (100) = -29337.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6296: Reward = -35499.61, Avg Reward (100) = -29304.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6297: Reward = -39606.20, Avg Reward (100) = -29304.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6298: Reward = -37924.67, Avg Reward (100) = -29345.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -37924.67, Border Penalty: -36503.75, Obstacle Penalty: -50.00
Episode 6299: Reward = -35499.61, Avg Reward (100) = -29369.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6300: Reward = -35499.61, Avg Reward (100) = -29315.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6301: Reward = -42504.46, Avg Reward (100) = -29315.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42504.46, Border Penalty: -37949.78, Obstacle Penalty: -50.00
Episode 6302: Reward = -35499.61, Avg Reward (100) = -29729.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6303: Reward = -35499.61, Avg Reward (100) = -29758.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6304: Reward = -35499.61, Avg Reward (100) = -29766.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6305: Reward = -35499.61, Avg Reward (100) = -30109.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6306: Reward = -35499.61, Avg Reward (100) = -30178.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6307: Reward = -35499.61, Avg Reward (100) = -30519.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6308: Reward = -35499.61, Avg Reward (100) = -30441.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6309: Reward = -48116.97, Avg Reward (100) = -30400.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 6310: Reward = -35499.61, Avg Reward (100) = -30559.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6311: Reward = -35499.61, Avg Reward (100) = -30559.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6312: Reward = -35499.61, Avg Reward (100) = -30559.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6313: Reward = -47848.55, Avg Reward (100) = -30435.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6314: Reward = -35499.61, Avg Reward (100) = -30582.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6315: Reward = -36089.25, Avg Reward (100) = -30582.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6316: Reward = -35499.61, Avg Reward (100) = -30648.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6317: Reward = -35499.61, Avg Reward (100) = -30991.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6318: Reward = -14881.38, Avg Reward (100) = -30878.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -14881.38, Border Penalty: -24075.82, Obstacle Penalty: -50.00
Episode 6319: Reward = -43263.20, Avg Reward (100) = -30672.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6320: Reward = -37669.33, Avg Reward (100) = -30750.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6321: Reward = -35499.61, Avg Reward (100) = -30772.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6322: Reward = -35499.61, Avg Reward (100) = -30772.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6323: Reward = -35499.61, Avg Reward (100) = -30772.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6324: Reward = -55917.21, Avg Reward (100) = -30840.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 6325: Reward = -35499.61, Avg Reward (100) = -31044.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6326: Reward = -35499.61, Avg Reward (100) = -31044.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6327: Reward = -35499.61, Avg Reward (100) = -31387.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6328: Reward = -35499.61, Avg Reward (100) = -31456.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6329: Reward = -35499.61, Avg Reward (100) = -31322.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6330: Reward = -25228.52, Avg Reward (100) = -31322.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6331: Reward = -35499.61, Avg Reward (100) = -31178.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6332: Reward = -35499.61, Avg Reward (100) = -31178.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6333: Reward = -1147.00, Avg Reward (100) = -31041.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6334: Reward = -35499.61, Avg Reward (100) = -30698.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6335: Reward = -33701.04, Avg Reward (100) = -30698.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6336: Reward = -35499.61, Avg Reward (100) = -30680.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6337: Reward = -49176.10, Avg Reward (100) = -30782.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6338: Reward = -29512.46, Avg Reward (100) = -30919.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6339: Reward = -33701.04, Avg Reward (100) = -31204.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6340: Reward = -35499.61, Avg Reward (100) = -31164.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6341: Reward = -28653.56, Avg Reward (100) = -31164.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6342: Reward = -35499.61, Avg Reward (100) = -31096.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6343: Reward = -35499.61, Avg Reward (100) = -31096.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6344: Reward = -32619.61, Avg Reward (100) = -31096.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6345: Reward = -33305.90, Avg Reward (100) = -31067.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33305.90, Border Penalty: -33833.45, Obstacle Penalty: -50.00
Episode 6346: Reward = -35499.61, Avg Reward (100) = -31045.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6347: Reward = -1098.00, Avg Reward (100) = -31045.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6348: Reward = -35499.61, Avg Reward (100) = -31042.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6349: Reward = -1394.00, Avg Reward (100) = -31042.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6350: Reward = -34685.86, Avg Reward (100) = -30701.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6351: Reward = -35499.61, Avg Reward (100) = -30693.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6352: Reward = -35499.61, Avg Reward (100) = -31036.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6353: Reward = -35499.61, Avg Reward (100) = -31036.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6354: Reward = -28653.56, Avg Reward (100) = -31015.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6355: Reward = -35499.61, Avg Reward (100) = -30940.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6356: Reward = -25228.52, Avg Reward (100) = -30940.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6357: Reward = -28683.61, Avg Reward (100) = -30838.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6358: Reward = -35499.61, Avg Reward (100) = -31114.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6359: Reward = -28653.56, Avg Reward (100) = -31114.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6360: Reward = -35499.61, Avg Reward (100) = -31114.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6361: Reward = -1049.00, Avg Reward (100) = -30977.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6362: Reward = -1049.00, Avg Reward (100) = -30633.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6363: Reward = -35499.61, Avg Reward (100) = -30631.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6364: Reward = -35499.61, Avg Reward (100) = -30862.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6365: Reward = -35499.61, Avg Reward (100) = -31205.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6366: Reward = -35499.61, Avg Reward (100) = -31205.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6367: Reward = -1000.00, Avg Reward (100) = -31547.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6368: Reward = -28653.56, Avg Reward (100) = -31202.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6369: Reward = -29512.46, Avg Reward (100) = -31133.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6370: Reward = -35499.61, Avg Reward (100) = -31102.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6371: Reward = -30651.53, Avg Reward (100) = -31102.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30651.53, Border Penalty: -32266.32, Obstacle Penalty: -50.00
Episode 6372: Reward = -49176.10, Avg Reward (100) = -31284.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6373: Reward = -43263.20, Avg Reward (100) = -31421.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6374: Reward = -35499.61, Avg Reward (100) = -31842.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6375: Reward = -35499.61, Avg Reward (100) = -31850.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6376: Reward = -35499.61, Avg Reward (100) = -32193.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6377: Reward = -12446.80, Avg Reward (100) = -32253.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6378: Reward = -40334.49, Avg Reward (100) = -32017.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 6379: Reward = -1196.00, Avg Reward (100) = -32410.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6380: Reward = -35499.61, Avg Reward (100) = -32067.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6381: Reward = -1443.00, Avg Reward (100) = -32067.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1443.00, Border Penalty: -5276.28, Obstacle Penalty: -50.00
Episode 6382: Reward = -26787.09, Avg Reward (100) = -31726.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 6383: Reward = -35499.61, Avg Reward (100) = -31639.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6384: Reward = -1147.00, Avg Reward (100) = -31984.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6385: Reward = -35499.61, Avg Reward (100) = -31661.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6386: Reward = -35499.61, Avg Reward (100) = -31591.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6387: Reward = -35499.61, Avg Reward (100) = -31591.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6388: Reward = -31735.80, Avg Reward (100) = -31454.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31735.80, Border Penalty: -33598.23, Obstacle Penalty: -50.00
Episode 6389: Reward = -35499.61, Avg Reward (100) = -31761.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6390: Reward = -33701.04, Avg Reward (100) = -31761.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6391: Reward = -35499.61, Avg Reward (100) = -31743.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6392: Reward = -35499.61, Avg Reward (100) = -32087.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6393: Reward = -35499.61, Avg Reward (100) = -32081.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6394: Reward = -49626.26, Avg Reward (100) = -32081.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6395: Reward = -32619.61, Avg Reward (100) = -32222.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6396: Reward = -33701.04, Avg Reward (100) = -32226.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6397: Reward = -32245.59, Avg Reward (100) = -32208.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 6398: Reward = -35499.61, Avg Reward (100) = -32134.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6399: Reward = -35499.61, Avg Reward (100) = -32110.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6400: Reward = -34685.86, Avg Reward (100) = -32110.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6401: Reward = -35499.61, Avg Reward (100) = -32102.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6402: Reward = -35499.61, Avg Reward (100) = -32032.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6403: Reward = -35499.61, Avg Reward (100) = -32032.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6404: Reward = -1049.00, Avg Reward (100) = -32032.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6405: Reward = -32619.61, Avg Reward (100) = -31687.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6406: Reward = -35499.61, Avg Reward (100) = -31659.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6407: Reward = -37669.33, Avg Reward (100) = -31659.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6408: Reward = -35499.61, Avg Reward (100) = -31680.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6409: Reward = -29512.46, Avg Reward (100) = -31680.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6410: Reward = -35499.61, Avg Reward (100) = -31494.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6411: Reward = -1147.00, Avg Reward (100) = -31494.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6412: Reward = -35499.61, Avg Reward (100) = -31151.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6413: Reward = -35499.61, Avg Reward (100) = -31151.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6414: Reward = -35499.61, Avg Reward (100) = -31027.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6415: Reward = -35499.61, Avg Reward (100) = -31027.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6416: Reward = -35499.61, Avg Reward (100) = -31021.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6417: Reward = -35499.61, Avg Reward (100) = -31021.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6418: Reward = -35499.61, Avg Reward (100) = -31021.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6419: Reward = -33469.53, Avg Reward (100) = -31227.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6420: Reward = -49163.20, Avg Reward (100) = -31129.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49163.20, Border Penalty: -39837.59, Obstacle Penalty: -50.00
Episode 6421: Reward = -35499.61, Avg Reward (100) = -31244.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6422: Reward = -33701.04, Avg Reward (100) = -31244.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6423: Reward = -1049.00, Avg Reward (100) = -31226.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6424: Reward = -35499.61, Avg Reward (100) = -30882.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6425: Reward = -35499.61, Avg Reward (100) = -30678.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6426: Reward = -47848.55, Avg Reward (100) = -30678.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6427: Reward = -1394.00, Avg Reward (100) = -30801.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6428: Reward = -35499.61, Avg Reward (100) = -30460.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6429: Reward = -1000.00, Avg Reward (100) = -30460.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6430: Reward = -25228.52, Avg Reward (100) = -30115.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6431: Reward = -34685.86, Avg Reward (100) = -30115.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6432: Reward = -35499.61, Avg Reward (100) = -30107.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6433: Reward = -35499.61, Avg Reward (100) = -30107.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6434: Reward = -32245.59, Avg Reward (100) = -30451.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6435: Reward = -1196.00, Avg Reward (100) = -30418.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6436: Reward = -35499.61, Avg Reward (100) = -30093.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6437: Reward = -35499.61, Avg Reward (100) = -30093.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6438: Reward = -35499.61, Avg Reward (100) = -29956.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6439: Reward = -33701.04, Avg Reward (100) = -30016.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6440: Reward = -49626.26, Avg Reward (100) = -30016.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6441: Reward = -35499.61, Avg Reward (100) = -30157.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6442: Reward = -35499.61, Avg Reward (100) = -30226.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6443: Reward = -32619.61, Avg Reward (100) = -30226.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6444: Reward = -35499.61, Avg Reward (100) = -30197.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6445: Reward = -43263.20, Avg Reward (100) = -30226.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6446: Reward = -35499.61, Avg Reward (100) = -30325.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6447: Reward = -49626.26, Avg Reward (100) = -30325.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6448: Reward = -35499.61, Avg Reward (100) = -30811.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6449: Reward = -35499.61, Avg Reward (100) = -30811.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6450: Reward = -35499.61, Avg Reward (100) = -31152.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6451: Reward = -32499.04, Avg Reward (100) = -31160.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32499.04, Border Penalty: -32458.42, Obstacle Penalty: -50.00
Episode 6452: Reward = -1196.00, Avg Reward (100) = -31130.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6453: Reward = -49626.26, Avg Reward (100) = -30787.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6454: Reward = -35499.61, Avg Reward (100) = -30928.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6455: Reward = -35499.61, Avg Reward (100) = -30997.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6456: Reward = -35499.61, Avg Reward (100) = -30997.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6457: Reward = -34685.86, Avg Reward (100) = -31099.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6458: Reward = -1000.00, Avg Reward (100) = -31159.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6459: Reward = -1394.00, Avg Reward (100) = -30814.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6460: Reward = -47848.55, Avg Reward (100) = -30542.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6461: Reward = -35499.61, Avg Reward (100) = -30665.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6462: Reward = -1098.00, Avg Reward (100) = -31010.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6463: Reward = -29512.46, Avg Reward (100) = -31010.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6464: Reward = -1098.00, Avg Reward (100) = -30950.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6465: Reward = -35499.61, Avg Reward (100) = -30606.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6466: Reward = -35499.61, Avg Reward (100) = -30606.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6467: Reward = -25228.52, Avg Reward (100) = -30606.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6468: Reward = -35499.61, Avg Reward (100) = -30849.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6469: Reward = -1098.00, Avg Reward (100) = -30917.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6470: Reward = -35499.61, Avg Reward (100) = -30633.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6471: Reward = -34927.46, Avg Reward (100) = -30633.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 6472: Reward = -30437.18, Avg Reward (100) = -30676.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 6473: Reward = -35499.61, Avg Reward (100) = -30488.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6474: Reward = -29512.46, Avg Reward (100) = -30411.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6475: Reward = -35499.61, Avg Reward (100) = -30351.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6476: Reward = -1098.00, Avg Reward (100) = -30351.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6477: Reward = -1049.00, Avg Reward (100) = -30007.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6478: Reward = -49176.10, Avg Reward (100) = -29893.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6479: Reward = -35499.61, Avg Reward (100) = -29981.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6480: Reward = -32245.59, Avg Reward (100) = -30324.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6481: Reward = -1000.00, Avg Reward (100) = -30292.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6482: Reward = -29512.46, Avg Reward (100) = -30287.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6483: Reward = -35499.61, Avg Reward (100) = -30315.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6484: Reward = -28653.56, Avg Reward (100) = -30315.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6485: Reward = -33469.53, Avg Reward (100) = -30590.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6486: Reward = -35499.61, Avg Reward (100) = -30569.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6487: Reward = -35499.61, Avg Reward (100) = -30569.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6488: Reward = -34685.86, Avg Reward (100) = -30569.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6489: Reward = -36089.25, Avg Reward (100) = -30599.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6490: Reward = -35499.61, Avg Reward (100) = -30605.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6491: Reward = -35499.61, Avg Reward (100) = -30623.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6492: Reward = -47848.55, Avg Reward (100) = -30623.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6493: Reward = -28653.56, Avg Reward (100) = -30746.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6494: Reward = -52270.10, Avg Reward (100) = -30678.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 6495: Reward = -35499.61, Avg Reward (100) = -30704.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6496: Reward = -35499.61, Avg Reward (100) = -30733.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6497: Reward = -35499.61, Avg Reward (100) = -30751.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6498: Reward = -35499.61, Avg Reward (100) = -30783.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6499: Reward = -50841.58, Avg Reward (100) = -30783.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50841.58, Border Penalty: -40517.28, Obstacle Penalty: -50.00
Episode 6500: Reward = -35499.61, Avg Reward (100) = -30937.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6501: Reward = -47848.55, Avg Reward (100) = -30945.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6502: Reward = -50011.42, Avg Reward (100) = -31068.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50011.42, Border Penalty: -38178.67, Obstacle Penalty: -50.00
Episode 6503: Reward = -40749.96, Avg Reward (100) = -31214.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40749.96, Border Penalty: -36139.82, Obstacle Penalty: -50.00
Episode 6504: Reward = -35499.61, Avg Reward (100) = -31266.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6505: Reward = -28772.37, Avg Reward (100) = -31611.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28772.37, Border Penalty: -31401.67, Obstacle Penalty: -50.00
Episode 6506: Reward = -29512.46, Avg Reward (100) = -31572.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6507: Reward = -35499.61, Avg Reward (100) = -31512.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6508: Reward = -43591.77, Avg Reward (100) = -31491.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43591.77, Border Penalty: -38351.20, Obstacle Penalty: -50.00
Episode 6509: Reward = -1098.00, Avg Reward (100) = -31572.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6510: Reward = -49176.10, Avg Reward (100) = -31287.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6511: Reward = -37669.33, Avg Reward (100) = -31424.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6512: Reward = -1098.00, Avg Reward (100) = -31789.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6513: Reward = -35499.61, Avg Reward (100) = -31445.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6514: Reward = -1196.00, Avg Reward (100) = -31445.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6515: Reward = -29512.46, Avg Reward (100) = -31102.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6516: Reward = -1098.00, Avg Reward (100) = -31042.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6517: Reward = -32245.59, Avg Reward (100) = -30698.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -30447.79, Obstacle Penalty: -50.00
Episode 6518: Reward = -33469.53, Avg Reward (100) = -30666.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6519: Reward = -35499.61, Avg Reward (100) = -30646.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6520: Reward = -35499.61, Avg Reward (100) = -30666.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6521: Reward = -1147.00, Avg Reward (100) = -30529.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6522: Reward = -35499.61, Avg Reward (100) = -30186.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6523: Reward = -35499.61, Avg Reward (100) = -30204.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6524: Reward = -35499.61, Avg Reward (100) = -30548.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6525: Reward = -1000.00, Avg Reward (100) = -30548.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6526: Reward = -35499.61, Avg Reward (100) = -30203.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6527: Reward = -36676.39, Avg Reward (100) = -30080.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36676.39, Border Penalty: -34346.55, Obstacle Penalty: -50.00
Episode 6528: Reward = -35499.61, Avg Reward (100) = -30433.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6529: Reward = -43263.20, Avg Reward (100) = -30433.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6530: Reward = -35499.61, Avg Reward (100) = -30855.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6531: Reward = -35499.61, Avg Reward (100) = -30958.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6532: Reward = -35499.61, Avg Reward (100) = -30966.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6533: Reward = -35499.61, Avg Reward (100) = -30966.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6534: Reward = -47848.55, Avg Reward (100) = -30966.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6535: Reward = -1196.00, Avg Reward (100) = -31122.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6536: Reward = -35499.61, Avg Reward (100) = -31122.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6537: Reward = -37669.33, Avg Reward (100) = -31122.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6538: Reward = -1000.00, Avg Reward (100) = -31144.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6539: Reward = -35499.61, Avg Reward (100) = -30799.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6540: Reward = -1049.00, Avg Reward (100) = -30817.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6541: Reward = -35499.61, Avg Reward (100) = -30331.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6542: Reward = -35499.61, Avg Reward (100) = -30331.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6543: Reward = -35499.61, Avg Reward (100) = -30331.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6544: Reward = -32619.61, Avg Reward (100) = -30360.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6545: Reward = -33701.04, Avg Reward (100) = -30331.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6546: Reward = -21549.43, Avg Reward (100) = -30235.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -21549.43, Border Penalty: -27427.83, Obstacle Penalty: -50.00
Episode 6547: Reward = -35499.61, Avg Reward (100) = -30096.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6548: Reward = -35499.61, Avg Reward (100) = -29955.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6549: Reward = -54604.04, Avg Reward (100) = -29955.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54604.04, Border Penalty: -41409.95, Obstacle Penalty: -50.00
Episode 6550: Reward = -33701.04, Avg Reward (100) = -30146.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6551: Reward = -35499.61, Avg Reward (100) = -30128.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6552: Reward = -35499.61, Avg Reward (100) = -30158.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6553: Reward = -12446.80, Avg Reward (100) = -30501.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6554: Reward = -28683.61, Avg Reward (100) = -30129.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6555: Reward = -36089.25, Avg Reward (100) = -30061.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6556: Reward = -43263.20, Avg Reward (100) = -30067.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6557: Reward = -1295.00, Avg Reward (100) = -30144.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6558: Reward = -12446.80, Avg Reward (100) = -29810.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6559: Reward = -35499.61, Avg Reward (100) = -29925.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6560: Reward = -35499.61, Avg Reward (100) = -30266.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6561: Reward = -35499.61, Avg Reward (100) = -30142.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6562: Reward = -35499.61, Avg Reward (100) = -30142.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6563: Reward = -28683.61, Avg Reward (100) = -30486.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6564: Reward = -35499.61, Avg Reward (100) = -30478.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6565: Reward = -35499.61, Avg Reward (100) = -30822.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6566: Reward = -1147.00, Avg Reward (100) = -30822.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6567: Reward = -35499.61, Avg Reward (100) = -30479.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6568: Reward = -39813.53, Avg Reward (100) = -30581.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39813.53, Border Penalty: -36223.90, Obstacle Penalty: -50.00
Episode 6569: Reward = -49626.26, Avg Reward (100) = -30624.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6570: Reward = -49626.26, Avg Reward (100) = -31110.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6571: Reward = -32619.61, Avg Reward (100) = -31251.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6572: Reward = -35499.61, Avg Reward (100) = -31228.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6573: Reward = -35499.61, Avg Reward (100) = -31279.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6574: Reward = -35499.61, Avg Reward (100) = -31279.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6575: Reward = -39606.20, Avg Reward (100) = -31338.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 6576: Reward = -35499.61, Avg Reward (100) = -31379.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6577: Reward = -1049.00, Avg Reward (100) = -31723.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6578: Reward = -35499.61, Avg Reward (100) = -31723.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6579: Reward = -35499.61, Avg Reward (100) = -31587.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6580: Reward = -1147.00, Avg Reward (100) = -31587.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6581: Reward = -39606.20, Avg Reward (100) = -31276.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6582: Reward = -35499.61, Avg Reward (100) = -31662.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6583: Reward = -35499.61, Avg Reward (100) = -31722.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6584: Reward = -35499.61, Avg Reward (100) = -31722.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6585: Reward = -35499.61, Avg Reward (100) = -31790.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6586: Reward = -33469.53, Avg Reward (100) = -31810.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6587: Reward = -35499.61, Avg Reward (100) = -31790.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6588: Reward = -37256.08, Avg Reward (100) = -31790.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 6589: Reward = -25228.52, Avg Reward (100) = -31816.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6590: Reward = -30392.74, Avg Reward (100) = -31707.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 6591: Reward = -1394.00, Avg Reward (100) = -31656.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6592: Reward = -1196.00, Avg Reward (100) = -31315.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6593: Reward = -35499.61, Avg Reward (100) = -30849.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6594: Reward = -28683.61, Avg Reward (100) = -30917.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6595: Reward = -35295.52, Avg Reward (100) = -30681.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34781.11, Obstacle Penalty: -50.00
Episode 6596: Reward = -35499.61, Avg Reward (100) = -30679.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6597: Reward = -35499.61, Avg Reward (100) = -30679.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6598: Reward = -47848.55, Avg Reward (100) = -30679.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6599: Reward = -28653.56, Avg Reward (100) = -30803.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6600: Reward = -35499.61, Avg Reward (100) = -30581.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6601: Reward = -33701.04, Avg Reward (100) = -30581.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6602: Reward = -1245.00, Avg Reward (100) = -30439.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6603: Reward = -27492.00, Avg Reward (100) = -29952.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 6604: Reward = -35499.61, Avg Reward (100) = -29819.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6605: Reward = -35499.61, Avg Reward (100) = -29819.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6606: Reward = -35499.61, Avg Reward (100) = -29886.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6607: Reward = -35499.61, Avg Reward (100) = -29946.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6608: Reward = -35499.61, Avg Reward (100) = -29946.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6609: Reward = -35499.61, Avg Reward (100) = -29865.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6610: Reward = -35499.61, Avg Reward (100) = -30209.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6611: Reward = -1049.00, Avg Reward (100) = -30072.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6612: Reward = -29512.46, Avg Reward (100) = -29706.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6613: Reward = -35499.61, Avg Reward (100) = -29990.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6614: Reward = -35499.61, Avg Reward (100) = -29990.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6615: Reward = -35499.61, Avg Reward (100) = -30333.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6616: Reward = -34685.86, Avg Reward (100) = -30393.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6617: Reward = -35499.61, Avg Reward (100) = -30729.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6618: Reward = -1196.00, Avg Reward (100) = -30762.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6619: Reward = -35499.61, Avg Reward (100) = -30439.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6620: Reward = -1049.00, Avg Reward (100) = -30439.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6621: Reward = -43263.20, Avg Reward (100) = -30095.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 6622: Reward = -29512.46, Avg Reward (100) = -30516.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6623: Reward = -35499.61, Avg Reward (100) = -30456.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6624: Reward = -35499.61, Avg Reward (100) = -30456.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6625: Reward = -35499.61, Avg Reward (100) = -30456.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6626: Reward = -33701.04, Avg Reward (100) = -30801.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6627: Reward = -35499.61, Avg Reward (100) = -30783.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6628: Reward = -35499.61, Avg Reward (100) = -30771.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6629: Reward = -35499.61, Avg Reward (100) = -30771.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6630: Reward = -35499.61, Avg Reward (100) = -30693.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6631: Reward = -1196.00, Avg Reward (100) = -30693.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6632: Reward = -35499.61, Avg Reward (100) = -30350.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6633: Reward = -32245.59, Avg Reward (100) = -30350.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6634: Reward = -35499.61, Avg Reward (100) = -30318.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6635: Reward = -35499.61, Avg Reward (100) = -30194.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6636: Reward = -32619.61, Avg Reward (100) = -30537.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6637: Reward = -35499.61, Avg Reward (100) = -30509.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6638: Reward = -1196.00, Avg Reward (100) = -30487.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6639: Reward = -35499.61, Avg Reward (100) = -30489.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6640: Reward = -35499.61, Avg Reward (100) = -30489.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6641: Reward = -47848.55, Avg Reward (100) = -30833.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6642: Reward = -35499.61, Avg Reward (100) = -30957.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6643: Reward = -1000.00, Avg Reward (100) = -30957.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6644: Reward = -35499.61, Avg Reward (100) = -30612.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6645: Reward = -35499.61, Avg Reward (100) = -30641.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6646: Reward = -1295.00, Avg Reward (100) = -30659.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6647: Reward = -1295.00, Avg Reward (100) = -30456.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6648: Reward = -35499.61, Avg Reward (100) = -30114.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6649: Reward = -43802.69, Avg Reward (100) = -30114.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 6650: Reward = -35499.61, Avg Reward (100) = -30006.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6651: Reward = -35499.61, Avg Reward (100) = -30024.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6652: Reward = -37669.33, Avg Reward (100) = -30024.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6653: Reward = -35499.61, Avg Reward (100) = -30046.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6654: Reward = -1295.00, Avg Reward (100) = -30276.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6655: Reward = -35499.61, Avg Reward (100) = -30002.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6656: Reward = -34685.86, Avg Reward (100) = -29996.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6657: Reward = -35499.61, Avg Reward (100) = -29911.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6658: Reward = -37664.73, Avg Reward (100) = -30253.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37664.73, Border Penalty: -34269.04, Obstacle Penalty: -50.00
Episode 6659: Reward = -34745.03, Avg Reward (100) = -30505.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34745.03, Border Penalty: -32351.37, Obstacle Penalty: -50.00
Episode 6660: Reward = -35499.61, Avg Reward (100) = -30497.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6661: Reward = -29512.46, Avg Reward (100) = -30497.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6662: Reward = -35499.61, Avg Reward (100) = -30437.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6663: Reward = -35499.61, Avg Reward (100) = -30437.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6664: Reward = -36089.25, Avg Reward (100) = -30506.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6665: Reward = -35499.61, Avg Reward (100) = -30512.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6666: Reward = -1196.00, Avg Reward (100) = -30512.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6667: Reward = -35499.61, Avg Reward (100) = -30512.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6668: Reward = -35499.61, Avg Reward (100) = -30512.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6669: Reward = -1394.00, Avg Reward (100) = -30469.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6670: Reward = -35499.61, Avg Reward (100) = -29987.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6671: Reward = -35499.61, Avg Reward (100) = -29845.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6672: Reward = -35499.61, Avg Reward (100) = -29874.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6673: Reward = -32815.85, Avg Reward (100) = -29874.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 6674: Reward = -35499.61, Avg Reward (100) = -29847.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6675: Reward = -35499.61, Avg Reward (100) = -29847.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6676: Reward = -48252.80, Avg Reward (100) = -29806.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 6677: Reward = -32245.59, Avg Reward (100) = -29934.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 6678: Reward = -43263.20, Avg Reward (100) = -30246.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6679: Reward = -33701.04, Avg Reward (100) = -30323.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6680: Reward = -33701.04, Avg Reward (100) = -30305.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6681: Reward = -35499.61, Avg Reward (100) = -30631.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6682: Reward = -35499.61, Avg Reward (100) = -30590.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6683: Reward = -28653.56, Avg Reward (100) = -30590.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6684: Reward = -35499.61, Avg Reward (100) = -30521.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6685: Reward = -33469.53, Avg Reward (100) = -30521.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6686: Reward = -34685.86, Avg Reward (100) = -30501.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6687: Reward = -32281.14, Avg Reward (100) = -30513.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32281.14, Border Penalty: -34088.48, Obstacle Penalty: -50.00
Episode 6688: Reward = -32619.61, Avg Reward (100) = -30481.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6689: Reward = -1147.00, Avg Reward (100) = -30435.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6690: Reward = -36089.25, Avg Reward (100) = -30194.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6691: Reward = -35295.52, Avg Reward (100) = -30251.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34781.11, Obstacle Penalty: -50.00
Episode 6692: Reward = -35499.61, Avg Reward (100) = -30590.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6693: Reward = -35499.61, Avg Reward (100) = -30933.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6694: Reward = -35499.61, Avg Reward (100) = -30933.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6695: Reward = -1196.00, Avg Reward (100) = -31001.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6696: Reward = -35499.61, Avg Reward (100) = -30660.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6697: Reward = -1252.40, Avg Reward (100) = -30660.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6698: Reward = -35499.61, Avg Reward (100) = -30318.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6699: Reward = -47848.55, Avg Reward (100) = -30194.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6700: Reward = -35499.61, Avg Reward (100) = -30386.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6701: Reward = -35499.61, Avg Reward (100) = -30386.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6702: Reward = -1000.00, Avg Reward (100) = -30404.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6703: Reward = -35499.61, Avg Reward (100) = -30402.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6704: Reward = -1295.00, Avg Reward (100) = -30482.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6705: Reward = -29512.46, Avg Reward (100) = -30140.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6706: Reward = -28653.56, Avg Reward (100) = -30080.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6707: Reward = -35499.61, Avg Reward (100) = -30011.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6708: Reward = -1049.00, Avg Reward (100) = -30011.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6709: Reward = -37669.33, Avg Reward (100) = -29667.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 6710: Reward = -33469.53, Avg Reward (100) = -29688.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6711: Reward = -35499.61, Avg Reward (100) = -29668.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6712: Reward = -1394.00, Avg Reward (100) = -30013.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6713: Reward = -35499.61, Avg Reward (100) = -29731.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6714: Reward = -42112.30, Avg Reward (100) = -29731.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 6715: Reward = -35499.61, Avg Reward (100) = -29798.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6716: Reward = -43263.20, Avg Reward (100) = -29798.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 6717: Reward = -30392.74, Avg Reward (100) = -29883.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30392.74, Border Penalty: -33055.16, Obstacle Penalty: -50.00
Episode 6718: Reward = -28683.61, Avg Reward (100) = -29832.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6719: Reward = -1394.00, Avg Reward (100) = -30107.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6720: Reward = -49626.26, Avg Reward (100) = -29766.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6721: Reward = -35499.61, Avg Reward (100) = -30252.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6722: Reward = -35499.61, Avg Reward (100) = -30174.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6723: Reward = -32245.59, Avg Reward (100) = -30234.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6724: Reward = -35499.61, Avg Reward (100) = -30202.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6725: Reward = -35499.61, Avg Reward (100) = -30202.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6726: Reward = -35499.61, Avg Reward (100) = -30202.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6727: Reward = -1049.00, Avg Reward (100) = -30220.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6728: Reward = -53955.87, Avg Reward (100) = -29875.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 6729: Reward = -28653.56, Avg Reward (100) = -30060.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 6730: Reward = -25228.52, Avg Reward (100) = -29991.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6731: Reward = -40955.38, Avg Reward (100) = -29888.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 6732: Reward = -1295.00, Avg Reward (100) = -30286.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6733: Reward = -35499.61, Avg Reward (100) = -29944.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6734: Reward = -35499.61, Avg Reward (100) = -29977.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6735: Reward = -35499.61, Avg Reward (100) = -29977.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6736: Reward = -35499.61, Avg Reward (100) = -29977.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6737: Reward = -35499.61, Avg Reward (100) = -30005.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6738: Reward = -35499.61, Avg Reward (100) = -30005.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6739: Reward = -35499.61, Avg Reward (100) = -30348.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6740: Reward = -35499.61, Avg Reward (100) = -30348.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6741: Reward = -35499.61, Avg Reward (100) = -30348.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6742: Reward = -1098.00, Avg Reward (100) = -30225.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6743: Reward = -55355.04, Avg Reward (100) = -29881.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -55355.04, Border Penalty: -39371.38, Obstacle Penalty: -50.00
Episode 6744: Reward = -35499.61, Avg Reward (100) = -30424.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6745: Reward = -1000.00, Avg Reward (100) = -30424.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6746: Reward = -47848.55, Avg Reward (100) = -30079.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6747: Reward = -35499.61, Avg Reward (100) = -30545.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6748: Reward = -35499.61, Avg Reward (100) = -30887.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6749: Reward = -35499.61, Avg Reward (100) = -30887.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6750: Reward = -32245.59, Avg Reward (100) = -30804.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6751: Reward = -35499.61, Avg Reward (100) = -30771.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6752: Reward = -35499.61, Avg Reward (100) = -30771.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6753: Reward = -26470.74, Avg Reward (100) = -30750.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 6754: Reward = -46653.19, Avg Reward (100) = -30659.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 6755: Reward = -28653.56, Avg Reward (100) = -31113.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6756: Reward = -35499.61, Avg Reward (100) = -31045.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6757: Reward = -47848.55, Avg Reward (100) = -31053.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6758: Reward = -33701.04, Avg Reward (100) = -31176.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6759: Reward = -35499.61, Avg Reward (100) = -31137.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6760: Reward = -35499.61, Avg Reward (100) = -31144.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6761: Reward = -35499.61, Avg Reward (100) = -31144.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6762: Reward = -199.01, Avg Reward (100) = -31204.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -199.01, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6763: Reward = -43263.20, Avg Reward (100) = -30851.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6764: Reward = -35499.61, Avg Reward (100) = -30929.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6765: Reward = -35499.61, Avg Reward (100) = -30923.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6766: Reward = -27052.21, Avg Reward (100) = -30923.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27052.21, Border Penalty: -31213.36, Obstacle Penalty: -50.00
Episode 6767: Reward = -35499.61, Avg Reward (100) = -31181.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6768: Reward = -33469.53, Avg Reward (100) = -31181.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6769: Reward = -35499.61, Avg Reward (100) = -31161.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6770: Reward = -1049.00, Avg Reward (100) = -31502.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6771: Reward = -35499.61, Avg Reward (100) = -31158.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6772: Reward = -34685.86, Avg Reward (100) = -31158.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6773: Reward = -35499.61, Avg Reward (100) = -31149.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6774: Reward = -1351.40, Avg Reward (100) = -31176.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6775: Reward = -28683.61, Avg Reward (100) = -30835.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6776: Reward = -35499.61, Avg Reward (100) = -30767.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6777: Reward = -35499.61, Avg Reward (100) = -30639.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6778: Reward = -1049.00, Avg Reward (100) = -30672.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6779: Reward = -35499.61, Avg Reward (100) = -30249.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6780: Reward = -35499.61, Avg Reward (100) = -30267.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6781: Reward = -35499.61, Avg Reward (100) = -30285.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6782: Reward = -1098.00, Avg Reward (100) = -30285.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6783: Reward = -35499.61, Avg Reward (100) = -29941.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6784: Reward = -1394.00, Avg Reward (100) = -30010.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6785: Reward = -35499.61, Avg Reward (100) = -29669.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6786: Reward = -35499.61, Avg Reward (100) = -29689.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6787: Reward = -1098.00, Avg Reward (100) = -29697.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6788: Reward = -29512.46, Avg Reward (100) = -29385.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6789: Reward = -12446.80, Avg Reward (100) = -29354.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6790: Reward = -32245.59, Avg Reward (100) = -29467.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6791: Reward = -32779.00, Avg Reward (100) = -29429.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32779.00, Border Penalty: -32732.43, Obstacle Penalty: -50.00
Episode 6792: Reward = -49626.26, Avg Reward (100) = -29404.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6793: Reward = -35499.61, Avg Reward (100) = -29545.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6794: Reward = -35499.61, Avg Reward (100) = -29545.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6795: Reward = -35499.61, Avg Reward (100) = -29545.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6796: Reward = -26787.09, Avg Reward (100) = -29888.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30322.06, Obstacle Penalty: -50.00
Episode 6797: Reward = -33701.04, Avg Reward (100) = -29801.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6798: Reward = -35499.61, Avg Reward (100) = -30125.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6799: Reward = -35499.61, Avg Reward (100) = -30125.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6800: Reward = -35499.61, Avg Reward (100) = -30002.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6801: Reward = -35499.61, Avg Reward (100) = -30002.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6802: Reward = -35499.61, Avg Reward (100) = -30002.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6803: Reward = -35499.61, Avg Reward (100) = -30347.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6804: Reward = -35499.61, Avg Reward (100) = -30347.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6805: Reward = -35499.61, Avg Reward (100) = -30689.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6806: Reward = -35499.61, Avg Reward (100) = -30749.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6807: Reward = -35499.61, Avg Reward (100) = -30817.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6808: Reward = -35499.61, Avg Reward (100) = -30817.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6809: Reward = -35499.61, Avg Reward (100) = -31162.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6810: Reward = -1098.00, Avg Reward (100) = -31140.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6811: Reward = -50364.13, Avg Reward (100) = -30816.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -50364.13, Border Penalty: -40386.88, Obstacle Penalty: -50.00
Episode 6812: Reward = -35499.61, Avg Reward (100) = -30965.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6813: Reward = -35499.61, Avg Reward (100) = -31306.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6814: Reward = -1147.00, Avg Reward (100) = -31306.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6815: Reward = -35499.61, Avg Reward (100) = -30896.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6816: Reward = -35499.61, Avg Reward (100) = -30896.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6817: Reward = -35499.61, Avg Reward (100) = -30819.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6818: Reward = -35499.61, Avg Reward (100) = -30870.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6819: Reward = -35499.61, Avg Reward (100) = -30938.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6820: Reward = -35499.61, Avg Reward (100) = -31279.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6821: Reward = -36089.25, Avg Reward (100) = -31138.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6822: Reward = -35499.61, Avg Reward (100) = -31144.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6823: Reward = -1049.00, Avg Reward (100) = -31144.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6824: Reward = -1295.00, Avg Reward (100) = -30832.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6825: Reward = -39606.20, Avg Reward (100) = -30490.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6826: Reward = -43263.20, Avg Reward (100) = -30531.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6827: Reward = -32619.61, Avg Reward (100) = -30608.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6828: Reward = -35499.61, Avg Reward (100) = -30924.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6829: Reward = -1049.00, Avg Reward (100) = -30740.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6830: Reward = -35499.61, Avg Reward (100) = -30464.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6831: Reward = -35499.61, Avg Reward (100) = -30566.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6832: Reward = -47439.38, Avg Reward (100) = -30512.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 6833: Reward = -1147.00, Avg Reward (100) = -30973.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6834: Reward = -35499.61, Avg Reward (100) = -30630.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6835: Reward = -35499.61, Avg Reward (100) = -30630.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6836: Reward = -35499.61, Avg Reward (100) = -30630.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6837: Reward = -1196.00, Avg Reward (100) = -30630.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6838: Reward = -35499.61, Avg Reward (100) = -30287.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6839: Reward = -35499.61, Avg Reward (100) = -30287.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6840: Reward = -35499.61, Avg Reward (100) = -30287.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6841: Reward = -29512.46, Avg Reward (100) = -30287.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6842: Reward = -35499.61, Avg Reward (100) = -30227.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6843: Reward = -33701.04, Avg Reward (100) = -30571.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 6844: Reward = -35499.61, Avg Reward (100) = -30354.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6845: Reward = -1147.00, Avg Reward (100) = -30354.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6846: Reward = -35499.61, Avg Reward (100) = -30356.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6847: Reward = -1295.00, Avg Reward (100) = -30232.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6848: Reward = -35499.61, Avg Reward (100) = -29890.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6849: Reward = -35499.61, Avg Reward (100) = -29890.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6850: Reward = -28683.61, Avg Reward (100) = -29890.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6851: Reward = -35499.61, Avg Reward (100) = -29854.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6852: Reward = -35499.61, Avg Reward (100) = -29854.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6853: Reward = -40334.49, Avg Reward (100) = -29854.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 6854: Reward = -43902.06, Avg Reward (100) = -29993.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 6855: Reward = -35499.61, Avg Reward (100) = -29966.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6856: Reward = -35499.61, Avg Reward (100) = -30034.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6857: Reward = -35499.61, Avg Reward (100) = -30034.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6858: Reward = -35499.61, Avg Reward (100) = -29911.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6859: Reward = -35499.61, Avg Reward (100) = -29929.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6860: Reward = -32632.70, Avg Reward (100) = -29929.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 6861: Reward = -35499.61, Avg Reward (100) = -29900.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6862: Reward = -35499.61, Avg Reward (100) = -29900.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6863: Reward = -1295.00, Avg Reward (100) = -30253.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6864: Reward = -35499.61, Avg Reward (100) = -29833.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6865: Reward = -1196.00, Avg Reward (100) = -29833.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6866: Reward = -1000.00, Avg Reward (100) = -29490.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6867: Reward = -1000.00, Avg Reward (100) = -29230.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6868: Reward = -42363.56, Avg Reward (100) = -28885.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 6869: Reward = -32619.61, Avg Reward (100) = -28974.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6870: Reward = -35499.61, Avg Reward (100) = -28945.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6871: Reward = -34685.86, Avg Reward (100) = -29289.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6872: Reward = -35499.61, Avg Reward (100) = -29281.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6873: Reward = -35499.61, Avg Reward (100) = -29289.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6874: Reward = -28683.61, Avg Reward (100) = -29289.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6875: Reward = -35499.61, Avg Reward (100) = -29563.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6876: Reward = -35499.61, Avg Reward (100) = -29631.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6877: Reward = -35499.61, Avg Reward (100) = -29631.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6878: Reward = -32619.61, Avg Reward (100) = -29631.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6879: Reward = -35499.61, Avg Reward (100) = -29946.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6880: Reward = -35499.61, Avg Reward (100) = -29946.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6881: Reward = -35499.61, Avg Reward (100) = -29946.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6882: Reward = -35499.61, Avg Reward (100) = -29946.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6883: Reward = -46242.48, Avg Reward (100) = -30291.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -36037.65, Obstacle Penalty: -50.00
Episode 6884: Reward = -35499.61, Avg Reward (100) = -30398.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6885: Reward = -1049.00, Avg Reward (100) = -30739.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6886: Reward = -35499.61, Avg Reward (100) = -30394.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6887: Reward = -49176.10, Avg Reward (100) = -30394.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6888: Reward = -35499.61, Avg Reward (100) = -30875.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6889: Reward = -35499.61, Avg Reward (100) = -30935.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6890: Reward = -35499.61, Avg Reward (100) = -31166.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6891: Reward = -1049.00, Avg Reward (100) = -31198.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6892: Reward = -35499.61, Avg Reward (100) = -30881.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6893: Reward = -1049.00, Avg Reward (100) = -30740.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6894: Reward = -35499.61, Avg Reward (100) = -30395.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6895: Reward = -38306.90, Avg Reward (100) = -30395.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 6896: Reward = -35499.61, Avg Reward (100) = -30423.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6897: Reward = -35499.61, Avg Reward (100) = -30510.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6898: Reward = -35499.61, Avg Reward (100) = -30528.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6899: Reward = -54604.04, Avg Reward (100) = -30528.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54604.04, Border Penalty: -41409.95, Obstacle Penalty: -50.00
Episode 6900: Reward = -35499.61, Avg Reward (100) = -30719.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6901: Reward = -35499.61, Avg Reward (100) = -30719.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6902: Reward = -1000.00, Avg Reward (100) = -30719.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6903: Reward = -34685.86, Avg Reward (100) = -30374.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6904: Reward = -32619.61, Avg Reward (100) = -30366.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6905: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6906: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6907: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6908: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6909: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6910: Reward = -35499.61, Avg Reward (100) = -30337.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6911: Reward = -12446.80, Avg Reward (100) = -30681.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 6912: Reward = -35499.61, Avg Reward (100) = -30302.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6913: Reward = -28882.62, Avg Reward (100) = -30302.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28882.62, Border Penalty: -32371.81, Obstacle Penalty: -50.00
Episode 6914: Reward = -35499.61, Avg Reward (100) = -30236.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6915: Reward = -32619.61, Avg Reward (100) = -30580.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6916: Reward = -35499.61, Avg Reward (100) = -30551.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6917: Reward = -1196.00, Avg Reward (100) = -30551.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6918: Reward = -35499.61, Avg Reward (100) = -30208.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6919: Reward = -35499.61, Avg Reward (100) = -30208.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6920: Reward = -35499.61, Avg Reward (100) = -30208.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6921: Reward = -1147.00, Avg Reward (100) = -30208.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6922: Reward = -35499.61, Avg Reward (100) = -29858.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6923: Reward = -35499.61, Avg Reward (100) = -29858.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6924: Reward = -29512.46, Avg Reward (100) = -30203.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6925: Reward = -46746.27, Avg Reward (100) = -30485.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46746.27, Border Penalty: -36091.83, Obstacle Penalty: -50.00
Episode 6926: Reward = -35499.61, Avg Reward (100) = -30556.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6927: Reward = -35499.61, Avg Reward (100) = -30479.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6928: Reward = -35499.61, Avg Reward (100) = -30508.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6929: Reward = -35499.61, Avg Reward (100) = -30508.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6930: Reward = -1196.00, Avg Reward (100) = -30852.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 6931: Reward = -1098.00, Avg Reward (100) = -30509.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6932: Reward = -1295.00, Avg Reward (100) = -30165.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 6933: Reward = -47832.05, Avg Reward (100) = -29704.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47832.05, Border Penalty: -34798.45, Obstacle Penalty: -50.00
Episode 6934: Reward = -35499.61, Avg Reward (100) = -30170.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6935: Reward = -35499.61, Avg Reward (100) = -30170.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6936: Reward = -35499.61, Avg Reward (100) = -30170.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6937: Reward = -28683.61, Avg Reward (100) = -30170.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6938: Reward = -35499.61, Avg Reward (100) = -30445.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6939: Reward = -39606.20, Avg Reward (100) = -30445.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6940: Reward = -32245.59, Avg Reward (100) = -30486.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6941: Reward = -32245.59, Avg Reward (100) = -30454.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 6942: Reward = -1394.00, Avg Reward (100) = -30481.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 6943: Reward = -35499.61, Avg Reward (100) = -30140.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6944: Reward = -28683.61, Avg Reward (100) = -30158.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6945: Reward = -35499.61, Avg Reward (100) = -30090.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6946: Reward = -40955.38, Avg Reward (100) = -30434.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 6947: Reward = -1147.00, Avg Reward (100) = -30488.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6948: Reward = -35499.61, Avg Reward (100) = -30487.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6949: Reward = -35499.61, Avg Reward (100) = -30487.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6950: Reward = -35499.61, Avg Reward (100) = -30487.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6951: Reward = -47848.55, Avg Reward (100) = -30555.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 6952: Reward = -34236.08, Avg Reward (100) = -30678.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -34470.76, Obstacle Penalty: -50.00
Episode 6953: Reward = -49176.10, Avg Reward (100) = -30666.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6954: Reward = -29512.46, Avg Reward (100) = -30754.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 6955: Reward = -35499.61, Avg Reward (100) = -30610.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6956: Reward = -49176.10, Avg Reward (100) = -30610.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6957: Reward = -35499.61, Avg Reward (100) = -30747.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6958: Reward = -33469.53, Avg Reward (100) = -30747.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6959: Reward = -49626.26, Avg Reward (100) = -30727.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 6960: Reward = -42363.56, Avg Reward (100) = -30868.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 6961: Reward = -35499.61, Avg Reward (100) = -30965.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6962: Reward = -35499.61, Avg Reward (100) = -30965.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6963: Reward = -35499.61, Avg Reward (100) = -30965.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6964: Reward = -25228.52, Avg Reward (100) = -31307.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6965: Reward = -35499.61, Avg Reward (100) = -31204.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6966: Reward = -39606.20, Avg Reward (100) = -31548.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 6967: Reward = -35499.61, Avg Reward (100) = -31934.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6968: Reward = -36089.25, Avg Reward (100) = -32279.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 6969: Reward = -25228.52, Avg Reward (100) = -32216.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 6970: Reward = -35499.61, Avg Reward (100) = -32142.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6971: Reward = -35499.61, Avg Reward (100) = -32142.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6972: Reward = -35499.61, Avg Reward (100) = -32150.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 6973: Reward = -65044.45, Avg Reward (100) = -32150.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -65044.45, Border Penalty: -38290.65, Obstacle Penalty: -50.00
Episode 6974: Reward = -33469.53, Avg Reward (100) = -32446.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 6975: Reward = -35499.61, Avg Reward (100) = -32493.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6976: Reward = -35499.61, Avg Reward (100) = -32493.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6977: Reward = -28683.61, Avg Reward (100) = -32493.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 6978: Reward = -35499.61, Avg Reward (100) = -32425.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6979: Reward = -35499.61, Avg Reward (100) = -32454.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6980: Reward = -43263.20, Avg Reward (100) = -32454.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6981: Reward = -35499.61, Avg Reward (100) = -32532.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6982: Reward = -35499.61, Avg Reward (100) = -32532.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6983: Reward = -27517.30, Avg Reward (100) = -32532.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -27517.30, Border Penalty: -32194.15, Obstacle Penalty: -50.00
Episode 6984: Reward = -49176.10, Avg Reward (100) = -32344.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 6985: Reward = -35499.61, Avg Reward (100) = -32481.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6986: Reward = -1000.00, Avg Reward (100) = -32826.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6987: Reward = -35499.61, Avg Reward (100) = -32481.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6988: Reward = -35499.61, Avg Reward (100) = -32344.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6989: Reward = -35499.61, Avg Reward (100) = -32344.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6990: Reward = -35499.61, Avg Reward (100) = -32344.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 6991: Reward = -28653.56, Avg Reward (100) = -32344.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 6992: Reward = -1049.00, Avg Reward (100) = -32620.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6993: Reward = -1000.00, Avg Reward (100) = -32275.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6994: Reward = -1147.00, Avg Reward (100) = -32275.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 6995: Reward = -34685.86, Avg Reward (100) = -31931.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 6996: Reward = -35499.61, Avg Reward (100) = -31895.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6997: Reward = -35499.61, Avg Reward (100) = -31895.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 6998: Reward = -43263.20, Avg Reward (100) = -31895.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 6999: Reward = -1147.00, Avg Reward (100) = -31973.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7000: Reward = -1049.00, Avg Reward (100) = -31438.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7001: Reward = -1000.00, Avg Reward (100) = -31094.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7002: Reward = -41706.38, Avg Reward (100) = -30749.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41706.38, Border Penalty: -31713.89, Obstacle Penalty: -50.00
Episode 7003: Reward = -35499.61, Avg Reward (100) = -31156.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7004: Reward = -34685.86, Avg Reward (100) = -31164.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7005: Reward = -35499.61, Avg Reward (100) = -31185.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7006: Reward = -45723.38, Avg Reward (100) = -31185.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -45723.38, Border Penalty: -38065.23, Obstacle Penalty: -50.00
Episode 7007: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7008: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7009: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7010: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7011: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7012: Reward = -12446.80, Avg Reward (100) = -31517.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7013: Reward = -35499.61, Avg Reward (100) = -31287.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7014: Reward = -35499.61, Avg Reward (100) = -31353.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7015: Reward = -35499.61, Avg Reward (100) = -31353.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7016: Reward = -29512.46, Avg Reward (100) = -31382.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7017: Reward = -1294.00, Avg Reward (100) = -31322.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 7018: Reward = -39671.98, Avg Reward (100) = -31323.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 7019: Reward = -33469.53, Avg Reward (100) = -31365.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7020: Reward = -32245.59, Avg Reward (100) = -31344.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7021: Reward = -35499.61, Avg Reward (100) = -31312.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7022: Reward = -1196.00, Avg Reward (100) = -31655.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7023: Reward = -35499.61, Avg Reward (100) = -31312.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7024: Reward = -35499.61, Avg Reward (100) = -31312.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7025: Reward = -35499.61, Avg Reward (100) = -31372.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7026: Reward = -38792.44, Avg Reward (100) = -31260.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 7027: Reward = -1147.00, Avg Reward (100) = -31293.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7028: Reward = -35499.61, Avg Reward (100) = -30949.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7029: Reward = -35499.61, Avg Reward (100) = -30949.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7030: Reward = -1394.00, Avg Reward (100) = -30949.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7031: Reward = -38636.47, Avg Reward (100) = -30951.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 7032: Reward = -1295.00, Avg Reward (100) = -31327.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7033: Reward = -28653.56, Avg Reward (100) = -31327.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 7034: Reward = -35499.61, Avg Reward (100) = -31135.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7035: Reward = -1394.00, Avg Reward (100) = -31135.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7036: Reward = -35499.61, Avg Reward (100) = -30794.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7037: Reward = -43263.20, Avg Reward (100) = -30794.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7038: Reward = -35499.61, Avg Reward (100) = -30939.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7039: Reward = -35499.61, Avg Reward (100) = -30939.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7040: Reward = -1295.00, Avg Reward (100) = -30898.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7041: Reward = -35499.61, Avg Reward (100) = -30589.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7042: Reward = -1098.00, Avg Reward (100) = -30621.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7043: Reward = -1394.00, Avg Reward (100) = -30618.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7044: Reward = -52661.12, Avg Reward (100) = -30277.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52661.12, Border Penalty: -41088.17, Obstacle Penalty: -50.00
Episode 7045: Reward = -39409.45, Avg Reward (100) = -30517.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39409.45, Border Penalty: -34826.64, Obstacle Penalty: -50.00
Episode 7046: Reward = -35499.61, Avg Reward (100) = -30556.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7047: Reward = -35499.61, Avg Reward (100) = -30502.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7048: Reward = -35499.61, Avg Reward (100) = -30845.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7049: Reward = -49176.10, Avg Reward (100) = -30845.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7050: Reward = -32245.59, Avg Reward (100) = -30982.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7051: Reward = -35499.61, Avg Reward (100) = -30949.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7052: Reward = -35499.61, Avg Reward (100) = -30826.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7053: Reward = -49626.26, Avg Reward (100) = -30839.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 7054: Reward = -1295.00, Avg Reward (100) = -30843.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7055: Reward = -35499.61, Avg Reward (100) = -30561.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7056: Reward = -39606.20, Avg Reward (100) = -30561.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7057: Reward = -28683.61, Avg Reward (100) = -30465.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7058: Reward = -1147.00, Avg Reward (100) = -30397.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7059: Reward = -1295.00, Avg Reward (100) = -30074.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7060: Reward = -12446.80, Avg Reward (100) = -29591.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7061: Reward = -35499.61, Avg Reward (100) = -29291.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7062: Reward = -35499.61, Avg Reward (100) = -29291.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7063: Reward = -57378.85, Avg Reward (100) = -29291.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -57378.85, Border Penalty: -35060.28, Obstacle Penalty: -50.00
Episode 7064: Reward = -35499.61, Avg Reward (100) = -29510.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7065: Reward = -35499.61, Avg Reward (100) = -29613.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7066: Reward = -1049.00, Avg Reward (100) = -29613.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7067: Reward = -35499.61, Avg Reward (100) = -29227.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7068: Reward = -35499.61, Avg Reward (100) = -29227.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7069: Reward = -35499.61, Avg Reward (100) = -29221.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7070: Reward = -35499.61, Avg Reward (100) = -29324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7071: Reward = -35499.61, Avg Reward (100) = -29324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7072: Reward = -35499.61, Avg Reward (100) = -29324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7073: Reward = -35499.61, Avg Reward (100) = -29324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7074: Reward = -43263.20, Avg Reward (100) = -29029.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7075: Reward = -33701.04, Avg Reward (100) = -29127.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7076: Reward = -47848.55, Avg Reward (100) = -29109.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7077: Reward = -35499.61, Avg Reward (100) = -29232.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7078: Reward = -35499.61, Avg Reward (100) = -29300.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7079: Reward = -35499.61, Avg Reward (100) = -29300.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7080: Reward = -35499.61, Avg Reward (100) = -29300.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7081: Reward = -35499.61, Avg Reward (100) = -29223.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7082: Reward = -35499.61, Avg Reward (100) = -29223.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7083: Reward = -33469.53, Avg Reward (100) = -29223.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7084: Reward = -35499.61, Avg Reward (100) = -29282.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7085: Reward = -35499.61, Avg Reward (100) = -29145.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7086: Reward = -47848.55, Avg Reward (100) = -29145.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -36300.06, Obstacle Penalty: -50.00
Episode 7087: Reward = -1098.00, Avg Reward (100) = -29614.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7088: Reward = -35499.61, Avg Reward (100) = -29270.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7089: Reward = -35499.61, Avg Reward (100) = -29270.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7090: Reward = -1394.00, Avg Reward (100) = -29270.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7091: Reward = -1000.00, Avg Reward (100) = -28929.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7092: Reward = -47848.55, Avg Reward (100) = -28652.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7093: Reward = -35499.61, Avg Reward (100) = -29120.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7094: Reward = -36089.25, Avg Reward (100) = -29465.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7095: Reward = -1245.00, Avg Reward (100) = -29815.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7096: Reward = -40411.33, Avg Reward (100) = -29480.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 7097: Reward = -12446.80, Avg Reward (100) = -29529.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7098: Reward = -35499.61, Avg Reward (100) = -29299.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7099: Reward = -1394.00, Avg Reward (100) = -29221.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7100: Reward = -35499.61, Avg Reward (100) = -29224.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7101: Reward = -1000.00, Avg Reward (100) = -29568.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7102: Reward = -35499.61, Avg Reward (100) = -29568.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7103: Reward = -35499.61, Avg Reward (100) = -29506.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7104: Reward = -1147.00, Avg Reward (100) = -29506.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7105: Reward = -35499.61, Avg Reward (100) = -29171.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7106: Reward = -35499.61, Avg Reward (100) = -29171.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7107: Reward = -35499.61, Avg Reward (100) = -29069.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7108: Reward = -61242.66, Avg Reward (100) = -29069.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -39298.61, Obstacle Penalty: -50.00
Episode 7109: Reward = -33469.53, Avg Reward (100) = -29326.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7110: Reward = -1394.00, Avg Reward (100) = -29306.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7111: Reward = -30063.90, Avg Reward (100) = -28965.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30063.90, Border Penalty: -32903.33, Obstacle Penalty: -50.00
Episode 7112: Reward = -35499.61, Avg Reward (100) = -28910.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7113: Reward = -35499.61, Avg Reward (100) = -29141.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7114: Reward = -52416.78, Avg Reward (100) = -29141.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52416.78, Border Penalty: -38942.04, Obstacle Penalty: -50.00
Episode 7115: Reward = -35499.61, Avg Reward (100) = -29310.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7116: Reward = -35499.61, Avg Reward (100) = -29310.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7117: Reward = -1000.00, Avg Reward (100) = -29370.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7118: Reward = -35499.61, Avg Reward (100) = -29367.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7119: Reward = -35499.61, Avg Reward (100) = -29325.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7120: Reward = -36089.25, Avg Reward (100) = -29345.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7121: Reward = -35499.61, Avg Reward (100) = -29384.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7122: Reward = -1196.00, Avg Reward (100) = -29384.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7123: Reward = -25228.52, Avg Reward (100) = -29384.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7124: Reward = -35499.61, Avg Reward (100) = -29281.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7125: Reward = -32619.61, Avg Reward (100) = -29281.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7126: Reward = -35499.61, Avg Reward (100) = -29252.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7127: Reward = -35499.61, Avg Reward (100) = -29219.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7128: Reward = -29512.46, Avg Reward (100) = -29563.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7129: Reward = -1147.00, Avg Reward (100) = -29503.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7130: Reward = -33469.53, Avg Reward (100) = -29160.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7131: Reward = -35499.61, Avg Reward (100) = -29480.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7132: Reward = -1394.00, Avg Reward (100) = -29449.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7133: Reward = -35499.61, Avg Reward (100) = -29450.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7134: Reward = -1098.00, Avg Reward (100) = -29518.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7135: Reward = -25228.52, Avg Reward (100) = -29174.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7136: Reward = -35499.61, Avg Reward (100) = -29413.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7137: Reward = -35499.61, Avg Reward (100) = -29413.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7138: Reward = -35499.61, Avg Reward (100) = -29335.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7139: Reward = -35499.61, Avg Reward (100) = -29335.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7140: Reward = -33701.04, Avg Reward (100) = -29335.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7141: Reward = -33469.53, Avg Reward (100) = -29659.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7142: Reward = -35499.61, Avg Reward (100) = -29639.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7143: Reward = -35499.61, Avg Reward (100) = -29983.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7144: Reward = -32619.61, Avg Reward (100) = -30324.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7145: Reward = -35499.61, Avg Reward (100) = -30124.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7146: Reward = -35499.61, Avg Reward (100) = -30084.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7147: Reward = -35499.61, Avg Reward (100) = -30084.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7148: Reward = -35499.61, Avg Reward (100) = -30084.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7149: Reward = -35499.61, Avg Reward (100) = -30084.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7150: Reward = -35499.61, Avg Reward (100) = -29948.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7151: Reward = -35499.61, Avg Reward (100) = -29980.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7152: Reward = -35499.61, Avg Reward (100) = -29980.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7153: Reward = -35499.61, Avg Reward (100) = -29980.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7154: Reward = -35499.61, Avg Reward (100) = -29839.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7155: Reward = -28653.56, Avg Reward (100) = -30181.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7156: Reward = -35499.61, Avg Reward (100) = -30113.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7157: Reward = -1000.00, Avg Reward (100) = -30071.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7158: Reward = -35499.61, Avg Reward (100) = -29795.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7159: Reward = -35499.61, Avg Reward (100) = -30138.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7160: Reward = -39606.20, Avg Reward (100) = -30480.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7161: Reward = -1147.00, Avg Reward (100) = -30752.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7162: Reward = -35499.61, Avg Reward (100) = -30408.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7163: Reward = -35499.61, Avg Reward (100) = -30408.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7164: Reward = -35499.61, Avg Reward (100) = -30189.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7165: Reward = -35499.61, Avg Reward (100) = -30189.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7166: Reward = -35499.61, Avg Reward (100) = -30189.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7167: Reward = -64271.59, Avg Reward (100) = -30534.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -64271.59, Border Penalty: -37382.85, Obstacle Penalty: -50.00
Episode 7168: Reward = -36089.25, Avg Reward (100) = -30822.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7169: Reward = -35499.61, Avg Reward (100) = -30828.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7170: Reward = -37669.33, Avg Reward (100) = -30828.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7171: Reward = -39606.20, Avg Reward (100) = -30849.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7172: Reward = -35499.61, Avg Reward (100) = -30890.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7173: Reward = -29512.46, Avg Reward (100) = -30890.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7174: Reward = -29512.46, Avg Reward (100) = -30830.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7175: Reward = -1252.40, Avg Reward (100) = -30693.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7176: Reward = -33701.04, Avg Reward (100) = -30368.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7177: Reward = -35499.61, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7178: Reward = -35499.61, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7179: Reward = -35499.61, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7180: Reward = -35499.61, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7181: Reward = -35499.61, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7182: Reward = -1245.00, Avg Reward (100) = -30227.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7183: Reward = -35499.61, Avg Reward (100) = -29884.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7184: Reward = -35499.61, Avg Reward (100) = -29905.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7185: Reward = -1394.00, Avg Reward (100) = -29905.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7186: Reward = -1098.00, Avg Reward (100) = -29564.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7187: Reward = -35499.61, Avg Reward (100) = -29096.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7188: Reward = -35499.61, Avg Reward (100) = -29440.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7189: Reward = -33701.04, Avg Reward (100) = -29440.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7190: Reward = -35499.61, Avg Reward (100) = -29422.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7191: Reward = -50841.58, Avg Reward (100) = -29763.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50841.58, Border Penalty: -40517.28, Obstacle Penalty: -50.00
Episode 7192: Reward = -35499.61, Avg Reward (100) = -30262.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7193: Reward = -28683.61, Avg Reward (100) = -30138.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7194: Reward = -35499.61, Avg Reward (100) = -30070.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7195: Reward = -35499.61, Avg Reward (100) = -30064.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7196: Reward = -35499.61, Avg Reward (100) = -30407.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7197: Reward = -32245.59, Avg Reward (100) = -30358.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7198: Reward = -35499.61, Avg Reward (100) = -30556.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7199: Reward = -35499.61, Avg Reward (100) = -30556.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7200: Reward = -35499.61, Avg Reward (100) = -30897.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7201: Reward = -35499.61, Avg Reward (100) = -30897.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7202: Reward = -39606.20, Avg Reward (100) = -31242.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7203: Reward = -35499.61, Avg Reward (100) = -31283.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7204: Reward = -1295.00, Avg Reward (100) = -31283.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7205: Reward = -35499.61, Avg Reward (100) = -31284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7206: Reward = -35499.61, Avg Reward (100) = -31284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7207: Reward = -35499.61, Avg Reward (100) = -31284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7208: Reward = -37669.33, Avg Reward (100) = -31284.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7209: Reward = -35499.61, Avg Reward (100) = -31048.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7210: Reward = -35499.61, Avg Reward (100) = -31069.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7211: Reward = -35499.61, Avg Reward (100) = -31410.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7212: Reward = -35499.61, Avg Reward (100) = -31464.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7213: Reward = -1000.00, Avg Reward (100) = -31464.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7214: Reward = -35499.61, Avg Reward (100) = -31119.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7215: Reward = -35499.61, Avg Reward (100) = -30950.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7216: Reward = -37669.33, Avg Reward (100) = -30950.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7217: Reward = -35499.61, Avg Reward (100) = -30972.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7218: Reward = -35499.61, Avg Reward (100) = -31317.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7219: Reward = -1098.00, Avg Reward (100) = -31317.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7220: Reward = -35499.61, Avg Reward (100) = -30973.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7221: Reward = -35499.61, Avg Reward (100) = -30967.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7222: Reward = -35499.61, Avg Reward (100) = -30967.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7223: Reward = -36089.25, Avg Reward (100) = -31310.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7224: Reward = -35499.61, Avg Reward (100) = -31418.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7225: Reward = -35499.61, Avg Reward (100) = -31418.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7226: Reward = -35499.61, Avg Reward (100) = -31447.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7227: Reward = -35499.61, Avg Reward (100) = -31447.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7228: Reward = -35499.61, Avg Reward (100) = -31447.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7229: Reward = -32245.59, Avg Reward (100) = -31507.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7230: Reward = -35499.61, Avg Reward (100) = -31818.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7231: Reward = -1196.00, Avg Reward (100) = -31838.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7232: Reward = -35499.61, Avg Reward (100) = -31495.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7233: Reward = -35499.61, Avg Reward (100) = -31836.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7234: Reward = -35499.61, Avg Reward (100) = -31836.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7235: Reward = -35499.61, Avg Reward (100) = -32180.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7236: Reward = -35499.61, Avg Reward (100) = -32283.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7237: Reward = -35499.61, Avg Reward (100) = -32283.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7238: Reward = -35499.61, Avg Reward (100) = -32283.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7239: Reward = -49174.12, Avg Reward (100) = -32283.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 7240: Reward = -35499.61, Avg Reward (100) = -32420.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7241: Reward = -35499.61, Avg Reward (100) = -32438.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7242: Reward = -1196.00, Avg Reward (100) = -32458.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7243: Reward = -34685.86, Avg Reward (100) = -32115.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7244: Reward = -35499.61, Avg Reward (100) = -32107.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7245: Reward = -1000.00, Avg Reward (100) = -32136.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7246: Reward = -35499.61, Avg Reward (100) = -31791.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7247: Reward = -1049.00, Avg Reward (100) = -31791.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7248: Reward = -1295.00, Avg Reward (100) = -31446.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7249: Reward = -35499.61, Avg Reward (100) = -31104.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7250: Reward = -35499.61, Avg Reward (100) = -31104.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7251: Reward = -61242.66, Avg Reward (100) = -31104.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -39298.61, Obstacle Penalty: -50.00
Episode 7252: Reward = -1098.00, Avg Reward (100) = -31362.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7253: Reward = -35499.61, Avg Reward (100) = -31018.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7254: Reward = -35499.61, Avg Reward (100) = -31018.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7255: Reward = -47848.55, Avg Reward (100) = -31018.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 7256: Reward = -35499.61, Avg Reward (100) = -31210.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7257: Reward = -35499.61, Avg Reward (100) = -31210.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7258: Reward = -35499.61, Avg Reward (100) = -31555.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7259: Reward = -25228.52, Avg Reward (100) = -31555.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7260: Reward = -35499.61, Avg Reward (100) = -31452.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7261: Reward = -35499.61, Avg Reward (100) = -31411.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7262: Reward = -1000.00, Avg Reward (100) = -31754.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7263: Reward = -47848.55, Avg Reward (100) = -31409.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7264: Reward = -35499.61, Avg Reward (100) = -31533.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7265: Reward = -35499.61, Avg Reward (100) = -31533.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7266: Reward = -35499.61, Avg Reward (100) = -31533.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7267: Reward = -32245.59, Avg Reward (100) = -31533.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7268: Reward = -35499.61, Avg Reward (100) = -31213.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7269: Reward = -35499.61, Avg Reward (100) = -31207.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7270: Reward = -35499.61, Avg Reward (100) = -31207.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7271: Reward = -1295.00, Avg Reward (100) = -31185.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7272: Reward = -39606.20, Avg Reward (100) = -30802.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7273: Reward = -1196.00, Avg Reward (100) = -30843.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7274: Reward = -35499.61, Avg Reward (100) = -30560.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7275: Reward = -28653.56, Avg Reward (100) = -30620.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7276: Reward = -1196.00, Avg Reward (100) = -30894.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7277: Reward = -1049.00, Avg Reward (100) = -30569.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7278: Reward = -1098.00, Avg Reward (100) = -30224.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7279: Reward = -35499.61, Avg Reward (100) = -29880.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7280: Reward = -47848.55, Avg Reward (100) = -29880.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7281: Reward = -32619.61, Avg Reward (100) = -30004.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7282: Reward = -1147.00, Avg Reward (100) = -29975.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7283: Reward = -35499.61, Avg Reward (100) = -29974.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7284: Reward = -35499.61, Avg Reward (100) = -29974.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7285: Reward = -47848.55, Avg Reward (100) = -29974.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7286: Reward = -29626.05, Avg Reward (100) = -30438.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 7287: Reward = -35499.61, Avg Reward (100) = -30724.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7288: Reward = -41220.20, Avg Reward (100) = -30724.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -41220.20, Border Penalty: -37060.94, Obstacle Penalty: -50.00
Episode 7289: Reward = -32619.61, Avg Reward (100) = -30781.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7290: Reward = -35499.61, Avg Reward (100) = -30770.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7291: Reward = -1049.00, Avg Reward (100) = -30770.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7292: Reward = -33469.53, Avg Reward (100) = -30272.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7293: Reward = -35499.61, Avg Reward (100) = -30252.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7294: Reward = -1098.00, Avg Reward (100) = -30320.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7295: Reward = -35499.61, Avg Reward (100) = -29976.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7296: Reward = -35499.61, Avg Reward (100) = -29976.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7297: Reward = -37540.47, Avg Reward (100) = -29976.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -37540.47, Border Penalty: -36239.43, Obstacle Penalty: -50.00
Episode 7298: Reward = -35499.61, Avg Reward (100) = -30029.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7299: Reward = -33701.04, Avg Reward (100) = -30029.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7300: Reward = -34685.86, Avg Reward (100) = -30011.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7301: Reward = -1000.00, Avg Reward (100) = -30003.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7302: Reward = -32619.61, Avg Reward (100) = -29658.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7303: Reward = -35499.61, Avg Reward (100) = -29588.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7304: Reward = -35499.61, Avg Reward (100) = -29588.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7305: Reward = -35499.61, Avg Reward (100) = -29930.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7306: Reward = -43263.20, Avg Reward (100) = -29930.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7307: Reward = -35499.61, Avg Reward (100) = -30008.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7308: Reward = -28653.56, Avg Reward (100) = -30008.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7309: Reward = -35499.61, Avg Reward (100) = -29917.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7310: Reward = -1394.00, Avg Reward (100) = -29917.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7311: Reward = -35499.61, Avg Reward (100) = -29576.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7312: Reward = -36089.25, Avg Reward (100) = -29576.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7313: Reward = -49176.10, Avg Reward (100) = -29582.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7314: Reward = -35499.61, Avg Reward (100) = -30064.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7315: Reward = -35499.61, Avg Reward (100) = -30064.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7316: Reward = -35499.61, Avg Reward (100) = -30064.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7317: Reward = -34685.86, Avg Reward (100) = -30042.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7318: Reward = -35499.61, Avg Reward (100) = -30034.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7319: Reward = -35499.61, Avg Reward (100) = -30034.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7320: Reward = -47025.21, Avg Reward (100) = -30378.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 7321: Reward = -1295.00, Avg Reward (100) = -30493.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7322: Reward = -33701.04, Avg Reward (100) = -30151.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7323: Reward = -35499.61, Avg Reward (100) = -30133.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7324: Reward = -35499.61, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7325: Reward = -35499.61, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7326: Reward = -35499.61, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7327: Reward = -35499.61, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7328: Reward = -35499.61, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7329: Reward = -29512.46, Avg Reward (100) = -30128.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7330: Reward = -35499.61, Avg Reward (100) = -30100.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7331: Reward = -35499.61, Avg Reward (100) = -30100.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7332: Reward = -9566.81, Avg Reward (100) = -30443.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 7333: Reward = -35499.61, Avg Reward (100) = -30184.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7334: Reward = -1344.00, Avg Reward (100) = -30184.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7335: Reward = -1000.00, Avg Reward (100) = -29842.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7336: Reward = -35499.61, Avg Reward (100) = -29497.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7337: Reward = -35499.61, Avg Reward (100) = -29497.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7338: Reward = -35499.61, Avg Reward (100) = -29497.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7339: Reward = -33382.70, Avg Reward (100) = -29497.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33382.70, Border Penalty: -34178.79, Obstacle Penalty: -50.00
Episode 7340: Reward = -35499.61, Avg Reward (100) = -29339.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7341: Reward = -35499.61, Avg Reward (100) = -29339.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7342: Reward = -1147.00, Avg Reward (100) = -29339.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7343: Reward = -1147.00, Avg Reward (100) = -29339.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7344: Reward = -35499.61, Avg Reward (100) = -29004.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7345: Reward = -35499.61, Avg Reward (100) = -29004.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7346: Reward = -35499.61, Avg Reward (100) = -29349.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7347: Reward = -35499.61, Avg Reward (100) = -29349.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7348: Reward = -35499.61, Avg Reward (100) = -29693.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7349: Reward = -35499.61, Avg Reward (100) = -30035.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7350: Reward = -35499.61, Avg Reward (100) = -30035.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7351: Reward = -1147.00, Avg Reward (100) = -30035.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7352: Reward = -49176.10, Avg Reward (100) = -29434.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7353: Reward = -31163.36, Avg Reward (100) = -29915.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31163.36, Border Penalty: -33115.60, Obstacle Penalty: -50.00
Episode 7354: Reward = -35499.61, Avg Reward (100) = -29872.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7355: Reward = -10868.79, Avg Reward (100) = -29872.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -10868.79, Border Penalty: -20727.79, Obstacle Penalty: -50.00
Episode 7356: Reward = -35499.61, Avg Reward (100) = -29502.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7357: Reward = -32851.49, Avg Reward (100) = -29502.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 7358: Reward = -35499.61, Avg Reward (100) = -29475.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7359: Reward = -35499.61, Avg Reward (100) = -29475.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7360: Reward = -35499.61, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7361: Reward = -35499.61, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7362: Reward = -51921.07, Avg Reward (100) = -29578.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51921.07, Border Penalty: -39998.94, Obstacle Penalty: -50.00
Episode 7363: Reward = -1147.00, Avg Reward (100) = -30087.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7364: Reward = -37669.33, Avg Reward (100) = -29620.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7365: Reward = -35499.61, Avg Reward (100) = -29642.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7366: Reward = -1000.00, Avg Reward (100) = -29642.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7367: Reward = -35499.61, Avg Reward (100) = -29297.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7368: Reward = -35499.61, Avg Reward (100) = -29329.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7369: Reward = -35499.61, Avg Reward (100) = -29329.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7370: Reward = -35499.61, Avg Reward (100) = -29329.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7371: Reward = -35499.61, Avg Reward (100) = -29329.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7372: Reward = -35499.61, Avg Reward (100) = -29671.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7373: Reward = -38432.03, Avg Reward (100) = -29630.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -38432.03, Border Penalty: -35963.06, Obstacle Penalty: -50.00
Episode 7374: Reward = -1098.00, Avg Reward (100) = -30003.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7375: Reward = -35499.61, Avg Reward (100) = -29659.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7376: Reward = -1147.00, Avg Reward (100) = -29727.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7377: Reward = -34833.52, Avg Reward (100) = -29727.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34833.52, Border Penalty: -32900.79, Obstacle Penalty: -50.00
Episode 7378: Reward = -35499.61, Avg Reward (100) = -30065.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7379: Reward = -35499.61, Avg Reward (100) = -30409.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7380: Reward = -35499.61, Avg Reward (100) = -30409.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7381: Reward = -35499.61, Avg Reward (100) = -30285.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7382: Reward = -35499.61, Avg Reward (100) = -30314.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7383: Reward = -1000.00, Avg Reward (100) = -30657.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7384: Reward = -35499.61, Avg Reward (100) = -30312.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7385: Reward = -35499.61, Avg Reward (100) = -30312.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7386: Reward = -35499.61, Avg Reward (100) = -30189.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7387: Reward = -1296.78, Avg Reward (100) = -30248.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7388: Reward = -29512.46, Avg Reward (100) = -29906.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7389: Reward = -49626.26, Avg Reward (100) = -29789.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 7390: Reward = -35499.61, Avg Reward (100) = -29959.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7391: Reward = -35499.61, Avg Reward (100) = -29959.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7392: Reward = -35499.61, Avg Reward (100) = -30303.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7393: Reward = -32245.59, Avg Reward (100) = -30323.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7394: Reward = -28653.56, Avg Reward (100) = -30291.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7395: Reward = -12446.80, Avg Reward (100) = -30566.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7396: Reward = -36089.25, Avg Reward (100) = -30336.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7397: Reward = -35499.61, Avg Reward (100) = -30342.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7398: Reward = -1394.00, Avg Reward (100) = -30321.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7399: Reward = -35499.61, Avg Reward (100) = -29980.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7400: Reward = -35499.61, Avg Reward (100) = -29998.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7401: Reward = -1000.00, Avg Reward (100) = -30006.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7402: Reward = -12446.80, Avg Reward (100) = -30006.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7403: Reward = -35499.61, Avg Reward (100) = -29805.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7404: Reward = -35499.61, Avg Reward (100) = -29805.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7405: Reward = -35499.61, Avg Reward (100) = -29805.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7406: Reward = -35499.61, Avg Reward (100) = -29805.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7407: Reward = -36089.25, Avg Reward (100) = -29727.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7408: Reward = -35499.61, Avg Reward (100) = -29733.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7409: Reward = -35499.61, Avg Reward (100) = -29801.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7410: Reward = -49626.26, Avg Reward (100) = -29801.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 7411: Reward = -35499.61, Avg Reward (100) = -30284.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7412: Reward = -35499.61, Avg Reward (100) = -30284.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7413: Reward = -12446.80, Avg Reward (100) = -30278.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7414: Reward = -33469.53, Avg Reward (100) = -29911.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7415: Reward = -35499.61, Avg Reward (100) = -29890.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7416: Reward = -49163.20, Avg Reward (100) = -29890.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49163.20, Border Penalty: -39837.59, Obstacle Penalty: -50.00
Episode 7417: Reward = -35499.61, Avg Reward (100) = -30027.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7418: Reward = -49176.10, Avg Reward (100) = -30035.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7419: Reward = -39606.20, Avg Reward (100) = -30172.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7420: Reward = -47848.55, Avg Reward (100) = -30213.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7421: Reward = -1000.00, Avg Reward (100) = -30221.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7422: Reward = -49176.10, Avg Reward (100) = -30218.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7423: Reward = -1295.00, Avg Reward (100) = -30373.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7424: Reward = -35499.61, Avg Reward (100) = -30031.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7425: Reward = -35499.61, Avg Reward (100) = -30031.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7426: Reward = -33469.53, Avg Reward (100) = -30031.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7427: Reward = -28683.61, Avg Reward (100) = -30011.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7428: Reward = -37799.90, Avg Reward (100) = -29942.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 7429: Reward = -35499.61, Avg Reward (100) = -29965.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7430: Reward = -35499.61, Avg Reward (100) = -30025.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7431: Reward = -29512.46, Avg Reward (100) = -30025.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7432: Reward = -1000.00, Avg Reward (100) = -29965.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7433: Reward = -35499.61, Avg Reward (100) = -29880.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7434: Reward = -35499.61, Avg Reward (100) = -29880.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7435: Reward = -29512.46, Avg Reward (100) = -30221.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7436: Reward = -1098.00, Avg Reward (100) = -30506.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7437: Reward = -1098.00, Avg Reward (100) = -30162.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7438: Reward = -12446.80, Avg Reward (100) = -29818.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7439: Reward = -28198.29, Avg Reward (100) = -29588.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 7440: Reward = -35499.61, Avg Reward (100) = -29536.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7441: Reward = -46242.48, Avg Reward (100) = -29536.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -36037.65, Obstacle Penalty: -50.00
Episode 7442: Reward = -35499.61, Avg Reward (100) = -29643.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7443: Reward = -35499.61, Avg Reward (100) = -29987.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7444: Reward = -12446.80, Avg Reward (100) = -30331.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7445: Reward = -9566.81, Avg Reward (100) = -30100.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 7446: Reward = -33701.04, Avg Reward (100) = -29841.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7447: Reward = -28882.62, Avg Reward (100) = -29823.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28882.62, Border Penalty: -32371.81, Obstacle Penalty: -50.00
Episode 7448: Reward = -35499.61, Avg Reward (100) = -29757.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7449: Reward = -28683.61, Avg Reward (100) = -29757.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7450: Reward = -51862.70, Avg Reward (100) = -29688.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -51862.70, Border Penalty: -41205.92, Obstacle Penalty: -50.00
Episode 7451: Reward = -1049.00, Avg Reward (100) = -29852.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7452: Reward = -35499.61, Avg Reward (100) = -29851.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7453: Reward = -33701.04, Avg Reward (100) = -29714.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7454: Reward = -35499.61, Avg Reward (100) = -29740.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7455: Reward = -35499.61, Avg Reward (100) = -29740.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7456: Reward = -35499.61, Avg Reward (100) = -29986.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7457: Reward = -29512.46, Avg Reward (100) = -29986.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7458: Reward = -25228.52, Avg Reward (100) = -29953.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7459: Reward = -28653.56, Avg Reward (100) = -29850.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7460: Reward = -35499.61, Avg Reward (100) = -29781.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7461: Reward = -35499.61, Avg Reward (100) = -29781.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7462: Reward = -49163.20, Avg Reward (100) = -29781.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49163.20, Border Penalty: -39837.59, Obstacle Penalty: -50.00
Episode 7463: Reward = -32619.61, Avg Reward (100) = -29754.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7464: Reward = -37669.33, Avg Reward (100) = -30069.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7465: Reward = -35499.61, Avg Reward (100) = -30069.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7466: Reward = -35499.61, Avg Reward (100) = -30069.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7467: Reward = -43263.20, Avg Reward (100) = -30414.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7468: Reward = -35499.61, Avg Reward (100) = -30491.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7469: Reward = -35499.61, Avg Reward (100) = -30491.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7470: Reward = -35499.61, Avg Reward (100) = -30491.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7471: Reward = -35499.61, Avg Reward (100) = -30491.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7472: Reward = -50413.96, Avg Reward (100) = -30491.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50413.96, Border Penalty: -38488.40, Obstacle Penalty: -50.00
Episode 7473: Reward = -35499.61, Avg Reward (100) = -30640.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7474: Reward = -35499.61, Avg Reward (100) = -30611.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7475: Reward = -28882.62, Avg Reward (100) = -30955.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28882.62, Border Penalty: -32371.81, Obstacle Penalty: -50.00
Episode 7476: Reward = -35499.61, Avg Reward (100) = -30889.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7477: Reward = -34685.86, Avg Reward (100) = -31232.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7478: Reward = -35499.61, Avg Reward (100) = -31231.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7479: Reward = -35499.61, Avg Reward (100) = -31231.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7480: Reward = -32619.61, Avg Reward (100) = -31231.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7481: Reward = -52585.18, Avg Reward (100) = -31202.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 7482: Reward = -1049.00, Avg Reward (100) = -31373.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7483: Reward = -36089.25, Avg Reward (100) = -31028.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7484: Reward = -1049.00, Avg Reward (100) = -31379.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7485: Reward = -35499.61, Avg Reward (100) = -31035.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7486: Reward = -12446.80, Avg Reward (100) = -31035.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7487: Reward = -1049.00, Avg Reward (100) = -30804.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7488: Reward = -25228.52, Avg Reward (100) = -30802.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7489: Reward = -35499.61, Avg Reward (100) = -30759.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7490: Reward = -1000.00, Avg Reward (100) = -30618.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7491: Reward = -1098.00, Avg Reward (100) = -30273.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7492: Reward = -44700.80, Avg Reward (100) = -29929.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -44700.80, Border Penalty: -38920.23, Obstacle Penalty: -50.00
Episode 7493: Reward = -12446.80, Avg Reward (100) = -30021.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7494: Reward = -35499.61, Avg Reward (100) = -29823.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7495: Reward = -35499.61, Avg Reward (100) = -29891.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7496: Reward = -1196.00, Avg Reward (100) = -30122.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7497: Reward = -39606.20, Avg Reward (100) = -29773.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7498: Reward = -37669.33, Avg Reward (100) = -29814.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7499: Reward = -35499.61, Avg Reward (100) = -30177.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7500: Reward = -1394.00, Avg Reward (100) = -30177.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 7501: Reward = -35499.61, Avg Reward (100) = -29836.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7502: Reward = -42112.30, Avg Reward (100) = -30181.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 7503: Reward = -35499.61, Avg Reward (100) = -30477.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7504: Reward = -35499.61, Avg Reward (100) = -30477.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7505: Reward = -35499.61, Avg Reward (100) = -30477.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7506: Reward = -35499.61, Avg Reward (100) = -30477.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7507: Reward = -1394.00, Avg Reward (100) = -30477.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7508: Reward = -1049.00, Avg Reward (100) = -30130.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7509: Reward = -1049.00, Avg Reward (100) = -29786.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7510: Reward = -35499.61, Avg Reward (100) = -29441.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7511: Reward = -29512.46, Avg Reward (100) = -29300.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7512: Reward = -35499.61, Avg Reward (100) = -29240.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7513: Reward = -35499.61, Avg Reward (100) = -29240.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7514: Reward = -35499.61, Avg Reward (100) = -29471.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7515: Reward = -25228.52, Avg Reward (100) = -29491.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7516: Reward = -35499.61, Avg Reward (100) = -29388.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7517: Reward = -32245.59, Avg Reward (100) = -29252.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7518: Reward = -35499.61, Avg Reward (100) = -29219.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7519: Reward = -35499.61, Avg Reward (100) = -29082.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7520: Reward = -35499.61, Avg Reward (100) = -29041.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7521: Reward = -35499.61, Avg Reward (100) = -28918.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7522: Reward = -35499.61, Avg Reward (100) = -29263.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7523: Reward = -1394.00, Avg Reward (100) = -29126.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7524: Reward = -35499.61, Avg Reward (100) = -29127.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7525: Reward = -43263.20, Avg Reward (100) = -29127.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7526: Reward = -35499.61, Avg Reward (100) = -29205.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7527: Reward = -1098.00, Avg Reward (100) = -29225.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7528: Reward = -35499.61, Avg Reward (100) = -28949.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7529: Reward = -35499.61, Avg Reward (100) = -28926.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7530: Reward = -35499.61, Avg Reward (100) = -28926.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7531: Reward = -35499.61, Avg Reward (100) = -28926.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7532: Reward = -35499.61, Avg Reward (100) = -28986.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7533: Reward = -1049.00, Avg Reward (100) = -29331.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7534: Reward = -35499.61, Avg Reward (100) = -28986.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7535: Reward = -1049.00, Avg Reward (100) = -28986.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7536: Reward = -35499.61, Avg Reward (100) = -28702.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7537: Reward = -35499.61, Avg Reward (100) = -29046.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7538: Reward = -27052.21, Avg Reward (100) = -29390.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27052.21, Border Penalty: -31213.36, Obstacle Penalty: -50.00
Episode 7539: Reward = -35499.61, Avg Reward (100) = -29536.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7540: Reward = -35499.61, Avg Reward (100) = -29609.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7541: Reward = -49626.26, Avg Reward (100) = -29609.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 7542: Reward = -46305.80, Avg Reward (100) = -29643.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46305.80, Border Penalty: -37626.48, Obstacle Penalty: -50.00
Episode 7543: Reward = -1196.00, Avg Reward (100) = -29751.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7544: Reward = -35499.61, Avg Reward (100) = -29408.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7545: Reward = -59127.30, Avg Reward (100) = -29638.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -59127.30, Border Penalty: -36104.90, Obstacle Penalty: -50.00
Episode 7546: Reward = -30790.88, Avg Reward (100) = -30134.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30790.88, Border Penalty: -32086.20, Obstacle Penalty: -50.00
Episode 7547: Reward = -32245.59, Avg Reward (100) = -30105.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7548: Reward = -1147.00, Avg Reward (100) = -30138.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7549: Reward = -28653.56, Avg Reward (100) = -29795.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7550: Reward = -1196.00, Avg Reward (100) = -29795.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7551: Reward = -28653.56, Avg Reward (100) = -29288.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7552: Reward = -29512.46, Avg Reward (100) = -29564.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7553: Reward = -35499.61, Avg Reward (100) = -29504.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7554: Reward = -1049.00, Avg Reward (100) = -29522.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7555: Reward = -34685.86, Avg Reward (100) = -29178.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7556: Reward = -35499.61, Avg Reward (100) = -29169.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7557: Reward = -35499.61, Avg Reward (100) = -29169.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7558: Reward = -35499.61, Avg Reward (100) = -29229.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7559: Reward = -1394.00, Avg Reward (100) = -29332.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7560: Reward = -1147.00, Avg Reward (100) = -29059.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7561: Reward = -35499.61, Avg Reward (100) = -28716.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7562: Reward = -53330.12, Avg Reward (100) = -28716.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -53330.12, Border Penalty: -41002.11, Obstacle Penalty: -50.00
Episode 7563: Reward = -35499.61, Avg Reward (100) = -28757.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7564: Reward = -35499.61, Avg Reward (100) = -28786.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7565: Reward = -35499.61, Avg Reward (100) = -28765.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7566: Reward = -35499.61, Avg Reward (100) = -28765.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7567: Reward = -47025.21, Avg Reward (100) = -28765.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 7568: Reward = -35499.61, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7569: Reward = -35499.61, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7570: Reward = -35499.61, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7571: Reward = -35499.61, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7572: Reward = -34685.86, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7573: Reward = -35499.61, Avg Reward (100) = -28645.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7574: Reward = -46653.19, Avg Reward (100) = -28645.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 7575: Reward = -35499.61, Avg Reward (100) = -28756.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7576: Reward = -1098.00, Avg Reward (100) = -28823.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7577: Reward = -35499.61, Avg Reward (100) = -28479.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7578: Reward = -35499.61, Avg Reward (100) = -28487.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7579: Reward = -25228.52, Avg Reward (100) = -28487.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7580: Reward = -35499.61, Avg Reward (100) = -28384.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7581: Reward = -35499.61, Avg Reward (100) = -28413.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7582: Reward = -39135.41, Avg Reward (100) = -28242.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36287.33, Obstacle Penalty: -50.00
Episode 7583: Reward = -35499.61, Avg Reward (100) = -28623.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7584: Reward = -35499.61, Avg Reward (100) = -28617.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7585: Reward = -25228.52, Avg Reward (100) = -28961.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7586: Reward = -35499.61, Avg Reward (100) = -28859.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7587: Reward = -35499.61, Avg Reward (100) = -29089.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7588: Reward = -34685.86, Avg Reward (100) = -29434.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7589: Reward = -35499.61, Avg Reward (100) = -29528.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7590: Reward = -35499.61, Avg Reward (100) = -29528.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7591: Reward = -35499.61, Avg Reward (100) = -29873.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7592: Reward = -33701.04, Avg Reward (100) = -30217.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7593: Reward = -35499.61, Avg Reward (100) = -30107.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7594: Reward = -32245.59, Avg Reward (100) = -30338.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7595: Reward = -35499.61, Avg Reward (100) = -30305.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7596: Reward = -1147.00, Avg Reward (100) = -30305.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7597: Reward = -1196.00, Avg Reward (100) = -30305.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7598: Reward = -35499.61, Avg Reward (100) = -29921.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7599: Reward = -35499.61, Avg Reward (100) = -29899.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7600: Reward = -35499.61, Avg Reward (100) = -29899.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7601: Reward = -35499.61, Avg Reward (100) = -30240.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7602: Reward = -49929.11, Avg Reward (100) = -30240.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49929.11, Border Penalty: -40385.74, Obstacle Penalty: -50.00
Episode 7603: Reward = -35499.61, Avg Reward (100) = -30318.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7604: Reward = -35499.61, Avg Reward (100) = -30318.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7605: Reward = -33701.04, Avg Reward (100) = -30318.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7606: Reward = -35499.61, Avg Reward (100) = -30300.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7607: Reward = -35499.61, Avg Reward (100) = -30300.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7608: Reward = -35499.61, Avg Reward (100) = -30641.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7609: Reward = -32245.59, Avg Reward (100) = -30986.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7610: Reward = -35499.61, Avg Reward (100) = -31298.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7611: Reward = -35499.61, Avg Reward (100) = -31298.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7612: Reward = -47848.55, Avg Reward (100) = -31358.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7613: Reward = -35499.61, Avg Reward (100) = -31481.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7614: Reward = -35499.61, Avg Reward (100) = -31481.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7615: Reward = -1049.00, Avg Reward (100) = -31481.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7616: Reward = -28653.56, Avg Reward (100) = -31239.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7617: Reward = -32619.61, Avg Reward (100) = -31171.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7618: Reward = -35499.61, Avg Reward (100) = -31175.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7619: Reward = -49626.26, Avg Reward (100) = -31175.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 7620: Reward = -1295.00, Avg Reward (100) = -31316.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7621: Reward = -25228.52, Avg Reward (100) = -30974.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7622: Reward = -35499.61, Avg Reward (100) = -30871.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7623: Reward = -35499.61, Avg Reward (100) = -30871.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7624: Reward = -35499.61, Avg Reward (100) = -31212.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7625: Reward = -35499.61, Avg Reward (100) = -31212.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7626: Reward = -35499.61, Avg Reward (100) = -31135.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7627: Reward = -35499.61, Avg Reward (100) = -31135.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7628: Reward = -35499.61, Avg Reward (100) = -31479.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7629: Reward = -35499.61, Avg Reward (100) = -31479.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7630: Reward = -1196.00, Avg Reward (100) = -31479.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7631: Reward = -35499.61, Avg Reward (100) = -31136.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7632: Reward = -1000.00, Avg Reward (100) = -31136.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7633: Reward = -1394.00, Avg Reward (100) = -30791.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7634: Reward = -1295.00, Avg Reward (100) = -30794.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7635: Reward = -35499.61, Avg Reward (100) = -30452.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7636: Reward = -35499.61, Avg Reward (100) = -30797.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7637: Reward = -25228.52, Avg Reward (100) = -30797.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7638: Reward = -28683.61, Avg Reward (100) = -30694.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7639: Reward = -35499.61, Avg Reward (100) = -30710.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7640: Reward = -31431.83, Avg Reward (100) = -30710.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -31431.83, Border Penalty: -32525.72, Obstacle Penalty: -50.00
Episode 7641: Reward = -35499.61, Avg Reward (100) = -30669.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7642: Reward = -35499.61, Avg Reward (100) = -30528.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7643: Reward = -35499.61, Avg Reward (100) = -30420.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7644: Reward = -30151.96, Avg Reward (100) = -30763.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30151.96, Border Penalty: -33060.24, Obstacle Penalty: -50.00
Episode 7645: Reward = -1196.00, Avg Reward (100) = -30710.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7646: Reward = -29512.46, Avg Reward (100) = -30130.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7647: Reward = -36004.66, Avg Reward (100) = -30118.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 7648: Reward = -1098.00, Avg Reward (100) = -30155.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7649: Reward = -35499.61, Avg Reward (100) = -30155.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7650: Reward = -35499.61, Avg Reward (100) = -30223.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7651: Reward = -35499.61, Avg Reward (100) = -30566.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7652: Reward = -35499.61, Avg Reward (100) = -30635.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7653: Reward = -35499.61, Avg Reward (100) = -30695.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7654: Reward = -35499.61, Avg Reward (100) = -30695.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7655: Reward = -35499.61, Avg Reward (100) = -31039.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7656: Reward = -35499.61, Avg Reward (100) = -31047.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7657: Reward = -27492.00, Avg Reward (100) = -31047.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 7658: Reward = -35499.61, Avg Reward (100) = -30967.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7659: Reward = -1000.00, Avg Reward (100) = -30967.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7660: Reward = -37669.33, Avg Reward (100) = -30963.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7661: Reward = -1098.00, Avg Reward (100) = -31328.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7662: Reward = -35499.61, Avg Reward (100) = -30984.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7663: Reward = -35499.61, Avg Reward (100) = -30806.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7664: Reward = -35499.61, Avg Reward (100) = -30806.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7665: Reward = -35499.61, Avg Reward (100) = -30806.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7666: Reward = -1147.00, Avg Reward (100) = -30806.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7667: Reward = -1196.00, Avg Reward (100) = -30463.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7668: Reward = -35499.61, Avg Reward (100) = -30004.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7669: Reward = -29879.41, Avg Reward (100) = -30004.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -29879.41, Border Penalty: -30090.09, Obstacle Penalty: -50.00
Episode 7670: Reward = -35499.61, Avg Reward (100) = -29948.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7671: Reward = -35499.61, Avg Reward (100) = -29948.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7672: Reward = -35499.61, Avg Reward (100) = -29948.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7673: Reward = -35499.61, Avg Reward (100) = -29956.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7674: Reward = -41554.36, Avg Reward (100) = -29956.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 7675: Reward = -28653.56, Avg Reward (100) = -29905.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7676: Reward = -1098.00, Avg Reward (100) = -29837.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7677: Reward = -36089.25, Avg Reward (100) = -29837.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7678: Reward = -1098.00, Avg Reward (100) = -29843.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7679: Reward = -35499.61, Avg Reward (100) = -29499.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7680: Reward = -29512.46, Avg Reward (100) = -29601.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7681: Reward = -32619.61, Avg Reward (100) = -29541.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7682: Reward = -29512.46, Avg Reward (100) = -29513.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7683: Reward = -35499.61, Avg Reward (100) = -29416.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7684: Reward = -35499.61, Avg Reward (100) = -29416.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7685: Reward = -36089.25, Avg Reward (100) = -29416.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 7686: Reward = -35499.61, Avg Reward (100) = -29525.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7687: Reward = -35499.61, Avg Reward (100) = -29525.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7688: Reward = -35499.61, Avg Reward (100) = -29525.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7689: Reward = -35499.61, Avg Reward (100) = -29533.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7690: Reward = -54036.93, Avg Reward (100) = -29533.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 7691: Reward = -33469.53, Avg Reward (100) = -29719.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7692: Reward = -50498.83, Avg Reward (100) = -29698.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50498.83, Border Penalty: -40565.62, Obstacle Penalty: -50.00
Episode 7693: Reward = -35499.61, Avg Reward (100) = -29866.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7694: Reward = -26061.91, Avg Reward (100) = -29866.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26061.91, Border Penalty: -30748.40, Obstacle Penalty: -50.00
Episode 7695: Reward = -35499.61, Avg Reward (100) = -29804.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7696: Reward = -1196.00, Avg Reward (100) = -29804.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7697: Reward = -59176.41, Avg Reward (100) = -29805.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -34852.61, Obstacle Penalty: -50.00
Episode 7698: Reward = -45485.92, Avg Reward (100) = -30385.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38982.36, Obstacle Penalty: -50.00
Episode 7699: Reward = -49176.10, Avg Reward (100) = -30485.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7700: Reward = -35499.61, Avg Reward (100) = -30621.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7701: Reward = -38636.47, Avg Reward (100) = -30621.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 7702: Reward = -50968.57, Avg Reward (100) = -30653.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -40121.91, Obstacle Penalty: -50.00
Episode 7703: Reward = -35499.61, Avg Reward (100) = -30663.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7704: Reward = -37799.90, Avg Reward (100) = -30663.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 7705: Reward = -39606.20, Avg Reward (100) = -30686.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7706: Reward = -35499.61, Avg Reward (100) = -30745.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7707: Reward = -35499.61, Avg Reward (100) = -30745.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7708: Reward = -28427.60, Avg Reward (100) = -30745.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28427.60, Border Penalty: -30641.62, Obstacle Penalty: -50.00
Episode 7709: Reward = -1147.00, Avg Reward (100) = -30674.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7710: Reward = -35499.61, Avg Reward (100) = -30363.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7711: Reward = -35499.61, Avg Reward (100) = -30363.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7712: Reward = -1049.00, Avg Reward (100) = -30363.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7713: Reward = -35499.61, Avg Reward (100) = -29895.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7714: Reward = -35499.61, Avg Reward (100) = -29895.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7715: Reward = -1394.00, Avg Reward (100) = -29895.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7716: Reward = -35499.61, Avg Reward (100) = -29899.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7717: Reward = -1394.00, Avg Reward (100) = -29967.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 7718: Reward = -35499.61, Avg Reward (100) = -29655.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7719: Reward = -35499.61, Avg Reward (100) = -29655.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7720: Reward = -1000.00, Avg Reward (100) = -29514.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7721: Reward = -35499.61, Avg Reward (100) = -29511.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7722: Reward = -35499.61, Avg Reward (100) = -29614.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7723: Reward = -35499.61, Avg Reward (100) = -29614.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7724: Reward = -35499.61, Avg Reward (100) = -29614.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7725: Reward = -49176.10, Avg Reward (100) = -29614.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7726: Reward = -33469.53, Avg Reward (100) = -29750.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7727: Reward = -35499.61, Avg Reward (100) = -29730.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7728: Reward = -43606.34, Avg Reward (100) = -29730.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43606.34, Border Penalty: -34347.32, Obstacle Penalty: -50.00
Episode 7729: Reward = -35499.61, Avg Reward (100) = -29811.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7730: Reward = -35499.61, Avg Reward (100) = -29811.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7731: Reward = -35499.61, Avg Reward (100) = -30154.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7732: Reward = -35499.61, Avg Reward (100) = -30154.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7733: Reward = -1295.00, Avg Reward (100) = -30499.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7734: Reward = -35499.61, Avg Reward (100) = -30498.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7735: Reward = -35499.61, Avg Reward (100) = -30840.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7736: Reward = -36089.25, Avg Reward (100) = -30840.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 7737: Reward = -35499.61, Avg Reward (100) = -30846.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7738: Reward = -35499.61, Avg Reward (100) = -30949.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7739: Reward = -28683.61, Avg Reward (100) = -31017.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7740: Reward = -1196.00, Avg Reward (100) = -30949.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7741: Reward = -35499.61, Avg Reward (100) = -30646.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7742: Reward = -35499.61, Avg Reward (100) = -30646.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7743: Reward = -35499.61, Avg Reward (100) = -30646.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7744: Reward = -35499.61, Avg Reward (100) = -30646.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7745: Reward = -32619.61, Avg Reward (100) = -30700.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7746: Reward = -35499.61, Avg Reward (100) = -31014.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7747: Reward = -37669.33, Avg Reward (100) = -31074.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7748: Reward = -12446.80, Avg Reward (100) = -31091.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 7749: Reward = -35499.61, Avg Reward (100) = -31204.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7750: Reward = -35499.61, Avg Reward (100) = -31204.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7751: Reward = -1147.00, Avg Reward (100) = -31204.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7752: Reward = -35499.61, Avg Reward (100) = -30861.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7753: Reward = -35499.61, Avg Reward (100) = -30861.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7754: Reward = -1147.00, Avg Reward (100) = -30861.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7755: Reward = -35499.61, Avg Reward (100) = -30517.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7756: Reward = -29512.46, Avg Reward (100) = -30517.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7757: Reward = -35499.61, Avg Reward (100) = -30457.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7758: Reward = -35499.61, Avg Reward (100) = -30537.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7759: Reward = -35499.61, Avg Reward (100) = -30537.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7760: Reward = -35499.61, Avg Reward (100) = -30882.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7761: Reward = -35499.61, Avg Reward (100) = -30861.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7762: Reward = -35499.61, Avg Reward (100) = -31205.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7763: Reward = -35499.61, Avg Reward (100) = -31205.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7764: Reward = -1394.00, Avg Reward (100) = -31205.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7765: Reward = -1000.00, Avg Reward (100) = -30864.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7766: Reward = -35499.61, Avg Reward (100) = -30519.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7767: Reward = -1394.00, Avg Reward (100) = -30862.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7768: Reward = -34685.86, Avg Reward (100) = -30864.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 7769: Reward = -34685.86, Avg Reward (100) = -30856.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7770: Reward = -28683.61, Avg Reward (100) = -30904.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7771: Reward = -28653.56, Avg Reward (100) = -30836.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7772: Reward = -35499.61, Avg Reward (100) = -30767.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7773: Reward = -1000.00, Avg Reward (100) = -30767.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7774: Reward = -35499.61, Avg Reward (100) = -30422.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7775: Reward = -1394.00, Avg Reward (100) = -30362.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7776: Reward = -35499.61, Avg Reward (100) = -30089.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7777: Reward = -1196.00, Avg Reward (100) = -30433.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7778: Reward = -29512.46, Avg Reward (100) = -30084.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7779: Reward = -37669.33, Avg Reward (100) = -30368.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -33463.03, Obstacle Penalty: -50.00
Episode 7780: Reward = -35499.61, Avg Reward (100) = -30390.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7781: Reward = -29512.46, Avg Reward (100) = -30450.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 7782: Reward = -35499.61, Avg Reward (100) = -30419.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7783: Reward = -1098.00, Avg Reward (100) = -30479.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7784: Reward = -35499.61, Avg Reward (100) = -30135.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7785: Reward = -49176.10, Avg Reward (100) = -30135.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7786: Reward = -33701.04, Avg Reward (100) = -30266.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7787: Reward = -35499.61, Avg Reward (100) = -30248.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7788: Reward = -1049.00, Avg Reward (100) = -30248.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7789: Reward = -37669.33, Avg Reward (100) = -29903.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7790: Reward = -1394.00, Avg Reward (100) = -29925.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7791: Reward = -1049.00, Avg Reward (100) = -29398.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7792: Reward = -33701.04, Avg Reward (100) = -29074.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7793: Reward = -35499.61, Avg Reward (100) = -28906.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7794: Reward = -35499.61, Avg Reward (100) = -28906.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7795: Reward = -47848.55, Avg Reward (100) = -29001.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 7796: Reward = -35499.61, Avg Reward (100) = -29124.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7797: Reward = -35499.61, Avg Reward (100) = -29467.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7798: Reward = -35499.61, Avg Reward (100) = -29230.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7799: Reward = -35499.61, Avg Reward (100) = -29131.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7800: Reward = -1295.00, Avg Reward (100) = -28994.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7801: Reward = -28683.61, Avg Reward (100) = -28652.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7802: Reward = -33469.53, Avg Reward (100) = -28552.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7803: Reward = -39606.20, Avg Reward (100) = -28377.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7804: Reward = -35499.61, Avg Reward (100) = -28418.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7805: Reward = -35499.61, Avg Reward (100) = -28395.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7806: Reward = -35499.61, Avg Reward (100) = -28354.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7807: Reward = -35499.61, Avg Reward (100) = -28354.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7808: Reward = -35499.61, Avg Reward (100) = -28354.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7809: Reward = -35499.61, Avg Reward (100) = -28425.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7810: Reward = -1000.00, Avg Reward (100) = -28768.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7811: Reward = -28653.56, Avg Reward (100) = -28423.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 7812: Reward = -35499.61, Avg Reward (100) = -28355.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7813: Reward = -1098.00, Avg Reward (100) = -28699.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7814: Reward = -35499.61, Avg Reward (100) = -28355.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7815: Reward = -1000.00, Avg Reward (100) = -28355.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7816: Reward = -1049.00, Avg Reward (100) = -28352.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7817: Reward = -35499.61, Avg Reward (100) = -28007.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7818: Reward = -35499.61, Avg Reward (100) = -28348.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7819: Reward = -35499.61, Avg Reward (100) = -28348.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7820: Reward = -35499.61, Avg Reward (100) = -28348.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7821: Reward = -34685.86, Avg Reward (100) = -28693.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7822: Reward = -35499.61, Avg Reward (100) = -28685.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7823: Reward = -49176.10, Avg Reward (100) = -28685.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7824: Reward = -35499.61, Avg Reward (100) = -28822.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7825: Reward = -35499.61, Avg Reward (100) = -28822.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7826: Reward = -35499.61, Avg Reward (100) = -28685.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7827: Reward = -25228.52, Avg Reward (100) = -28705.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7828: Reward = -1450.40, Avg Reward (100) = -28603.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 7829: Reward = -35499.61, Avg Reward (100) = -28181.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7830: Reward = -35499.61, Avg Reward (100) = -28181.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7831: Reward = -35499.61, Avg Reward (100) = -28181.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7832: Reward = -1000.00, Avg Reward (100) = -28181.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7833: Reward = -34685.86, Avg Reward (100) = -27836.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7834: Reward = -1049.00, Avg Reward (100) = -28170.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7835: Reward = -33469.53, Avg Reward (100) = -27825.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -31745.04, Obstacle Penalty: -50.00
Episode 7836: Reward = -35499.61, Avg Reward (100) = -27805.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7837: Reward = -1049.00, Avg Reward (100) = -27799.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7838: Reward = -35499.61, Avg Reward (100) = -27455.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7839: Reward = -35499.61, Avg Reward (100) = -27455.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7840: Reward = -35499.61, Avg Reward (100) = -27523.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7841: Reward = -35499.61, Avg Reward (100) = -27866.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7842: Reward = -25228.52, Avg Reward (100) = -27866.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7843: Reward = -34685.86, Avg Reward (100) = -27763.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7844: Reward = -35499.61, Avg Reward (100) = -27755.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7845: Reward = -1394.00, Avg Reward (100) = -27755.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7846: Reward = -1000.00, Avg Reward (100) = -27443.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7847: Reward = -35499.61, Avg Reward (100) = -27098.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7848: Reward = -1394.00, Avg Reward (100) = -27076.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7849: Reward = -37254.99, Avg Reward (100) = -26966.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37254.99, Border Penalty: -34365.02, Obstacle Penalty: -50.00
Episode 7850: Reward = -35499.61, Avg Reward (100) = -26983.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7851: Reward = -35499.61, Avg Reward (100) = -26983.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7852: Reward = -35499.61, Avg Reward (100) = -27327.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7853: Reward = -35499.61, Avg Reward (100) = -27327.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7854: Reward = -1049.00, Avg Reward (100) = -27327.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7855: Reward = -33701.04, Avg Reward (100) = -27326.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7856: Reward = -35499.61, Avg Reward (100) = -27308.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7857: Reward = -33701.04, Avg Reward (100) = -27368.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 7858: Reward = -28683.61, Avg Reward (100) = -27350.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 7859: Reward = -35499.61, Avg Reward (100) = -27281.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7860: Reward = -35499.61, Avg Reward (100) = -27281.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7861: Reward = -36022.43, Avg Reward (100) = -27281.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 7862: Reward = -35499.61, Avg Reward (100) = -27287.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7863: Reward = -49626.26, Avg Reward (100) = -27287.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 7864: Reward = -35499.61, Avg Reward (100) = -27428.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7865: Reward = -35499.61, Avg Reward (100) = -27769.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7866: Reward = -35499.61, Avg Reward (100) = -28114.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7867: Reward = -1098.00, Avg Reward (100) = -28114.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7868: Reward = -35499.61, Avg Reward (100) = -28111.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7869: Reward = -1147.00, Avg Reward (100) = -28119.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7870: Reward = -1196.00, Avg Reward (100) = -27784.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7871: Reward = -39606.20, Avg Reward (100) = -27509.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7872: Reward = -35499.61, Avg Reward (100) = -27618.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7873: Reward = -39606.20, Avg Reward (100) = -27618.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 7874: Reward = -34982.32, Avg Reward (100) = -28004.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34982.32, Border Penalty: -33449.43, Obstacle Penalty: -50.00
Episode 7875: Reward = -43263.20, Avg Reward (100) = -27999.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7876: Reward = -35499.61, Avg Reward (100) = -28418.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7877: Reward = -33469.53, Avg Reward (100) = -28418.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7878: Reward = -1098.00, Avg Reward (100) = -28741.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7879: Reward = -35499.61, Avg Reward (100) = -28457.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7880: Reward = -35499.61, Avg Reward (100) = -28435.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7881: Reward = -35499.61, Avg Reward (100) = -28435.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7882: Reward = -35499.61, Avg Reward (100) = -28495.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7883: Reward = -35499.61, Avg Reward (100) = -28495.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7884: Reward = -1147.00, Avg Reward (100) = -28839.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7885: Reward = -35499.61, Avg Reward (100) = -28495.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7886: Reward = -35499.61, Avg Reward (100) = -28358.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7887: Reward = -35499.61, Avg Reward (100) = -28376.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7888: Reward = -35499.61, Avg Reward (100) = -28376.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7889: Reward = -32245.59, Avg Reward (100) = -28721.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7890: Reward = -35499.61, Avg Reward (100) = -28667.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7891: Reward = -35499.61, Avg Reward (100) = -29008.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7892: Reward = -35499.61, Avg Reward (100) = -29352.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7893: Reward = -1295.00, Avg Reward (100) = -29370.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7894: Reward = -35499.61, Avg Reward (100) = -29028.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7895: Reward = -35499.61, Avg Reward (100) = -29028.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7896: Reward = -35499.61, Avg Reward (100) = -28905.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7897: Reward = -1295.00, Avg Reward (100) = -28905.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7898: Reward = -35499.61, Avg Reward (100) = -28563.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7899: Reward = -1000.00, Avg Reward (100) = -28563.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7900: Reward = -35499.61, Avg Reward (100) = -28218.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7901: Reward = -35499.61, Avg Reward (100) = -28560.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7902: Reward = -35499.61, Avg Reward (100) = -28628.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7903: Reward = -1098.00, Avg Reward (100) = -28648.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7904: Reward = -49176.10, Avg Reward (100) = -28263.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7905: Reward = -35499.61, Avg Reward (100) = -28400.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7906: Reward = -33469.53, Avg Reward (100) = -28400.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7907: Reward = -35499.61, Avg Reward (100) = -28380.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7908: Reward = -25228.52, Avg Reward (100) = -28380.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7909: Reward = -35499.61, Avg Reward (100) = -28277.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7910: Reward = -32245.59, Avg Reward (100) = -28277.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7911: Reward = -35499.61, Avg Reward (100) = -28589.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7912: Reward = -35499.61, Avg Reward (100) = -28658.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7913: Reward = -35499.61, Avg Reward (100) = -28658.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7914: Reward = -35499.61, Avg Reward (100) = -29002.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7915: Reward = -35499.61, Avg Reward (100) = -29002.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7916: Reward = -35499.61, Avg Reward (100) = -29347.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7917: Reward = -35499.61, Avg Reward (100) = -29691.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7918: Reward = -35499.61, Avg Reward (100) = -29691.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7919: Reward = -35499.61, Avg Reward (100) = -29691.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7920: Reward = -37669.33, Avg Reward (100) = -29691.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7921: Reward = -35499.61, Avg Reward (100) = -29713.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7922: Reward = -1000.00, Avg Reward (100) = -29721.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7923: Reward = -35499.61, Avg Reward (100) = -29376.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7924: Reward = -35499.61, Avg Reward (100) = -29239.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7925: Reward = -35499.61, Avg Reward (100) = -29239.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7926: Reward = -35499.61, Avg Reward (100) = -29239.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7927: Reward = -49176.10, Avg Reward (100) = -29239.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7928: Reward = -35499.61, Avg Reward (100) = -29479.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7929: Reward = -35499.61, Avg Reward (100) = -29819.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7930: Reward = -43263.20, Avg Reward (100) = -29819.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7931: Reward = -35499.61, Avg Reward (100) = -29897.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7932: Reward = -1049.00, Avg Reward (100) = -29897.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7933: Reward = -34685.86, Avg Reward (100) = -29897.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7934: Reward = -35499.61, Avg Reward (100) = -29897.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7935: Reward = -35499.61, Avg Reward (100) = -30242.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7936: Reward = -35499.61, Avg Reward (100) = -30262.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7937: Reward = -36089.25, Avg Reward (100) = -30262.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 7938: Reward = -34685.86, Avg Reward (100) = -30613.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7939: Reward = -35499.61, Avg Reward (100) = -30605.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7940: Reward = -35499.61, Avg Reward (100) = -30605.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7941: Reward = -35499.61, Avg Reward (100) = -30605.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7942: Reward = -49176.10, Avg Reward (100) = -30605.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 7943: Reward = -59176.41, Avg Reward (100) = -30844.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -34852.61, Obstacle Penalty: -50.00
Episode 7944: Reward = -35499.61, Avg Reward (100) = -31089.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7945: Reward = -35499.61, Avg Reward (100) = -31089.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7946: Reward = -35499.61, Avg Reward (100) = -31430.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7947: Reward = -35499.61, Avg Reward (100) = -31775.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7948: Reward = -35499.61, Avg Reward (100) = -31775.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7949: Reward = -43263.20, Avg Reward (100) = -32116.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7950: Reward = -32245.59, Avg Reward (100) = -32176.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7951: Reward = -1394.00, Avg Reward (100) = -32144.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7952: Reward = -32245.59, Avg Reward (100) = -31803.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 7953: Reward = -1196.00, Avg Reward (100) = -31770.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 7954: Reward = -56903.56, Avg Reward (100) = -31427.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -56903.56, Border Penalty: -34894.96, Obstacle Penalty: -50.00
Episode 7955: Reward = -35499.61, Avg Reward (100) = -31985.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7956: Reward = -1098.00, Avg Reward (100) = -32003.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7957: Reward = -1295.00, Avg Reward (100) = -31659.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 7958: Reward = -1098.00, Avg Reward (100) = -31335.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7959: Reward = -1049.00, Avg Reward (100) = -31060.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7960: Reward = -25228.52, Avg Reward (100) = -30715.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7961: Reward = -25228.52, Avg Reward (100) = -30612.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 7962: Reward = -35499.61, Avg Reward (100) = -30504.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7963: Reward = -1394.00, Avg Reward (100) = -30504.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 7964: Reward = -49626.26, Avg Reward (100) = -30022.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 7965: Reward = -35499.61, Avg Reward (100) = -30163.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7966: Reward = -35499.61, Avg Reward (100) = -30163.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7967: Reward = -49176.10, Avg Reward (100) = -30163.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -37163.81, Obstacle Penalty: -50.00
Episode 7968: Reward = -35499.61, Avg Reward (100) = -30644.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7969: Reward = -32245.59, Avg Reward (100) = -30644.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7970: Reward = -33469.53, Avg Reward (100) = -30955.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 7971: Reward = -34685.86, Avg Reward (100) = -31278.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 7972: Reward = -32245.59, Avg Reward (100) = -31229.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 7973: Reward = -35499.61, Avg Reward (100) = -31196.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7974: Reward = -35499.61, Avg Reward (100) = -31155.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 7975: Reward = -35499.61, Avg Reward (100) = -31160.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 7976: Reward = -35499.61, Avg Reward (100) = -31083.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7977: Reward = -1049.00, Avg Reward (100) = -31083.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7978: Reward = -35499.61, Avg Reward (100) = -30758.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7979: Reward = -37669.33, Avg Reward (100) = -31102.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 7980: Reward = -35499.61, Avg Reward (100) = -31124.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7981: Reward = -1147.00, Avg Reward (100) = -31124.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7982: Reward = -35499.61, Avg Reward (100) = -30781.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7983: Reward = -41280.90, Avg Reward (100) = -30781.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 7984: Reward = -43263.20, Avg Reward (100) = -30838.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 7985: Reward = -35499.61, Avg Reward (100) = -31259.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7986: Reward = -35499.61, Avg Reward (100) = -31259.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7987: Reward = -41554.36, Avg Reward (100) = -31259.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 7988: Reward = -35499.61, Avg Reward (100) = -31320.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7989: Reward = -1049.00, Avg Reward (100) = -31320.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7990: Reward = -42651.70, Avg Reward (100) = -31008.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -37572.03, Obstacle Penalty: -50.00
Episode 7991: Reward = -1000.00, Avg Reward (100) = -31080.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7992: Reward = -35499.61, Avg Reward (100) = -30735.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7993: Reward = -35499.61, Avg Reward (100) = -30735.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7994: Reward = -1049.00, Avg Reward (100) = -31077.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7995: Reward = -35499.61, Avg Reward (100) = -30732.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7996: Reward = -1049.00, Avg Reward (100) = -30732.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7997: Reward = -35499.61, Avg Reward (100) = -30388.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 7998: Reward = -1147.00, Avg Reward (100) = -30730.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 7999: Reward = -35499.61, Avg Reward (100) = -30386.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8000: Reward = -35499.61, Avg Reward (100) = -30731.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8001: Reward = -35499.61, Avg Reward (100) = -30731.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8002: Reward = -28683.61, Avg Reward (100) = -30731.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8003: Reward = -32245.59, Avg Reward (100) = -30663.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8004: Reward = -35499.61, Avg Reward (100) = -30974.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8005: Reward = -51399.59, Avg Reward (100) = -30838.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51399.59, Border Penalty: -38028.67, Obstacle Penalty: -50.00
Episode 8006: Reward = -35499.61, Avg Reward (100) = -30997.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8007: Reward = -25228.52, Avg Reward (100) = -31017.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8008: Reward = -32619.61, Avg Reward (100) = -30914.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8009: Reward = -35499.61, Avg Reward (100) = -30988.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8010: Reward = -35499.61, Avg Reward (100) = -30988.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8011: Reward = -28683.61, Avg Reward (100) = -31021.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8012: Reward = -35499.61, Avg Reward (100) = -30953.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8013: Reward = -37669.33, Avg Reward (100) = -30953.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8014: Reward = -1450.40, Avg Reward (100) = -30974.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 8015: Reward = -55917.21, Avg Reward (100) = -30634.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 8016: Reward = -49626.26, Avg Reward (100) = -30838.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8017: Reward = -35499.61, Avg Reward (100) = -30979.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8018: Reward = -35499.61, Avg Reward (100) = -30979.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8019: Reward = -35499.61, Avg Reward (100) = -30979.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8020: Reward = -43263.20, Avg Reward (100) = -30979.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8021: Reward = -1098.00, Avg Reward (100) = -31035.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8022: Reward = -28653.56, Avg Reward (100) = -30691.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8023: Reward = -35499.61, Avg Reward (100) = -30968.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8024: Reward = -1394.00, Avg Reward (100) = -30968.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8025: Reward = -1049.00, Avg Reward (100) = -30627.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8026: Reward = -35499.61, Avg Reward (100) = -30282.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8027: Reward = -35499.61, Avg Reward (100) = -30282.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8028: Reward = -43263.20, Avg Reward (100) = -30145.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8029: Reward = -30447.02, Avg Reward (100) = -30223.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -32385.11, Obstacle Penalty: -50.00
Episode 8030: Reward = -28653.56, Avg Reward (100) = -30172.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8031: Reward = -36089.25, Avg Reward (100) = -30026.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8032: Reward = -35499.61, Avg Reward (100) = -30032.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8033: Reward = -39606.20, Avg Reward (100) = -30377.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8034: Reward = -35499.61, Avg Reward (100) = -30426.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8035: Reward = -1098.00, Avg Reward (100) = -30426.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8036: Reward = -46653.19, Avg Reward (100) = -30082.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 8037: Reward = -32245.59, Avg Reward (100) = -30194.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8038: Reward = -35499.61, Avg Reward (100) = -30155.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8039: Reward = -28653.56, Avg Reward (100) = -30163.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8040: Reward = -1295.00, Avg Reward (100) = -30095.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8041: Reward = -38636.47, Avg Reward (100) = -29753.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 8042: Reward = -49176.10, Avg Reward (100) = -29784.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8043: Reward = -39606.20, Avg Reward (100) = -29784.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8044: Reward = -35499.61, Avg Reward (100) = -29588.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8045: Reward = -32619.61, Avg Reward (100) = -29588.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8046: Reward = -39606.20, Avg Reward (100) = -29560.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8047: Reward = -35499.61, Avg Reward (100) = -29601.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8048: Reward = -35499.61, Avg Reward (100) = -29601.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8049: Reward = -58564.79, Avg Reward (100) = -29601.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 8050: Reward = -1196.00, Avg Reward (100) = -29754.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8051: Reward = -35499.61, Avg Reward (100) = -29443.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8052: Reward = -49176.10, Avg Reward (100) = -29784.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8053: Reward = -35499.61, Avg Reward (100) = -29954.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8054: Reward = -1147.00, Avg Reward (100) = -30297.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8055: Reward = -41280.90, Avg Reward (100) = -29739.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 8056: Reward = -1000.00, Avg Reward (100) = -29797.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8057: Reward = -35499.61, Avg Reward (100) = -29796.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8058: Reward = -35499.61, Avg Reward (100) = -30138.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8059: Reward = -43263.20, Avg Reward (100) = -30482.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8060: Reward = -1000.00, Avg Reward (100) = -30904.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8061: Reward = -35499.61, Avg Reward (100) = -30662.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8062: Reward = -35499.61, Avg Reward (100) = -30764.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8063: Reward = -35499.61, Avg Reward (100) = -30764.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8064: Reward = -35499.61, Avg Reward (100) = -31106.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8065: Reward = -28683.61, Avg Reward (100) = -30964.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8066: Reward = -35499.61, Avg Reward (100) = -30896.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8067: Reward = -1394.00, Avg Reward (100) = -30896.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8068: Reward = -12446.80, Avg Reward (100) = -30418.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8069: Reward = -35499.61, Avg Reward (100) = -30188.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8070: Reward = -35499.61, Avg Reward (100) = -30220.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8071: Reward = -35499.61, Avg Reward (100) = -30241.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8072: Reward = -35499.61, Avg Reward (100) = -30249.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8073: Reward = -35499.61, Avg Reward (100) = -30281.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8074: Reward = -35499.61, Avg Reward (100) = -30281.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8075: Reward = -1294.00, Avg Reward (100) = -30281.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8076: Reward = -43263.20, Avg Reward (100) = -29939.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8077: Reward = -1147.00, Avg Reward (100) = -30017.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8078: Reward = -1147.00, Avg Reward (100) = -30018.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8079: Reward = -1000.00, Avg Reward (100) = -29674.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8080: Reward = -28683.61, Avg Reward (100) = -29308.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8081: Reward = -35499.61, Avg Reward (100) = -29239.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8082: Reward = -35499.61, Avg Reward (100) = -29583.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8083: Reward = -35499.61, Avg Reward (100) = -29583.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8084: Reward = -28198.15, Avg Reward (100) = -29525.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -28198.15, Border Penalty: -31301.43, Obstacle Penalty: -50.00
Episode 8085: Reward = -35499.61, Avg Reward (100) = -29374.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8086: Reward = -35499.61, Avg Reward (100) = -29374.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8087: Reward = -35499.61, Avg Reward (100) = -29374.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8088: Reward = -35499.61, Avg Reward (100) = -29314.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8089: Reward = -1049.00, Avg Reward (100) = -29314.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8090: Reward = -37669.33, Avg Reward (100) = -29314.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8091: Reward = -1196.00, Avg Reward (100) = -29264.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8092: Reward = -35499.61, Avg Reward (100) = -29266.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8093: Reward = -35499.61, Avg Reward (100) = -29266.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8094: Reward = -35499.61, Avg Reward (100) = -29266.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8095: Reward = -28683.61, Avg Reward (100) = -29611.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8096: Reward = -39623.45, Avg Reward (100) = -29542.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -39623.45, Border Penalty: -37438.80, Obstacle Penalty: -50.00
Episode 8097: Reward = -1196.00, Avg Reward (100) = -29928.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8098: Reward = -35499.61, Avg Reward (100) = -29585.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8099: Reward = -35499.61, Avg Reward (100) = -29929.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8100: Reward = -43263.20, Avg Reward (100) = -29929.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8101: Reward = -35499.61, Avg Reward (100) = -30006.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8102: Reward = -35499.61, Avg Reward (100) = -30006.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8103: Reward = -14881.38, Avg Reward (100) = -30074.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -14881.38, Border Penalty: -24075.82, Obstacle Penalty: -50.00
Episode 8104: Reward = -35499.61, Avg Reward (100) = -29901.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8105: Reward = -35499.61, Avg Reward (100) = -29901.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8106: Reward = -1295.00, Avg Reward (100) = -29742.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8107: Reward = -47848.55, Avg Reward (100) = -29400.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8108: Reward = -35499.61, Avg Reward (100) = -29626.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8109: Reward = -1295.00, Avg Reward (100) = -29655.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8110: Reward = -35499.61, Avg Reward (100) = -29313.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8111: Reward = -35499.61, Avg Reward (100) = -29313.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8112: Reward = -49626.26, Avg Reward (100) = -29381.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8113: Reward = -35499.61, Avg Reward (100) = -29522.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8114: Reward = -35499.61, Avg Reward (100) = -29500.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8115: Reward = -1295.00, Avg Reward (100) = -29841.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8116: Reward = -1049.00, Avg Reward (100) = -29295.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8117: Reward = -35499.61, Avg Reward (100) = -28809.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8118: Reward = -32245.59, Avg Reward (100) = -28809.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8119: Reward = -1098.00, Avg Reward (100) = -28776.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8120: Reward = -1098.00, Avg Reward (100) = -28432.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8121: Reward = -35499.61, Avg Reward (100) = -28011.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8122: Reward = -49626.26, Avg Reward (100) = -28355.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8123: Reward = -35499.61, Avg Reward (100) = -28564.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8124: Reward = -35499.61, Avg Reward (100) = -28564.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8125: Reward = -50011.42, Avg Reward (100) = -28906.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50011.42, Border Penalty: -38178.67, Obstacle Penalty: -50.00
Episode 8126: Reward = -43263.20, Avg Reward (100) = -29395.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8127: Reward = -40411.33, Avg Reward (100) = -29473.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 8128: Reward = -32619.61, Avg Reward (100) = -29522.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8129: Reward = -35499.61, Avg Reward (100) = -29415.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8130: Reward = -35499.61, Avg Reward (100) = -29466.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8131: Reward = -34685.86, Avg Reward (100) = -29534.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8132: Reward = -35499.61, Avg Reward (100) = -29520.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8133: Reward = -25228.52, Avg Reward (100) = -29520.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8134: Reward = -35499.61, Avg Reward (100) = -29377.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8135: Reward = -26943.44, Avg Reward (100) = -29377.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26943.44, Border Penalty: -31417.73, Obstacle Penalty: -50.00
Episode 8136: Reward = -35499.61, Avg Reward (100) = -29635.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8137: Reward = -37669.33, Avg Reward (100) = -29524.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8138: Reward = -35499.61, Avg Reward (100) = -29578.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8139: Reward = -35499.61, Avg Reward (100) = -29578.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8140: Reward = -28683.61, Avg Reward (100) = -29646.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8141: Reward = -35499.61, Avg Reward (100) = -29920.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8142: Reward = -35499.61, Avg Reward (100) = -29889.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8143: Reward = -35499.61, Avg Reward (100) = -29752.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8144: Reward = -1196.00, Avg Reward (100) = -29711.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8145: Reward = -28683.61, Avg Reward (100) = -29368.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8146: Reward = -1049.00, Avg Reward (100) = -29329.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8147: Reward = -28653.56, Avg Reward (100) = -28943.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8148: Reward = -35499.61, Avg Reward (100) = -28875.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8149: Reward = -35499.61, Avg Reward (100) = -28875.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8150: Reward = -47477.73, Avg Reward (100) = -28644.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47477.73, Border Penalty: -38905.30, Obstacle Penalty: -50.00
Episode 8151: Reward = -35499.61, Avg Reward (100) = -29107.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8152: Reward = -1196.00, Avg Reward (100) = -29107.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8153: Reward = -25228.52, Avg Reward (100) = -28627.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8154: Reward = -1295.00, Avg Reward (100) = -28524.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8155: Reward = -1098.00, Avg Reward (100) = -28526.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8156: Reward = -35499.61, Avg Reward (100) = -28124.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8157: Reward = -35499.61, Avg Reward (100) = -28469.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8158: Reward = -1049.00, Avg Reward (100) = -28469.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8159: Reward = -35499.61, Avg Reward (100) = -28124.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8160: Reward = -35499.61, Avg Reward (100) = -28047.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8161: Reward = -35499.61, Avg Reward (100) = -28392.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8162: Reward = -35499.61, Avg Reward (100) = -28392.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8163: Reward = -35499.61, Avg Reward (100) = -28392.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8164: Reward = -35499.61, Avg Reward (100) = -28392.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8165: Reward = -35499.61, Avg Reward (100) = -28392.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8166: Reward = -35499.61, Avg Reward (100) = -28460.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8167: Reward = -1393.00, Avg Reward (100) = -28460.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8168: Reward = -35499.61, Avg Reward (100) = -28460.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8169: Reward = -37669.33, Avg Reward (100) = -28690.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8170: Reward = -29626.05, Avg Reward (100) = -28712.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 8171: Reward = -35499.61, Avg Reward (100) = -28653.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8172: Reward = -35499.61, Avg Reward (100) = -28653.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8173: Reward = -29626.05, Avg Reward (100) = -28653.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 8174: Reward = -35499.61, Avg Reward (100) = -28595.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8175: Reward = -21549.43, Avg Reward (100) = -28595.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -21549.43, Border Penalty: -27427.83, Obstacle Penalty: -50.00
Episode 8176: Reward = -33469.53, Avg Reward (100) = -28797.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -31745.04, Obstacle Penalty: -50.00
Episode 8177: Reward = -1294.00, Avg Reward (100) = -28699.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8178: Reward = -49626.26, Avg Reward (100) = -28701.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8179: Reward = -35499.61, Avg Reward (100) = -29185.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8180: Reward = -53955.87, Avg Reward (100) = -29530.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 8181: Reward = -1394.00, Avg Reward (100) = -29783.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8182: Reward = -35499.61, Avg Reward (100) = -29442.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8183: Reward = -35499.61, Avg Reward (100) = -29442.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8184: Reward = -1049.00, Avg Reward (100) = -29442.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8185: Reward = -35499.61, Avg Reward (100) = -29171.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8186: Reward = -1098.00, Avg Reward (100) = -29171.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8187: Reward = -35499.61, Avg Reward (100) = -28827.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8188: Reward = -32619.61, Avg Reward (100) = -28827.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8189: Reward = -35499.61, Avg Reward (100) = -28798.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8190: Reward = -28653.56, Avg Reward (100) = -29142.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8191: Reward = -35499.61, Avg Reward (100) = -29052.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8192: Reward = -35499.61, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8193: Reward = -35499.61, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8194: Reward = -35499.61, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8195: Reward = -35499.61, Avg Reward (100) = -29395.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8196: Reward = -1196.00, Avg Reward (100) = -29463.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8197: Reward = -35499.61, Avg Reward (100) = -29079.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8198: Reward = -1147.00, Avg Reward (100) = -29422.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8199: Reward = -35499.61, Avg Reward (100) = -29079.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8200: Reward = -35499.61, Avg Reward (100) = -29079.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8201: Reward = -35499.61, Avg Reward (100) = -29001.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8202: Reward = -32619.61, Avg Reward (100) = -29001.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8203: Reward = -1295.00, Avg Reward (100) = -28972.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8204: Reward = -35499.61, Avg Reward (100) = -28836.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8205: Reward = -36089.25, Avg Reward (100) = -28836.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8206: Reward = -35499.61, Avg Reward (100) = -28842.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8207: Reward = -35499.61, Avg Reward (100) = -29184.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8208: Reward = -1394.00, Avg Reward (100) = -29061.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8209: Reward = -35499.61, Avg Reward (100) = -28720.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8210: Reward = -1000.00, Avg Reward (100) = -29062.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8211: Reward = -35499.61, Avg Reward (100) = -28717.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8212: Reward = -35499.61, Avg Reward (100) = -28717.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8213: Reward = -43263.20, Avg Reward (100) = -28575.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8214: Reward = -28653.56, Avg Reward (100) = -28653.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8215: Reward = -35499.61, Avg Reward (100) = -28585.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8216: Reward = -28653.56, Avg Reward (100) = -28927.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8217: Reward = -35499.61, Avg Reward (100) = -29203.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8218: Reward = -39606.20, Avg Reward (100) = -29203.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8219: Reward = -33701.04, Avg Reward (100) = -29276.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8220: Reward = -35499.61, Avg Reward (100) = -29602.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8221: Reward = -30437.18, Avg Reward (100) = -29946.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 8222: Reward = -49626.26, Avg Reward (100) = -29896.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 8223: Reward = -35499.61, Avg Reward (100) = -29896.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8224: Reward = -47848.55, Avg Reward (100) = -29896.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8225: Reward = -35499.61, Avg Reward (100) = -30019.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8226: Reward = -35499.61, Avg Reward (100) = -29874.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8227: Reward = -35499.61, Avg Reward (100) = -29797.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8228: Reward = -12446.80, Avg Reward (100) = -29747.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8229: Reward = -35499.61, Avg Reward (100) = -29546.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8230: Reward = -35499.61, Avg Reward (100) = -29546.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8231: Reward = -35499.61, Avg Reward (100) = -29546.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8232: Reward = -43263.20, Avg Reward (100) = -29554.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8233: Reward = -35499.61, Avg Reward (100) = -29631.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8234: Reward = -35499.61, Avg Reward (100) = -29734.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8235: Reward = -35499.61, Avg Reward (100) = -29734.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8236: Reward = -34685.86, Avg Reward (100) = -29820.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8237: Reward = -35499.61, Avg Reward (100) = -29812.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8238: Reward = -35499.61, Avg Reward (100) = -29790.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8239: Reward = -1245.00, Avg Reward (100) = -29790.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8240: Reward = -43263.20, Avg Reward (100) = -29447.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8241: Reward = -1295.00, Avg Reward (100) = -29593.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8242: Reward = -35499.61, Avg Reward (100) = -29251.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8243: Reward = -35499.61, Avg Reward (100) = -29251.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8244: Reward = -35499.61, Avg Reward (100) = -29251.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8245: Reward = -1295.00, Avg Reward (100) = -29594.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8246: Reward = -33701.04, Avg Reward (100) = -29320.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8247: Reward = -35499.61, Avg Reward (100) = -29647.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8248: Reward = -35499.61, Avg Reward (100) = -29715.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8249: Reward = -33469.53, Avg Reward (100) = -29715.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8250: Reward = -35499.61, Avg Reward (100) = -29695.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8251: Reward = -34685.86, Avg Reward (100) = -29575.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8252: Reward = -35499.61, Avg Reward (100) = -29567.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8253: Reward = -35499.61, Avg Reward (100) = -29910.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8254: Reward = -48044.60, Avg Reward (100) = -30013.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 8255: Reward = -35499.61, Avg Reward (100) = -30480.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8256: Reward = -50944.91, Avg Reward (100) = -30824.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50944.91, Border Penalty: -38739.57, Obstacle Penalty: -50.00
Episode 8257: Reward = -1098.00, Avg Reward (100) = -30979.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8258: Reward = -35499.61, Avg Reward (100) = -30635.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8259: Reward = -35499.61, Avg Reward (100) = -30979.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8260: Reward = -1049.00, Avg Reward (100) = -30979.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8261: Reward = -35499.61, Avg Reward (100) = -30635.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8262: Reward = -47848.55, Avg Reward (100) = -30635.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8263: Reward = -35499.61, Avg Reward (100) = -30758.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8264: Reward = -1147.00, Avg Reward (100) = -30758.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8265: Reward = -35499.61, Avg Reward (100) = -30415.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8266: Reward = -35499.61, Avg Reward (100) = -30415.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8267: Reward = -35499.61, Avg Reward (100) = -30415.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8268: Reward = -1049.00, Avg Reward (100) = -30756.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8269: Reward = -1394.00, Avg Reward (100) = -30411.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8270: Reward = -30447.02, Avg Reward (100) = -30048.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -32385.11, Obstacle Penalty: -50.00
Episode 8271: Reward = -35499.61, Avg Reward (100) = -30057.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8272: Reward = -1049.00, Avg Reward (100) = -30057.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8273: Reward = -33701.04, Avg Reward (100) = -29712.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8274: Reward = -35499.61, Avg Reward (100) = -29753.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8275: Reward = -43263.20, Avg Reward (100) = -29753.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8276: Reward = -35499.61, Avg Reward (100) = -29970.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8277: Reward = -58564.79, Avg Reward (100) = -29990.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 8278: Reward = -35499.61, Avg Reward (100) = -30563.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8279: Reward = -35499.61, Avg Reward (100) = -30422.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8280: Reward = -35499.61, Avg Reward (100) = -30422.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8281: Reward = -35499.61, Avg Reward (100) = -30237.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8282: Reward = -35499.61, Avg Reward (100) = -30578.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8283: Reward = -35499.61, Avg Reward (100) = -30578.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8284: Reward = -45417.44, Avg Reward (100) = -30578.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45417.44, Border Penalty: -38590.88, Obstacle Penalty: -50.00
Episode 8285: Reward = -28882.62, Avg Reward (100) = -31022.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28882.62, Border Penalty: -31768.55, Obstacle Penalty: -50.00
Episode 8286: Reward = -35499.61, Avg Reward (100) = -30956.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8287: Reward = -33701.04, Avg Reward (100) = -31300.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8288: Reward = -35499.61, Avg Reward (100) = -31282.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8289: Reward = -35499.61, Avg Reward (100) = -31311.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8290: Reward = -35499.61, Avg Reward (100) = -31311.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8291: Reward = -35499.61, Avg Reward (100) = -31379.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8292: Reward = -1295.00, Avg Reward (100) = -31379.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8293: Reward = -35499.61, Avg Reward (100) = -31037.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8294: Reward = -28653.56, Avg Reward (100) = -31037.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8295: Reward = -1000.00, Avg Reward (100) = -30969.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8296: Reward = -43336.15, Avg Reward (100) = -30624.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43336.15, Border Penalty: -38005.91, Obstacle Penalty: -50.00
Episode 8297: Reward = -1098.00, Avg Reward (100) = -31045.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8298: Reward = -35499.61, Avg Reward (100) = -30701.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8299: Reward = -1147.00, Avg Reward (100) = -31045.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8300: Reward = -51939.83, Avg Reward (100) = -30701.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51939.83, Border Penalty: -40603.20, Obstacle Penalty: -50.00
Episode 8301: Reward = -43263.20, Avg Reward (100) = -30865.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8302: Reward = -1471.25, Avg Reward (100) = -30943.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -1471.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8303: Reward = -35499.61, Avg Reward (100) = -30632.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8304: Reward = -35499.61, Avg Reward (100) = -30974.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8305: Reward = -35499.61, Avg Reward (100) = -30974.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8306: Reward = -35499.61, Avg Reward (100) = -30968.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8307: Reward = -33469.53, Avg Reward (100) = -30968.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8308: Reward = -1049.00, Avg Reward (100) = -30947.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8309: Reward = -35499.61, Avg Reward (100) = -30944.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8310: Reward = -34685.86, Avg Reward (100) = -30944.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8311: Reward = -35499.61, Avg Reward (100) = -31281.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8312: Reward = -35499.61, Avg Reward (100) = -31281.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8313: Reward = -37669.33, Avg Reward (100) = -31281.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8314: Reward = -35499.61, Avg Reward (100) = -31225.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8315: Reward = -34685.86, Avg Reward (100) = -31293.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8316: Reward = -35499.61, Avg Reward (100) = -31285.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8317: Reward = -35499.61, Avg Reward (100) = -31354.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8318: Reward = -35499.61, Avg Reward (100) = -31354.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8319: Reward = -35499.61, Avg Reward (100) = -31313.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8320: Reward = -1049.00, Avg Reward (100) = -31331.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8321: Reward = -1196.00, Avg Reward (100) = -30986.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8322: Reward = -33469.53, Avg Reward (100) = -30694.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8323: Reward = -35499.61, Avg Reward (100) = -30532.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8324: Reward = -65103.65, Avg Reward (100) = -30532.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -65103.65, Border Penalty: -41707.10, Obstacle Penalty: -50.00
Episode 8325: Reward = -49176.10, Avg Reward (100) = -30705.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8326: Reward = -26914.26, Avg Reward (100) = -30841.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26914.26, Border Penalty: -31408.38, Obstacle Penalty: -50.00
Episode 8327: Reward = -37669.33, Avg Reward (100) = -30756.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8328: Reward = -1196.00, Avg Reward (100) = -30777.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8329: Reward = -43263.20, Avg Reward (100) = -30665.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -35267.92, Obstacle Penalty: -50.00
Episode 8330: Reward = -35499.61, Avg Reward (100) = -30742.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8331: Reward = -35499.61, Avg Reward (100) = -30742.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8332: Reward = -34685.86, Avg Reward (100) = -30742.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8333: Reward = -35499.61, Avg Reward (100) = -30657.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8334: Reward = -36089.25, Avg Reward (100) = -30657.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8335: Reward = -35499.61, Avg Reward (100) = -30662.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8336: Reward = -35499.61, Avg Reward (100) = -30662.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8337: Reward = -35499.61, Avg Reward (100) = -30671.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8338: Reward = -1049.00, Avg Reward (100) = -30671.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8339: Reward = -35499.61, Avg Reward (100) = -30326.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8340: Reward = -35499.61, Avg Reward (100) = -30669.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8341: Reward = -35499.61, Avg Reward (100) = -30591.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8342: Reward = -35499.61, Avg Reward (100) = -30933.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8343: Reward = -35499.61, Avg Reward (100) = -30933.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8344: Reward = -32612.87, Avg Reward (100) = -30933.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 8345: Reward = -35499.61, Avg Reward (100) = -30904.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8346: Reward = -35499.61, Avg Reward (100) = -31246.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8347: Reward = -35499.61, Avg Reward (100) = -31264.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8348: Reward = -35499.61, Avg Reward (100) = -31264.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8349: Reward = -35499.61, Avg Reward (100) = -31264.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8350: Reward = -1147.00, Avg Reward (100) = -31285.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8351: Reward = -1000.00, Avg Reward (100) = -30941.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8352: Reward = -35499.61, Avg Reward (100) = -30604.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8353: Reward = -1196.00, Avg Reward (100) = -30604.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8354: Reward = -36089.25, Avg Reward (100) = -30261.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8355: Reward = -33701.04, Avg Reward (100) = -30142.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8356: Reward = -35499.61, Avg Reward (100) = -30124.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8357: Reward = -35499.61, Avg Reward (100) = -29969.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8358: Reward = -35499.61, Avg Reward (100) = -30313.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8359: Reward = -35499.61, Avg Reward (100) = -30313.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8360: Reward = -32619.61, Avg Reward (100) = -30313.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 8361: Reward = -35499.61, Avg Reward (100) = -30629.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8362: Reward = -35499.61, Avg Reward (100) = -30629.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8363: Reward = -35499.61, Avg Reward (100) = -30505.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8364: Reward = -33469.53, Avg Reward (100) = -30505.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8365: Reward = -35499.61, Avg Reward (100) = -30829.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8366: Reward = -34482.45, Avg Reward (100) = -30829.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 8367: Reward = -47439.38, Avg Reward (100) = -30818.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 8368: Reward = -35499.61, Avg Reward (100) = -30938.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8369: Reward = -1000.00, Avg Reward (100) = -31282.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8370: Reward = -35499.61, Avg Reward (100) = -31278.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8371: Reward = -35499.61, Avg Reward (100) = -31329.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8372: Reward = -35499.61, Avg Reward (100) = -31329.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8373: Reward = -33701.04, Avg Reward (100) = -31673.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8374: Reward = -1295.00, Avg Reward (100) = -31673.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8375: Reward = -12446.80, Avg Reward (100) = -31331.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8376: Reward = -35499.61, Avg Reward (100) = -31023.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8377: Reward = -35499.61, Avg Reward (100) = -31023.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8378: Reward = -43263.20, Avg Reward (100) = -30793.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8379: Reward = -28683.61, Avg Reward (100) = -30870.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8380: Reward = -33469.53, Avg Reward (100) = -30802.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8381: Reward = -35499.61, Avg Reward (100) = -30782.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8382: Reward = -1098.00, Avg Reward (100) = -30782.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8383: Reward = -35499.61, Avg Reward (100) = -30438.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8384: Reward = -35499.61, Avg Reward (100) = -30438.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8385: Reward = -35499.61, Avg Reward (100) = -30339.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8386: Reward = -35499.61, Avg Reward (100) = -30405.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8387: Reward = -33701.04, Avg Reward (100) = -30405.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8388: Reward = -59176.41, Avg Reward (100) = -30405.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -34852.61, Obstacle Penalty: -50.00
Episode 8389: Reward = -35499.61, Avg Reward (100) = -30641.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8390: Reward = -31653.57, Avg Reward (100) = -30641.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 8391: Reward = -32245.59, Avg Reward (100) = -30603.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8392: Reward = -32245.59, Avg Reward (100) = -30570.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8393: Reward = -1098.00, Avg Reward (100) = -30880.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8394: Reward = -1049.00, Avg Reward (100) = -30536.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8395: Reward = -25228.52, Avg Reward (100) = -30260.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8396: Reward = -1147.00, Avg Reward (100) = -30502.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8397: Reward = -1000.00, Avg Reward (100) = -30080.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8398: Reward = -35499.61, Avg Reward (100) = -30079.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8399: Reward = -35499.61, Avg Reward (100) = -30079.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8400: Reward = -35499.61, Avg Reward (100) = -30423.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8401: Reward = -35499.61, Avg Reward (100) = -30258.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8402: Reward = -35499.61, Avg Reward (100) = -30181.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8403: Reward = -35499.61, Avg Reward (100) = -30521.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8404: Reward = -41156.53, Avg Reward (100) = -30521.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -41156.53, Border Penalty: -35816.55, Obstacle Penalty: -50.00
Episode 8405: Reward = -1000.00, Avg Reward (100) = -30578.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8406: Reward = -35499.61, Avg Reward (100) = -30233.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8407: Reward = -35499.61, Avg Reward (100) = -30233.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8408: Reward = -35499.61, Avg Reward (100) = -30253.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8409: Reward = -1394.00, Avg Reward (100) = -30597.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8410: Reward = -35499.61, Avg Reward (100) = -30256.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8411: Reward = -1000.00, Avg Reward (100) = -30265.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8412: Reward = -35499.61, Avg Reward (100) = -29920.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8413: Reward = -35499.61, Avg Reward (100) = -29920.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8414: Reward = -35499.61, Avg Reward (100) = -29898.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8415: Reward = -35499.61, Avg Reward (100) = -29898.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8416: Reward = -35499.61, Avg Reward (100) = -29906.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8417: Reward = -1394.00, Avg Reward (100) = -29906.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8418: Reward = -39606.20, Avg Reward (100) = -29565.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8419: Reward = -35499.61, Avg Reward (100) = -29606.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8420: Reward = -37669.33, Avg Reward (100) = -29606.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8421: Reward = -35499.61, Avg Reward (100) = -29972.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8422: Reward = -35499.61, Avg Reward (100) = -30315.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8423: Reward = -39216.62, Avg Reward (100) = -30336.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39216.62, Border Penalty: -36024.72, Obstacle Penalty: -50.00
Episode 8424: Reward = -35499.61, Avg Reward (100) = -30373.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8425: Reward = -49626.26, Avg Reward (100) = -30077.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8426: Reward = -1147.00, Avg Reward (100) = -30081.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8427: Reward = -35499.61, Avg Reward (100) = -29824.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8428: Reward = -35499.61, Avg Reward (100) = -29802.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8429: Reward = -35499.61, Avg Reward (100) = -30145.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8430: Reward = -34685.86, Avg Reward (100) = -30067.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8431: Reward = -1295.00, Avg Reward (100) = -30059.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8432: Reward = -35499.61, Avg Reward (100) = -29717.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8433: Reward = -35499.61, Avg Reward (100) = -29725.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8434: Reward = -35499.61, Avg Reward (100) = -29725.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8435: Reward = -35499.61, Avg Reward (100) = -29719.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8436: Reward = -33701.04, Avg Reward (100) = -29719.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8437: Reward = -35499.61, Avg Reward (100) = -29701.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8438: Reward = -31735.80, Avg Reward (100) = -29701.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31735.80, Border Penalty: -33598.23, Obstacle Penalty: -50.00
Episode 8439: Reward = -32619.61, Avg Reward (100) = -30008.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8440: Reward = -35499.61, Avg Reward (100) = -29979.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8441: Reward = -35499.61, Avg Reward (100) = -29979.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8442: Reward = -43263.20, Avg Reward (100) = -29979.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8443: Reward = -35499.61, Avg Reward (100) = -30057.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8444: Reward = -35499.61, Avg Reward (100) = -30057.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8445: Reward = -49626.26, Avg Reward (100) = -30086.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8446: Reward = -35499.61, Avg Reward (100) = -30227.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8447: Reward = -49176.10, Avg Reward (100) = -30227.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8448: Reward = -47848.55, Avg Reward (100) = -30364.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8449: Reward = -35499.61, Avg Reward (100) = -30487.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8450: Reward = -12446.80, Avg Reward (100) = -30487.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8451: Reward = -35499.61, Avg Reward (100) = -30600.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8452: Reward = -35499.61, Avg Reward (100) = -30945.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8453: Reward = -35499.61, Avg Reward (100) = -30945.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8454: Reward = -1000.00, Avg Reward (100) = -31288.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8455: Reward = -35499.61, Avg Reward (100) = -30938.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8456: Reward = -35499.61, Avg Reward (100) = -30955.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8457: Reward = -33701.04, Avg Reward (100) = -30955.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8458: Reward = -39606.20, Avg Reward (100) = -30938.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 8459: Reward = -49626.26, Avg Reward (100) = -30979.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8460: Reward = -43263.20, Avg Reward (100) = -31120.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8461: Reward = -49176.10, Avg Reward (100) = -31226.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8462: Reward = -35499.61, Avg Reward (100) = -31363.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8463: Reward = -1098.00, Avg Reward (100) = -31363.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8464: Reward = -35499.61, Avg Reward (100) = -31019.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8465: Reward = -35499.61, Avg Reward (100) = -31039.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8466: Reward = -29512.46, Avg Reward (100) = -31039.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 8467: Reward = -35499.61, Avg Reward (100) = -30990.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8468: Reward = -59645.17, Avg Reward (100) = -30870.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 8469: Reward = -35499.61, Avg Reward (100) = -31112.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8470: Reward = -35499.61, Avg Reward (100) = -31457.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8471: Reward = -1196.00, Avg Reward (100) = -31457.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8472: Reward = -39606.20, Avg Reward (100) = -31114.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8473: Reward = -35499.61, Avg Reward (100) = -31155.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8474: Reward = -1147.00, Avg Reward (100) = -31173.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8475: Reward = -1049.00, Avg Reward (100) = -31171.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8476: Reward = -47848.55, Avg Reward (100) = -31057.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8477: Reward = -35499.61, Avg Reward (100) = -31181.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8478: Reward = -35499.61, Avg Reward (100) = -31181.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8479: Reward = -32619.61, Avg Reward (100) = -31103.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8480: Reward = -35499.61, Avg Reward (100) = -31142.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8481: Reward = -35499.61, Avg Reward (100) = -31163.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8482: Reward = -35499.61, Avg Reward (100) = -31163.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8483: Reward = -34345.81, Avg Reward (100) = -31507.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34345.81, Border Penalty: -35118.36, Obstacle Penalty: -50.00
Episode 8484: Reward = -35499.61, Avg Reward (100) = -31495.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8485: Reward = -35499.61, Avg Reward (100) = -31495.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8486: Reward = -35499.61, Avg Reward (100) = -31495.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8487: Reward = -35499.61, Avg Reward (100) = -31495.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8488: Reward = -35499.61, Avg Reward (100) = -31513.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8489: Reward = -42112.30, Avg Reward (100) = -31276.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42112.30, Border Penalty: -37653.26, Obstacle Penalty: -50.00
Episode 8490: Reward = -1196.00, Avg Reward (100) = -31343.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8491: Reward = -35499.61, Avg Reward (100) = -31038.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8492: Reward = -35499.61, Avg Reward (100) = -31071.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8493: Reward = -35499.61, Avg Reward (100) = -31103.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8494: Reward = -30416.69, Avg Reward (100) = -31447.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30416.69, Border Penalty: -33691.42, Obstacle Penalty: -50.00
Episode 8495: Reward = -35499.61, Avg Reward (100) = -31741.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8496: Reward = -37669.33, Avg Reward (100) = -31843.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8497: Reward = -32619.61, Avg Reward (100) = -32209.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8498: Reward = -47848.55, Avg Reward (100) = -32525.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8499: Reward = -35499.61, Avg Reward (100) = -32648.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8500: Reward = -12446.80, Avg Reward (100) = -32648.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8501: Reward = -25228.52, Avg Reward (100) = -32418.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8502: Reward = -35499.61, Avg Reward (100) = -32315.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8503: Reward = -35499.61, Avg Reward (100) = -32315.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8504: Reward = -35499.61, Avg Reward (100) = -32315.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8505: Reward = -35499.61, Avg Reward (100) = -32259.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8506: Reward = -35499.61, Avg Reward (100) = -32604.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8507: Reward = -32619.61, Avg Reward (100) = -32604.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8508: Reward = -35499.61, Avg Reward (100) = -32575.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8509: Reward = -31163.36, Avg Reward (100) = -32575.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31163.36, Border Penalty: -33115.60, Obstacle Penalty: -50.00
Episode 8510: Reward = -32815.85, Avg Reward (100) = -32872.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 8511: Reward = -35499.61, Avg Reward (100) = -32846.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8512: Reward = -35499.61, Avg Reward (100) = -33191.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8513: Reward = -35499.61, Avg Reward (100) = -33191.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8514: Reward = -35499.61, Avg Reward (100) = -33191.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8515: Reward = -1049.00, Avg Reward (100) = -33191.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8516: Reward = -35499.61, Avg Reward (100) = -32846.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8517: Reward = -35499.61, Avg Reward (100) = -32846.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8518: Reward = -35499.61, Avg Reward (100) = -33187.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8519: Reward = -1395.78, Avg Reward (100) = -33146.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1395.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8520: Reward = -35499.61, Avg Reward (100) = -32805.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8521: Reward = -35499.61, Avg Reward (100) = -32783.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8522: Reward = -28683.61, Avg Reward (100) = -32783.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8523: Reward = -32619.61, Avg Reward (100) = -32715.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8524: Reward = -1196.00, Avg Reward (100) = -32649.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8525: Reward = -43263.20, Avg Reward (100) = -32306.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8526: Reward = -35499.61, Avg Reward (100) = -32243.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8527: Reward = -28683.61, Avg Reward (100) = -32586.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8528: Reward = -37669.33, Avg Reward (100) = -32518.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8529: Reward = -35499.61, Avg Reward (100) = -32540.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8530: Reward = -32245.59, Avg Reward (100) = -32540.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8531: Reward = -38625.36, Avg Reward (100) = -32515.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38625.36, Border Penalty: -36583.92, Obstacle Penalty: -50.00
Episode 8532: Reward = -35499.61, Avg Reward (100) = -32889.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8533: Reward = -35499.61, Avg Reward (100) = -32889.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8534: Reward = -49626.26, Avg Reward (100) = -32889.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8535: Reward = -35499.61, Avg Reward (100) = -33030.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8536: Reward = -1295.00, Avg Reward (100) = -33030.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8537: Reward = -32245.59, Avg Reward (100) = -32706.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8538: Reward = -25228.52, Avg Reward (100) = -32673.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8539: Reward = -39606.20, Avg Reward (100) = -32608.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8540: Reward = -35499.61, Avg Reward (100) = -32678.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8541: Reward = -28653.56, Avg Reward (100) = -32678.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8542: Reward = -35499.61, Avg Reward (100) = -32610.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8543: Reward = -35499.61, Avg Reward (100) = -32532.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8544: Reward = -35499.61, Avg Reward (100) = -32532.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8545: Reward = -39606.20, Avg Reward (100) = -32532.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8546: Reward = -35499.61, Avg Reward (100) = -32432.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8547: Reward = -35499.61, Avg Reward (100) = -32432.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8548: Reward = -1196.00, Avg Reward (100) = -32295.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8549: Reward = -35499.61, Avg Reward (100) = -31828.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8550: Reward = -28653.56, Avg Reward (100) = -31828.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8551: Reward = -35499.61, Avg Reward (100) = -31990.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8552: Reward = -35499.61, Avg Reward (100) = -31990.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8553: Reward = -35499.61, Avg Reward (100) = -31990.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8554: Reward = -35499.61, Avg Reward (100) = -31990.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8555: Reward = -35499.61, Avg Reward (100) = -32335.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8556: Reward = -35499.61, Avg Reward (100) = -32335.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8557: Reward = -1295.00, Avg Reward (100) = -32335.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8558: Reward = -1394.00, Avg Reward (100) = -32011.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8559: Reward = -39606.20, Avg Reward (100) = -31629.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8560: Reward = -29512.46, Avg Reward (100) = -31529.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 8561: Reward = -1295.00, Avg Reward (100) = -31392.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8562: Reward = -1098.00, Avg Reward (100) = -30913.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8563: Reward = -33469.53, Avg Reward (100) = -30569.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8564: Reward = -1049.00, Avg Reward (100) = -30892.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8565: Reward = -43263.20, Avg Reward (100) = -30548.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8566: Reward = -35499.61, Avg Reward (100) = -30626.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8567: Reward = -59176.41, Avg Reward (100) = -30685.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59176.41, Border Penalty: -32572.60, Obstacle Penalty: -50.00
Episode 8568: Reward = -35499.61, Avg Reward (100) = -30922.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8569: Reward = -35499.61, Avg Reward (100) = -30681.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8570: Reward = -35499.61, Avg Reward (100) = -30681.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8571: Reward = -35499.61, Avg Reward (100) = -30681.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8572: Reward = -46746.27, Avg Reward (100) = -31024.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46746.27, Border Penalty: -36091.83, Obstacle Penalty: -50.00
Episode 8573: Reward = -35499.61, Avg Reward (100) = -31095.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8574: Reward = -1147.00, Avg Reward (100) = -31095.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8575: Reward = -35499.61, Avg Reward (100) = -31095.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8576: Reward = -35499.61, Avg Reward (100) = -31440.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8577: Reward = -35499.61, Avg Reward (100) = -31316.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8578: Reward = -35499.61, Avg Reward (100) = -31316.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8579: Reward = -35499.61, Avg Reward (100) = -31316.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8580: Reward = -35499.61, Avg Reward (100) = -31345.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8581: Reward = -49626.26, Avg Reward (100) = -31345.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8582: Reward = -28683.61, Avg Reward (100) = -31486.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8583: Reward = -35499.61, Avg Reward (100) = -31418.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8584: Reward = -32619.61, Avg Reward (100) = -31430.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8585: Reward = -28683.61, Avg Reward (100) = -31401.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8586: Reward = -12446.80, Avg Reward (100) = -31333.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8587: Reward = -35499.61, Avg Reward (100) = -31102.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8588: Reward = -35499.61, Avg Reward (100) = -31102.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8589: Reward = -1394.00, Avg Reward (100) = -31102.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 8590: Reward = -25228.52, Avg Reward (100) = -30695.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8591: Reward = -1393.00, Avg Reward (100) = -30935.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8592: Reward = -25539.05, Avg Reward (100) = -30594.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -25539.05, Border Penalty: -30186.28, Obstacle Penalty: -50.00
Episode 8593: Reward = -33305.90, Avg Reward (100) = -30495.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33305.90, Border Penalty: -33833.45, Obstacle Penalty: -50.00
Episode 8594: Reward = -35499.61, Avg Reward (100) = -30473.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8595: Reward = -35499.61, Avg Reward (100) = -30524.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8596: Reward = -35499.61, Avg Reward (100) = -30524.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8597: Reward = -25228.52, Avg Reward (100) = -30502.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8598: Reward = -35499.61, Avg Reward (100) = -30428.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8599: Reward = -35499.61, Avg Reward (100) = -30304.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8600: Reward = -1098.00, Avg Reward (100) = -30304.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8601: Reward = -37669.33, Avg Reward (100) = -30191.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8602: Reward = -1000.00, Avg Reward (100) = -30315.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8603: Reward = -35499.61, Avg Reward (100) = -29970.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8604: Reward = -35499.61, Avg Reward (100) = -29970.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8605: Reward = -35499.61, Avg Reward (100) = -29970.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8606: Reward = -1295.00, Avg Reward (100) = -29970.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8607: Reward = -35499.61, Avg Reward (100) = -29628.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8608: Reward = -35499.61, Avg Reward (100) = -29657.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8609: Reward = -46305.80, Avg Reward (100) = -29657.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46305.80, Border Penalty: -37626.48, Obstacle Penalty: -50.00
Episode 8610: Reward = -1394.00, Avg Reward (100) = -29809.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8611: Reward = -35499.61, Avg Reward (100) = -29494.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8612: Reward = -35499.61, Avg Reward (100) = -29494.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8613: Reward = -35499.61, Avg Reward (100) = -29494.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8614: Reward = -35499.61, Avg Reward (100) = -29494.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8615: Reward = -35499.61, Avg Reward (100) = -29494.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8616: Reward = -33701.04, Avg Reward (100) = -29839.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8617: Reward = -55296.44, Avg Reward (100) = -29821.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -55296.44, Border Penalty: -41620.00, Obstacle Penalty: -50.00
Episode 8618: Reward = -1147.00, Avg Reward (100) = -30019.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8619: Reward = -35499.61, Avg Reward (100) = -29675.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8620: Reward = -35499.61, Avg Reward (100) = -30016.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8621: Reward = -1393.00, Avg Reward (100) = -30016.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8622: Reward = -49176.10, Avg Reward (100) = -29675.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8623: Reward = -35499.61, Avg Reward (100) = -29880.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8624: Reward = -49626.26, Avg Reward (100) = -29909.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 8625: Reward = -35499.61, Avg Reward (100) = -30393.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8626: Reward = -35499.61, Avg Reward (100) = -30316.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8627: Reward = -1098.00, Avg Reward (100) = -30316.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8628: Reward = -60525.04, Avg Reward (100) = -30040.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -60525.04, Border Penalty: -33483.35, Obstacle Penalty: -50.00
Episode 8629: Reward = -28683.61, Avg Reward (100) = -30268.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8630: Reward = -35499.61, Avg Reward (100) = -30200.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8631: Reward = -35499.61, Avg Reward (100) = -30233.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8632: Reward = -1000.00, Avg Reward (100) = -30202.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8633: Reward = -35499.61, Avg Reward (100) = -29857.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8634: Reward = -1098.00, Avg Reward (100) = -29857.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8635: Reward = -1049.00, Avg Reward (100) = -29371.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8636: Reward = -34685.86, Avg Reward (100) = -29027.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8637: Reward = -37669.33, Avg Reward (100) = -29361.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8638: Reward = -75412.97, Avg Reward (100) = -29415.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -75412.97, Border Penalty: -36901.02, Obstacle Penalty: -50.00
Episode 8639: Reward = -35499.61, Avg Reward (100) = -29917.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8640: Reward = -35499.61, Avg Reward (100) = -29876.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8641: Reward = -35499.61, Avg Reward (100) = -29876.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8642: Reward = -35499.61, Avg Reward (100) = -29944.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8643: Reward = -1147.00, Avg Reward (100) = -29944.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8644: Reward = -35499.61, Avg Reward (100) = -29601.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8645: Reward = -35499.61, Avg Reward (100) = -29601.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8646: Reward = -35499.61, Avg Reward (100) = -29560.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8647: Reward = -1000.00, Avg Reward (100) = -29560.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8648: Reward = -34685.86, Avg Reward (100) = -29215.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 8649: Reward = -35499.61, Avg Reward (100) = -29549.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8650: Reward = -43263.20, Avg Reward (100) = -29549.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8651: Reward = -32619.61, Avg Reward (100) = -29696.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8652: Reward = -1196.00, Avg Reward (100) = -29667.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8653: Reward = -1196.00, Avg Reward (100) = -29324.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8654: Reward = -35499.61, Avg Reward (100) = -28981.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8655: Reward = -35499.61, Avg Reward (100) = -28981.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8656: Reward = -35499.61, Avg Reward (100) = -28981.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8657: Reward = -43263.20, Avg Reward (100) = -28981.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8658: Reward = -35499.61, Avg Reward (100) = -29400.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8659: Reward = -46653.19, Avg Reward (100) = -29741.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -37604.99, Obstacle Penalty: -50.00
Episode 8660: Reward = -1196.00, Avg Reward (100) = -29812.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8661: Reward = -35499.61, Avg Reward (100) = -29529.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8662: Reward = -35499.61, Avg Reward (100) = -29871.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8663: Reward = -35499.61, Avg Reward (100) = -30215.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8664: Reward = -35499.61, Avg Reward (100) = -30235.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8665: Reward = -28653.56, Avg Reward (100) = -30580.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 8666: Reward = -35499.61, Avg Reward (100) = -30433.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8667: Reward = -35499.61, Avg Reward (100) = -30433.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8668: Reward = -35499.61, Avg Reward (100) = -30197.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8669: Reward = -35499.61, Avg Reward (100) = -30197.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8670: Reward = -35499.61, Avg Reward (100) = -30197.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8671: Reward = -35499.61, Avg Reward (100) = -30197.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8672: Reward = -1098.00, Avg Reward (100) = -30197.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8673: Reward = -35499.61, Avg Reward (100) = -29740.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8674: Reward = -32619.61, Avg Reward (100) = -29740.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8675: Reward = -47848.55, Avg Reward (100) = -30055.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 8676: Reward = -1351.40, Avg Reward (100) = -30178.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8677: Reward = -35499.61, Avg Reward (100) = -29837.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8678: Reward = -35499.61, Avg Reward (100) = -29837.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8679: Reward = -1049.00, Avg Reward (100) = -29837.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8680: Reward = -29512.46, Avg Reward (100) = -29492.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 8681: Reward = -35499.61, Avg Reward (100) = -29433.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8682: Reward = -1098.00, Avg Reward (100) = -29291.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8683: Reward = -1049.00, Avg Reward (100) = -29015.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8684: Reward = -35499.61, Avg Reward (100) = -28671.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8685: Reward = -43263.20, Avg Reward (100) = -28700.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8686: Reward = -35499.61, Avg Reward (100) = -28846.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8687: Reward = -35499.61, Avg Reward (100) = -29076.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8688: Reward = -35499.61, Avg Reward (100) = -29076.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8689: Reward = -35499.61, Avg Reward (100) = -29076.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8690: Reward = -35499.61, Avg Reward (100) = -29417.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8691: Reward = -25228.52, Avg Reward (100) = -29520.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8692: Reward = -35499.61, Avg Reward (100) = -29758.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8693: Reward = -32245.59, Avg Reward (100) = -29858.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8694: Reward = -1295.00, Avg Reward (100) = -29847.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8695: Reward = -35499.61, Avg Reward (100) = -29505.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8696: Reward = -34685.86, Avg Reward (100) = -29505.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8697: Reward = -1196.00, Avg Reward (100) = -29497.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8698: Reward = -43263.20, Avg Reward (100) = -29257.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8699: Reward = -35499.61, Avg Reward (100) = -29334.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8700: Reward = -33469.53, Avg Reward (100) = -29334.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8701: Reward = -35499.61, Avg Reward (100) = -29658.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8702: Reward = -35499.61, Avg Reward (100) = -29636.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8703: Reward = -35499.61, Avg Reward (100) = -29981.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8704: Reward = -35499.61, Avg Reward (100) = -29981.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8705: Reward = -32619.61, Avg Reward (100) = -29981.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8706: Reward = -35499.61, Avg Reward (100) = -29953.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8707: Reward = -35499.61, Avg Reward (100) = -30295.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8708: Reward = -25468.63, Avg Reward (100) = -30295.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 8709: Reward = -1000.00, Avg Reward (100) = -30194.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8710: Reward = -1147.00, Avg Reward (100) = -29741.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8711: Reward = -33469.53, Avg Reward (100) = -29739.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8712: Reward = -1147.00, Avg Reward (100) = -29718.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8713: Reward = -35499.61, Avg Reward (100) = -29375.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8714: Reward = -1196.00, Avg Reward (100) = -29375.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8715: Reward = -35499.61, Avg Reward (100) = -29032.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8716: Reward = -35499.61, Avg Reward (100) = -29032.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8717: Reward = -1049.00, Avg Reward (100) = -29050.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8718: Reward = -25228.52, Avg Reward (100) = -28507.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8719: Reward = -32619.61, Avg Reward (100) = -28748.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8720: Reward = -1294.00, Avg Reward (100) = -28719.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 8721: Reward = -28683.61, Avg Reward (100) = -28377.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8722: Reward = -1147.00, Avg Reward (100) = -28650.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8723: Reward = -32619.61, Avg Reward (100) = -28170.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8724: Reward = -35499.61, Avg Reward (100) = -28141.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8725: Reward = -35499.61, Avg Reward (100) = -28000.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8726: Reward = -35499.61, Avg Reward (100) = -28000.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8727: Reward = -35499.61, Avg Reward (100) = -28000.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8728: Reward = -35499.61, Avg Reward (100) = -28344.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8729: Reward = -35499.61, Avg Reward (100) = -28094.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8730: Reward = -35499.61, Avg Reward (100) = -28162.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8731: Reward = -35499.61, Avg Reward (100) = -28162.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8732: Reward = -47439.38, Avg Reward (100) = -28162.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 8733: Reward = -35499.61, Avg Reward (100) = -28626.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8734: Reward = -35499.61, Avg Reward (100) = -28626.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8735: Reward = -35499.61, Avg Reward (100) = -28970.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8736: Reward = -28683.61, Avg Reward (100) = -29315.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8737: Reward = -1000.00, Avg Reward (100) = -29255.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8738: Reward = -35499.61, Avg Reward (100) = -28888.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8739: Reward = -36089.25, Avg Reward (100) = -28489.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8740: Reward = -35499.61, Avg Reward (100) = -28495.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8741: Reward = -35499.61, Avg Reward (100) = -28495.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8742: Reward = -1000.00, Avg Reward (100) = -28495.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8743: Reward = -32245.59, Avg Reward (100) = -28150.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8744: Reward = -1049.00, Avg Reward (100) = -28461.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8745: Reward = -39606.20, Avg Reward (100) = -28116.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8746: Reward = -33701.04, Avg Reward (100) = -28157.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 8747: Reward = -1000.00, Avg Reward (100) = -28139.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8748: Reward = -12446.80, Avg Reward (100) = -28139.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8749: Reward = -35499.61, Avg Reward (100) = -27917.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8750: Reward = -35499.61, Avg Reward (100) = -27917.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8751: Reward = -32619.61, Avg Reward (100) = -27839.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8752: Reward = -35499.61, Avg Reward (100) = -27839.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8753: Reward = -12446.80, Avg Reward (100) = -28182.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8754: Reward = -35499.61, Avg Reward (100) = -28295.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8755: Reward = -49176.10, Avg Reward (100) = -28295.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 8756: Reward = -35499.61, Avg Reward (100) = -28432.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8757: Reward = -1049.00, Avg Reward (100) = -28432.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8758: Reward = -35499.61, Avg Reward (100) = -28009.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8759: Reward = -12446.80, Avg Reward (100) = -28009.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8760: Reward = -35499.61, Avg Reward (100) = -27667.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8761: Reward = -35499.61, Avg Reward (100) = -28010.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8762: Reward = -26787.09, Avg Reward (100) = -28010.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 8763: Reward = -35499.61, Avg Reward (100) = -27923.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8764: Reward = -1049.00, Avg Reward (100) = -27923.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8765: Reward = -35499.61, Avg Reward (100) = -27579.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8766: Reward = -49626.26, Avg Reward (100) = -27647.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8767: Reward = -35499.61, Avg Reward (100) = -27789.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8768: Reward = -1147.00, Avg Reward (100) = -27789.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8769: Reward = -25228.52, Avg Reward (100) = -27445.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8770: Reward = -1098.00, Avg Reward (100) = -27342.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8771: Reward = -35499.61, Avg Reward (100) = -26998.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8772: Reward = -35499.61, Avg Reward (100) = -26998.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8773: Reward = -28653.56, Avg Reward (100) = -27342.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8774: Reward = -33469.53, Avg Reward (100) = -27274.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 8775: Reward = -1394.00, Avg Reward (100) = -27282.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 8776: Reward = -35499.61, Avg Reward (100) = -26818.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8777: Reward = -2156.56, Avg Reward (100) = -27159.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 8778: Reward = -1394.00, Avg Reward (100) = -26826.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8779: Reward = -35499.61, Avg Reward (100) = -26485.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8780: Reward = -35499.61, Avg Reward (100) = -26829.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8781: Reward = -35499.61, Avg Reward (100) = -26889.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8782: Reward = -35499.61, Avg Reward (100) = -26889.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8783: Reward = -41843.95, Avg Reward (100) = -27233.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41843.95, Border Penalty: -37341.73, Obstacle Penalty: -50.00
Episode 8784: Reward = -35499.61, Avg Reward (100) = -27641.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8785: Reward = -35499.61, Avg Reward (100) = -27641.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8786: Reward = -34685.86, Avg Reward (100) = -27563.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8787: Reward = -35499.61, Avg Reward (100) = -27555.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8788: Reward = -35499.61, Avg Reward (100) = -27555.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8789: Reward = -35499.61, Avg Reward (100) = -27555.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8790: Reward = -35499.61, Avg Reward (100) = -27555.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8791: Reward = -35499.61, Avg Reward (100) = -27555.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8792: Reward = -1492.00, Avg Reward (100) = -27658.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 8793: Reward = -35499.61, Avg Reward (100) = -27318.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8794: Reward = -35499.61, Avg Reward (100) = -27351.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8795: Reward = -35499.61, Avg Reward (100) = -27693.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8796: Reward = -2156.56, Avg Reward (100) = -27693.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 8797: Reward = -39409.45, Avg Reward (100) = -27367.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39409.45, Border Penalty: -34826.64, Obstacle Penalty: -50.00
Episode 8798: Reward = -37669.33, Avg Reward (100) = -27749.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8799: Reward = -32245.59, Avg Reward (100) = -27693.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8800: Reward = -35499.61, Avg Reward (100) = -27661.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8801: Reward = -28653.56, Avg Reward (100) = -27681.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 8802: Reward = -27492.00, Avg Reward (100) = -27613.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 8803: Reward = -32245.59, Avg Reward (100) = -27533.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8804: Reward = -35499.61, Avg Reward (100) = -27500.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8805: Reward = -50968.57, Avg Reward (100) = -27500.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -40121.91, Obstacle Penalty: -50.00
Episode 8806: Reward = -35499.61, Avg Reward (100) = -27684.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8807: Reward = -35499.61, Avg Reward (100) = -27684.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8808: Reward = -35499.61, Avg Reward (100) = -27684.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8809: Reward = -37669.33, Avg Reward (100) = -27784.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8810: Reward = -1000.00, Avg Reward (100) = -28151.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8811: Reward = -1000.00, Avg Reward (100) = -28149.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8812: Reward = -35499.61, Avg Reward (100) = -27824.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8813: Reward = -25228.52, Avg Reward (100) = -28168.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8814: Reward = -1394.00, Avg Reward (100) = -28065.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8815: Reward = -34164.73, Avg Reward (100) = -28067.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 8816: Reward = -35499.61, Avg Reward (100) = -28054.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8817: Reward = -39606.20, Avg Reward (100) = -28054.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8818: Reward = -39606.20, Avg Reward (100) = -28440.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8819: Reward = -25228.52, Avg Reward (100) = -28583.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8820: Reward = -49626.26, Avg Reward (100) = -28509.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8821: Reward = -33469.53, Avg Reward (100) = -28993.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 8822: Reward = -53075.23, Avg Reward (100) = -29041.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -41137.98, Obstacle Penalty: -50.00
Episode 8823: Reward = -1147.00, Avg Reward (100) = -29560.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8824: Reward = -49626.26, Avg Reward (100) = -29245.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8825: Reward = -35499.61, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8826: Reward = -35499.61, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8827: Reward = -35499.61, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8828: Reward = -35499.61, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8829: Reward = -35499.61, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8830: Reward = -53075.23, Avg Reward (100) = -29386.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -41137.98, Obstacle Penalty: -50.00
Episode 8831: Reward = -32619.61, Avg Reward (100) = -29562.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8832: Reward = -1098.00, Avg Reward (100) = -29533.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8833: Reward = -35499.61, Avg Reward (100) = -29070.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8834: Reward = -35499.61, Avg Reward (100) = -29070.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8835: Reward = -37669.33, Avg Reward (100) = -29070.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8836: Reward = -39606.20, Avg Reward (100) = -29092.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8837: Reward = -35499.61, Avg Reward (100) = -29201.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8838: Reward = -35499.61, Avg Reward (100) = -29546.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8839: Reward = -35499.61, Avg Reward (100) = -29546.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8840: Reward = -35499.61, Avg Reward (100) = -29540.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8841: Reward = -35499.61, Avg Reward (100) = -29540.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8842: Reward = -28683.61, Avg Reward (100) = -29540.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8843: Reward = -35499.61, Avg Reward (100) = -29817.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8844: Reward = -35499.61, Avg Reward (100) = -29849.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8845: Reward = -35499.61, Avg Reward (100) = -30194.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8846: Reward = -35499.61, Avg Reward (100) = -30153.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8847: Reward = -35499.61, Avg Reward (100) = -30171.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8848: Reward = -33701.04, Avg Reward (100) = -30516.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -33409.77, Obstacle Penalty: -50.00
Episode 8849: Reward = -33486.06, Avg Reward (100) = -30728.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33486.06, Border Penalty: -34346.12, Obstacle Penalty: -50.00
Episode 8850: Reward = -35499.61, Avg Reward (100) = -30708.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8851: Reward = -35499.61, Avg Reward (100) = -30708.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8852: Reward = -32619.61, Avg Reward (100) = -30737.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8853: Reward = -1147.00, Avg Reward (100) = -30708.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8854: Reward = -35499.61, Avg Reward (100) = -30595.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8855: Reward = -35499.61, Avg Reward (100) = -30595.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8856: Reward = -35499.61, Avg Reward (100) = -30458.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 8857: Reward = -35499.61, Avg Reward (100) = -30458.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8858: Reward = -32619.61, Avg Reward (100) = -30803.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8859: Reward = -35499.61, Avg Reward (100) = -30774.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8860: Reward = -35499.61, Avg Reward (100) = -31005.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8861: Reward = -12446.80, Avg Reward (100) = -31005.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8862: Reward = -35499.61, Avg Reward (100) = -30774.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8863: Reward = -35499.61, Avg Reward (100) = -30861.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8864: Reward = -35499.61, Avg Reward (100) = -30861.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8865: Reward = -1295.00, Avg Reward (100) = -31206.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8866: Reward = -35499.61, Avg Reward (100) = -30864.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8867: Reward = -43263.20, Avg Reward (100) = -30722.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8868: Reward = -35499.61, Avg Reward (100) = -30800.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8869: Reward = -1000.00, Avg Reward (100) = -31144.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8870: Reward = -35499.61, Avg Reward (100) = -30901.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8871: Reward = -35499.61, Avg Reward (100) = -31245.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8872: Reward = -35499.61, Avg Reward (100) = -31245.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8873: Reward = -35499.61, Avg Reward (100) = -31245.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8874: Reward = -35499.61, Avg Reward (100) = -31314.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8875: Reward = -35499.61, Avg Reward (100) = -31334.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8876: Reward = -1147.00, Avg Reward (100) = -31675.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8877: Reward = -39606.20, Avg Reward (100) = -31332.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8878: Reward = -49626.26, Avg Reward (100) = -31706.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8879: Reward = -1394.00, Avg Reward (100) = -32188.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 8880: Reward = -35499.61, Avg Reward (100) = -31847.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8881: Reward = -35499.61, Avg Reward (100) = -31847.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8882: Reward = -43263.20, Avg Reward (100) = -31847.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8883: Reward = -34685.86, Avg Reward (100) = -31925.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8884: Reward = -1295.00, Avg Reward (100) = -31853.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 8885: Reward = -43263.20, Avg Reward (100) = -31511.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8886: Reward = -35499.61, Avg Reward (100) = -31589.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8887: Reward = -43263.20, Avg Reward (100) = -31597.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8888: Reward = -12446.80, Avg Reward (100) = -31675.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8889: Reward = -1196.00, Avg Reward (100) = -31444.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8890: Reward = -35499.61, Avg Reward (100) = -31101.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8891: Reward = -35499.61, Avg Reward (100) = -31101.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8892: Reward = -35499.61, Avg Reward (100) = -31101.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8893: Reward = -1049.00, Avg Reward (100) = -31441.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8894: Reward = -35499.61, Avg Reward (100) = -31097.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8895: Reward = -32619.61, Avg Reward (100) = -31097.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8896: Reward = -35499.61, Avg Reward (100) = -31068.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8897: Reward = -35499.61, Avg Reward (100) = -31401.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8898: Reward = -35499.61, Avg Reward (100) = -31362.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8899: Reward = -35499.61, Avg Reward (100) = -31341.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8900: Reward = -35499.61, Avg Reward (100) = -31373.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8901: Reward = -1000.00, Avg Reward (100) = -31373.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8902: Reward = -35499.61, Avg Reward (100) = -31097.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8903: Reward = -35499.61, Avg Reward (100) = -31177.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8904: Reward = -32245.59, Avg Reward (100) = -31209.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8905: Reward = -35499.61, Avg Reward (100) = -31177.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8906: Reward = -35499.61, Avg Reward (100) = -31022.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8907: Reward = -35499.61, Avg Reward (100) = -31022.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8908: Reward = -32245.59, Avg Reward (100) = -31022.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8909: Reward = -35499.61, Avg Reward (100) = -30989.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8910: Reward = -35499.61, Avg Reward (100) = -30968.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8911: Reward = -39606.20, Avg Reward (100) = -31313.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 8912: Reward = -1394.00, Avg Reward (100) = -31699.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8913: Reward = -35499.61, Avg Reward (100) = -31358.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8914: Reward = -25228.52, Avg Reward (100) = -31460.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8915: Reward = -35499.61, Avg Reward (100) = -31699.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8916: Reward = -35499.61, Avg Reward (100) = -31712.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8917: Reward = -26033.58, Avg Reward (100) = -31712.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26033.58, Border Penalty: -30278.69, Obstacle Penalty: -50.00
Episode 8918: Reward = -35499.61, Avg Reward (100) = -31576.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8919: Reward = -35499.61, Avg Reward (100) = -31535.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8920: Reward = -29512.46, Avg Reward (100) = -31638.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 8921: Reward = -35499.61, Avg Reward (100) = -31437.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8922: Reward = -35499.61, Avg Reward (100) = -31457.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8923: Reward = -35499.61, Avg Reward (100) = -31282.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8924: Reward = -35499.61, Avg Reward (100) = -31625.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8925: Reward = -1394.00, Avg Reward (100) = -31484.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 8926: Reward = -1000.00, Avg Reward (100) = -31143.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8927: Reward = -43806.78, Avg Reward (100) = -30798.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43806.78, Border Penalty: -37514.70, Obstacle Penalty: -50.00
Episode 8928: Reward = -35499.61, Avg Reward (100) = -30881.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8929: Reward = -33469.53, Avg Reward (100) = -30881.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8930: Reward = -34685.86, Avg Reward (100) = -30860.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 8931: Reward = -36089.25, Avg Reward (100) = -30677.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8932: Reward = -35499.61, Avg Reward (100) = -30711.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8933: Reward = -49626.26, Avg Reward (100) = -31055.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8934: Reward = -1000.00, Avg Reward (100) = -31197.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8935: Reward = -52333.05, Avg Reward (100) = -30852.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40617.02, Obstacle Penalty: -50.00
Episode 8936: Reward = -35499.61, Avg Reward (100) = -30998.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8937: Reward = -32245.59, Avg Reward (100) = -30957.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8938: Reward = -25228.52, Avg Reward (100) = -30925.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8939: Reward = -35499.61, Avg Reward (100) = -30822.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8940: Reward = -46653.19, Avg Reward (100) = -30822.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -35324.98, Obstacle Penalty: -50.00
Episode 8941: Reward = -35499.61, Avg Reward (100) = -30933.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8942: Reward = -35499.61, Avg Reward (100) = -30933.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8943: Reward = -35499.61, Avg Reward (100) = -31002.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8944: Reward = -1000.00, Avg Reward (100) = -31002.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8945: Reward = -35499.61, Avg Reward (100) = -30657.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8946: Reward = -47848.55, Avg Reward (100) = -30657.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 8947: Reward = -35499.61, Avg Reward (100) = -30780.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8948: Reward = -35499.61, Avg Reward (100) = -30780.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8949: Reward = -1147.00, Avg Reward (100) = -30798.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8950: Reward = -35499.61, Avg Reward (100) = -30475.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8951: Reward = -25228.52, Avg Reward (100) = -30475.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 8952: Reward = -1147.00, Avg Reward (100) = -30372.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8953: Reward = -35499.61, Avg Reward (100) = -30057.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8954: Reward = -35499.61, Avg Reward (100) = -30401.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8955: Reward = -59645.17, Avg Reward (100) = -30401.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 8956: Reward = -35499.61, Avg Reward (100) = -30642.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8957: Reward = -1049.00, Avg Reward (100) = -30642.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8958: Reward = -26470.74, Avg Reward (100) = -30298.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 8959: Reward = -1000.00, Avg Reward (100) = -30236.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8960: Reward = -35499.61, Avg Reward (100) = -29891.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8961: Reward = -35499.61, Avg Reward (100) = -29891.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8962: Reward = -36089.25, Avg Reward (100) = -30122.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 8963: Reward = -35499.61, Avg Reward (100) = -30128.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8964: Reward = -1196.00, Avg Reward (100) = -30128.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 8965: Reward = -35499.61, Avg Reward (100) = -29785.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8966: Reward = -28683.61, Avg Reward (100) = -30127.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 8967: Reward = -35499.61, Avg Reward (100) = -30059.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8968: Reward = -35499.61, Avg Reward (100) = -29981.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8969: Reward = -35499.61, Avg Reward (100) = -29981.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8970: Reward = -35499.61, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8971: Reward = -35499.61, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8972: Reward = -35499.61, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8973: Reward = -35499.61, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8974: Reward = -35499.61, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8975: Reward = -1196.00, Avg Reward (100) = -30326.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8976: Reward = -35499.61, Avg Reward (100) = -29983.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8977: Reward = -34741.98, Avg Reward (100) = -30326.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 8978: Reward = -49626.26, Avg Reward (100) = -30278.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 8979: Reward = -1098.00, Avg Reward (100) = -30278.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8980: Reward = -33469.53, Avg Reward (100) = -30275.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 8981: Reward = -12769.82, Avg Reward (100) = -30254.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -12769.82, Border Penalty: -22136.90, Obstacle Penalty: -50.00
Episode 8982: Reward = -27492.00, Avg Reward (100) = -30027.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 8983: Reward = -1000.00, Avg Reward (100) = -29869.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8984: Reward = -35499.61, Avg Reward (100) = -29533.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8985: Reward = -35499.61, Avg Reward (100) = -29875.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8986: Reward = -43569.45, Avg Reward (100) = -29797.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43569.45, Border Penalty: -37743.09, Obstacle Penalty: -50.00
Episode 8987: Reward = -32245.59, Avg Reward (100) = -29878.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 8988: Reward = -35499.61, Avg Reward (100) = -29768.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 8989: Reward = -35499.61, Avg Reward (100) = -29998.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8990: Reward = -12446.80, Avg Reward (100) = -30341.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 8991: Reward = -35499.61, Avg Reward (100) = -30111.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8992: Reward = -37669.33, Avg Reward (100) = -30111.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 8993: Reward = -35499.61, Avg Reward (100) = -30132.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8994: Reward = -35499.61, Avg Reward (100) = -30477.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8995: Reward = -35499.61, Avg Reward (100) = -30477.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8996: Reward = -1098.00, Avg Reward (100) = -30506.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 8997: Reward = -43263.20, Avg Reward (100) = -30162.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 8998: Reward = -35499.61, Avg Reward (100) = -30239.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 8999: Reward = -35499.61, Avg Reward (100) = -30239.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9000: Reward = -35499.61, Avg Reward (100) = -30239.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9001: Reward = -35499.61, Avg Reward (100) = -30239.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9002: Reward = -1394.00, Avg Reward (100) = -30584.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9003: Reward = -35499.61, Avg Reward (100) = -30243.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9004: Reward = -9048.28, Avg Reward (100) = -30243.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -9048.28, Border Penalty: -18608.47, Obstacle Penalty: -50.00
Episode 9005: Reward = -1049.00, Avg Reward (100) = -30011.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9006: Reward = -29512.46, Avg Reward (100) = -29667.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9007: Reward = -1000.00, Avg Reward (100) = -29607.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9008: Reward = -35499.61, Avg Reward (100) = -29262.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9009: Reward = -1295.00, Avg Reward (100) = -29294.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9010: Reward = -44239.55, Avg Reward (100) = -28952.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -44239.55, Border Penalty: -33822.50, Obstacle Penalty: -50.00
Episode 9011: Reward = -35499.61, Avg Reward (100) = -29040.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9012: Reward = -32245.59, Avg Reward (100) = -28999.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9013: Reward = -35499.61, Avg Reward (100) = -29307.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9014: Reward = -47848.55, Avg Reward (100) = -29307.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9015: Reward = -1000.00, Avg Reward (100) = -29533.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9016: Reward = -35499.61, Avg Reward (100) = -29188.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9017: Reward = -35499.61, Avg Reward (100) = -29188.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9018: Reward = -49176.10, Avg Reward (100) = -29283.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9019: Reward = -48812.51, Avg Reward (100) = -29420.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48812.51, Border Penalty: -39225.76, Obstacle Penalty: -50.00
Episode 9020: Reward = -47848.55, Avg Reward (100) = -29553.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9021: Reward = -32619.61, Avg Reward (100) = -29736.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9022: Reward = -28198.29, Avg Reward (100) = -29707.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 9023: Reward = -35499.61, Avg Reward (100) = -29634.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9024: Reward = -33469.53, Avg Reward (100) = -29634.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9025: Reward = -35499.61, Avg Reward (100) = -29614.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9026: Reward = -35499.61, Avg Reward (100) = -29955.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9027: Reward = -35499.61, Avg Reward (100) = -30300.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9028: Reward = -35499.61, Avg Reward (100) = -30217.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9029: Reward = -32619.61, Avg Reward (100) = -30217.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9030: Reward = -35499.61, Avg Reward (100) = -30209.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9031: Reward = -35499.61, Avg Reward (100) = -30217.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9032: Reward = -35499.61, Avg Reward (100) = -30211.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9033: Reward = -1295.00, Avg Reward (100) = -30211.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9034: Reward = -35499.61, Avg Reward (100) = -29728.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9035: Reward = -1049.00, Avg Reward (100) = -30073.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9036: Reward = -1395.78, Avg Reward (100) = -29560.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1395.78, Border Penalty: -1747.83, Obstacle Penalty: -70.87
Episode 9037: Reward = -28683.61, Avg Reward (100) = -29219.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9038: Reward = -35499.61, Avg Reward (100) = -29183.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9039: Reward = -1295.00, Avg Reward (100) = -29286.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9040: Reward = -33701.04, Avg Reward (100) = -28944.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9041: Reward = -1098.00, Avg Reward (100) = -28814.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9042: Reward = -1196.00, Avg Reward (100) = -28470.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9043: Reward = -1098.00, Avg Reward (100) = -28127.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9044: Reward = -35499.61, Avg Reward (100) = -27783.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9045: Reward = -35499.61, Avg Reward (100) = -28128.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9046: Reward = -35499.61, Avg Reward (100) = -28128.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9047: Reward = -1394.00, Avg Reward (100) = -28005.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9048: Reward = -35499.61, Avg Reward (100) = -27664.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9049: Reward = -35499.61, Avg Reward (100) = -27664.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9050: Reward = -35499.61, Avg Reward (100) = -28007.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9051: Reward = -12446.80, Avg Reward (100) = -28007.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9052: Reward = -35499.61, Avg Reward (100) = -27879.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9053: Reward = -26326.21, Avg Reward (100) = -28223.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 9054: Reward = -35499.61, Avg Reward (100) = -28131.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9055: Reward = -35499.61, Avg Reward (100) = -28131.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9056: Reward = -35499.61, Avg Reward (100) = -27890.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9057: Reward = -9566.81, Avg Reward (100) = -27890.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 9058: Reward = -12446.80, Avg Reward (100) = -27975.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9059: Reward = -1196.00, Avg Reward (100) = -27835.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9060: Reward = -1049.00, Avg Reward (100) = -27836.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9061: Reward = -35499.61, Avg Reward (100) = -27492.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9062: Reward = -25751.89, Avg Reward (100) = -27492.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 9063: Reward = -28653.56, Avg Reward (100) = -27389.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9064: Reward = -35499.61, Avg Reward (100) = -27320.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9065: Reward = -35499.61, Avg Reward (100) = -27663.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9066: Reward = -35499.61, Avg Reward (100) = -27663.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9067: Reward = -35499.61, Avg Reward (100) = -27731.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9068: Reward = -1049.00, Avg Reward (100) = -27731.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9069: Reward = -33378.53, Avg Reward (100) = -27387.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 9070: Reward = -1147.00, Avg Reward (100) = -27366.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9071: Reward = -37669.33, Avg Reward (100) = -27022.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9072: Reward = -35499.61, Avg Reward (100) = -27044.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9073: Reward = -35499.61, Avg Reward (100) = -27044.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9074: Reward = -49626.26, Avg Reward (100) = -27044.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9075: Reward = -35499.61, Avg Reward (100) = -27185.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9076: Reward = -35499.61, Avg Reward (100) = -27528.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9077: Reward = -43263.20, Avg Reward (100) = -27528.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9078: Reward = -35499.61, Avg Reward (100) = -27613.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9079: Reward = -32245.59, Avg Reward (100) = -27472.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9080: Reward = -35499.61, Avg Reward (100) = -27784.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9081: Reward = -32619.61, Avg Reward (100) = -27804.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9082: Reward = -28653.56, Avg Reward (100) = -28002.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9083: Reward = -35499.61, Avg Reward (100) = -28014.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9084: Reward = -35499.61, Avg Reward (100) = -28359.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9085: Reward = -1147.00, Avg Reward (100) = -28359.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9086: Reward = -35499.61, Avg Reward (100) = -28015.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9087: Reward = -49176.10, Avg Reward (100) = -27935.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9088: Reward = -1000.00, Avg Reward (100) = -28104.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9089: Reward = -35499.61, Avg Reward (100) = -27759.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9090: Reward = -35499.61, Avg Reward (100) = -27759.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9091: Reward = -35499.61, Avg Reward (100) = -27990.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9092: Reward = -35499.61, Avg Reward (100) = -27990.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9093: Reward = -35499.61, Avg Reward (100) = -27968.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9094: Reward = -1000.00, Avg Reward (100) = -27968.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9095: Reward = -12446.80, Avg Reward (100) = -27623.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9096: Reward = -1147.00, Avg Reward (100) = -27392.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9097: Reward = -35499.61, Avg Reward (100) = -27393.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9098: Reward = -35499.61, Avg Reward (100) = -27315.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9099: Reward = -35499.61, Avg Reward (100) = -27315.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9100: Reward = -34164.73, Avg Reward (100) = -27315.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 9101: Reward = -35499.61, Avg Reward (100) = -27302.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9102: Reward = -35499.61, Avg Reward (100) = -27302.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9103: Reward = -28683.61, Avg Reward (100) = -27643.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9104: Reward = -32245.59, Avg Reward (100) = -27575.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9105: Reward = -33701.04, Avg Reward (100) = -27807.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9106: Reward = -25228.52, Avg Reward (100) = -28133.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9107: Reward = -1295.00, Avg Reward (100) = -28090.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9108: Reward = -34685.86, Avg Reward (100) = -28093.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9109: Reward = -35499.61, Avg Reward (100) = -28085.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9110: Reward = -1394.00, Avg Reward (100) = -28427.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9111: Reward = -39606.20, Avg Reward (100) = -27999.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9112: Reward = -39135.41, Avg Reward (100) = -28040.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39135.41, Border Penalty: -36959.92, Obstacle Penalty: -50.00
Episode 9113: Reward = -1394.00, Avg Reward (100) = -28109.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9114: Reward = -1196.00, Avg Reward (100) = -27768.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9115: Reward = -1049.00, Avg Reward (100) = -27301.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9116: Reward = -1098.00, Avg Reward (100) = -27302.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9117: Reward = -35499.61, Avg Reward (100) = -26958.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9118: Reward = -46321.87, Avg Reward (100) = -26958.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46321.87, Border Penalty: -37856.94, Obstacle Penalty: -50.00
Episode 9119: Reward = -1196.00, Avg Reward (100) = -26929.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9120: Reward = -35499.61, Avg Reward (100) = -26453.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9121: Reward = -35499.61, Avg Reward (100) = -26329.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9122: Reward = -1049.00, Avg Reward (100) = -26358.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9123: Reward = -36089.25, Avg Reward (100) = -26087.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9124: Reward = -29512.46, Avg Reward (100) = -26093.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9125: Reward = -1098.00, Avg Reward (100) = -26053.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9126: Reward = -35499.61, Avg Reward (100) = -25709.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9127: Reward = -35499.61, Avg Reward (100) = -25709.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9128: Reward = -35499.61, Avg Reward (100) = -25709.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9129: Reward = -35499.61, Avg Reward (100) = -25709.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9130: Reward = -1098.00, Avg Reward (100) = -25738.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9131: Reward = -35499.61, Avg Reward (100) = -25394.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9132: Reward = -49626.26, Avg Reward (100) = -25394.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 9133: Reward = -49176.10, Avg Reward (100) = -25535.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9134: Reward = -35499.61, Avg Reward (100) = -26014.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9135: Reward = -32619.61, Avg Reward (100) = -26014.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9136: Reward = -49176.10, Avg Reward (100) = -26330.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9137: Reward = -1000.00, Avg Reward (100) = -26807.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9138: Reward = -12446.80, Avg Reward (100) = -26531.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9139: Reward = -29512.46, Avg Reward (100) = -26300.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9140: Reward = -1098.00, Avg Reward (100) = -26582.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9141: Reward = -35499.61, Avg Reward (100) = -26256.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9142: Reward = -35499.61, Avg Reward (100) = -26600.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9143: Reward = -39606.20, Avg Reward (100) = -26943.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9144: Reward = -1196.00, Avg Reward (100) = -27328.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9145: Reward = -35499.61, Avg Reward (100) = -26985.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9146: Reward = -1049.00, Avg Reward (100) = -26985.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9147: Reward = -1147.00, Avg Reward (100) = -26641.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9148: Reward = -35499.61, Avg Reward (100) = -26638.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9149: Reward = -35499.61, Avg Reward (100) = -26638.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9150: Reward = -34741.98, Avg Reward (100) = -26638.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 9151: Reward = -35499.61, Avg Reward (100) = -26631.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9152: Reward = -47848.55, Avg Reward (100) = -26861.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 9153: Reward = -35499.61, Avg Reward (100) = -26985.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9154: Reward = -35499.61, Avg Reward (100) = -27077.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9155: Reward = -35499.61, Avg Reward (100) = -27077.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9156: Reward = -1098.00, Avg Reward (100) = -27077.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9157: Reward = -35499.61, Avg Reward (100) = -26733.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9158: Reward = -33701.04, Avg Reward (100) = -26992.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9159: Reward = -35499.61, Avg Reward (100) = -27204.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9160: Reward = -35499.61, Avg Reward (100) = -27547.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9161: Reward = -35499.61, Avg Reward (100) = -27892.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9162: Reward = -35499.61, Avg Reward (100) = -27892.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9163: Reward = -39606.20, Avg Reward (100) = -27989.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9164: Reward = -35499.61, Avg Reward (100) = -28099.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9165: Reward = -35499.61, Avg Reward (100) = -28099.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9166: Reward = -5512.44, Avg Reward (100) = -28099.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -5512.44, Border Penalty: -12922.87, Obstacle Penalty: -50.00
Episode 9167: Reward = -35499.61, Avg Reward (100) = -27799.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9168: Reward = -35499.61, Avg Reward (100) = -27799.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9169: Reward = -32245.59, Avg Reward (100) = -28144.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9170: Reward = -32619.61, Avg Reward (100) = -28132.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9171: Reward = -35499.61, Avg Reward (100) = -28447.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9172: Reward = -37669.33, Avg Reward (100) = -28425.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9173: Reward = -35499.61, Avg Reward (100) = -28447.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9174: Reward = -35499.61, Avg Reward (100) = -28447.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9175: Reward = -1295.00, Avg Reward (100) = -28306.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9176: Reward = -1000.00, Avg Reward (100) = -27964.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9177: Reward = -43263.20, Avg Reward (100) = -27619.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9178: Reward = -36089.25, Avg Reward (100) = -27619.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 9179: Reward = -26061.91, Avg Reward (100) = -27625.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26061.91, Border Penalty: -30748.40, Obstacle Penalty: -50.00
Episode 9180: Reward = -35499.61, Avg Reward (100) = -27563.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9181: Reward = -43263.20, Avg Reward (100) = -27563.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9182: Reward = -29220.94, Avg Reward (100) = -27669.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29220.94, Border Penalty: -32231.25, Obstacle Penalty: -50.00
Episode 9183: Reward = -32235.76, Avg Reward (100) = -27675.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 9184: Reward = -35499.61, Avg Reward (100) = -27642.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9185: Reward = -33701.04, Avg Reward (100) = -27642.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9186: Reward = -57378.85, Avg Reward (100) = -27968.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -57378.85, Border Penalty: -39620.28, Obstacle Penalty: -50.00
Episode 9187: Reward = -35499.61, Avg Reward (100) = -28187.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9188: Reward = -35499.61, Avg Reward (100) = -28050.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9189: Reward = -1000.00, Avg Reward (100) = -28395.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9190: Reward = -47848.55, Avg Reward (100) = -28050.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9191: Reward = -35499.61, Avg Reward (100) = -28173.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9192: Reward = -35499.61, Avg Reward (100) = -28173.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9193: Reward = -32619.61, Avg Reward (100) = -28173.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9194: Reward = -35499.61, Avg Reward (100) = -28144.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9195: Reward = -35499.61, Avg Reward (100) = -28489.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9196: Reward = -47848.55, Avg Reward (100) = -28720.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9197: Reward = -1294.00, Avg Reward (100) = -29187.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9198: Reward = -35499.61, Avg Reward (100) = -28845.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9199: Reward = -35499.61, Avg Reward (100) = -28845.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9200: Reward = -35499.61, Avg Reward (100) = -28845.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9201: Reward = -1196.00, Avg Reward (100) = -28858.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9202: Reward = -35499.61, Avg Reward (100) = -28515.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9203: Reward = -35499.61, Avg Reward (100) = -28515.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9204: Reward = -1098.00, Avg Reward (100) = -28583.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9205: Reward = -35499.61, Avg Reward (100) = -28272.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9206: Reward = -28653.56, Avg Reward (100) = -28290.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9207: Reward = -35499.61, Avg Reward (100) = -28324.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9208: Reward = -35499.61, Avg Reward (100) = -28666.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9209: Reward = -35499.61, Avg Reward (100) = -28674.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9210: Reward = -37669.33, Avg Reward (100) = -28674.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9211: Reward = -1049.00, Avg Reward (100) = -29037.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9212: Reward = -35499.61, Avg Reward (100) = -28652.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9213: Reward = -33469.53, Avg Reward (100) = -28615.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9214: Reward = -35499.61, Avg Reward (100) = -28936.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9215: Reward = -35499.61, Avg Reward (100) = -29279.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9216: Reward = -35499.61, Avg Reward (100) = -29623.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9217: Reward = -35499.61, Avg Reward (100) = -29967.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9218: Reward = -35499.61, Avg Reward (100) = -29967.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9219: Reward = -35499.61, Avg Reward (100) = -29859.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9220: Reward = -28683.61, Avg Reward (100) = -30202.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9221: Reward = -35499.61, Avg Reward (100) = -30134.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9222: Reward = -35499.61, Avg Reward (100) = -30134.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9223: Reward = -1147.00, Avg Reward (100) = -30479.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9224: Reward = -35499.61, Avg Reward (100) = -30129.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9225: Reward = -35499.61, Avg Reward (100) = -30189.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9226: Reward = -35499.61, Avg Reward (100) = -30533.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9227: Reward = -1098.00, Avg Reward (100) = -30533.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9228: Reward = -1000.00, Avg Reward (100) = -30189.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9229: Reward = -35499.61, Avg Reward (100) = -29844.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9230: Reward = -35499.61, Avg Reward (100) = -29844.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9231: Reward = -34685.86, Avg Reward (100) = -30188.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9232: Reward = -35499.61, Avg Reward (100) = -30180.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9233: Reward = -31653.57, Avg Reward (100) = -30039.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -32812.61, Obstacle Penalty: -50.00
Episode 9234: Reward = -35499.61, Avg Reward (100) = -29863.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9235: Reward = -35499.61, Avg Reward (100) = -29863.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9236: Reward = -33701.04, Avg Reward (100) = -29892.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9237: Reward = -35499.61, Avg Reward (100) = -29738.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9238: Reward = -9566.81, Avg Reward (100) = -30083.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 9239: Reward = -49626.26, Avg Reward (100) = -30054.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9240: Reward = -33701.04, Avg Reward (100) = -30255.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9241: Reward = -35499.61, Avg Reward (100) = -30581.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9242: Reward = -35499.61, Avg Reward (100) = -30581.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9243: Reward = -48044.60, Avg Reward (100) = -30581.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -39571.43, Obstacle Penalty: -50.00
Episode 9244: Reward = -35499.61, Avg Reward (100) = -30665.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9245: Reward = -43263.20, Avg Reward (100) = -31008.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9246: Reward = -35499.61, Avg Reward (100) = -31086.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9247: Reward = -28653.56, Avg Reward (100) = -31430.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 9248: Reward = -35499.61, Avg Reward (100) = -31706.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9249: Reward = -36089.25, Avg Reward (100) = -31706.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9250: Reward = -35499.61, Avg Reward (100) = -31711.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9251: Reward = -1000.00, Avg Reward (100) = -31719.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9252: Reward = -35499.61, Avg Reward (100) = -31374.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9253: Reward = -51921.07, Avg Reward (100) = -31250.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51921.07, Border Penalty: -39998.94, Obstacle Penalty: -50.00
Episode 9254: Reward = -35499.61, Avg Reward (100) = -31415.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9255: Reward = -35499.61, Avg Reward (100) = -31415.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9256: Reward = -37669.33, Avg Reward (100) = -31415.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9257: Reward = -37669.33, Avg Reward (100) = -31780.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9258: Reward = -49285.73, Avg Reward (100) = -31802.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49285.73, Border Penalty: -40370.16, Obstacle Penalty: -50.00
Episode 9259: Reward = -35499.61, Avg Reward (100) = -31958.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9260: Reward = -35499.61, Avg Reward (100) = -31958.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9261: Reward = -12446.80, Avg Reward (100) = -31958.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9262: Reward = -35499.61, Avg Reward (100) = -31727.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9263: Reward = -35499.61, Avg Reward (100) = -31727.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9264: Reward = -35499.61, Avg Reward (100) = -31686.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9265: Reward = -10868.79, Avg Reward (100) = -31686.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -10868.79, Border Penalty: -20727.79, Obstacle Penalty: -50.00
Episode 9266: Reward = -35499.61, Avg Reward (100) = -31440.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9267: Reward = -32851.49, Avg Reward (100) = -31740.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 9268: Reward = -39606.20, Avg Reward (100) = -31713.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9269: Reward = -35499.61, Avg Reward (100) = -31755.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9270: Reward = -47848.55, Avg Reward (100) = -31787.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9271: Reward = -43263.20, Avg Reward (100) = -31939.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9272: Reward = -12446.80, Avg Reward (100) = -32017.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9273: Reward = -35499.61, Avg Reward (100) = -31765.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9274: Reward = -1000.00, Avg Reward (100) = -31765.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9275: Reward = -35499.61, Avg Reward (100) = -31420.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9276: Reward = -35499.61, Avg Reward (100) = -31762.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9277: Reward = -35499.61, Avg Reward (100) = -32107.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9278: Reward = -1000.00, Avg Reward (100) = -32029.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9279: Reward = -32619.61, Avg Reward (100) = -31678.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9280: Reward = -25228.52, Avg Reward (100) = -31744.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9281: Reward = -1147.00, Avg Reward (100) = -31641.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9282: Reward = -35499.61, Avg Reward (100) = -31220.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9283: Reward = -35499.61, Avg Reward (100) = -31283.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9284: Reward = -33469.53, Avg Reward (100) = -31315.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9285: Reward = -50329.95, Avg Reward (100) = -31295.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50329.95, Border Penalty: -39553.62, Obstacle Penalty: -50.00
Episode 9286: Reward = -35499.61, Avg Reward (100) = -31461.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9287: Reward = -1049.00, Avg Reward (100) = -31243.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9288: Reward = -35499.61, Avg Reward (100) = -30898.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9289: Reward = -35468.23, Avg Reward (100) = -30898.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35468.23, Border Penalty: -35365.46, Obstacle Penalty: -50.00
Episode 9290: Reward = -26470.74, Avg Reward (100) = -31243.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 9291: Reward = -35499.61, Avg Reward (100) = -31029.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9292: Reward = -35499.61, Avg Reward (100) = -31029.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9293: Reward = -35499.61, Avg Reward (100) = -31029.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9294: Reward = -32619.61, Avg Reward (100) = -31058.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9295: Reward = -35499.61, Avg Reward (100) = -31029.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9296: Reward = -35499.61, Avg Reward (100) = -31029.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9297: Reward = -35499.61, Avg Reward (100) = -30906.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9298: Reward = -35499.61, Avg Reward (100) = -31248.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9299: Reward = -28653.56, Avg Reward (100) = -31248.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9300: Reward = -43991.18, Avg Reward (100) = -31179.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43991.18, Border Penalty: -38112.80, Obstacle Penalty: -50.00
Episode 9301: Reward = -1098.00, Avg Reward (100) = -31264.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9302: Reward = -1147.00, Avg Reward (100) = -31263.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9303: Reward = -29512.46, Avg Reward (100) = -30920.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9304: Reward = -1295.00, Avg Reward (100) = -30860.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9305: Reward = -35499.61, Avg Reward (100) = -30862.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9306: Reward = -35499.61, Avg Reward (100) = -30862.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9307: Reward = -1000.00, Avg Reward (100) = -30930.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9308: Reward = -35499.61, Avg Reward (100) = -30585.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9309: Reward = -1196.00, Avg Reward (100) = -30585.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9310: Reward = -35499.61, Avg Reward (100) = -30242.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9311: Reward = -1394.00, Avg Reward (100) = -30220.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9312: Reward = -33469.53, Avg Reward (100) = -30224.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9313: Reward = -35499.61, Avg Reward (100) = -30203.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9314: Reward = -35499.61, Avg Reward (100) = -30224.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9315: Reward = -35499.61, Avg Reward (100) = -30224.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9316: Reward = -12446.80, Avg Reward (100) = -30224.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9317: Reward = -35499.61, Avg Reward (100) = -29993.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9318: Reward = -35499.61, Avg Reward (100) = -29993.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9319: Reward = -35499.61, Avg Reward (100) = -29993.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9320: Reward = -35499.61, Avg Reward (100) = -29993.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9321: Reward = -25228.52, Avg Reward (100) = -30061.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9322: Reward = -35499.61, Avg Reward (100) = -29959.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9323: Reward = -37669.33, Avg Reward (100) = -29959.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9324: Reward = -52315.20, Avg Reward (100) = -30324.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 9325: Reward = -35499.61, Avg Reward (100) = -30492.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9326: Reward = -35499.61, Avg Reward (100) = -30492.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9327: Reward = -35499.61, Avg Reward (100) = -30492.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9328: Reward = -29512.46, Avg Reward (100) = -30836.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9329: Reward = -35499.61, Avg Reward (100) = -31121.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9330: Reward = -33701.04, Avg Reward (100) = -31121.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9331: Reward = -49626.26, Avg Reward (100) = -31103.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9332: Reward = -35499.61, Avg Reward (100) = -31253.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9333: Reward = -35499.61, Avg Reward (100) = -31253.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9334: Reward = -1049.00, Avg Reward (100) = -31291.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9335: Reward = -35499.61, Avg Reward (100) = -30947.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9336: Reward = -39606.20, Avg Reward (100) = -30947.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9337: Reward = -35499.61, Avg Reward (100) = -31006.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9338: Reward = -35499.61, Avg Reward (100) = -31006.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9339: Reward = -41016.83, Avg Reward (100) = -31265.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -41016.83, Border Penalty: -32467.24, Obstacle Penalty: -50.00
Episode 9340: Reward = -35499.61, Avg Reward (100) = -31179.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9341: Reward = -35499.61, Avg Reward (100) = -31197.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9342: Reward = -35499.61, Avg Reward (100) = -31197.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9343: Reward = -1295.00, Avg Reward (100) = -31197.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9344: Reward = -1295.00, Avg Reward (100) = -30729.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9345: Reward = -35499.61, Avg Reward (100) = -30387.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9346: Reward = -33701.04, Avg Reward (100) = -30310.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9347: Reward = -49176.10, Avg Reward (100) = -30292.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9348: Reward = -35499.61, Avg Reward (100) = -30497.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9349: Reward = -35499.61, Avg Reward (100) = -30497.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9350: Reward = -28683.61, Avg Reward (100) = -30491.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9351: Reward = -35499.61, Avg Reward (100) = -30423.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9352: Reward = -35499.61, Avg Reward (100) = -30768.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9353: Reward = -35499.61, Avg Reward (100) = -30768.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9354: Reward = -1147.00, Avg Reward (100) = -30604.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9355: Reward = -35499.61, Avg Reward (100) = -30260.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9356: Reward = -35499.61, Avg Reward (100) = -30260.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9357: Reward = -35499.61, Avg Reward (100) = -30238.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9358: Reward = -35499.61, Avg Reward (100) = -30217.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9359: Reward = -1098.00, Avg Reward (100) = -30079.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9360: Reward = -42103.80, Avg Reward (100) = -29735.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42103.80, Border Penalty: -37936.77, Obstacle Penalty: -50.00
Episode 9361: Reward = -35499.61, Avg Reward (100) = -29801.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9362: Reward = -35499.61, Avg Reward (100) = -30031.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9363: Reward = -35499.61, Avg Reward (100) = -30031.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9364: Reward = -1049.00, Avg Reward (100) = -30031.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9365: Reward = -28683.61, Avg Reward (100) = -29687.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -29464.60, Obstacle Penalty: -50.00
Episode 9366: Reward = -1098.00, Avg Reward (100) = -29865.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9367: Reward = -1098.00, Avg Reward (100) = -29521.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9368: Reward = -28683.61, Avg Reward (100) = -29204.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9369: Reward = -35499.61, Avg Reward (100) = -29094.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9370: Reward = -35499.61, Avg Reward (100) = -29094.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9371: Reward = -35499.61, Avg Reward (100) = -28971.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9372: Reward = -35499.61, Avg Reward (100) = -28893.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9373: Reward = -35499.61, Avg Reward (100) = -29124.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9374: Reward = -32632.70, Avg Reward (100) = -29124.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -32955.05, Obstacle Penalty: -50.00
Episode 9375: Reward = -12446.80, Avg Reward (100) = -29440.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9376: Reward = -35499.61, Avg Reward (100) = -29210.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9377: Reward = -39606.20, Avg Reward (100) = -29210.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9378: Reward = -12446.80, Avg Reward (100) = -29251.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9379: Reward = -35499.61, Avg Reward (100) = -29365.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9380: Reward = -35499.61, Avg Reward (100) = -29394.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9381: Reward = -35499.61, Avg Reward (100) = -29497.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9382: Reward = -49176.10, Avg Reward (100) = -29840.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9383: Reward = -35499.61, Avg Reward (100) = -29977.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9384: Reward = -37669.33, Avg Reward (100) = -29977.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9385: Reward = -35499.61, Avg Reward (100) = -30019.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9386: Reward = -1147.00, Avg Reward (100) = -29871.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9387: Reward = -35499.61, Avg Reward (100) = -29527.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9388: Reward = -35499.61, Avg Reward (100) = -29872.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9389: Reward = -26787.09, Avg Reward (100) = -29872.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 9390: Reward = -35499.61, Avg Reward (100) = -29785.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9391: Reward = -1196.00, Avg Reward (100) = -29875.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9392: Reward = -1147.00, Avg Reward (100) = -29532.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9393: Reward = -35499.61, Avg Reward (100) = -29188.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9394: Reward = -1000.00, Avg Reward (100) = -29188.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9395: Reward = -35499.61, Avg Reward (100) = -28872.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9396: Reward = -28653.56, Avg Reward (100) = -28872.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9397: Reward = -35499.61, Avg Reward (100) = -28804.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9398: Reward = -1049.00, Avg Reward (100) = -28804.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9399: Reward = -34685.86, Avg Reward (100) = -28459.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9400: Reward = -35499.61, Avg Reward (100) = -28520.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9401: Reward = -35499.61, Avg Reward (100) = -28435.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9402: Reward = -35499.61, Avg Reward (100) = -28779.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9403: Reward = -35499.61, Avg Reward (100) = -29122.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9404: Reward = -53334.41, Avg Reward (100) = -29182.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 9405: Reward = -35499.61, Avg Reward (100) = -29702.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9406: Reward = -35499.61, Avg Reward (100) = -29702.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9407: Reward = -35499.61, Avg Reward (100) = -29702.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9408: Reward = -35499.61, Avg Reward (100) = -30047.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9409: Reward = -35499.61, Avg Reward (100) = -30047.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9410: Reward = -35499.61, Avg Reward (100) = -30391.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9411: Reward = -28683.61, Avg Reward (100) = -30391.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9412: Reward = -35499.61, Avg Reward (100) = -30663.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9413: Reward = -35499.61, Avg Reward (100) = -30684.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9414: Reward = -35499.61, Avg Reward (100) = -30684.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9415: Reward = -1196.00, Avg Reward (100) = -30684.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9416: Reward = -35499.61, Avg Reward (100) = -30341.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9417: Reward = -39606.20, Avg Reward (100) = -30571.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9418: Reward = -35499.61, Avg Reward (100) = -30612.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9419: Reward = -35499.61, Avg Reward (100) = -30612.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9420: Reward = -1394.00, Avg Reward (100) = -30612.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9421: Reward = -35499.61, Avg Reward (100) = -30271.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9422: Reward = -35499.61, Avg Reward (100) = -30374.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9423: Reward = -12446.80, Avg Reward (100) = -30374.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9424: Reward = -28683.61, Avg Reward (100) = -30122.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9425: Reward = -35499.61, Avg Reward (100) = -29885.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9426: Reward = -35499.61, Avg Reward (100) = -29885.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9427: Reward = -26326.21, Avg Reward (100) = -29885.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 9428: Reward = -35499.61, Avg Reward (100) = -29794.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9429: Reward = -32245.59, Avg Reward (100) = -29854.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9430: Reward = -1049.00, Avg Reward (100) = -29821.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9431: Reward = -47848.55, Avg Reward (100) = -29494.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9432: Reward = -1147.00, Avg Reward (100) = -29477.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9433: Reward = -35499.61, Avg Reward (100) = -29133.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9434: Reward = -1049.00, Avg Reward (100) = -29133.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9435: Reward = -49626.26, Avg Reward (100) = -29133.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 9436: Reward = -35499.61, Avg Reward (100) = -29274.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9437: Reward = -35499.61, Avg Reward (100) = -29233.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9438: Reward = -52333.05, Avg Reward (100) = -29233.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40617.02, Obstacle Penalty: -50.00
Episode 9439: Reward = -12769.82, Avg Reward (100) = -29402.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -12769.82, Border Penalty: -22136.90, Obstacle Penalty: -50.00
Episode 9440: Reward = -43802.69, Avg Reward (100) = -29119.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 9441: Reward = -38414.23, Avg Reward (100) = -29202.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -36175.60, Obstacle Penalty: -50.00
Episode 9442: Reward = -32245.59, Avg Reward (100) = -29231.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9443: Reward = -35499.61, Avg Reward (100) = -29199.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9444: Reward = -35499.61, Avg Reward (100) = -29541.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9445: Reward = -28653.56, Avg Reward (100) = -29883.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9446: Reward = -46653.19, Avg Reward (100) = -29814.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 9447: Reward = -32619.61, Avg Reward (100) = -29944.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9448: Reward = -1196.00, Avg Reward (100) = -29778.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9449: Reward = -35499.61, Avg Reward (100) = -29435.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9450: Reward = -35499.61, Avg Reward (100) = -29435.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9451: Reward = -1098.00, Avg Reward (100) = -29504.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9452: Reward = -35499.61, Avg Reward (100) = -29160.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9453: Reward = -34911.19, Avg Reward (100) = -29160.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 18, Reward Breakdown -> Delta_x Reward: -34911.19, Border Penalty: -35568.93, Obstacle Penalty: -50.00
Episode 9454: Reward = -49176.10, Avg Reward (100) = -29154.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9455: Reward = -28683.61, Avg Reward (100) = -29634.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9456: Reward = -35499.61, Avg Reward (100) = -29566.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9457: Reward = -35499.61, Avg Reward (100) = -29566.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9458: Reward = -35499.61, Avg Reward (100) = -29566.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9459: Reward = -35499.61, Avg Reward (100) = -29566.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9460: Reward = -35499.61, Avg Reward (100) = -29910.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9461: Reward = -35499.61, Avg Reward (100) = -29844.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9462: Reward = -35499.61, Avg Reward (100) = -29844.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9463: Reward = -35499.61, Avg Reward (100) = -29844.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9464: Reward = -1000.00, Avg Reward (100) = -29844.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9465: Reward = -35499.61, Avg Reward (100) = -29843.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9466: Reward = -12446.80, Avg Reward (100) = -29911.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9467: Reward = -35499.61, Avg Reward (100) = -30025.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9468: Reward = -35499.61, Avg Reward (100) = -30369.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9469: Reward = -28653.56, Avg Reward (100) = -30437.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9470: Reward = -35499.61, Avg Reward (100) = -30369.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9471: Reward = -1049.00, Avg Reward (100) = -30369.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9472: Reward = -36022.43, Avg Reward (100) = -30024.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 9473: Reward = -35499.61, Avg Reward (100) = -30029.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9474: Reward = -35499.61, Avg Reward (100) = -30029.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9475: Reward = -35499.61, Avg Reward (100) = -30058.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9476: Reward = -35499.61, Avg Reward (100) = -30289.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9477: Reward = -39606.20, Avg Reward (100) = -30289.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9478: Reward = -35499.61, Avg Reward (100) = -30289.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9479: Reward = -35499.61, Avg Reward (100) = -30519.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9480: Reward = -1000.00, Avg Reward (100) = -30519.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9481: Reward = -1049.00, Avg Reward (100) = -30174.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9482: Reward = -39606.20, Avg Reward (100) = -29830.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9483: Reward = -9048.28, Avg Reward (100) = -29734.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -9048.28, Border Penalty: -18608.47, Obstacle Penalty: -50.00
Episode 9484: Reward = -49626.26, Avg Reward (100) = -29469.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9485: Reward = -35499.61, Avg Reward (100) = -29589.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9486: Reward = -28653.56, Avg Reward (100) = -29589.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9487: Reward = -1196.00, Avg Reward (100) = -29864.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9488: Reward = -35499.61, Avg Reward (100) = -29521.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9489: Reward = -35499.61, Avg Reward (100) = -29521.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9490: Reward = -35499.61, Avg Reward (100) = -29608.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9491: Reward = -35499.61, Avg Reward (100) = -29608.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9492: Reward = -1196.00, Avg Reward (100) = -29951.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9493: Reward = -49176.10, Avg Reward (100) = -29952.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9494: Reward = -35499.61, Avg Reward (100) = -30088.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9495: Reward = -32619.61, Avg Reward (100) = -30433.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9496: Reward = -35499.61, Avg Reward (100) = -30405.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9497: Reward = -35499.61, Avg Reward (100) = -30473.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9498: Reward = -1000.00, Avg Reward (100) = -30473.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9499: Reward = -44524.86, Avg Reward (100) = -30473.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44524.86, Border Penalty: -38099.33, Obstacle Penalty: -50.00
Episode 9500: Reward = -35499.61, Avg Reward (100) = -30571.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9501: Reward = -36089.25, Avg Reward (100) = -30571.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9502: Reward = -38306.90, Avg Reward (100) = -30577.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 9503: Reward = -35499.61, Avg Reward (100) = -30605.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9504: Reward = -37669.33, Avg Reward (100) = -30605.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9505: Reward = -35499.61, Avg Reward (100) = -30448.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9506: Reward = -29512.46, Avg Reward (100) = -30448.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9507: Reward = -35499.61, Avg Reward (100) = -30388.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9508: Reward = -1000.00, Avg Reward (100) = -30388.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9509: Reward = -49176.10, Avg Reward (100) = -30043.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9510: Reward = -35499.61, Avg Reward (100) = -30180.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9511: Reward = -35499.61, Avg Reward (100) = -30180.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9512: Reward = -37799.90, Avg Reward (100) = -30248.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37799.90, Border Penalty: -35729.16, Obstacle Penalty: -50.00
Episode 9513: Reward = -1394.00, Avg Reward (100) = -30271.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9514: Reward = -33469.53, Avg Reward (100) = -29930.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9515: Reward = -1147.00, Avg Reward (100) = -29910.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9516: Reward = -35499.61, Avg Reward (100) = -29909.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9517: Reward = -1000.00, Avg Reward (100) = -29909.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9518: Reward = -43263.20, Avg Reward (100) = -29523.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9519: Reward = -1394.00, Avg Reward (100) = -29601.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9520: Reward = -35499.61, Avg Reward (100) = -29260.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9521: Reward = -35499.61, Avg Reward (100) = -29601.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9522: Reward = -35499.61, Avg Reward (100) = -29601.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9523: Reward = -35499.61, Avg Reward (100) = -29601.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9524: Reward = -35499.61, Avg Reward (100) = -29832.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9525: Reward = -1295.00, Avg Reward (100) = -29900.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9526: Reward = -35499.61, Avg Reward (100) = -29558.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9527: Reward = -35499.61, Avg Reward (100) = -29558.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9528: Reward = -35499.61, Avg Reward (100) = -29649.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9529: Reward = -34685.86, Avg Reward (100) = -29649.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9530: Reward = -1394.00, Avg Reward (100) = -29674.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9531: Reward = -28653.56, Avg Reward (100) = -29677.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9532: Reward = -35499.61, Avg Reward (100) = -29485.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9533: Reward = -33469.53, Avg Reward (100) = -29829.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9534: Reward = -1000.00, Avg Reward (100) = -29809.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9535: Reward = -35499.61, Avg Reward (100) = -29808.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9536: Reward = -43569.45, Avg Reward (100) = -29667.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43569.45, Border Penalty: -37743.09, Obstacle Penalty: -50.00
Episode 9537: Reward = -36089.25, Avg Reward (100) = -29748.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9538: Reward = -33469.53, Avg Reward (100) = -29753.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9539: Reward = -35499.61, Avg Reward (100) = -29565.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9540: Reward = -35499.61, Avg Reward (100) = -29792.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9541: Reward = -35499.61, Avg Reward (100) = -29709.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9542: Reward = -35499.61, Avg Reward (100) = -29680.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9543: Reward = -35499.61, Avg Reward (100) = -29712.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9544: Reward = -1394.00, Avg Reward (100) = -29712.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9545: Reward = -49626.26, Avg Reward (100) = -29371.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9546: Reward = -1049.00, Avg Reward (100) = -29581.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9547: Reward = -35499.61, Avg Reward (100) = -29125.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9548: Reward = -28653.56, Avg Reward (100) = -29154.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9549: Reward = -35499.61, Avg Reward (100) = -29428.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9550: Reward = -35499.61, Avg Reward (100) = -29428.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9551: Reward = -36618.19, Avg Reward (100) = -29428.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36618.19, Border Penalty: -35596.62, Obstacle Penalty: -50.00
Episode 9552: Reward = -39606.20, Avg Reward (100) = -29784.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9553: Reward = -35499.61, Avg Reward (100) = -29825.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9554: Reward = -35499.61, Avg Reward (100) = -29831.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9555: Reward = -35499.61, Avg Reward (100) = -29694.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9556: Reward = -35499.61, Avg Reward (100) = -29762.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9557: Reward = -35499.61, Avg Reward (100) = -29762.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9558: Reward = -35499.61, Avg Reward (100) = -29762.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9559: Reward = -37669.33, Avg Reward (100) = -29762.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9560: Reward = -35499.61, Avg Reward (100) = -29784.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9561: Reward = -35499.61, Avg Reward (100) = -29784.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9562: Reward = -32245.59, Avg Reward (100) = -29784.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9563: Reward = -1295.00, Avg Reward (100) = -29751.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9564: Reward = -33701.04, Avg Reward (100) = -29409.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9565: Reward = -35499.61, Avg Reward (100) = -29736.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9566: Reward = -1245.00, Avg Reward (100) = -29736.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9567: Reward = -35499.61, Avg Reward (100) = -29624.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9568: Reward = -35499.61, Avg Reward (100) = -29624.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9569: Reward = -1394.00, Avg Reward (100) = -29624.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9570: Reward = -35499.61, Avg Reward (100) = -29351.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9571: Reward = -35499.61, Avg Reward (100) = -29351.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9572: Reward = -1196.00, Avg Reward (100) = -29696.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9573: Reward = -35499.61, Avg Reward (100) = -29348.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9574: Reward = -35499.61, Avg Reward (100) = -29348.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9575: Reward = -35499.61, Avg Reward (100) = -29348.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9576: Reward = -35499.61, Avg Reward (100) = -29348.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9577: Reward = -35499.61, Avg Reward (100) = -29348.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9578: Reward = -1049.00, Avg Reward (100) = -29307.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9579: Reward = -36089.25, Avg Reward (100) = -28962.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9580: Reward = -35499.61, Avg Reward (100) = -28968.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9581: Reward = -35499.61, Avg Reward (100) = -29313.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9582: Reward = -35499.61, Avg Reward (100) = -29658.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9583: Reward = -35499.61, Avg Reward (100) = -29616.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9584: Reward = -55917.21, Avg Reward (100) = -29881.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 9585: Reward = -35499.61, Avg Reward (100) = -29944.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9586: Reward = -39813.53, Avg Reward (100) = -29944.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39813.53, Border Penalty: -36223.90, Obstacle Penalty: -50.00
Episode 9587: Reward = -1049.00, Avg Reward (100) = -30056.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9588: Reward = -1000.00, Avg Reward (100) = -30054.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9589: Reward = -35499.61, Avg Reward (100) = -29709.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9590: Reward = -35499.61, Avg Reward (100) = -29709.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9591: Reward = -35499.61, Avg Reward (100) = -29709.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9592: Reward = -35499.61, Avg Reward (100) = -29709.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9593: Reward = -33469.53, Avg Reward (100) = -30052.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9594: Reward = -35499.61, Avg Reward (100) = -29895.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9595: Reward = -35499.61, Avg Reward (100) = -29895.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9596: Reward = -32619.61, Avg Reward (100) = -29924.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9597: Reward = -35499.61, Avg Reward (100) = -29895.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9598: Reward = -35499.61, Avg Reward (100) = -29895.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9599: Reward = -35499.61, Avg Reward (100) = -30240.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9600: Reward = -37669.33, Avg Reward (100) = -30150.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9601: Reward = -33701.04, Avg Reward (100) = -30171.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9602: Reward = -1196.00, Avg Reward (100) = -30148.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9603: Reward = -31906.40, Avg Reward (100) = -29776.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -31906.40, Border Penalty: -30658.66, Obstacle Penalty: -50.00
Episode 9604: Reward = -35499.61, Avg Reward (100) = -29741.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9605: Reward = -28653.56, Avg Reward (100) = -29719.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9606: Reward = -35499.61, Avg Reward (100) = -29650.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9607: Reward = -34685.86, Avg Reward (100) = -29710.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9608: Reward = -35499.61, Avg Reward (100) = -29702.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9609: Reward = -1000.00, Avg Reward (100) = -30047.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9610: Reward = -36089.25, Avg Reward (100) = -29565.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9611: Reward = -35499.61, Avg Reward (100) = -29571.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9612: Reward = -35499.61, Avg Reward (100) = -29571.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9613: Reward = -35499.61, Avg Reward (100) = -29548.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9614: Reward = -34685.86, Avg Reward (100) = -29889.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9615: Reward = -35499.61, Avg Reward (100) = -29901.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9616: Reward = -35499.61, Avg Reward (100) = -30245.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9617: Reward = -35499.61, Avg Reward (100) = -30245.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9618: Reward = -35499.61, Avg Reward (100) = -30590.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9619: Reward = -28653.56, Avg Reward (100) = -30512.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 9620: Reward = -35499.61, Avg Reward (100) = -30785.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9621: Reward = -35499.61, Avg Reward (100) = -30785.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9622: Reward = -1394.00, Avg Reward (100) = -30785.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9623: Reward = -5472.60, Avg Reward (100) = -30444.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -5472.60, Border Penalty: -15256.44, Obstacle Penalty: -50.00
Episode 9624: Reward = -1049.00, Avg Reward (100) = -30144.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9625: Reward = -37669.33, Avg Reward (100) = -29799.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9626: Reward = -35499.61, Avg Reward (100) = -30163.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9627: Reward = -35499.61, Avg Reward (100) = -30163.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9628: Reward = -35499.61, Avg Reward (100) = -30163.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9629: Reward = -35499.61, Avg Reward (100) = -30163.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9630: Reward = -35499.61, Avg Reward (100) = -30171.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9631: Reward = -35499.61, Avg Reward (100) = -30512.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9632: Reward = -12446.80, Avg Reward (100) = -30581.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9633: Reward = -35499.61, Avg Reward (100) = -30350.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9634: Reward = -33469.53, Avg Reward (100) = -30370.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9635: Reward = -35499.61, Avg Reward (100) = -30695.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9636: Reward = -32619.61, Avg Reward (100) = -30695.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9637: Reward = -28653.56, Avg Reward (100) = -30585.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9638: Reward = -35499.61, Avg Reward (100) = -30511.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9639: Reward = -47025.21, Avg Reward (100) = -30531.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 9640: Reward = -1147.00, Avg Reward (100) = -30647.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9641: Reward = -1295.00, Avg Reward (100) = -30303.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9642: Reward = -36089.25, Avg Reward (100) = -29961.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9643: Reward = -28683.61, Avg Reward (100) = -29967.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9644: Reward = -35499.61, Avg Reward (100) = -29899.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9645: Reward = -36089.25, Avg Reward (100) = -30240.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 9646: Reward = -35499.61, Avg Reward (100) = -30105.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9647: Reward = -1049.00, Avg Reward (100) = -30449.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9648: Reward = -35499.61, Avg Reward (100) = -30105.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9649: Reward = -30416.69, Avg Reward (100) = -30173.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30416.69, Border Penalty: -33691.42, Obstacle Penalty: -50.00
Episode 9650: Reward = -35499.61, Avg Reward (100) = -30122.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9651: Reward = -1296.78, Avg Reward (100) = -30122.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9652: Reward = -35499.61, Avg Reward (100) = -29769.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9653: Reward = -1098.00, Avg Reward (100) = -29728.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9654: Reward = -35499.61, Avg Reward (100) = -29384.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9655: Reward = -50968.57, Avg Reward (100) = -29384.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -37193.87, Obstacle Penalty: -50.00
Episode 9656: Reward = -35499.61, Avg Reward (100) = -29539.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9657: Reward = -35499.61, Avg Reward (100) = -29539.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9658: Reward = -35499.61, Avg Reward (100) = -29539.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9659: Reward = -35499.61, Avg Reward (100) = -29539.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9660: Reward = -1245.00, Avg Reward (100) = -29517.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9661: Reward = -35499.61, Avg Reward (100) = -29174.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9662: Reward = -35499.61, Avg Reward (100) = -29174.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9663: Reward = -1000.00, Avg Reward (100) = -29207.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9664: Reward = -35499.61, Avg Reward (100) = -29204.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9665: Reward = -35499.61, Avg Reward (100) = -29222.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9666: Reward = -35499.61, Avg Reward (100) = -29222.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9667: Reward = -48016.18, Avg Reward (100) = -29564.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48016.18, Border Penalty: -39202.87, Obstacle Penalty: -50.00
Episode 9668: Reward = -35499.61, Avg Reward (100) = -29690.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9669: Reward = -1147.00, Avg Reward (100) = -29690.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9670: Reward = -37669.33, Avg Reward (100) = -29687.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9671: Reward = -35499.61, Avg Reward (100) = -29709.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9672: Reward = -35499.61, Avg Reward (100) = -29709.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9673: Reward = -1147.00, Avg Reward (100) = -30052.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9674: Reward = -35499.61, Avg Reward (100) = -29708.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9675: Reward = -35499.61, Avg Reward (100) = -29708.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9676: Reward = -35499.61, Avg Reward (100) = -29708.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9677: Reward = -32815.85, Avg Reward (100) = -29708.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 9678: Reward = -37669.33, Avg Reward (100) = -29681.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9679: Reward = -26033.58, Avg Reward (100) = -30048.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26033.58, Border Penalty: -30278.69, Obstacle Penalty: -50.00
Episode 9680: Reward = -34685.86, Avg Reward (100) = -29947.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9681: Reward = -1394.00, Avg Reward (100) = -29939.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9682: Reward = -1394.00, Avg Reward (100) = -29598.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9683: Reward = -32245.59, Avg Reward (100) = -29257.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9684: Reward = -35499.61, Avg Reward (100) = -29224.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9685: Reward = -28653.56, Avg Reward (100) = -29020.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 9686: Reward = -35499.61, Avg Reward (100) = -28952.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9687: Reward = -35499.61, Avg Reward (100) = -28909.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9688: Reward = -1394.00, Avg Reward (100) = -29253.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9689: Reward = -35499.61, Avg Reward (100) = -29257.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9690: Reward = -1196.00, Avg Reward (100) = -29257.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9691: Reward = -35499.61, Avg Reward (100) = -28914.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9692: Reward = -35499.61, Avg Reward (100) = -28914.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9693: Reward = -1000.00, Avg Reward (100) = -28914.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9694: Reward = -1000.00, Avg Reward (100) = -28589.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9695: Reward = -35499.61, Avg Reward (100) = -28244.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9696: Reward = -1049.00, Avg Reward (100) = -28244.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9697: Reward = -35499.61, Avg Reward (100) = -27929.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9698: Reward = -35499.61, Avg Reward (100) = -27929.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9699: Reward = -37669.33, Avg Reward (100) = -27929.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9700: Reward = -35499.61, Avg Reward (100) = -27950.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9701: Reward = -35499.61, Avg Reward (100) = -27929.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9702: Reward = -1147.00, Avg Reward (100) = -27947.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9703: Reward = -41280.90, Avg Reward (100) = -27946.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 9704: Reward = -35499.61, Avg Reward (100) = -28040.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9705: Reward = -35499.61, Avg Reward (100) = -28040.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9706: Reward = -35499.61, Avg Reward (100) = -28108.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9707: Reward = -34685.86, Avg Reward (100) = -28108.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9708: Reward = -35499.61, Avg Reward (100) = -28108.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9709: Reward = -35499.61, Avg Reward (100) = -28108.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9710: Reward = -1098.00, Avg Reward (100) = -28453.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9711: Reward = -35499.61, Avg Reward (100) = -28103.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9712: Reward = -28653.56, Avg Reward (100) = -28103.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9713: Reward = -36089.25, Avg Reward (100) = -28035.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9714: Reward = -35499.61, Avg Reward (100) = -28041.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9715: Reward = -35499.61, Avg Reward (100) = -28049.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9716: Reward = -35499.61, Avg Reward (100) = -28049.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9717: Reward = -12446.80, Avg Reward (100) = -28049.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9718: Reward = -52920.56, Avg Reward (100) = -27818.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52920.56, Border Penalty: -40398.08, Obstacle Penalty: -50.00
Episode 9719: Reward = -47025.21, Avg Reward (100) = -27993.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 9720: Reward = -32619.61, Avg Reward (100) = -28176.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9721: Reward = -35499.61, Avg Reward (100) = -28148.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9722: Reward = -35499.61, Avg Reward (100) = -28148.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9723: Reward = -35499.61, Avg Reward (100) = -28489.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9724: Reward = -49176.10, Avg Reward (100) = -28789.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9725: Reward = -35499.61, Avg Reward (100) = -29270.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9726: Reward = -35499.61, Avg Reward (100) = -29248.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9727: Reward = -35499.61, Avg Reward (100) = -29248.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9728: Reward = -49626.26, Avg Reward (100) = -29248.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9729: Reward = -1147.00, Avg Reward (100) = -29390.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9730: Reward = -1098.00, Avg Reward (100) = -29046.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9731: Reward = -1000.00, Avg Reward (100) = -28702.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9732: Reward = -47848.55, Avg Reward (100) = -28357.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9733: Reward = -35499.61, Avg Reward (100) = -28711.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9734: Reward = -33701.04, Avg Reward (100) = -28711.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9735: Reward = -35499.61, Avg Reward (100) = -28714.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9736: Reward = -35499.61, Avg Reward (100) = -28714.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9737: Reward = -39409.45, Avg Reward (100) = -28742.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39409.45, Border Penalty: -34826.64, Obstacle Penalty: -50.00
Episode 9738: Reward = -35499.61, Avg Reward (100) = -28850.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9739: Reward = -1000.00, Avg Reward (100) = -28850.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9740: Reward = -35499.61, Avg Reward (100) = -28390.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9741: Reward = -36089.25, Avg Reward (100) = -28733.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9742: Reward = -35499.61, Avg Reward (100) = -29081.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9743: Reward = -49176.10, Avg Reward (100) = -29075.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9744: Reward = -35499.61, Avg Reward (100) = -29280.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9745: Reward = -1098.00, Avg Reward (100) = -29280.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9746: Reward = -43263.20, Avg Reward (100) = -28930.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9747: Reward = -34741.98, Avg Reward (100) = -29008.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 9748: Reward = -33701.04, Avg Reward (100) = -29345.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9749: Reward = -37669.33, Avg Reward (100) = -29327.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9750: Reward = -35499.61, Avg Reward (100) = -29399.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9751: Reward = -1196.00, Avg Reward (100) = -29399.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9752: Reward = -39671.98, Avg Reward (100) = -29398.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39671.98, Border Penalty: -37131.56, Obstacle Penalty: -50.00
Episode 9753: Reward = -33469.53, Avg Reward (100) = -29440.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9754: Reward = -37669.33, Avg Reward (100) = -29764.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9755: Reward = -35499.61, Avg Reward (100) = -29785.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9756: Reward = -53615.70, Avg Reward (100) = -29631.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -41236.93, Obstacle Penalty: -50.00
Episode 9757: Reward = -33701.04, Avg Reward (100) = -29812.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9758: Reward = -28683.61, Avg Reward (100) = -29794.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9759: Reward = -35499.61, Avg Reward (100) = -29726.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9760: Reward = -1295.00, Avg Reward (100) = -29726.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9761: Reward = -35499.61, Avg Reward (100) = -29726.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9762: Reward = -1049.00, Avg Reward (100) = -29726.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9763: Reward = -35499.61, Avg Reward (100) = -29382.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9764: Reward = -31625.50, Avg Reward (100) = -29727.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -31625.50, Border Penalty: -32393.25, Obstacle Penalty: -50.00
Episode 9765: Reward = -1049.00, Avg Reward (100) = -29688.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9766: Reward = -1049.00, Avg Reward (100) = -29344.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9767: Reward = -35499.61, Avg Reward (100) = -28999.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9768: Reward = -1394.00, Avg Reward (100) = -28874.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9769: Reward = -1049.00, Avg Reward (100) = -28533.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9770: Reward = -35499.61, Avg Reward (100) = -28532.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9771: Reward = -35499.61, Avg Reward (100) = -28510.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9772: Reward = -35499.61, Avg Reward (100) = -28510.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9773: Reward = -35499.61, Avg Reward (100) = -28510.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9774: Reward = -49176.10, Avg Reward (100) = -28854.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9775: Reward = -44524.86, Avg Reward (100) = -28990.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44524.86, Border Penalty: -38099.33, Obstacle Penalty: -50.00
Episode 9776: Reward = -35499.61, Avg Reward (100) = -29081.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9777: Reward = -35499.61, Avg Reward (100) = -29081.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9778: Reward = -35499.61, Avg Reward (100) = -29107.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9779: Reward = -35499.61, Avg Reward (100) = -29086.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9780: Reward = -35499.61, Avg Reward (100) = -29180.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9781: Reward = -35499.61, Avg Reward (100) = -29189.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9782: Reward = -1196.00, Avg Reward (100) = -29530.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9783: Reward = -35499.61, Avg Reward (100) = -29528.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9784: Reward = -35499.61, Avg Reward (100) = -29560.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9785: Reward = -35499.61, Avg Reward (100) = -29560.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9786: Reward = -1295.00, Avg Reward (100) = -29629.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9787: Reward = -35499.61, Avg Reward (100) = -29287.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9788: Reward = -1147.00, Avg Reward (100) = -29287.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9789: Reward = -35499.61, Avg Reward (100) = -29284.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9790: Reward = -1147.00, Avg Reward (100) = -29284.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9791: Reward = -50968.57, Avg Reward (100) = -29284.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -40121.91, Obstacle Penalty: -50.00
Episode 9792: Reward = -35499.61, Avg Reward (100) = -29438.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9793: Reward = -1049.00, Avg Reward (100) = -29438.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9794: Reward = -27052.21, Avg Reward (100) = -29439.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27052.21, Border Penalty: -31213.36, Obstacle Penalty: -50.00
Episode 9795: Reward = -35499.61, Avg Reward (100) = -29699.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9796: Reward = -28653.56, Avg Reward (100) = -29699.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9797: Reward = -35499.61, Avg Reward (100) = -29975.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9798: Reward = -35499.61, Avg Reward (100) = -29975.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9799: Reward = -43263.20, Avg Reward (100) = -29975.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9800: Reward = -1394.00, Avg Reward (100) = -30031.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 9801: Reward = -35499.61, Avg Reward (100) = -29690.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9802: Reward = -35499.61, Avg Reward (100) = -29690.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9803: Reward = -35499.61, Avg Reward (100) = -30034.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9804: Reward = -35499.61, Avg Reward (100) = -29976.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9805: Reward = -52286.92, Avg Reward (100) = -29976.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52286.92, Border Penalty: -41203.02, Obstacle Penalty: -50.00
Episode 9806: Reward = -35499.61, Avg Reward (100) = -30144.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9807: Reward = -35499.61, Avg Reward (100) = -30144.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9808: Reward = -35499.61, Avg Reward (100) = -30152.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9809: Reward = -35499.61, Avg Reward (100) = -30152.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9810: Reward = -32245.59, Avg Reward (100) = -30152.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9811: Reward = -34982.32, Avg Reward (100) = -30463.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34982.32, Border Penalty: -33449.43, Obstacle Penalty: -50.00
Episode 9812: Reward = -35499.61, Avg Reward (100) = -30458.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9813: Reward = -1295.00, Avg Reward (100) = -30527.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9814: Reward = -35499.61, Avg Reward (100) = -30179.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9815: Reward = -28653.56, Avg Reward (100) = -30179.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9816: Reward = -35499.61, Avg Reward (100) = -30110.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9817: Reward = -40334.49, Avg Reward (100) = -30110.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 9818: Reward = -1000.00, Avg Reward (100) = -30389.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9819: Reward = -1098.00, Avg Reward (100) = -29870.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9820: Reward = -28834.82, Avg Reward (100) = -29411.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -28834.82, Border Penalty: -31841.71, Obstacle Penalty: -50.00
Episode 9821: Reward = -35499.61, Avg Reward (100) = -29373.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9822: Reward = -35499.61, Avg Reward (100) = -29373.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9823: Reward = -1098.00, Avg Reward (100) = -29373.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9824: Reward = -1098.00, Avg Reward (100) = -29029.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9825: Reward = -35499.61, Avg Reward (100) = -28548.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9826: Reward = -35499.61, Avg Reward (100) = -28548.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9827: Reward = -35499.61, Avg Reward (100) = -28548.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9828: Reward = -35499.61, Avg Reward (100) = -28548.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9829: Reward = -53477.40, Avg Reward (100) = -28407.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -53477.40, Border Penalty: -39653.09, Obstacle Penalty: -50.00
Episode 9830: Reward = -35499.61, Avg Reward (100) = -28930.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9831: Reward = -35499.61, Avg Reward (100) = -29274.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9832: Reward = -35499.61, Avg Reward (100) = -29619.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9833: Reward = -35499.61, Avg Reward (100) = -29496.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9834: Reward = -34685.86, Avg Reward (100) = -29496.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9835: Reward = -28683.61, Avg Reward (100) = -29506.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9836: Reward = -1394.00, Avg Reward (100) = -29437.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 9837: Reward = -1196.00, Avg Reward (100) = -29096.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9838: Reward = -49626.26, Avg Reward (100) = -28714.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9839: Reward = -35499.61, Avg Reward (100) = -28855.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9840: Reward = -35499.61, Avg Reward (100) = -29200.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9841: Reward = -35499.61, Avg Reward (100) = -29200.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9842: Reward = -28198.29, Avg Reward (100) = -29195.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 9843: Reward = -25228.52, Avg Reward (100) = -29122.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9844: Reward = -35499.61, Avg Reward (100) = -28882.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9845: Reward = -35499.61, Avg Reward (100) = -28882.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9846: Reward = -35499.61, Avg Reward (100) = -29226.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9847: Reward = -57983.46, Avg Reward (100) = -29148.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57983.46, Border Penalty: -41230.57, Obstacle Penalty: -50.00
Episode 9848: Reward = -30447.02, Avg Reward (100) = -29381.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30447.02, Border Penalty: -31610.28, Obstacle Penalty: -50.00
Episode 9849: Reward = -35499.61, Avg Reward (100) = -29348.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9850: Reward = -32619.61, Avg Reward (100) = -29327.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9851: Reward = -35499.61, Avg Reward (100) = -29298.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9852: Reward = -1147.00, Avg Reward (100) = -29641.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9853: Reward = -35499.61, Avg Reward (100) = -29256.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9854: Reward = -33469.53, Avg Reward (100) = -29276.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9855: Reward = -35499.61, Avg Reward (100) = -29234.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9856: Reward = -1147.00, Avg Reward (100) = -29234.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9857: Reward = -35499.61, Avg Reward (100) = -28709.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9858: Reward = -37669.33, Avg Reward (100) = -28727.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 9859: Reward = -1000.00, Avg Reward (100) = -28817.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9860: Reward = -35499.61, Avg Reward (100) = -28472.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9861: Reward = -47848.55, Avg Reward (100) = -28814.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 9862: Reward = -1049.00, Avg Reward (100) = -28938.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9863: Reward = -35499.61, Avg Reward (100) = -28938.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9864: Reward = -1000.00, Avg Reward (100) = -28938.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9865: Reward = -1049.00, Avg Reward (100) = -28631.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9866: Reward = -35499.61, Avg Reward (100) = -28631.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9867: Reward = -34685.86, Avg Reward (100) = -28976.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9868: Reward = -28438.08, Avg Reward (100) = -28968.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -28438.08, Border Penalty: -30917.02, Obstacle Penalty: -50.00
Episode 9869: Reward = -49626.26, Avg Reward (100) = -29238.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9870: Reward = -1049.00, Avg Reward (100) = -29724.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9871: Reward = -43263.20, Avg Reward (100) = -29379.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 9872: Reward = -43416.55, Avg Reward (100) = -29457.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43416.55, Border Penalty: -36009.30, Obstacle Penalty: -50.00
Episode 9873: Reward = -35499.61, Avg Reward (100) = -29536.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9874: Reward = -35499.61, Avg Reward (100) = -29536.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9875: Reward = -35499.61, Avg Reward (100) = -29399.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9876: Reward = -37054.55, Avg Reward (100) = -29309.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37054.55, Border Penalty: -35755.93, Obstacle Penalty: -50.00
Episode 9877: Reward = -35499.61, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9878: Reward = -35499.61, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9879: Reward = -35499.61, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9880: Reward = -35499.61, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9881: Reward = -35499.61, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9882: Reward = -1049.00, Avg Reward (100) = -29325.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9883: Reward = -35499.61, Avg Reward (100) = -29323.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9884: Reward = -46119.91, Avg Reward (100) = -29323.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46119.91, Border Penalty: -32195.27, Obstacle Penalty: -50.00
Episode 9885: Reward = -1098.00, Avg Reward (100) = -29429.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9886: Reward = -1147.00, Avg Reward (100) = -29085.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9887: Reward = -35499.61, Avg Reward (100) = -29084.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9888: Reward = -49176.10, Avg Reward (100) = -29084.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9889: Reward = -35499.61, Avg Reward (100) = -29564.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9890: Reward = -1295.00, Avg Reward (100) = -29564.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9891: Reward = -35499.61, Avg Reward (100) = -29566.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9892: Reward = -1295.00, Avg Reward (100) = -29411.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9893: Reward = -35499.61, Avg Reward (100) = -29069.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9894: Reward = -32245.59, Avg Reward (100) = -29414.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 9895: Reward = -51639.54, Avg Reward (100) = -29465.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51639.54, Border Penalty: -40925.70, Obstacle Penalty: -50.00
Episode 9896: Reward = -35499.61, Avg Reward (100) = -29627.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9897: Reward = -58806.38, Avg Reward (100) = -29695.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -58806.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 9898: Reward = -29512.46, Avg Reward (100) = -29928.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 9899: Reward = -25468.63, Avg Reward (100) = -29869.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 9900: Reward = -35499.61, Avg Reward (100) = -29691.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9901: Reward = -35499.61, Avg Reward (100) = -30032.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9902: Reward = -35499.61, Avg Reward (100) = -30032.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9903: Reward = -47848.55, Avg Reward (100) = -30032.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9904: Reward = -35499.61, Avg Reward (100) = -30155.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9905: Reward = -37256.08, Avg Reward (100) = -30155.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 9906: Reward = -12446.80, Avg Reward (100) = -30005.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9907: Reward = -1443.00, Avg Reward (100) = -29774.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1443.00, Border Penalty: -5276.28, Obstacle Penalty: -50.00
Episode 9908: Reward = -49176.10, Avg Reward (100) = -29434.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 9909: Reward = -35499.61, Avg Reward (100) = -29570.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9910: Reward = -52270.10, Avg Reward (100) = -29570.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -33387.39, Obstacle Penalty: -50.00
Episode 9911: Reward = -35499.61, Avg Reward (100) = -29771.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9912: Reward = -35499.61, Avg Reward (100) = -29776.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9913: Reward = -49626.26, Avg Reward (100) = -29776.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 9914: Reward = -35499.61, Avg Reward (100) = -30259.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9915: Reward = -35499.61, Avg Reward (100) = -30259.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9916: Reward = -33701.04, Avg Reward (100) = -30328.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9917: Reward = -35499.61, Avg Reward (100) = -30310.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9918: Reward = -1000.00, Avg Reward (100) = -30261.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9919: Reward = -35499.61, Avg Reward (100) = -30261.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9920: Reward = -35499.61, Avg Reward (100) = -30605.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9921: Reward = -1049.00, Avg Reward (100) = -30672.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9922: Reward = -35499.61, Avg Reward (100) = -30327.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9923: Reward = -35499.61, Avg Reward (100) = -30327.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9924: Reward = -35499.61, Avg Reward (100) = -30672.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9925: Reward = -47848.55, Avg Reward (100) = -31016.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9926: Reward = -33469.53, Avg Reward (100) = -31139.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 9927: Reward = -34685.86, Avg Reward (100) = -31119.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9928: Reward = -47848.55, Avg Reward (100) = -31111.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 9929: Reward = -25228.52, Avg Reward (100) = -31234.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9930: Reward = -35499.61, Avg Reward (100) = -30952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9931: Reward = -35499.61, Avg Reward (100) = -30952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9932: Reward = -35499.61, Avg Reward (100) = -30952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9933: Reward = -35499.61, Avg Reward (100) = -30952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9934: Reward = -25228.52, Avg Reward (100) = -30952.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9935: Reward = -35499.61, Avg Reward (100) = -30857.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9936: Reward = -25228.52, Avg Reward (100) = -30925.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 9937: Reward = -32619.61, Avg Reward (100) = -31164.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9938: Reward = -35499.61, Avg Reward (100) = -31478.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9939: Reward = -35499.61, Avg Reward (100) = -31336.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9940: Reward = -28653.56, Avg Reward (100) = -31336.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 9941: Reward = -35499.61, Avg Reward (100) = -31268.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9942: Reward = -35499.61, Avg Reward (100) = -31268.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9943: Reward = -35499.61, Avg Reward (100) = -31341.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9944: Reward = -35499.61, Avg Reward (100) = -31444.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9945: Reward = -36089.25, Avg Reward (100) = -31444.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 9946: Reward = -34685.86, Avg Reward (100) = -31450.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9947: Reward = -35499.61, Avg Reward (100) = -31442.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9948: Reward = -35499.61, Avg Reward (100) = -31217.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9949: Reward = -35499.61, Avg Reward (100) = -31267.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9950: Reward = -35499.61, Avg Reward (100) = -31267.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9951: Reward = -35499.61, Avg Reward (100) = -31296.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9952: Reward = -35499.61, Avg Reward (100) = -31296.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9953: Reward = -35499.61, Avg Reward (100) = -31640.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9954: Reward = -35499.61, Avg Reward (100) = -31640.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9955: Reward = -35499.61, Avg Reward (100) = -31660.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9956: Reward = -35499.61, Avg Reward (100) = -31660.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9957: Reward = -35499.61, Avg Reward (100) = -32003.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9958: Reward = -34685.86, Avg Reward (100) = -32003.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 9959: Reward = -35499.61, Avg Reward (100) = -31974.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9960: Reward = -39606.20, Avg Reward (100) = -32319.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 9961: Reward = -1000.00, Avg Reward (100) = -32360.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9962: Reward = -1049.00, Avg Reward (100) = -31891.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9963: Reward = -35499.61, Avg Reward (100) = -31891.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9964: Reward = -1098.00, Avg Reward (100) = -31891.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9965: Reward = -35499.61, Avg Reward (100) = -31892.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9966: Reward = -33701.04, Avg Reward (100) = -32237.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9967: Reward = -1196.00, Avg Reward (100) = -32219.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9968: Reward = -29726.76, Avg Reward (100) = -31884.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -29726.76, Border Penalty: -31473.70, Obstacle Penalty: -50.00
Episode 9969: Reward = -35499.61, Avg Reward (100) = -31897.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9970: Reward = -12446.80, Avg Reward (100) = -31755.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9971: Reward = -35499.61, Avg Reward (100) = -31869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9972: Reward = -35499.61, Avg Reward (100) = -31792.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9973: Reward = -35499.61, Avg Reward (100) = -31712.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9974: Reward = -29626.05, Avg Reward (100) = -31712.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 9975: Reward = -35499.61, Avg Reward (100) = -31654.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9976: Reward = -35499.61, Avg Reward (100) = -31654.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9977: Reward = -35499.61, Avg Reward (100) = -31638.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9978: Reward = -35499.61, Avg Reward (100) = -31638.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9979: Reward = -35499.61, Avg Reward (100) = -31638.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9980: Reward = -12446.80, Avg Reward (100) = -31638.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 9981: Reward = -33701.04, Avg Reward (100) = -31408.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 9982: Reward = -35499.61, Avg Reward (100) = -31390.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9983: Reward = -35499.61, Avg Reward (100) = -31734.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9984: Reward = -35499.61, Avg Reward (100) = -31734.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9985: Reward = -35499.61, Avg Reward (100) = -31628.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9986: Reward = -35499.61, Avg Reward (100) = -31972.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9987: Reward = -1196.00, Avg Reward (100) = -32316.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 9988: Reward = -1000.00, Avg Reward (100) = -31972.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9989: Reward = -35499.61, Avg Reward (100) = -31491.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 9990: Reward = -35499.61, Avg Reward (100) = -31491.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 9991: Reward = -1000.00, Avg Reward (100) = -31833.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 9992: Reward = -44987.75, Avg Reward (100) = -31488.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44987.75, Border Penalty: -38825.57, Obstacle Penalty: -50.00
Episode 9993: Reward = -28683.61, Avg Reward (100) = -31925.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 9994: Reward = -35499.61, Avg Reward (100) = -31857.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9995: Reward = -35499.61, Avg Reward (100) = -31889.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9996: Reward = -1295.00, Avg Reward (100) = -31728.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 9997: Reward = -35499.61, Avg Reward (100) = -31386.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 9998: Reward = -38414.23, Avg Reward (100) = -31153.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -36175.60, Obstacle Penalty: -50.00
Episode 9999: Reward = -32619.61, Avg Reward (100) = -31242.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 10000: Reward = -35499.61, Avg Reward (100) = -31313.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10001: Reward = -32245.59, Avg Reward (100) = -31313.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10002: Reward = -35499.61, Avg Reward (100) = -31281.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10003: Reward = -34685.86, Avg Reward (100) = -31281.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10004: Reward = -35499.61, Avg Reward (100) = -31149.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10005: Reward = -35499.61, Avg Reward (100) = -31149.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10006: Reward = -32612.87, Avg Reward (100) = -31131.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 10007: Reward = -35499.61, Avg Reward (100) = -31333.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10008: Reward = -35499.61, Avg Reward (100) = -31674.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10009: Reward = -28683.61, Avg Reward (100) = -31537.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10010: Reward = -35499.61, Avg Reward (100) = -31469.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10011: Reward = -1394.00, Avg Reward (100) = -31301.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10012: Reward = -35499.61, Avg Reward (100) = -30960.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10013: Reward = -43263.20, Avg Reward (100) = -30960.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10014: Reward = -35499.61, Avg Reward (100) = -30896.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10015: Reward = -39606.20, Avg Reward (100) = -30896.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10016: Reward = -35499.61, Avg Reward (100) = -30937.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10017: Reward = -12446.80, Avg Reward (100) = -30955.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10018: Reward = -35499.61, Avg Reward (100) = -30725.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10019: Reward = -35499.61, Avg Reward (100) = -31070.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10020: Reward = -35499.61, Avg Reward (100) = -31070.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10021: Reward = -28653.56, Avg Reward (100) = -31070.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10022: Reward = -35499.61, Avg Reward (100) = -31346.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10023: Reward = -35499.61, Avg Reward (100) = -31346.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10024: Reward = -25228.52, Avg Reward (100) = -31346.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10025: Reward = -35499.61, Avg Reward (100) = -31243.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10026: Reward = -35499.61, Avg Reward (100) = -31120.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10027: Reward = -35499.61, Avg Reward (100) = -31140.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10028: Reward = -34685.86, Avg Reward (100) = -31148.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 10029: Reward = -34927.46, Avg Reward (100) = -31016.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 10030: Reward = -35499.61, Avg Reward (100) = -31113.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10031: Reward = -34685.86, Avg Reward (100) = -31113.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10032: Reward = -1049.00, Avg Reward (100) = -31105.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10033: Reward = -29512.46, Avg Reward (100) = -30761.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10034: Reward = -35499.61, Avg Reward (100) = -30701.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10035: Reward = -39606.20, Avg Reward (100) = -30804.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10036: Reward = -35499.61, Avg Reward (100) = -30845.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10037: Reward = -35499.61, Avg Reward (100) = -30947.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10038: Reward = -35499.61, Avg Reward (100) = -30976.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10039: Reward = -35499.61, Avg Reward (100) = -30976.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10040: Reward = -35499.61, Avg Reward (100) = -30976.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10041: Reward = -9566.81, Avg Reward (100) = -31045.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 10042: Reward = -35499.61, Avg Reward (100) = -30785.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10043: Reward = -39606.20, Avg Reward (100) = -30785.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10044: Reward = -35499.61, Avg Reward (100) = -30826.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10045: Reward = -33469.53, Avg Reward (100) = -30826.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10046: Reward = -35499.61, Avg Reward (100) = -30800.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10047: Reward = -28653.56, Avg Reward (100) = -30808.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10048: Reward = -35499.61, Avg Reward (100) = -30740.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10049: Reward = -47848.55, Avg Reward (100) = -30740.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10050: Reward = -35499.61, Avg Reward (100) = -30863.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10051: Reward = -35499.61, Avg Reward (100) = -30863.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10052: Reward = -36089.25, Avg Reward (100) = -30863.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10053: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10054: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10055: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10056: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10057: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10058: Reward = -35499.61, Avg Reward (100) = -30869.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10059: Reward = -35499.61, Avg Reward (100) = -30877.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10060: Reward = -35499.61, Avg Reward (100) = -30877.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10061: Reward = -32245.59, Avg Reward (100) = -30836.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10062: Reward = -1196.00, Avg Reward (100) = -31149.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10063: Reward = -35499.61, Avg Reward (100) = -31150.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10064: Reward = -47848.55, Avg Reward (100) = -31150.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10065: Reward = -35499.61, Avg Reward (100) = -31618.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10066: Reward = -33701.04, Avg Reward (100) = -31618.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10067: Reward = -35499.61, Avg Reward (100) = -31618.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10068: Reward = -35499.61, Avg Reward (100) = -31961.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10069: Reward = -35499.61, Avg Reward (100) = -32019.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10070: Reward = -35499.61, Avg Reward (100) = -32019.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10071: Reward = -35499.61, Avg Reward (100) = -32249.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10072: Reward = -35499.61, Avg Reward (100) = -32249.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10073: Reward = -34685.86, Avg Reward (100) = -32249.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10074: Reward = -35499.61, Avg Reward (100) = -32241.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10075: Reward = -35499.61, Avg Reward (100) = -32300.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10076: Reward = -35499.61, Avg Reward (100) = -32300.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10077: Reward = -33701.04, Avg Reward (100) = -32300.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10078: Reward = -35499.61, Avg Reward (100) = -32282.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10079: Reward = -29512.46, Avg Reward (100) = -32282.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10080: Reward = -25228.52, Avg Reward (100) = -32222.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10081: Reward = -35499.61, Avg Reward (100) = -32350.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10082: Reward = -35499.61, Avg Reward (100) = -32368.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10083: Reward = -32619.61, Avg Reward (100) = -32368.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10084: Reward = -35499.61, Avg Reward (100) = -32339.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10085: Reward = -34685.86, Avg Reward (100) = -32339.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10086: Reward = -35499.61, Avg Reward (100) = -32331.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10087: Reward = -1196.00, Avg Reward (100) = -32331.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10088: Reward = -35499.61, Avg Reward (100) = -32331.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10089: Reward = -30650.91, Avg Reward (100) = -32676.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30650.91, Border Penalty: -32829.87, Obstacle Penalty: -50.00
Episode 10090: Reward = -35499.61, Avg Reward (100) = -32627.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10091: Reward = -35499.61, Avg Reward (100) = -32627.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10092: Reward = -35499.61, Avg Reward (100) = -32972.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10093: Reward = -1196.00, Avg Reward (100) = -32877.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10094: Reward = -35499.61, Avg Reward (100) = -32602.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10095: Reward = -35499.61, Avg Reward (100) = -32602.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10096: Reward = -35499.61, Avg Reward (100) = -32602.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10097: Reward = -49626.26, Avg Reward (100) = -32944.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10098: Reward = -32619.61, Avg Reward (100) = -33086.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10099: Reward = -35499.61, Avg Reward (100) = -33028.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10100: Reward = -35499.61, Avg Reward (100) = -33057.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10101: Reward = -35499.61, Avg Reward (100) = -33057.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10102: Reward = -35499.61, Avg Reward (100) = -33089.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10103: Reward = -1196.00, Avg Reward (100) = -33089.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10104: Reward = -29512.46, Avg Reward (100) = -32754.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10105: Reward = -37833.70, Avg Reward (100) = -32694.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37833.70, Border Penalty: -36129.36, Obstacle Penalty: -50.00
Episode 10106: Reward = -43263.20, Avg Reward (100) = -32718.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10107: Reward = -35499.61, Avg Reward (100) = -32824.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10108: Reward = -35499.61, Avg Reward (100) = -32824.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10109: Reward = -37256.08, Avg Reward (100) = -32824.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 10110: Reward = -1000.00, Avg Reward (100) = -32910.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10111: Reward = -35499.61, Avg Reward (100) = -32565.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10112: Reward = -35499.61, Avg Reward (100) = -32906.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10113: Reward = -28653.56, Avg Reward (100) = -32906.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10114: Reward = -35499.61, Avg Reward (100) = -32760.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10115: Reward = -35499.61, Avg Reward (100) = -32760.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10116: Reward = -1295.00, Avg Reward (100) = -32719.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10117: Reward = -34555.01, Avg Reward (100) = -32377.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -34555.01, Border Penalty: -34038.31, Obstacle Penalty: -50.00
Episode 10118: Reward = -28653.56, Avg Reward (100) = -32598.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10119: Reward = -35499.61, Avg Reward (100) = -32529.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10120: Reward = -35499.61, Avg Reward (100) = -32529.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10121: Reward = -35499.61, Avg Reward (100) = -32529.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10122: Reward = -36089.25, Avg Reward (100) = -32598.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10123: Reward = -1196.00, Avg Reward (100) = -32604.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10124: Reward = -35499.61, Avg Reward (100) = -32261.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10125: Reward = -35499.61, Avg Reward (100) = -32363.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10126: Reward = -33701.04, Avg Reward (100) = -32363.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10127: Reward = -35499.61, Avg Reward (100) = -32345.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10128: Reward = -35499.61, Avg Reward (100) = -32345.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10129: Reward = -35499.61, Avg Reward (100) = -32354.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10130: Reward = -35499.61, Avg Reward (100) = -32359.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10131: Reward = -35499.61, Avg Reward (100) = -32359.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10132: Reward = -35499.61, Avg Reward (100) = -32367.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10133: Reward = -35499.61, Avg Reward (100) = -32712.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10134: Reward = -35499.61, Avg Reward (100) = -32772.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10135: Reward = -35499.61, Avg Reward (100) = -32772.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10136: Reward = -35499.61, Avg Reward (100) = -32731.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10137: Reward = -37669.33, Avg Reward (100) = -32731.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10138: Reward = -1049.00, Avg Reward (100) = -32752.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10139: Reward = -1394.00, Avg Reward (100) = -32408.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10140: Reward = -34236.08, Avg Reward (100) = -32067.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34236.08, Border Penalty: -34470.76, Obstacle Penalty: -50.00
Episode 10141: Reward = -43263.20, Avg Reward (100) = -32054.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10142: Reward = -35499.61, Avg Reward (100) = -32391.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10143: Reward = -35499.61, Avg Reward (100) = -32391.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10144: Reward = -35499.61, Avg Reward (100) = -32350.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10145: Reward = -48772.41, Avg Reward (100) = -32350.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48772.41, Border Penalty: -39513.14, Obstacle Penalty: -50.00
Episode 10146: Reward = -35499.61, Avg Reward (100) = -32503.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10147: Reward = -32245.59, Avg Reward (100) = -32503.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 10148: Reward = -28653.56, Avg Reward (100) = -32539.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10149: Reward = -49626.26, Avg Reward (100) = -32471.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10150: Reward = -35499.61, Avg Reward (100) = -32488.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10151: Reward = -47848.55, Avg Reward (100) = -32488.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10152: Reward = -35499.61, Avg Reward (100) = -32612.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10153: Reward = -36089.25, Avg Reward (100) = -32606.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10154: Reward = -33469.53, Avg Reward (100) = -32612.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10155: Reward = -39606.20, Avg Reward (100) = -32592.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10156: Reward = -35499.61, Avg Reward (100) = -32633.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10157: Reward = -26326.21, Avg Reward (100) = -32633.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 10158: Reward = -35499.61, Avg Reward (100) = -32541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10159: Reward = -35499.61, Avg Reward (100) = -32541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10160: Reward = -28653.56, Avg Reward (100) = -32541.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10161: Reward = -35499.61, Avg Reward (100) = -32472.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10162: Reward = -1098.00, Avg Reward (100) = -32505.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10163: Reward = -35499.61, Avg Reward (100) = -32504.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10164: Reward = -35499.61, Avg Reward (100) = -32504.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10165: Reward = -35499.61, Avg Reward (100) = -32381.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10166: Reward = -35499.61, Avg Reward (100) = -32381.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10167: Reward = -35499.61, Avg Reward (100) = -32399.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10168: Reward = -29512.46, Avg Reward (100) = -32399.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10169: Reward = -35499.61, Avg Reward (100) = -32339.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10170: Reward = -1049.00, Avg Reward (100) = -32339.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10171: Reward = -28653.56, Avg Reward (100) = -31994.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10172: Reward = -1394.00, Avg Reward (100) = -31926.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10173: Reward = -32632.70, Avg Reward (100) = -31585.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 10174: Reward = -35499.61, Avg Reward (100) = -31564.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10175: Reward = -35499.61, Avg Reward (100) = -31564.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10176: Reward = -35499.61, Avg Reward (100) = -31564.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10177: Reward = -25228.52, Avg Reward (100) = -31564.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10178: Reward = -35499.61, Avg Reward (100) = -31479.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10179: Reward = -47848.55, Avg Reward (100) = -31479.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10180: Reward = -35499.61, Avg Reward (100) = -31663.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10181: Reward = -1196.00, Avg Reward (100) = -31765.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10182: Reward = -35499.61, Avg Reward (100) = -31422.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10183: Reward = -28683.61, Avg Reward (100) = -31422.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10184: Reward = -35499.61, Avg Reward (100) = -31383.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10185: Reward = -35499.61, Avg Reward (100) = -31383.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10186: Reward = -33701.04, Avg Reward (100) = -31391.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10187: Reward = -33469.53, Avg Reward (100) = -31373.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10188: Reward = -1049.00, Avg Reward (100) = -31696.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10189: Reward = -35499.61, Avg Reward (100) = -31351.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10190: Reward = -35499.61, Avg Reward (100) = -31400.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10191: Reward = -35499.61, Avg Reward (100) = -31400.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10192: Reward = -1000.00, Avg Reward (100) = -31400.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10193: Reward = -35499.61, Avg Reward (100) = -31055.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10194: Reward = -1295.00, Avg Reward (100) = -31398.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10195: Reward = -12446.80, Avg Reward (100) = -31056.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10196: Reward = -35499.61, Avg Reward (100) = -30825.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10197: Reward = -35499.61, Avg Reward (100) = -30825.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10198: Reward = -1098.00, Avg Reward (100) = -30684.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10199: Reward = -35499.61, Avg Reward (100) = -30369.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10200: Reward = -35499.61, Avg Reward (100) = -30369.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10201: Reward = -1000.00, Avg Reward (100) = -30369.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10202: Reward = -37669.33, Avg Reward (100) = -30024.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10203: Reward = -1196.00, Avg Reward (100) = -30046.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10204: Reward = -35499.61, Avg Reward (100) = -30046.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10205: Reward = -35499.61, Avg Reward (100) = -30105.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10206: Reward = -35499.61, Avg Reward (100) = -30082.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10207: Reward = -32245.59, Avg Reward (100) = -30005.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10208: Reward = -35499.61, Avg Reward (100) = -29972.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10209: Reward = -1049.00, Avg Reward (100) = -29972.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10210: Reward = -35499.61, Avg Reward (100) = -29610.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10211: Reward = -35499.61, Avg Reward (100) = -29955.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10212: Reward = -35499.61, Avg Reward (100) = -29955.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10213: Reward = -1000.00, Avg Reward (100) = -29955.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10214: Reward = -35499.61, Avg Reward (100) = -29678.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10215: Reward = -49174.12, Avg Reward (100) = -29678.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 10216: Reward = -1295.00, Avg Reward (100) = -29815.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10217: Reward = -35499.61, Avg Reward (100) = -29815.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10218: Reward = -35499.61, Avg Reward (100) = -29825.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10219: Reward = -36089.25, Avg Reward (100) = -29893.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10220: Reward = -35499.61, Avg Reward (100) = -29899.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10221: Reward = -28653.56, Avg Reward (100) = -29899.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10222: Reward = -35499.61, Avg Reward (100) = -29830.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10223: Reward = -35499.61, Avg Reward (100) = -29825.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10224: Reward = -35499.61, Avg Reward (100) = -30168.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10225: Reward = -1098.00, Avg Reward (100) = -30168.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10226: Reward = -35499.61, Avg Reward (100) = -29824.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10227: Reward = -10868.79, Avg Reward (100) = -29842.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -10868.79, Border Penalty: -20727.79, Obstacle Penalty: -50.00
Episode 10228: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10229: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10230: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10231: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10232: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10233: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10234: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10235: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10236: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10237: Reward = -35499.61, Avg Reward (100) = -29595.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10238: Reward = -35499.61, Avg Reward (100) = -29574.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10239: Reward = -35499.61, Avg Reward (100) = -29918.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10240: Reward = -35499.61, Avg Reward (100) = -30259.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10241: Reward = -28683.61, Avg Reward (100) = -30272.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10242: Reward = -35499.61, Avg Reward (100) = -30126.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10243: Reward = -1196.00, Avg Reward (100) = -30126.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10244: Reward = -38792.44, Avg Reward (100) = -29783.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 10245: Reward = -35499.61, Avg Reward (100) = -29816.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10246: Reward = -39606.20, Avg Reward (100) = -29683.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10247: Reward = -35499.61, Avg Reward (100) = -29724.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10248: Reward = -35499.61, Avg Reward (100) = -29757.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10249: Reward = -35499.61, Avg Reward (100) = -29825.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10250: Reward = -33469.53, Avg Reward (100) = -29684.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10251: Reward = -35499.61, Avg Reward (100) = -29664.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10252: Reward = -35499.61, Avg Reward (100) = -29540.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10253: Reward = -47848.55, Avg Reward (100) = -29540.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10254: Reward = -29512.46, Avg Reward (100) = -29658.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10255: Reward = -33469.53, Avg Reward (100) = -29618.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 10256: Reward = -35499.61, Avg Reward (100) = -29557.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10257: Reward = -35499.61, Avg Reward (100) = -29557.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10258: Reward = -35499.61, Avg Reward (100) = -29649.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10259: Reward = -33469.53, Avg Reward (100) = -29649.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10260: Reward = -29512.46, Avg Reward (100) = -29628.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10261: Reward = -32619.61, Avg Reward (100) = -29637.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10262: Reward = -25228.52, Avg Reward (100) = -29608.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10263: Reward = -46768.94, Avg Reward (100) = -29849.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46768.94, Border Penalty: -38317.83, Obstacle Penalty: -50.00
Episode 10264: Reward = -35499.61, Avg Reward (100) = -29962.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10265: Reward = -1000.00, Avg Reward (100) = -29962.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10266: Reward = -35499.61, Avg Reward (100) = -29617.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10267: Reward = -35499.61, Avg Reward (100) = -29617.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10268: Reward = -35499.61, Avg Reward (100) = -29617.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10269: Reward = -1344.00, Avg Reward (100) = -29677.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10270: Reward = -35499.61, Avg Reward (100) = -29335.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10271: Reward = -12446.80, Avg Reward (100) = -29680.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10272: Reward = -35499.61, Avg Reward (100) = -29518.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10273: Reward = -35499.61, Avg Reward (100) = -29859.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10274: Reward = -36089.25, Avg Reward (100) = -29887.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10275: Reward = -25228.52, Avg Reward (100) = -29893.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10276: Reward = -2156.56, Avg Reward (100) = -29791.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -2156.56, Border Penalty: -12072.03, Obstacle Penalty: -50.00
Episode 10277: Reward = -26352.94, Avg Reward (100) = -29457.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -26352.94, Border Penalty: -30813.49, Obstacle Penalty: -50.00
Episode 10278: Reward = -49626.26, Avg Reward (100) = -29468.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10279: Reward = -25228.52, Avg Reward (100) = -29610.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10280: Reward = -1049.00, Avg Reward (100) = -29384.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10281: Reward = -32245.59, Avg Reward (100) = -29039.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10282: Reward = -35499.61, Avg Reward (100) = -29350.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10283: Reward = -1196.00, Avg Reward (100) = -29350.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10284: Reward = -35499.61, Avg Reward (100) = -29075.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10285: Reward = -1394.00, Avg Reward (100) = -29075.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10286: Reward = -25228.52, Avg Reward (100) = -28734.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10287: Reward = -34685.86, Avg Reward (100) = -28649.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 10288: Reward = -35499.61, Avg Reward (100) = -28661.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10289: Reward = -28683.61, Avg Reward (100) = -29006.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10290: Reward = -35499.61, Avg Reward (100) = -28937.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10291: Reward = -1351.40, Avg Reward (100) = -28937.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10292: Reward = -1295.00, Avg Reward (100) = -28596.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10293: Reward = -35499.61, Avg Reward (100) = -28599.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10294: Reward = -1394.00, Avg Reward (100) = -28599.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10295: Reward = -35499.61, Avg Reward (100) = -28600.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10296: Reward = -35499.61, Avg Reward (100) = -28830.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10297: Reward = -35499.61, Avg Reward (100) = -28830.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10298: Reward = -35499.61, Avg Reward (100) = -28830.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10299: Reward = -35499.61, Avg Reward (100) = -29174.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10300: Reward = -32245.59, Avg Reward (100) = -29174.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10301: Reward = -34685.86, Avg Reward (100) = -29142.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10302: Reward = -34685.86, Avg Reward (100) = -29479.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10303: Reward = -35499.61, Avg Reward (100) = -29449.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10304: Reward = -35499.61, Avg Reward (100) = -29792.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10305: Reward = -35499.61, Avg Reward (100) = -29792.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10306: Reward = -36224.14, Avg Reward (100) = -29792.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36224.14, Border Penalty: -34054.01, Obstacle Penalty: -50.00
Episode 10307: Reward = -1049.00, Avg Reward (100) = -29799.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10308: Reward = -35499.61, Avg Reward (100) = -29487.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10309: Reward = -33701.04, Avg Reward (100) = -29487.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10310: Reward = -35499.61, Avg Reward (100) = -29814.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10311: Reward = -35499.61, Avg Reward (100) = -29814.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10312: Reward = -35499.61, Avg Reward (100) = -29814.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10313: Reward = -35499.61, Avg Reward (100) = -29814.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10314: Reward = -29626.05, Avg Reward (100) = -30159.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29626.05, Border Penalty: -32421.34, Obstacle Penalty: -50.00
Episode 10315: Reward = -47848.55, Avg Reward (100) = -30100.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10316: Reward = -35499.61, Avg Reward (100) = -30087.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10317: Reward = -35499.61, Avg Reward (100) = -30429.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10318: Reward = -35499.61, Avg Reward (100) = -30429.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10319: Reward = -1295.00, Avg Reward (100) = -30429.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10320: Reward = -35499.61, Avg Reward (100) = -30081.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10321: Reward = -35499.61, Avg Reward (100) = -30081.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10322: Reward = -47848.55, Avg Reward (100) = -30149.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 10323: Reward = -35499.61, Avg Reward (100) = -30273.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10324: Reward = -35499.61, Avg Reward (100) = -30273.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10325: Reward = -37669.33, Avg Reward (100) = -30273.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10326: Reward = -1294.00, Avg Reward (100) = -30638.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10327: Reward = -35499.61, Avg Reward (100) = -30296.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10328: Reward = -36089.25, Avg Reward (100) = -30543.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10329: Reward = -35499.61, Avg Reward (100) = -30549.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10330: Reward = -29512.46, Avg Reward (100) = -30549.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10331: Reward = -34685.86, Avg Reward (100) = -30489.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10332: Reward = -35499.61, Avg Reward (100) = -30481.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10333: Reward = -35499.61, Avg Reward (100) = -30481.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10334: Reward = -36089.25, Avg Reward (100) = -30481.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10335: Reward = -32619.61, Avg Reward (100) = -30487.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10336: Reward = -1394.00, Avg Reward (100) = -30458.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10337: Reward = -34927.46, Avg Reward (100) = -30117.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 10338: Reward = -48812.51, Avg Reward (100) = -30111.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48812.51, Border Penalty: -39225.76, Obstacle Penalty: -50.00
Episode 10339: Reward = -1147.00, Avg Reward (100) = -30244.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10340: Reward = -35499.61, Avg Reward (100) = -29901.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10341: Reward = -35499.61, Avg Reward (100) = -29901.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10342: Reward = -36089.25, Avg Reward (100) = -29969.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 10343: Reward = -39606.20, Avg Reward (100) = -29975.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10344: Reward = -1000.00, Avg Reward (100) = -30359.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10345: Reward = -35499.61, Avg Reward (100) = -29981.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10346: Reward = -47848.55, Avg Reward (100) = -29981.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 10347: Reward = -47848.55, Avg Reward (100) = -30063.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10348: Reward = -35499.61, Avg Reward (100) = -30187.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10349: Reward = -35499.61, Avg Reward (100) = -30187.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10350: Reward = -35499.61, Avg Reward (100) = -30187.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10351: Reward = -47848.55, Avg Reward (100) = -30207.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10352: Reward = -35499.61, Avg Reward (100) = -30330.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10353: Reward = -1049.00, Avg Reward (100) = -30330.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10354: Reward = -37669.33, Avg Reward (100) = -29862.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10355: Reward = -35499.61, Avg Reward (100) = -29944.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10356: Reward = -25228.52, Avg Reward (100) = -29964.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10357: Reward = -35499.61, Avg Reward (100) = -29862.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10358: Reward = -49626.26, Avg Reward (100) = -29862.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10359: Reward = -35499.61, Avg Reward (100) = -30003.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10360: Reward = -35499.61, Avg Reward (100) = -30023.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10361: Reward = -35499.61, Avg Reward (100) = -30083.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10362: Reward = -35499.61, Avg Reward (100) = -30112.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10363: Reward = -35499.61, Avg Reward (100) = -30215.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10364: Reward = -35499.61, Avg Reward (100) = -30102.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10365: Reward = -36224.14, Avg Reward (100) = -30102.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36224.14, Border Penalty: -34054.01, Obstacle Penalty: -50.00
Episode 10366: Reward = -35499.61, Avg Reward (100) = -30454.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10367: Reward = -37669.33, Avg Reward (100) = -30454.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10368: Reward = -35499.61, Avg Reward (100) = -30476.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10369: Reward = -42304.65, Avg Reward (100) = -30476.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 10370: Reward = -47848.55, Avg Reward (100) = -30885.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10371: Reward = -1000.00, Avg Reward (100) = -31009.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10372: Reward = -35499.61, Avg Reward (100) = -30894.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10373: Reward = -35499.61, Avg Reward (100) = -30894.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10374: Reward = -35499.61, Avg Reward (100) = -30894.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10375: Reward = -35499.61, Avg Reward (100) = -30889.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10376: Reward = -35499.61, Avg Reward (100) = -30991.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10377: Reward = -35499.61, Avg Reward (100) = -31325.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10378: Reward = -43263.20, Avg Reward (100) = -31416.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10379: Reward = -1147.00, Avg Reward (100) = -31353.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10380: Reward = -35499.61, Avg Reward (100) = -31112.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10381: Reward = -35499.61, Avg Reward (100) = -31456.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10382: Reward = -36089.25, Avg Reward (100) = -31489.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10383: Reward = -35499.61, Avg Reward (100) = -31495.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10384: Reward = -35499.61, Avg Reward (100) = -31838.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10385: Reward = -1098.00, Avg Reward (100) = -31838.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10386: Reward = -35499.61, Avg Reward (100) = -31835.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10387: Reward = -35499.61, Avg Reward (100) = -31937.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10388: Reward = -28653.56, Avg Reward (100) = -31946.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10389: Reward = -35499.61, Avg Reward (100) = -31877.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10390: Reward = -32619.61, Avg Reward (100) = -31945.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10391: Reward = -35499.61, Avg Reward (100) = -31917.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10392: Reward = -33701.04, Avg Reward (100) = -32258.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10393: Reward = -38636.47, Avg Reward (100) = -32582.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 10394: Reward = -35499.61, Avg Reward (100) = -32613.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10395: Reward = -35499.61, Avg Reward (100) = -32954.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10396: Reward = -35499.61, Avg Reward (100) = -32954.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10397: Reward = -33701.04, Avg Reward (100) = -32954.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10398: Reward = -1147.00, Avg Reward (100) = -32936.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10399: Reward = -26787.09, Avg Reward (100) = -32593.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 10400: Reward = -35499.61, Avg Reward (100) = -32506.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10401: Reward = -32619.61, Avg Reward (100) = -32538.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10402: Reward = -35499.61, Avg Reward (100) = -32518.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10403: Reward = -1147.00, Avg Reward (100) = -32526.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10404: Reward = -28353.68, Avg Reward (100) = -32182.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -28353.68, Border Penalty: -30935.67, Obstacle Penalty: -50.00
Episode 10405: Reward = -35499.61, Avg Reward (100) = -32111.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10406: Reward = -35499.61, Avg Reward (100) = -32111.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10407: Reward = -35499.61, Avg Reward (100) = -32104.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10408: Reward = -35499.61, Avg Reward (100) = -32448.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10409: Reward = -28653.56, Avg Reward (100) = -32448.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10410: Reward = -35499.61, Avg Reward (100) = -32398.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10411: Reward = -33701.04, Avg Reward (100) = -32398.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10412: Reward = -35499.61, Avg Reward (100) = -32380.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10413: Reward = -35499.61, Avg Reward (100) = -32380.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10414: Reward = -35499.61, Avg Reward (100) = -32380.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10415: Reward = -29512.46, Avg Reward (100) = -32438.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10416: Reward = -35499.61, Avg Reward (100) = -32255.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10417: Reward = -35499.61, Avg Reward (100) = -32255.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10418: Reward = -35499.61, Avg Reward (100) = -32255.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10419: Reward = -35499.61, Avg Reward (100) = -32255.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10420: Reward = -41280.90, Avg Reward (100) = -32597.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 10421: Reward = -35499.61, Avg Reward (100) = -32655.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10422: Reward = -32245.59, Avg Reward (100) = -32655.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10423: Reward = -1147.00, Avg Reward (100) = -32499.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10424: Reward = -35499.61, Avg Reward (100) = -32155.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10425: Reward = -35499.61, Avg Reward (100) = -32155.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10426: Reward = -1196.00, Avg Reward (100) = -32134.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10427: Reward = -35499.61, Avg Reward (100) = -32133.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10428: Reward = -1147.00, Avg Reward (100) = -32133.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10429: Reward = -28683.61, Avg Reward (100) = -31783.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10430: Reward = -35499.61, Avg Reward (100) = -31715.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10431: Reward = -32235.76, Avg Reward (100) = -31775.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 10432: Reward = -35499.61, Avg Reward (100) = -31750.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10433: Reward = -35499.61, Avg Reward (100) = -31750.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10434: Reward = -35499.61, Avg Reward (100) = -31750.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10435: Reward = -47848.55, Avg Reward (100) = -31745.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10436: Reward = -47848.55, Avg Reward (100) = -31897.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10437: Reward = -46100.60, Avg Reward (100) = -32361.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46100.60, Border Penalty: -39023.41, Obstacle Penalty: -50.00
Episode 10438: Reward = -39606.20, Avg Reward (100) = -32473.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10439: Reward = -35499.61, Avg Reward (100) = -32381.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10440: Reward = -35499.61, Avg Reward (100) = -32725.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10441: Reward = -35499.61, Avg Reward (100) = -32725.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10442: Reward = -1098.00, Avg Reward (100) = -32725.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10443: Reward = -35499.61, Avg Reward (100) = -32375.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10444: Reward = -35499.61, Avg Reward (100) = -32334.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10445: Reward = -35499.61, Avg Reward (100) = -32679.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10446: Reward = -35499.61, Avg Reward (100) = -32679.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10447: Reward = -35499.61, Avg Reward (100) = -32555.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10448: Reward = -35499.61, Avg Reward (100) = -32432.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10449: Reward = -35499.61, Avg Reward (100) = -32432.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10450: Reward = -35499.61, Avg Reward (100) = -32432.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10451: Reward = -1394.00, Avg Reward (100) = -32432.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10452: Reward = -1394.00, Avg Reward (100) = -31967.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10453: Reward = -35499.61, Avg Reward (100) = -31626.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10454: Reward = -1098.00, Avg Reward (100) = -31971.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10455: Reward = -35499.61, Avg Reward (100) = -31605.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10456: Reward = -49626.26, Avg Reward (100) = -31605.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10457: Reward = -35499.61, Avg Reward (100) = -31849.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10458: Reward = -35499.61, Avg Reward (100) = -31849.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10459: Reward = -35499.61, Avg Reward (100) = -31708.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10460: Reward = -1000.00, Avg Reward (100) = -31708.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10461: Reward = -1098.00, Avg Reward (100) = -31363.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10462: Reward = -36089.25, Avg Reward (100) = -31019.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10463: Reward = -35499.61, Avg Reward (100) = -31024.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10464: Reward = -35499.61, Avg Reward (100) = -31024.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10465: Reward = -1000.00, Avg Reward (100) = -31024.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10466: Reward = -35499.61, Avg Reward (100) = -30672.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10467: Reward = -1394.00, Avg Reward (100) = -30672.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10468: Reward = -47848.55, Avg Reward (100) = -30309.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10469: Reward = -35499.61, Avg Reward (100) = -30433.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10470: Reward = -1049.00, Avg Reward (100) = -30365.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10471: Reward = -1098.00, Avg Reward (100) = -29897.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10472: Reward = -49176.10, Avg Reward (100) = -29898.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10473: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10474: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10475: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10476: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10477: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10478: Reward = -35499.61, Avg Reward (100) = -30035.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10479: Reward = -35499.61, Avg Reward (100) = -29957.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10480: Reward = -37079.93, Avg Reward (100) = -30301.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37079.93, Border Penalty: -35854.99, Obstacle Penalty: -50.00
Episode 10481: Reward = -35499.61, Avg Reward (100) = -30316.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10482: Reward = -37669.33, Avg Reward (100) = -30316.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10483: Reward = -35499.61, Avg Reward (100) = -30332.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10484: Reward = -35499.61, Avg Reward (100) = -30332.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10485: Reward = -35499.61, Avg Reward (100) = -30332.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10486: Reward = -35499.61, Avg Reward (100) = -30676.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10487: Reward = -33382.70, Avg Reward (100) = -30676.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33382.70, Border Penalty: -34178.79, Obstacle Penalty: -50.00
Episode 10488: Reward = -33469.53, Avg Reward (100) = -30655.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10489: Reward = -35499.61, Avg Reward (100) = -30703.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10490: Reward = -1000.00, Avg Reward (100) = -30703.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10491: Reward = -47848.55, Avg Reward (100) = -30387.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10492: Reward = -32619.61, Avg Reward (100) = -30510.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10493: Reward = -33012.83, Avg Reward (100) = -30500.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -33012.83, Border Penalty: -34599.83, Obstacle Penalty: -50.00
Episode 10494: Reward = -35499.61, Avg Reward (100) = -30443.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10495: Reward = -35499.61, Avg Reward (100) = -30443.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10496: Reward = -27921.09, Avg Reward (100) = -30443.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27921.09, Border Penalty: -31646.78, Obstacle Penalty: -50.00
Episode 10497: Reward = -29512.46, Avg Reward (100) = -30368.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10498: Reward = -35499.61, Avg Reward (100) = -30326.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10499: Reward = -35499.61, Avg Reward (100) = -30669.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10500: Reward = -1049.00, Avg Reward (100) = -30756.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10501: Reward = -35499.61, Avg Reward (100) = -30412.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10502: Reward = -35499.61, Avg Reward (100) = -30441.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10503: Reward = -35499.61, Avg Reward (100) = -30441.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10504: Reward = -47914.45, Avg Reward (100) = -30784.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -35978.46, Obstacle Penalty: -50.00
Episode 10505: Reward = -43263.20, Avg Reward (100) = -30980.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10506: Reward = -32619.61, Avg Reward (100) = -31057.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10507: Reward = -35499.61, Avg Reward (100) = -31029.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10508: Reward = -35499.61, Avg Reward (100) = -31029.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10509: Reward = -35499.61, Avg Reward (100) = -31029.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10510: Reward = -35499.61, Avg Reward (100) = -31097.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10511: Reward = -35499.61, Avg Reward (100) = -31097.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10512: Reward = -35499.61, Avg Reward (100) = -31115.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10513: Reward = -35499.61, Avg Reward (100) = -31115.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10514: Reward = -34685.86, Avg Reward (100) = -31115.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10515: Reward = -35499.61, Avg Reward (100) = -31107.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10516: Reward = -1098.00, Avg Reward (100) = -31167.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10517: Reward = -40334.49, Avg Reward (100) = -30823.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 10518: Reward = -47848.55, Avg Reward (100) = -30871.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10519: Reward = -35499.61, Avg Reward (100) = -30995.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10520: Reward = -35499.61, Avg Reward (100) = -30995.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10521: Reward = -32619.61, Avg Reward (100) = -30937.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10522: Reward = -35499.61, Avg Reward (100) = -30908.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10523: Reward = -49176.10, Avg Reward (100) = -30941.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10524: Reward = -35499.61, Avg Reward (100) = -31421.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10525: Reward = -35499.61, Avg Reward (100) = -31421.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10526: Reward = -45485.92, Avg Reward (100) = -31421.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38982.36, Obstacle Penalty: -50.00
Episode 10527: Reward = -35499.61, Avg Reward (100) = -31864.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10528: Reward = -35499.61, Avg Reward (100) = -31864.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10529: Reward = -33469.53, Avg Reward (100) = -32207.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 10530: Reward = -1000.00, Avg Reward (100) = -32255.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10531: Reward = -1394.00, Avg Reward (100) = -31910.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10532: Reward = -35499.61, Avg Reward (100) = -31602.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10533: Reward = -42651.70, Avg Reward (100) = -31602.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -37572.03, Obstacle Penalty: -50.00
Episode 10534: Reward = -35499.61, Avg Reward (100) = -31673.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10535: Reward = -1196.00, Avg Reward (100) = -31673.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10536: Reward = -33469.53, Avg Reward (100) = -31207.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10537: Reward = -35499.61, Avg Reward (100) = -31063.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10538: Reward = -35499.61, Avg Reward (100) = -30957.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10539: Reward = -33701.04, Avg Reward (100) = -30916.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10540: Reward = -33469.53, Avg Reward (100) = -30898.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10541: Reward = -49176.10, Avg Reward (100) = -30878.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10542: Reward = -35499.61, Avg Reward (100) = -31014.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10543: Reward = -37669.33, Avg Reward (100) = -31358.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10544: Reward = -35499.61, Avg Reward (100) = -31380.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10545: Reward = -35499.61, Avg Reward (100) = -31380.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10546: Reward = -35499.61, Avg Reward (100) = -31380.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10547: Reward = -35499.61, Avg Reward (100) = -31380.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10548: Reward = -1295.00, Avg Reward (100) = -31380.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10549: Reward = -35499.61, Avg Reward (100) = -31038.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10550: Reward = -35499.61, Avg Reward (100) = -31038.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10551: Reward = -1147.00, Avg Reward (100) = -31038.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10552: Reward = -29512.46, Avg Reward (100) = -31035.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10553: Reward = -27052.21, Avg Reward (100) = -31317.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27052.21, Border Penalty: -31213.36, Obstacle Penalty: -50.00
Episode 10554: Reward = -1000.00, Avg Reward (100) = -31232.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10555: Reward = -12446.80, Avg Reward (100) = -31231.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10556: Reward = -35499.61, Avg Reward (100) = -31001.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10557: Reward = -35499.61, Avg Reward (100) = -30859.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10558: Reward = -35499.61, Avg Reward (100) = -30859.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10559: Reward = -1147.00, Avg Reward (100) = -30859.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10560: Reward = -35499.61, Avg Reward (100) = -30516.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10561: Reward = -35499.61, Avg Reward (100) = -30861.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10562: Reward = -30437.18, Avg Reward (100) = -31205.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 10563: Reward = -29512.46, Avg Reward (100) = -31148.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10564: Reward = -35499.61, Avg Reward (100) = -31089.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10565: Reward = -35499.61, Avg Reward (100) = -31089.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10566: Reward = -28653.56, Avg Reward (100) = -31434.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10567: Reward = -34685.86, Avg Reward (100) = -31365.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10568: Reward = -35499.61, Avg Reward (100) = -31698.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10569: Reward = -33469.53, Avg Reward (100) = -31574.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10570: Reward = -1147.00, Avg Reward (100) = -31554.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10571: Reward = -35499.61, Avg Reward (100) = -31555.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10572: Reward = -35499.61, Avg Reward (100) = -31899.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10573: Reward = -28683.61, Avg Reward (100) = -31762.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10574: Reward = -35499.61, Avg Reward (100) = -31694.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10575: Reward = -1147.00, Avg Reward (100) = -31694.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10576: Reward = -39606.20, Avg Reward (100) = -31351.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10577: Reward = -35499.61, Avg Reward (100) = -31392.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10578: Reward = -36089.25, Avg Reward (100) = -31392.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10579: Reward = -35499.61, Avg Reward (100) = -31398.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10580: Reward = -35499.61, Avg Reward (100) = -31398.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10581: Reward = -1000.00, Avg Reward (100) = -31382.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10582: Reward = -49176.10, Avg Reward (100) = -31037.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10583: Reward = -1394.00, Avg Reward (100) = -31152.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10584: Reward = -35499.61, Avg Reward (100) = -30811.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10585: Reward = -37669.33, Avg Reward (100) = -30811.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10586: Reward = -43127.23, Avg Reward (100) = -30833.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43127.23, Border Penalty: -37650.14, Obstacle Penalty: -50.00
Episode 10587: Reward = -35499.61, Avg Reward (100) = -30909.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10588: Reward = -1196.00, Avg Reward (100) = -30930.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10589: Reward = -35499.61, Avg Reward (100) = -30607.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10590: Reward = -28683.61, Avg Reward (100) = -30607.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10591: Reward = -49176.10, Avg Reward (100) = -30884.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10592: Reward = -49176.10, Avg Reward (100) = -30897.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10593: Reward = -1196.00, Avg Reward (100) = -31063.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10594: Reward = -35499.61, Avg Reward (100) = -30745.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10595: Reward = -1049.00, Avg Reward (100) = -30745.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10596: Reward = -35499.61, Avg Reward (100) = -30400.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10597: Reward = -29512.46, Avg Reward (100) = -30476.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10598: Reward = -1252.40, Avg Reward (100) = -30476.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10599: Reward = -35499.61, Avg Reward (100) = -30134.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10600: Reward = -28683.61, Avg Reward (100) = -30134.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10601: Reward = -34685.86, Avg Reward (100) = -30410.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10602: Reward = -1049.00, Avg Reward (100) = -30402.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10603: Reward = -30650.91, Avg Reward (100) = -30057.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30650.91, Border Penalty: -32829.87, Obstacle Penalty: -50.00
Episode 10604: Reward = -35499.61, Avg Reward (100) = -30009.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10605: Reward = -35499.61, Avg Reward (100) = -29885.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10606: Reward = -35499.61, Avg Reward (100) = -29807.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10607: Reward = -48567.86, Avg Reward (100) = -29836.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 10608: Reward = -33469.53, Avg Reward (100) = -29967.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10609: Reward = -25228.52, Avg Reward (100) = -29946.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10610: Reward = -25228.52, Avg Reward (100) = -29844.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10611: Reward = -35499.61, Avg Reward (100) = -29741.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10612: Reward = -49176.10, Avg Reward (100) = -29741.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10613: Reward = -35499.61, Avg Reward (100) = -29878.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10614: Reward = -35499.61, Avg Reward (100) = -29878.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10615: Reward = -1147.00, Avg Reward (100) = -29886.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10616: Reward = -35499.61, Avg Reward (100) = -29542.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10617: Reward = -1049.00, Avg Reward (100) = -29886.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10618: Reward = -33469.53, Avg Reward (100) = -29493.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10619: Reward = -35499.61, Avg Reward (100) = -29350.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10620: Reward = -835.48, Avg Reward (100) = -29350.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -835.48, Border Penalty: -6922.18, Obstacle Penalty: -50.00
Episode 10621: Reward = -35499.61, Avg Reward (100) = -29003.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10622: Reward = -35499.61, Avg Reward (100) = -29032.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10623: Reward = -12446.80, Avg Reward (100) = -29032.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10624: Reward = -35499.61, Avg Reward (100) = -28664.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10625: Reward = -42573.15, Avg Reward (100) = -28664.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42573.15, Border Penalty: -33822.50, Obstacle Penalty: -50.00
Episode 10626: Reward = -35499.61, Avg Reward (100) = -28735.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10627: Reward = -1147.00, Avg Reward (100) = -28635.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10628: Reward = -32815.85, Avg Reward (100) = -28292.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 10629: Reward = -35499.61, Avg Reward (100) = -28265.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10630: Reward = -33701.04, Avg Reward (100) = -28285.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -31129.77, Obstacle Penalty: -50.00
Episode 10631: Reward = -35499.61, Avg Reward (100) = -28612.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10632: Reward = -25228.52, Avg Reward (100) = -28953.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10633: Reward = -35499.61, Avg Reward (100) = -28851.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10634: Reward = -1394.00, Avg Reward (100) = -28779.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10635: Reward = -35499.61, Avg Reward (100) = -28438.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10636: Reward = -35499.61, Avg Reward (100) = -28781.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10637: Reward = -35499.61, Avg Reward (100) = -28801.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10638: Reward = -25228.52, Avg Reward (100) = -28801.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10639: Reward = -32245.59, Avg Reward (100) = -28699.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10640: Reward = -28653.56, Avg Reward (100) = -28684.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10641: Reward = -35499.61, Avg Reward (100) = -28636.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10642: Reward = -35499.61, Avg Reward (100) = -28499.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10643: Reward = -35499.61, Avg Reward (100) = -28499.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10644: Reward = -46653.19, Avg Reward (100) = -28477.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 10645: Reward = -35499.61, Avg Reward (100) = -28589.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10646: Reward = -32619.61, Avg Reward (100) = -28589.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10647: Reward = -35499.61, Avg Reward (100) = -28560.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10648: Reward = -12446.80, Avg Reward (100) = -28560.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10649: Reward = -30549.19, Avg Reward (100) = -28672.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30549.19, Border Penalty: -30639.42, Obstacle Penalty: -50.00
Episode 10650: Reward = -35499.61, Avg Reward (100) = -28622.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10651: Reward = -1049.00, Avg Reward (100) = -28622.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10652: Reward = -35499.61, Avg Reward (100) = -28621.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10653: Reward = -35499.61, Avg Reward (100) = -28681.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10654: Reward = -35499.61, Avg Reward (100) = -28766.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10655: Reward = -46305.80, Avg Reward (100) = -29111.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46305.80, Border Penalty: -37626.48, Obstacle Penalty: -50.00
Episode 10656: Reward = -45485.92, Avg Reward (100) = -29449.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38982.36, Obstacle Penalty: -50.00
Episode 10657: Reward = -35499.61, Avg Reward (100) = -29549.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10658: Reward = -1295.00, Avg Reward (100) = -29549.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10659: Reward = -35499.61, Avg Reward (100) = -29207.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10660: Reward = -43263.20, Avg Reward (100) = -29551.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10661: Reward = -39606.20, Avg Reward (100) = -29628.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10662: Reward = -35499.61, Avg Reward (100) = -29669.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10663: Reward = -35499.61, Avg Reward (100) = -29720.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10664: Reward = -35499.61, Avg Reward (100) = -29780.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10665: Reward = -12446.80, Avg Reward (100) = -29780.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10666: Reward = -35499.61, Avg Reward (100) = -29549.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10667: Reward = -12446.80, Avg Reward (100) = -29618.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10668: Reward = -1295.00, Avg Reward (100) = -29395.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10669: Reward = -35499.61, Avg Reward (100) = -29053.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10670: Reward = -1049.00, Avg Reward (100) = -29074.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10671: Reward = -34685.86, Avg Reward (100) = -29073.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10672: Reward = -12446.80, Avg Reward (100) = -29064.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10673: Reward = -35499.61, Avg Reward (100) = -28834.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10674: Reward = -35499.61, Avg Reward (100) = -28902.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10675: Reward = -35499.61, Avg Reward (100) = -28902.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10676: Reward = -35499.61, Avg Reward (100) = -29246.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10677: Reward = -35499.61, Avg Reward (100) = -29204.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10678: Reward = -35499.61, Avg Reward (100) = -29204.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10679: Reward = -35499.61, Avg Reward (100) = -29199.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10680: Reward = -36089.25, Avg Reward (100) = -29199.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10681: Reward = -35499.61, Avg Reward (100) = -29204.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10682: Reward = -35499.61, Avg Reward (100) = -29549.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10683: Reward = -35499.61, Avg Reward (100) = -29413.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10684: Reward = -12446.80, Avg Reward (100) = -29754.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10685: Reward = -1049.00, Avg Reward (100) = -29523.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10686: Reward = -35499.61, Avg Reward (100) = -29157.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10687: Reward = -47848.55, Avg Reward (100) = -29081.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10688: Reward = -36022.43, Avg Reward (100) = -29204.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 10689: Reward = -35499.61, Avg Reward (100) = -29553.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10690: Reward = -35499.61, Avg Reward (100) = -29553.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10691: Reward = -46722.66, Avg Reward (100) = -29621.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46722.66, Border Penalty: -37557.92, Obstacle Penalty: -50.00
Episode 10692: Reward = -35499.61, Avg Reward (100) = -29596.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10693: Reward = -35499.61, Avg Reward (100) = -29459.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10694: Reward = -28683.61, Avg Reward (100) = -29802.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10695: Reward = -35499.61, Avg Reward (100) = -29734.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10696: Reward = -36089.25, Avg Reward (100) = -30079.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10697: Reward = -35499.61, Avg Reward (100) = -30085.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10698: Reward = -1049.00, Avg Reward (100) = -30145.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10699: Reward = -35499.61, Avg Reward (100) = -30142.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10700: Reward = -35499.61, Avg Reward (100) = -30142.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10701: Reward = -35499.61, Avg Reward (100) = -30211.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10702: Reward = -35499.61, Avg Reward (100) = -30219.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10703: Reward = -930.25, Avg Reward (100) = -30563.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -930.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10704: Reward = -35499.61, Avg Reward (100) = -30266.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10705: Reward = -32619.61, Avg Reward (100) = -30266.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 10706: Reward = -35499.61, Avg Reward (100) = -30237.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10707: Reward = -1049.00, Avg Reward (100) = -30237.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10708: Reward = -1196.00, Avg Reward (100) = -29762.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10709: Reward = -49626.26, Avg Reward (100) = -29439.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10710: Reward = -1000.00, Avg Reward (100) = -29683.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10711: Reward = -28653.56, Avg Reward (100) = -29441.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10712: Reward = -5472.60, Avg Reward (100) = -29373.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -5472.60, Border Penalty: -15256.44, Obstacle Penalty: -50.00
Episode 10713: Reward = -34685.86, Avg Reward (100) = -28936.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10714: Reward = -35499.61, Avg Reward (100) = -28927.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10715: Reward = -33701.04, Avg Reward (100) = -28927.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10716: Reward = -1196.00, Avg Reward (100) = -29253.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10717: Reward = -25228.52, Avg Reward (100) = -28910.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10718: Reward = -1098.00, Avg Reward (100) = -29152.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10719: Reward = -35499.61, Avg Reward (100) = -28828.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10720: Reward = -35499.61, Avg Reward (100) = -28828.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10721: Reward = -35499.61, Avg Reward (100) = -29175.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10722: Reward = -1000.00, Avg Reward (100) = -29175.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10723: Reward = -35499.61, Avg Reward (100) = -28830.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10724: Reward = -35499.61, Avg Reward (100) = -29060.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10725: Reward = -33701.04, Avg Reward (100) = -29060.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10726: Reward = -35499.61, Avg Reward (100) = -28971.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10727: Reward = -35499.61, Avg Reward (100) = -28971.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10728: Reward = -1351.40, Avg Reward (100) = -29315.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10729: Reward = -1049.00, Avg Reward (100) = -29000.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10730: Reward = -1147.00, Avg Reward (100) = -28656.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10731: Reward = -37669.33, Avg Reward (100) = -28330.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 10732: Reward = -35499.61, Avg Reward (100) = -28352.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10733: Reward = -49626.26, Avg Reward (100) = -28455.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10734: Reward = -35499.61, Avg Reward (100) = -28596.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10735: Reward = -35499.61, Avg Reward (100) = -28937.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10736: Reward = -1295.00, Avg Reward (100) = -28937.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10737: Reward = -32245.59, Avg Reward (100) = -28595.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10738: Reward = -35499.61, Avg Reward (100) = -28562.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10739: Reward = -35499.61, Avg Reward (100) = -28665.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10740: Reward = -35499.61, Avg Reward (100) = -28698.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10741: Reward = -1098.00, Avg Reward (100) = -28766.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10742: Reward = -35499.61, Avg Reward (100) = -28422.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10743: Reward = -25228.52, Avg Reward (100) = -28422.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10744: Reward = -35499.61, Avg Reward (100) = -28319.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10745: Reward = -35499.61, Avg Reward (100) = -28208.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10746: Reward = -35499.61, Avg Reward (100) = -28208.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10747: Reward = -35499.61, Avg Reward (100) = -28237.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10748: Reward = -35499.61, Avg Reward (100) = -28237.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10749: Reward = -35499.61, Avg Reward (100) = -28467.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10750: Reward = -1098.00, Avg Reward (100) = -28517.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10751: Reward = -35499.61, Avg Reward (100) = -28173.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10752: Reward = -36791.87, Avg Reward (100) = -28517.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36791.87, Border Penalty: -35260.12, Obstacle Penalty: -50.00
Episode 10753: Reward = -35499.61, Avg Reward (100) = -28530.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10754: Reward = -35499.61, Avg Reward (100) = -28530.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10755: Reward = -35499.61, Avg Reward (100) = -28530.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10756: Reward = -35499.61, Avg Reward (100) = -28422.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10757: Reward = -29512.46, Avg Reward (100) = -28322.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10758: Reward = -35499.61, Avg Reward (100) = -28262.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10759: Reward = -35499.61, Avg Reward (100) = -28604.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10760: Reward = -33701.04, Avg Reward (100) = -28604.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10761: Reward = -1450.40, Avg Reward (100) = -28509.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10762: Reward = -38414.23, Avg Reward (100) = -28127.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38414.23, Border Penalty: -36175.60, Obstacle Penalty: -50.00
Episode 10763: Reward = -12446.80, Avg Reward (100) = -28156.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10764: Reward = -35499.61, Avg Reward (100) = -27926.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10765: Reward = -52585.18, Avg Reward (100) = -27926.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 10766: Reward = -32619.61, Avg Reward (100) = -28327.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10767: Reward = -1147.00, Avg Reward (100) = -28298.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10768: Reward = -12446.80, Avg Reward (100) = -28185.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10769: Reward = -35499.61, Avg Reward (100) = -28297.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10770: Reward = -35499.61, Avg Reward (100) = -28297.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10771: Reward = -35499.61, Avg Reward (100) = -28641.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10772: Reward = -35499.61, Avg Reward (100) = -28650.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10773: Reward = -49626.26, Avg Reward (100) = -28880.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 10774: Reward = -35499.61, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10775: Reward = -35499.61, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10776: Reward = -35499.61, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10777: Reward = -35499.61, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10778: Reward = -35499.61, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10779: Reward = -1394.00, Avg Reward (100) = -29021.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10780: Reward = -35499.61, Avg Reward (100) = -28680.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10781: Reward = -35499.61, Avg Reward (100) = -28674.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10782: Reward = -1000.00, Avg Reward (100) = -28674.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10783: Reward = -33469.53, Avg Reward (100) = -28329.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10784: Reward = -35499.61, Avg Reward (100) = -28309.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10785: Reward = -35499.61, Avg Reward (100) = -28540.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10786: Reward = -28653.56, Avg Reward (100) = -28884.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10787: Reward = -35499.61, Avg Reward (100) = -28816.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10788: Reward = -35499.61, Avg Reward (100) = -28692.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10789: Reward = -58564.79, Avg Reward (100) = -28687.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 10790: Reward = -1147.00, Avg Reward (100) = -28918.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10791: Reward = -1000.00, Avg Reward (100) = -28574.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10792: Reward = -35499.61, Avg Reward (100) = -28117.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10793: Reward = -12446.80, Avg Reward (100) = -28117.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10794: Reward = -12446.80, Avg Reward (100) = -27886.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10795: Reward = -35499.61, Avg Reward (100) = -27724.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10796: Reward = -49626.26, Avg Reward (100) = -27724.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 10797: Reward = -35499.61, Avg Reward (100) = -27859.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10798: Reward = -46242.48, Avg Reward (100) = -27859.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -36037.65, Obstacle Penalty: -50.00
Episode 10799: Reward = -1098.00, Avg Reward (100) = -28311.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10800: Reward = -35499.61, Avg Reward (100) = -27967.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10801: Reward = -1295.00, Avg Reward (100) = -27967.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10802: Reward = -43263.20, Avg Reward (100) = -27625.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10803: Reward = -35499.61, Avg Reward (100) = -27703.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10804: Reward = -35499.61, Avg Reward (100) = -28049.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10805: Reward = -1049.00, Avg Reward (100) = -28049.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10806: Reward = -46242.48, Avg Reward (100) = -27733.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -31477.65, Obstacle Penalty: -50.00
Episode 10807: Reward = -29512.46, Avg Reward (100) = -27840.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10808: Reward = -33701.04, Avg Reward (100) = -28125.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10809: Reward = -34685.86, Avg Reward (100) = -28450.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10810: Reward = -35499.61, Avg Reward (100) = -28301.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10811: Reward = -28653.56, Avg Reward (100) = -28646.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10812: Reward = -35499.61, Avg Reward (100) = -28646.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10813: Reward = -35499.61, Avg Reward (100) = -28946.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10814: Reward = -35499.61, Avg Reward (100) = -28954.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10815: Reward = -32619.61, Avg Reward (100) = -28954.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10816: Reward = -5472.60, Avg Reward (100) = -28943.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -5472.60, Border Penalty: -15256.44, Obstacle Penalty: -50.00
Episode 10817: Reward = -1394.00, Avg Reward (100) = -28986.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10818: Reward = -35499.61, Avg Reward (100) = -28748.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10819: Reward = -36089.25, Avg Reward (100) = -29092.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10820: Reward = -1294.00, Avg Reward (100) = -29097.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 10821: Reward = -35499.61, Avg Reward (100) = -28755.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10822: Reward = -57983.46, Avg Reward (100) = -28755.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57983.46, Border Penalty: -41230.57, Obstacle Penalty: -50.00
Episode 10823: Reward = -35499.61, Avg Reward (100) = -29325.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10824: Reward = -35499.61, Avg Reward (100) = -29325.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10825: Reward = -1147.00, Avg Reward (100) = -29325.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10826: Reward = -35499.61, Avg Reward (100) = -29000.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10827: Reward = -1000.00, Avg Reward (100) = -29000.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10828: Reward = -1098.00, Avg Reward (100) = -28655.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10829: Reward = -35499.61, Avg Reward (100) = -28652.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10830: Reward = -39606.20, Avg Reward (100) = -28997.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10831: Reward = -35499.61, Avg Reward (100) = -29381.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10832: Reward = -1196.00, Avg Reward (100) = -29360.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10833: Reward = -47914.45, Avg Reward (100) = -29017.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 10834: Reward = -1147.00, Avg Reward (100) = -28999.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10835: Reward = -1098.00, Avg Reward (100) = -28656.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10836: Reward = -47025.21, Avg Reward (100) = -28312.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 10837: Reward = -35499.61, Avg Reward (100) = -28769.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10838: Reward = -35499.61, Avg Reward (100) = -28802.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10839: Reward = -12446.80, Avg Reward (100) = -28802.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10840: Reward = -35499.61, Avg Reward (100) = -28571.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10841: Reward = -35499.61, Avg Reward (100) = -28571.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10842: Reward = -1295.00, Avg Reward (100) = -28915.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10843: Reward = -35499.61, Avg Reward (100) = -28573.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10844: Reward = -35499.61, Avg Reward (100) = -28676.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10845: Reward = -32245.59, Avg Reward (100) = -28676.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10846: Reward = -35499.61, Avg Reward (100) = -28643.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10847: Reward = -1394.00, Avg Reward (100) = -28643.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10848: Reward = -35499.61, Avg Reward (100) = -28302.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10849: Reward = -35499.61, Avg Reward (100) = -28302.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10850: Reward = -32619.61, Avg Reward (100) = -28302.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 10851: Reward = -35499.61, Avg Reward (100) = -28618.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10852: Reward = -39606.20, Avg Reward (100) = -28618.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10853: Reward = -1098.00, Avg Reward (100) = -28646.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10854: Reward = -35499.61, Avg Reward (100) = -28302.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10855: Reward = -35499.61, Avg Reward (100) = -28302.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10856: Reward = -49176.10, Avg Reward (100) = -28302.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10857: Reward = -35499.61, Avg Reward (100) = -28438.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10858: Reward = -35499.61, Avg Reward (100) = -28498.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10859: Reward = -35499.61, Avg Reward (100) = -28498.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10860: Reward = -35499.61, Avg Reward (100) = -28498.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10861: Reward = -35499.61, Avg Reward (100) = -28516.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10862: Reward = -32245.59, Avg Reward (100) = -28857.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10863: Reward = -35499.61, Avg Reward (100) = -28795.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10864: Reward = -35499.61, Avg Reward (100) = -29026.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10865: Reward = -43263.20, Avg Reward (100) = -29026.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10866: Reward = -28653.56, Avg Reward (100) = -28932.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10867: Reward = -32281.14, Avg Reward (100) = -28893.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32281.14, Border Penalty: -34088.48, Obstacle Penalty: -50.00
Episode 10868: Reward = -35499.61, Avg Reward (100) = -29204.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10869: Reward = -35499.61, Avg Reward (100) = -29435.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10870: Reward = -1295.00, Avg Reward (100) = -29435.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10871: Reward = -47848.55, Avg Reward (100) = -29093.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10872: Reward = -1394.00, Avg Reward (100) = -29216.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10873: Reward = -35499.61, Avg Reward (100) = -28875.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10874: Reward = -36089.25, Avg Reward (100) = -28734.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 10875: Reward = -35499.61, Avg Reward (100) = -28740.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10876: Reward = -35499.61, Avg Reward (100) = -28740.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10877: Reward = -35499.61, Avg Reward (100) = -28740.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10878: Reward = -25228.52, Avg Reward (100) = -28740.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10879: Reward = -35499.61, Avg Reward (100) = -28637.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10880: Reward = -35499.61, Avg Reward (100) = -28978.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10881: Reward = -35499.61, Avg Reward (100) = -28978.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10882: Reward = -12446.80, Avg Reward (100) = -28978.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10883: Reward = -35499.61, Avg Reward (100) = -29092.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10884: Reward = -49176.10, Avg Reward (100) = -29113.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10885: Reward = -12446.80, Avg Reward (100) = -29249.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10886: Reward = -47848.55, Avg Reward (100) = -29019.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 10887: Reward = -1196.00, Avg Reward (100) = -29211.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10888: Reward = -35499.61, Avg Reward (100) = -28868.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10889: Reward = -49176.10, Avg Reward (100) = -28868.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10890: Reward = -39606.20, Avg Reward (100) = -28774.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 10891: Reward = -43263.20, Avg Reward (100) = -29159.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10892: Reward = -35499.61, Avg Reward (100) = -29581.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10893: Reward = -35499.61, Avg Reward (100) = -29581.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10894: Reward = -35499.61, Avg Reward (100) = -29812.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10895: Reward = -35499.61, Avg Reward (100) = -30042.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10896: Reward = -43263.20, Avg Reward (100) = -30042.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 10897: Reward = -12446.80, Avg Reward (100) = -29979.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10898: Reward = -1294.00, Avg Reward (100) = -29748.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10899: Reward = -35499.61, Avg Reward (100) = -29299.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10900: Reward = -41554.36, Avg Reward (100) = -29643.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -37419.35, Obstacle Penalty: -50.00
Episode 10901: Reward = -1049.00, Avg Reward (100) = -29703.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10902: Reward = -35499.61, Avg Reward (100) = -29701.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10903: Reward = -1098.00, Avg Reward (100) = -29623.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10904: Reward = -35499.61, Avg Reward (100) = -29279.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10905: Reward = -35499.61, Avg Reward (100) = -29279.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10906: Reward = -25228.52, Avg Reward (100) = -29624.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 10907: Reward = -33469.53, Avg Reward (100) = -29413.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10908: Reward = -35499.61, Avg Reward (100) = -29453.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10909: Reward = -1098.00, Avg Reward (100) = -29471.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10910: Reward = -35499.61, Avg Reward (100) = -29135.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10911: Reward = -35499.61, Avg Reward (100) = -29135.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10912: Reward = -1147.00, Avg Reward (100) = -29204.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10913: Reward = -51664.90, Avg Reward (100) = -28860.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -51664.90, Border Penalty: -39024.54, Obstacle Penalty: -50.00
Episode 10914: Reward = -35499.61, Avg Reward (100) = -29022.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10915: Reward = -34685.86, Avg Reward (100) = -29022.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10916: Reward = -36089.25, Avg Reward (100) = -29042.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10917: Reward = -12446.80, Avg Reward (100) = -29349.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10918: Reward = -29512.46, Avg Reward (100) = -29459.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 10919: Reward = -36089.25, Avg Reward (100) = -29399.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 10920: Reward = -35499.61, Avg Reward (100) = -29399.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10921: Reward = -1394.00, Avg Reward (100) = -29741.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10922: Reward = -1147.00, Avg Reward (100) = -29400.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10923: Reward = -1394.00, Avg Reward (100) = -28832.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 10924: Reward = -35499.61, Avg Reward (100) = -28491.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10925: Reward = -35499.61, Avg Reward (100) = -28491.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10926: Reward = -35499.61, Avg Reward (100) = -28834.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10927: Reward = -35499.61, Avg Reward (100) = -28834.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10928: Reward = -34685.86, Avg Reward (100) = -29179.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10929: Reward = -35499.61, Avg Reward (100) = -29515.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10930: Reward = -1098.00, Avg Reward (100) = -29515.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10931: Reward = -35499.61, Avg Reward (100) = -29130.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10932: Reward = -35499.61, Avg Reward (100) = -29130.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10933: Reward = -1196.00, Avg Reward (100) = -29473.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 10934: Reward = -28683.61, Avg Reward (100) = -29006.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10935: Reward = -31653.57, Avg Reward (100) = -29281.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 10936: Reward = -36004.66, Avg Reward (100) = -29587.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 10937: Reward = -35499.61, Avg Reward (100) = -29477.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10938: Reward = -35499.61, Avg Reward (100) = -29477.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10939: Reward = -28198.29, Avg Reward (100) = -29477.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 10940: Reward = -35499.61, Avg Reward (100) = -29634.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 10941: Reward = -35499.61, Avg Reward (100) = -29634.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10942: Reward = -35499.61, Avg Reward (100) = -29634.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10943: Reward = -35499.61, Avg Reward (100) = -29976.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10944: Reward = -35499.61, Avg Reward (100) = -29976.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10945: Reward = -12446.80, Avg Reward (100) = -29976.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10946: Reward = -35499.61, Avg Reward (100) = -29778.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10947: Reward = -28683.61, Avg Reward (100) = -29778.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10948: Reward = -49176.10, Avg Reward (100) = -30051.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10949: Reward = -35499.61, Avg Reward (100) = -30188.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10950: Reward = -1098.00, Avg Reward (100) = -30188.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10951: Reward = -35499.61, Avg Reward (100) = -29873.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10952: Reward = -1295.00, Avg Reward (100) = -29873.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10953: Reward = -35499.61, Avg Reward (100) = -29490.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10954: Reward = -28683.61, Avg Reward (100) = -29834.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10955: Reward = -32619.61, Avg Reward (100) = -29765.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10956: Reward = -35499.61, Avg Reward (100) = -29737.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10957: Reward = -35499.61, Avg Reward (100) = -29600.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10958: Reward = -1147.00, Avg Reward (100) = -29600.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10959: Reward = -32245.59, Avg Reward (100) = -29256.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 10960: Reward = -35499.61, Avg Reward (100) = -29224.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10961: Reward = -33701.04, Avg Reward (100) = -29224.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10962: Reward = -35499.61, Avg Reward (100) = -29206.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10963: Reward = -35499.61, Avg Reward (100) = -29238.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10964: Reward = -35499.61, Avg Reward (100) = -29238.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10965: Reward = -35499.61, Avg Reward (100) = -29238.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10966: Reward = -32619.61, Avg Reward (100) = -29161.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 10967: Reward = -35499.61, Avg Reward (100) = -29200.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10968: Reward = -35499.61, Avg Reward (100) = -29233.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10969: Reward = -33701.04, Avg Reward (100) = -29233.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 10970: Reward = -49176.10, Avg Reward (100) = -29215.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 10971: Reward = -35499.61, Avg Reward (100) = -29693.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10972: Reward = -28653.56, Avg Reward (100) = -29570.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10973: Reward = -35499.61, Avg Reward (100) = -29842.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10974: Reward = -35499.61, Avg Reward (100) = -29842.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 10975: Reward = -33469.53, Avg Reward (100) = -29837.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 10976: Reward = -35499.61, Avg Reward (100) = -29816.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10977: Reward = -35499.61, Avg Reward (100) = -29816.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10978: Reward = -12446.80, Avg Reward (100) = -29816.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 10979: Reward = -35499.61, Avg Reward (100) = -29688.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10980: Reward = -35499.61, Avg Reward (100) = -29688.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10981: Reward = -59645.17, Avg Reward (100) = -29688.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 10982: Reward = -32499.04, Avg Reward (100) = -29930.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32499.04, Border Penalty: -32458.42, Obstacle Penalty: -50.00
Episode 10983: Reward = -28653.56, Avg Reward (100) = -30130.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 10984: Reward = -35499.61, Avg Reward (100) = -30062.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10985: Reward = -35499.61, Avg Reward (100) = -29925.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10986: Reward = -29512.46, Avg Reward (100) = -30156.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 10987: Reward = -30063.90, Avg Reward (100) = -29972.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30063.90, Border Penalty: -32903.33, Obstacle Penalty: -50.00
Episode 10988: Reward = -29358.58, Avg Reward (100) = -30261.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 10989: Reward = -1049.00, Avg Reward (100) = -30200.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 10990: Reward = -32245.59, Avg Reward (100) = -29718.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10991: Reward = -35499.61, Avg Reward (100) = -29645.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10992: Reward = -35499.61, Avg Reward (100) = -29567.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10993: Reward = -34685.86, Avg Reward (100) = -29567.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 10994: Reward = -32245.59, Avg Reward (100) = -29559.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 10995: Reward = -35499.61, Avg Reward (100) = -29526.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10996: Reward = -35499.61, Avg Reward (100) = -29526.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 10997: Reward = -51766.43, Avg Reward (100) = -29449.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -51766.43, Border Penalty: -40266.79, Obstacle Penalty: -50.00
Episode 10998: Reward = -1295.00, Avg Reward (100) = -29842.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 10999: Reward = -1098.00, Avg Reward (100) = -29842.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11000: Reward = -35499.61, Avg Reward (100) = -29498.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11001: Reward = -35499.61, Avg Reward (100) = -29437.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11002: Reward = -35499.61, Avg Reward (100) = -29782.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11003: Reward = -1098.00, Avg Reward (100) = -29782.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11004: Reward = -32675.73, Avg Reward (100) = -29782.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32675.73, Border Penalty: -30294.06, Obstacle Penalty: -50.00
Episode 11005: Reward = -43263.20, Avg Reward (100) = -29754.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11006: Reward = -35499.61, Avg Reward (100) = -29831.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11007: Reward = -35499.61, Avg Reward (100) = -29934.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11008: Reward = -12446.80, Avg Reward (100) = -29954.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11009: Reward = -1477.33, Avg Reward (100) = -29724.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1477.33, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11010: Reward = -35499.61, Avg Reward (100) = -29728.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11011: Reward = -35499.61, Avg Reward (100) = -29728.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11012: Reward = -35499.61, Avg Reward (100) = -29728.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11013: Reward = -55296.44, Avg Reward (100) = -30071.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -55296.44, Border Penalty: -41620.00, Obstacle Penalty: -50.00
Episode 11014: Reward = -1147.00, Avg Reward (100) = -30107.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11015: Reward = -32815.85, Avg Reward (100) = -29764.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 11016: Reward = -35499.61, Avg Reward (100) = -29745.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11017: Reward = -35499.61, Avg Reward (100) = -29739.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11018: Reward = -35499.61, Avg Reward (100) = -29970.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11019: Reward = -35499.61, Avg Reward (100) = -30030.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11020: Reward = -36089.25, Avg Reward (100) = -30024.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11021: Reward = -35499.61, Avg Reward (100) = -30030.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11022: Reward = -35499.61, Avg Reward (100) = -30371.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11023: Reward = -43263.20, Avg Reward (100) = -30714.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11024: Reward = -35499.61, Avg Reward (100) = -31133.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11025: Reward = -35499.61, Avg Reward (100) = -31133.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11026: Reward = -31349.38, Avg Reward (100) = -31133.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -31349.38, Border Penalty: -33641.07, Obstacle Penalty: -50.00
Episode 11027: Reward = -39606.20, Avg Reward (100) = -31092.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11028: Reward = -1196.00, Avg Reward (100) = -31133.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11029: Reward = -35499.61, Avg Reward (100) = -30798.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11030: Reward = -35499.61, Avg Reward (100) = -30798.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11031: Reward = -35499.61, Avg Reward (100) = -31142.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11032: Reward = -12446.80, Avg Reward (100) = -31142.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11033: Reward = -35499.61, Avg Reward (100) = -30911.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11034: Reward = -35499.61, Avg Reward (100) = -31254.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11035: Reward = -32245.59, Avg Reward (100) = -31322.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11036: Reward = -35499.61, Avg Reward (100) = -31328.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11037: Reward = -35499.61, Avg Reward (100) = -31323.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11038: Reward = -12769.82, Avg Reward (100) = -31323.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -12769.82, Border Penalty: -22136.90, Obstacle Penalty: -50.00
Episode 11039: Reward = -33701.04, Avg Reward (100) = -31096.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11040: Reward = -37669.33, Avg Reward (100) = -31151.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11041: Reward = -35499.61, Avg Reward (100) = -31173.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11042: Reward = -28683.61, Avg Reward (100) = -31173.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11043: Reward = -35499.61, Avg Reward (100) = -31105.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11044: Reward = -35499.61, Avg Reward (100) = -31105.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11045: Reward = -35499.61, Avg Reward (100) = -31105.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11046: Reward = -28653.56, Avg Reward (100) = -31335.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11047: Reward = -35499.61, Avg Reward (100) = -31267.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11048: Reward = -35499.61, Avg Reward (100) = -31335.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11049: Reward = -35499.61, Avg Reward (100) = -31198.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11050: Reward = -35499.61, Avg Reward (100) = -31198.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11051: Reward = -35499.61, Avg Reward (100) = -31542.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11052: Reward = -43263.20, Avg Reward (100) = -31542.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11053: Reward = -1196.00, Avg Reward (100) = -31962.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11054: Reward = -35499.61, Avg Reward (100) = -31619.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11055: Reward = -35499.61, Avg Reward (100) = -31687.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11056: Reward = -29358.58, Avg Reward (100) = -31716.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29358.58, Border Penalty: -31831.02, Obstacle Penalty: -50.00
Episode 11057: Reward = -32619.61, Avg Reward (100) = -31654.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11058: Reward = -35499.61, Avg Reward (100) = -31625.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11059: Reward = -43991.18, Avg Reward (100) = -31969.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -43991.18, Border Penalty: -38112.80, Obstacle Penalty: -50.00
Episode 11060: Reward = -35499.61, Avg Reward (100) = -32086.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11061: Reward = -33469.53, Avg Reward (100) = -32086.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11062: Reward = -1295.00, Avg Reward (100) = -32084.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11063: Reward = -35499.61, Avg Reward (100) = -31742.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11064: Reward = -34741.98, Avg Reward (100) = -31742.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 11065: Reward = -42363.56, Avg Reward (100) = -31734.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 11066: Reward = -33701.04, Avg Reward (100) = -31803.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11067: Reward = -35499.61, Avg Reward (100) = -31814.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11068: Reward = -35499.61, Avg Reward (100) = -31814.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11069: Reward = -12446.80, Avg Reward (100) = -31814.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11070: Reward = -35499.61, Avg Reward (100) = -31601.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11071: Reward = -35499.61, Avg Reward (100) = -31465.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11072: Reward = -35499.61, Avg Reward (100) = -31465.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11073: Reward = -43263.20, Avg Reward (100) = -31533.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11074: Reward = -33701.04, Avg Reward (100) = -31611.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11075: Reward = -35499.61, Avg Reward (100) = -31593.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11076: Reward = -35499.61, Avg Reward (100) = -31613.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11077: Reward = -35499.61, Avg Reward (100) = -31613.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11078: Reward = -35499.61, Avg Reward (100) = -31613.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11079: Reward = -33701.04, Avg Reward (100) = -31844.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11080: Reward = -35499.61, Avg Reward (100) = -31826.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11081: Reward = -35499.61, Avg Reward (100) = -31826.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11082: Reward = -1000.00, Avg Reward (100) = -31584.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11083: Reward = -1000.00, Avg Reward (100) = -31269.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11084: Reward = -35499.61, Avg Reward (100) = -30993.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11085: Reward = -1393.00, Avg Reward (100) = -30993.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11086: Reward = -35499.61, Avg Reward (100) = -30651.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11087: Reward = -43263.20, Avg Reward (100) = -30711.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11088: Reward = -33701.04, Avg Reward (100) = -30843.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11089: Reward = -35499.61, Avg Reward (100) = -30887.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11090: Reward = -35499.61, Avg Reward (100) = -31231.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11091: Reward = -35499.61, Avg Reward (100) = -31264.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11092: Reward = -43263.20, Avg Reward (100) = -31264.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11093: Reward = -1147.00, Avg Reward (100) = -31341.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11094: Reward = -35499.61, Avg Reward (100) = -31006.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11095: Reward = -35499.61, Avg Reward (100) = -31039.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11096: Reward = -35499.61, Avg Reward (100) = -31039.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11097: Reward = -35499.61, Avg Reward (100) = -31039.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11098: Reward = -35499.61, Avg Reward (100) = -30876.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11099: Reward = -35499.61, Avg Reward (100) = -31218.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11100: Reward = -35499.61, Avg Reward (100) = -31562.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11101: Reward = -35499.61, Avg Reward (100) = -31562.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11102: Reward = -35499.61, Avg Reward (100) = -31562.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11103: Reward = -25228.52, Avg Reward (100) = -31562.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11104: Reward = -35499.61, Avg Reward (100) = -31803.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11105: Reward = -35499.61, Avg Reward (100) = -31832.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11106: Reward = -35499.61, Avg Reward (100) = -31754.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11107: Reward = -35499.61, Avg Reward (100) = -31754.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11108: Reward = -35499.61, Avg Reward (100) = -31754.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11109: Reward = -35499.61, Avg Reward (100) = -31984.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11110: Reward = -36791.87, Avg Reward (100) = -32325.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36791.87, Border Penalty: -35260.12, Obstacle Penalty: -50.00
Episode 11111: Reward = -35499.61, Avg Reward (100) = -32338.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11112: Reward = -35499.61, Avg Reward (100) = -32338.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11113: Reward = -1098.00, Avg Reward (100) = -32338.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11114: Reward = -44886.55, Avg Reward (100) = -31796.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44886.55, Border Penalty: -36167.36, Obstacle Penalty: -50.00
Episode 11115: Reward = -1000.00, Avg Reward (100) = -32233.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11116: Reward = -35499.61, Avg Reward (100) = -31915.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11117: Reward = -35499.61, Avg Reward (100) = -31915.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11118: Reward = -35499.61, Avg Reward (100) = -31915.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11119: Reward = -35499.61, Avg Reward (100) = -31915.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11120: Reward = -1295.00, Avg Reward (100) = -31915.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11121: Reward = -35499.61, Avg Reward (100) = -31567.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11122: Reward = -35499.61, Avg Reward (100) = -31567.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11123: Reward = -35499.61, Avg Reward (100) = -31567.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11124: Reward = -35499.61, Avg Reward (100) = -31489.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11125: Reward = -1294.00, Avg Reward (100) = -31489.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11126: Reward = -33469.53, Avg Reward (100) = -31147.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11127: Reward = -33996.79, Avg Reward (100) = -31168.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -33996.79, Border Penalty: -34775.92, Obstacle Penalty: -50.00
Episode 11128: Reward = -1196.00, Avg Reward (100) = -31112.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11129: Reward = -35499.61, Avg Reward (100) = -31112.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11130: Reward = -35499.61, Avg Reward (100) = -31112.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11131: Reward = -36089.25, Avg Reward (100) = -31112.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11132: Reward = -35499.61, Avg Reward (100) = -31118.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11133: Reward = -35499.61, Avg Reward (100) = -31349.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11134: Reward = -41280.90, Avg Reward (100) = -31349.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 11135: Reward = -35499.61, Avg Reward (100) = -31407.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11136: Reward = -35499.61, Avg Reward (100) = -31439.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11137: Reward = -39606.20, Avg Reward (100) = -31439.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11138: Reward = -33701.04, Avg Reward (100) = -31480.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11139: Reward = -28653.56, Avg Reward (100) = -31689.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11140: Reward = -55917.21, Avg Reward (100) = -31639.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 11141: Reward = -35499.61, Avg Reward (100) = -31821.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11142: Reward = -28653.56, Avg Reward (100) = -31821.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11143: Reward = -34685.86, Avg Reward (100) = -31821.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11144: Reward = -35499.61, Avg Reward (100) = -31813.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11145: Reward = -25228.52, Avg Reward (100) = -31813.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11146: Reward = -35499.61, Avg Reward (100) = -31710.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11147: Reward = -1295.00, Avg Reward (100) = -31779.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11148: Reward = -1000.00, Avg Reward (100) = -31437.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11149: Reward = -35499.61, Avg Reward (100) = -31092.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11150: Reward = -12446.80, Avg Reward (100) = -31092.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11151: Reward = -1000.00, Avg Reward (100) = -30861.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11152: Reward = -35499.61, Avg Reward (100) = -30516.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11153: Reward = -1147.00, Avg Reward (100) = -30439.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11154: Reward = -35499.61, Avg Reward (100) = -30438.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11155: Reward = -35499.61, Avg Reward (100) = -30438.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11156: Reward = -35499.61, Avg Reward (100) = -30438.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11157: Reward = -35499.61, Avg Reward (100) = -30500.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11158: Reward = -1295.00, Avg Reward (100) = -30528.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11159: Reward = -35499.61, Avg Reward (100) = -30186.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11160: Reward = -43263.20, Avg Reward (100) = -30101.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11161: Reward = -1196.00, Avg Reward (100) = -30179.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11162: Reward = -35499.61, Avg Reward (100) = -29856.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11163: Reward = -35499.61, Avg Reward (100) = -30198.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11164: Reward = -35499.61, Avg Reward (100) = -30198.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11165: Reward = -35499.61, Avg Reward (100) = -30206.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11166: Reward = -28683.61, Avg Reward (100) = -30137.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11167: Reward = -29512.46, Avg Reward (100) = -30087.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11168: Reward = -35499.61, Avg Reward (100) = -30027.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11169: Reward = -35499.61, Avg Reward (100) = -30027.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11170: Reward = -33701.04, Avg Reward (100) = -30258.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -31129.77, Obstacle Penalty: -50.00
Episode 11171: Reward = -49626.26, Avg Reward (100) = -30240.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 11172: Reward = -35499.61, Avg Reward (100) = -30381.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11173: Reward = -35499.61, Avg Reward (100) = -30381.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11174: Reward = -47848.55, Avg Reward (100) = -30303.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11175: Reward = -52315.20, Avg Reward (100) = -30445.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 11176: Reward = -49626.26, Avg Reward (100) = -30613.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 11177: Reward = -35499.61, Avg Reward (100) = -30754.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11178: Reward = -35499.61, Avg Reward (100) = -30754.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11179: Reward = -1394.00, Avg Reward (100) = -30754.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11180: Reward = -35499.61, Avg Reward (100) = -30431.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11181: Reward = -35499.61, Avg Reward (100) = -30431.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11182: Reward = -1049.00, Avg Reward (100) = -30431.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11183: Reward = -35499.61, Avg Reward (100) = -30432.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11184: Reward = -35499.61, Avg Reward (100) = -30777.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11185: Reward = -35499.61, Avg Reward (100) = -30777.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11186: Reward = -33469.53, Avg Reward (100) = -31118.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 11187: Reward = -32619.61, Avg Reward (100) = -31097.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11188: Reward = -35499.61, Avg Reward (100) = -30991.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11189: Reward = -35499.61, Avg Reward (100) = -31009.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11190: Reward = -1147.00, Avg Reward (100) = -31009.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11191: Reward = -35499.61, Avg Reward (100) = -30665.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11192: Reward = -35499.61, Avg Reward (100) = -30665.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11193: Reward = -35499.61, Avg Reward (100) = -30588.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11194: Reward = -1049.00, Avg Reward (100) = -30931.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11195: Reward = -25228.52, Avg Reward (100) = -30587.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11196: Reward = -25228.52, Avg Reward (100) = -30484.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11197: Reward = -29512.46, Avg Reward (100) = -30381.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11198: Reward = -43263.20, Avg Reward (100) = -30322.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11199: Reward = -36089.25, Avg Reward (100) = -30399.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11200: Reward = -35499.61, Avg Reward (100) = -30405.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11201: Reward = -35499.61, Avg Reward (100) = -30405.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11202: Reward = -49626.26, Avg Reward (100) = -30405.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 11203: Reward = -1049.00, Avg Reward (100) = -30546.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11204: Reward = -35499.61, Avg Reward (100) = -30305.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11205: Reward = -35499.61, Avg Reward (100) = -30305.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11206: Reward = -29512.46, Avg Reward (100) = -30305.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11207: Reward = -35499.61, Avg Reward (100) = -30245.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11208: Reward = -35499.61, Avg Reward (100) = -30245.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11209: Reward = -1049.00, Avg Reward (100) = -30245.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11210: Reward = -1049.00, Avg Reward (100) = -29900.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11211: Reward = -53581.73, Avg Reward (100) = -29543.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -53581.73, Border Penalty: -38234.62, Obstacle Penalty: -50.00
Episode 11212: Reward = -35499.61, Avg Reward (100) = -29724.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11213: Reward = -53334.41, Avg Reward (100) = -29724.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 11214: Reward = -35499.61, Avg Reward (100) = -30246.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11215: Reward = -52270.10, Avg Reward (100) = -30152.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 11216: Reward = -48812.51, Avg Reward (100) = -30665.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -48812.51, Border Penalty: -39225.76, Obstacle Penalty: -50.00
Episode 11217: Reward = -35499.61, Avg Reward (100) = -30798.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11218: Reward = -35499.61, Avg Reward (100) = -30798.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11219: Reward = -35499.61, Avg Reward (100) = -30798.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11220: Reward = -1098.00, Avg Reward (100) = -30798.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11221: Reward = -35499.61, Avg Reward (100) = -30796.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11222: Reward = -35499.61, Avg Reward (100) = -30796.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11223: Reward = -35499.61, Avg Reward (100) = -30796.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11224: Reward = -35499.61, Avg Reward (100) = -30796.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11225: Reward = -30056.79, Avg Reward (100) = -30796.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -33036.80, Obstacle Penalty: -50.00
Episode 11226: Reward = -35499.61, Avg Reward (100) = -31084.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11227: Reward = -25228.52, Avg Reward (100) = -31104.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11228: Reward = -29512.46, Avg Reward (100) = -31016.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11229: Reward = -35499.61, Avg Reward (100) = -31299.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11230: Reward = -35499.61, Avg Reward (100) = -31299.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11231: Reward = -25228.52, Avg Reward (100) = -31299.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11232: Reward = -35499.61, Avg Reward (100) = -31191.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11233: Reward = -35499.61, Avg Reward (100) = -31191.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11234: Reward = -35499.61, Avg Reward (100) = -31191.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11235: Reward = -35499.61, Avg Reward (100) = -31133.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11236: Reward = -29512.46, Avg Reward (100) = -31133.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11237: Reward = -35499.61, Avg Reward (100) = -31073.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11238: Reward = -35499.61, Avg Reward (100) = -31032.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11239: Reward = -35499.61, Avg Reward (100) = -31050.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11240: Reward = -1049.00, Avg Reward (100) = -31118.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11241: Reward = -35499.61, Avg Reward (100) = -30570.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11242: Reward = -35499.61, Avg Reward (100) = -30570.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11243: Reward = -35499.61, Avg Reward (100) = -30638.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11244: Reward = -12446.80, Avg Reward (100) = -30646.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11245: Reward = -35499.61, Avg Reward (100) = -30416.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11246: Reward = -28653.56, Avg Reward (100) = -30519.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11247: Reward = -35499.61, Avg Reward (100) = -30450.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11248: Reward = -1196.00, Avg Reward (100) = -30792.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11249: Reward = -35499.61, Avg Reward (100) = -30794.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11250: Reward = -39606.20, Avg Reward (100) = -30794.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11251: Reward = -35499.61, Avg Reward (100) = -31066.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11252: Reward = -35499.61, Avg Reward (100) = -31411.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11253: Reward = -35499.61, Avg Reward (100) = -31411.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11254: Reward = -33701.04, Avg Reward (100) = -31754.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11255: Reward = -35499.61, Avg Reward (100) = -31736.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11256: Reward = -35499.61, Avg Reward (100) = -31736.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11257: Reward = -1000.00, Avg Reward (100) = -31736.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11258: Reward = -35499.61, Avg Reward (100) = -31391.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11259: Reward = -35499.61, Avg Reward (100) = -31733.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11260: Reward = -35499.61, Avg Reward (100) = -31733.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11261: Reward = -33469.53, Avg Reward (100) = -31656.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11262: Reward = -35499.61, Avg Reward (100) = -31978.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11263: Reward = -35499.61, Avg Reward (100) = -31978.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11264: Reward = -35499.61, Avg Reward (100) = -31978.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11265: Reward = -35499.61, Avg Reward (100) = -31978.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11266: Reward = -54261.02, Avg Reward (100) = -31978.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54261.02, Border Penalty: -40768.21, Obstacle Penalty: -50.00
Episode 11267: Reward = -37669.33, Avg Reward (100) = -32234.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11268: Reward = -28653.56, Avg Reward (100) = -32316.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11269: Reward = -44053.85, Avg Reward (100) = -32247.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44053.85, Border Penalty: -33891.44, Obstacle Penalty: -50.00
Episode 11270: Reward = -1492.00, Avg Reward (100) = -32333.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 11271: Reward = -25228.52, Avg Reward (100) = -32011.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11272: Reward = -1000.00, Avg Reward (100) = -31767.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11273: Reward = -28198.29, Avg Reward (100) = -31422.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 11274: Reward = -35499.61, Avg Reward (100) = -31349.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11275: Reward = -37669.33, Avg Reward (100) = -31225.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11276: Reward = -35499.61, Avg Reward (100) = -31079.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11277: Reward = -35499.61, Avg Reward (100) = -30937.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11278: Reward = -1000.00, Avg Reward (100) = -30937.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11279: Reward = -25228.52, Avg Reward (100) = -30592.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11280: Reward = -35499.61, Avg Reward (100) = -30831.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11281: Reward = -49176.10, Avg Reward (100) = -30831.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11282: Reward = -49176.10, Avg Reward (100) = -30968.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11283: Reward = -35499.61, Avg Reward (100) = -31449.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11284: Reward = -35499.61, Avg Reward (100) = -31449.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11285: Reward = -39606.20, Avg Reward (100) = -31449.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11286: Reward = -35499.61, Avg Reward (100) = -31490.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11287: Reward = -35499.61, Avg Reward (100) = -31510.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11288: Reward = -25228.52, Avg Reward (100) = -31539.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11289: Reward = -1000.00, Avg Reward (100) = -31436.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11290: Reward = -28683.61, Avg Reward (100) = -31091.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11291: Reward = -35499.61, Avg Reward (100) = -31367.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11292: Reward = -42651.70, Avg Reward (100) = -31367.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -37572.03, Obstacle Penalty: -50.00
Episode 11293: Reward = -1147.00, Avg Reward (100) = -31438.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11294: Reward = -1049.00, Avg Reward (100) = -31095.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11295: Reward = -35499.61, Avg Reward (100) = -31095.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11296: Reward = -35499.61, Avg Reward (100) = -31197.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11297: Reward = -35499.61, Avg Reward (100) = -31300.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11298: Reward = -35499.61, Avg Reward (100) = -31360.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11299: Reward = -35499.61, Avg Reward (100) = -31282.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11300: Reward = -49176.10, Avg Reward (100) = -31276.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11301: Reward = -39606.20, Avg Reward (100) = -31413.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11302: Reward = -35499.61, Avg Reward (100) = -31454.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11303: Reward = -32619.61, Avg Reward (100) = -31313.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11304: Reward = -25228.52, Avg Reward (100) = -31629.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11305: Reward = -39606.20, Avg Reward (100) = -31526.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11306: Reward = -49174.12, Avg Reward (100) = -31567.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39057.96, Obstacle Penalty: -50.00
Episode 11307: Reward = -34685.86, Avg Reward (100) = -31764.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11308: Reward = -35499.61, Avg Reward (100) = -31756.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11309: Reward = -35499.61, Avg Reward (100) = -31756.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11310: Reward = -35499.61, Avg Reward (100) = -32100.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11311: Reward = -35499.61, Avg Reward (100) = -32445.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11312: Reward = -35499.61, Avg Reward (100) = -32264.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11313: Reward = -43263.20, Avg Reward (100) = -32264.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11314: Reward = -47848.55, Avg Reward (100) = -32163.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11315: Reward = -35499.61, Avg Reward (100) = -32287.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11316: Reward = -33469.53, Avg Reward (100) = -32119.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11317: Reward = -39606.20, Avg Reward (100) = -31965.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11318: Reward = -35499.61, Avg Reward (100) = -32006.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11319: Reward = -47848.55, Avg Reward (100) = -32006.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11320: Reward = -35499.61, Avg Reward (100) = -32130.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11321: Reward = -1000.00, Avg Reward (100) = -32474.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11322: Reward = -35499.61, Avg Reward (100) = -32129.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11323: Reward = -54604.04, Avg Reward (100) = -32129.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54604.04, Border Penalty: -41409.95, Obstacle Penalty: -50.00
Episode 11324: Reward = -49176.10, Avg Reward (100) = -32320.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11325: Reward = -35499.61, Avg Reward (100) = -32457.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11326: Reward = -37669.33, Avg Reward (100) = -32511.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11327: Reward = -12446.80, Avg Reward (100) = -32533.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11328: Reward = -35499.61, Avg Reward (100) = -32405.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11329: Reward = -1147.00, Avg Reward (100) = -32465.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11330: Reward = -32245.59, Avg Reward (100) = -32121.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11331: Reward = -28683.61, Avg Reward (100) = -32089.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11332: Reward = -35499.61, Avg Reward (100) = -32123.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11333: Reward = -44558.04, Avg Reward (100) = -32123.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44558.04, Border Penalty: -38678.35, Obstacle Penalty: -50.00
Episode 11334: Reward = -35499.61, Avg Reward (100) = -32214.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11335: Reward = -1000.00, Avg Reward (100) = -32214.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11336: Reward = -49176.10, Avg Reward (100) = -31869.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11337: Reward = -28683.61, Avg Reward (100) = -32066.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11338: Reward = -47848.55, Avg Reward (100) = -31997.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11339: Reward = -35499.61, Avg Reward (100) = -32121.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11340: Reward = -35499.61, Avg Reward (100) = -32121.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11341: Reward = -35499.61, Avg Reward (100) = -32465.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11342: Reward = -35499.61, Avg Reward (100) = -32465.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11343: Reward = -47214.73, Avg Reward (100) = -32465.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47214.73, Border Penalty: -38611.89, Obstacle Penalty: -50.00
Episode 11344: Reward = -1049.00, Avg Reward (100) = -32583.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11345: Reward = -54036.93, Avg Reward (100) = -32469.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 11346: Reward = -35499.61, Avg Reward (100) = -32654.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11347: Reward = -35499.61, Avg Reward (100) = -32722.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11348: Reward = -32619.61, Avg Reward (100) = -32722.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11349: Reward = -1196.00, Avg Reward (100) = -33037.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11350: Reward = -35499.61, Avg Reward (100) = -32694.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11351: Reward = -57378.85, Avg Reward (100) = -32653.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -57378.85, Border Penalty: -39620.28, Obstacle Penalty: -50.00
Episode 11352: Reward = -35499.61, Avg Reward (100) = -32871.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11353: Reward = -32619.61, Avg Reward (100) = -32871.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11354: Reward = -35499.61, Avg Reward (100) = -32843.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11355: Reward = -33469.53, Avg Reward (100) = -32861.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11356: Reward = -1098.00, Avg Reward (100) = -32840.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11357: Reward = -35499.61, Avg Reward (100) = -32496.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11358: Reward = -35499.61, Avg Reward (100) = -32841.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11359: Reward = -35499.61, Avg Reward (100) = -32841.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11360: Reward = -53157.35, Avg Reward (100) = -32841.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53157.35, Border Penalty: -38183.32, Obstacle Penalty: -50.00
Episode 11361: Reward = -35499.61, Avg Reward (100) = -33018.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11362: Reward = -35499.61, Avg Reward (100) = -33038.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11363: Reward = -35499.61, Avg Reward (100) = -33038.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11364: Reward = -35499.61, Avg Reward (100) = -33038.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11365: Reward = -28683.61, Avg Reward (100) = -33038.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11366: Reward = -35499.61, Avg Reward (100) = -32970.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11367: Reward = -35499.61, Avg Reward (100) = -32782.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11368: Reward = -35499.61, Avg Reward (100) = -32761.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11369: Reward = -1098.00, Avg Reward (100) = -32829.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11370: Reward = -47848.55, Avg Reward (100) = -32400.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 11371: Reward = -1196.00, Avg Reward (100) = -32863.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11372: Reward = -49176.10, Avg Reward (100) = -32623.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11373: Reward = -25228.52, Avg Reward (100) = -33105.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11374: Reward = -35499.61, Avg Reward (100) = -33075.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11375: Reward = -1000.00, Avg Reward (100) = -33075.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11376: Reward = -35499.61, Avg Reward (100) = -32708.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11377: Reward = -1098.00, Avg Reward (100) = -32708.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11378: Reward = -35499.61, Avg Reward (100) = -32364.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11379: Reward = -35499.61, Avg Reward (100) = -32709.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11380: Reward = -35499.61, Avg Reward (100) = -32812.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11381: Reward = -29512.46, Avg Reward (100) = -32812.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11382: Reward = -42113.29, Avg Reward (100) = -32615.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42113.29, Border Penalty: -35930.51, Obstacle Penalty: -50.00
Episode 11383: Reward = -35499.61, Avg Reward (100) = -32545.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11384: Reward = -39606.20, Avg Reward (100) = -32545.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11385: Reward = -35499.61, Avg Reward (100) = -32586.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11386: Reward = -35499.61, Avg Reward (100) = -32545.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11387: Reward = -28683.61, Avg Reward (100) = -32545.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11388: Reward = -34482.45, Avg Reward (100) = -32476.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 11389: Reward = -30437.18, Avg Reward (100) = -32569.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 11390: Reward = -35499.61, Avg Reward (100) = -32863.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11391: Reward = -35499.61, Avg Reward (100) = -32932.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11392: Reward = -1147.00, Avg Reward (100) = -32932.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11393: Reward = -35499.61, Avg Reward (100) = -32516.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11394: Reward = -25228.52, Avg Reward (100) = -32860.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11395: Reward = -35499.61, Avg Reward (100) = -33102.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11396: Reward = -35499.61, Avg Reward (100) = -33102.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11397: Reward = -1098.00, Avg Reward (100) = -33102.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11398: Reward = -35499.61, Avg Reward (100) = -32758.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11399: Reward = -35499.61, Avg Reward (100) = -32758.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11400: Reward = -35499.61, Avg Reward (100) = -32758.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11401: Reward = -49626.26, Avg Reward (100) = -32621.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 11402: Reward = -45485.92, Avg Reward (100) = -32721.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38982.36, Obstacle Penalty: -50.00
Episode 11403: Reward = -1295.00, Avg Reward (100) = -32821.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11404: Reward = -35499.61, Avg Reward (100) = -32508.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11405: Reward = -27507.44, Avg Reward (100) = -32611.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27507.44, Border Penalty: -30836.76, Obstacle Penalty: -50.00
Episode 11406: Reward = -49626.26, Avg Reward (100) = -32490.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 11407: Reward = -28653.56, Avg Reward (100) = -32494.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11408: Reward = -35499.61, Avg Reward (100) = -32434.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11409: Reward = -36089.25, Avg Reward (100) = -32434.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11410: Reward = -35499.61, Avg Reward (100) = -32440.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11411: Reward = -35499.61, Avg Reward (100) = -32440.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11412: Reward = -35499.61, Avg Reward (100) = -32440.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11413: Reward = -34685.86, Avg Reward (100) = -32440.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11414: Reward = -35499.61, Avg Reward (100) = -32354.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11415: Reward = -33701.04, Avg Reward (100) = -32230.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11416: Reward = -43263.20, Avg Reward (100) = -32212.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11417: Reward = -35499.61, Avg Reward (100) = -32310.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11418: Reward = -35499.61, Avg Reward (100) = -32269.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11419: Reward = -35499.61, Avg Reward (100) = -32269.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11420: Reward = -35499.61, Avg Reward (100) = -32146.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11421: Reward = -35499.61, Avg Reward (100) = -32146.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11422: Reward = -35499.61, Avg Reward (100) = -32491.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11423: Reward = -27702.15, Avg Reward (100) = -32491.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27702.15, Border Penalty: -30554.88, Obstacle Penalty: -50.00
Episode 11424: Reward = -35499.61, Avg Reward (100) = -32222.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11425: Reward = -35499.61, Avg Reward (100) = -32085.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11426: Reward = -35499.61, Avg Reward (100) = -32085.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11427: Reward = -49176.10, Avg Reward (100) = -32063.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11428: Reward = -33469.53, Avg Reward (100) = -32431.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11429: Reward = -42304.65, Avg Reward (100) = -32410.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 11430: Reward = -1196.00, Avg Reward (100) = -32822.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11431: Reward = -38306.90, Avg Reward (100) = -32511.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 11432: Reward = -33701.04, Avg Reward (100) = -32608.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11433: Reward = -35499.61, Avg Reward (100) = -32590.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11434: Reward = -35499.61, Avg Reward (100) = -32499.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11435: Reward = -1049.00, Avg Reward (100) = -32499.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11436: Reward = -35499.61, Avg Reward (100) = -32500.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11437: Reward = -35499.61, Avg Reward (100) = -32363.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11438: Reward = -35499.61, Avg Reward (100) = -32431.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11439: Reward = -28653.56, Avg Reward (100) = -32307.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11440: Reward = -25228.52, Avg Reward (100) = -32239.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11441: Reward = -36089.25, Avg Reward (100) = -32136.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11442: Reward = -35499.61, Avg Reward (100) = -32142.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11443: Reward = -35499.61, Avg Reward (100) = -32142.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11444: Reward = -35499.61, Avg Reward (100) = -32025.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11445: Reward = -35499.61, Avg Reward (100) = -32370.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11446: Reward = -33469.53, Avg Reward (100) = -32184.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11447: Reward = -1000.00, Avg Reward (100) = -32164.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11448: Reward = -35499.61, Avg Reward (100) = -31819.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11449: Reward = -35499.61, Avg Reward (100) = -31848.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11450: Reward = -35499.61, Avg Reward (100) = -32191.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11451: Reward = -49169.59, Avg Reward (100) = -32191.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -49169.59, Border Penalty: -40600.36, Obstacle Penalty: -50.00
Episode 11452: Reward = -35499.61, Avg Reward (100) = -32109.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11453: Reward = -1098.00, Avg Reward (100) = -32109.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11454: Reward = -35499.61, Avg Reward (100) = -31793.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11455: Reward = -35499.61, Avg Reward (100) = -31793.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11456: Reward = -47848.55, Avg Reward (100) = -31814.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11457: Reward = -35499.61, Avg Reward (100) = -32281.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11458: Reward = -35499.61, Avg Reward (100) = -32281.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11459: Reward = -1196.00, Avg Reward (100) = -32281.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11460: Reward = -35499.61, Avg Reward (100) = -31938.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11461: Reward = -35499.61, Avg Reward (100) = -31762.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11462: Reward = -32245.59, Avg Reward (100) = -31762.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11463: Reward = -1098.00, Avg Reward (100) = -31729.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11464: Reward = -36089.25, Avg Reward (100) = -31385.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11465: Reward = -28683.61, Avg Reward (100) = -31391.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11466: Reward = -25228.52, Avg Reward (100) = -31391.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11467: Reward = -28653.56, Avg Reward (100) = -31288.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11468: Reward = -35499.61, Avg Reward (100) = -31220.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11469: Reward = -47848.55, Avg Reward (100) = -31220.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11470: Reward = -1394.00, Avg Reward (100) = -31687.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11471: Reward = -33701.04, Avg Reward (100) = -31223.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11472: Reward = -35499.61, Avg Reward (100) = -31548.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11473: Reward = -35499.61, Avg Reward (100) = -31411.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11474: Reward = -34164.73, Avg Reward (100) = -31514.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 11475: Reward = -35499.61, Avg Reward (100) = -31500.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11476: Reward = -35499.61, Avg Reward (100) = -31845.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11477: Reward = -35499.61, Avg Reward (100) = -31845.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11478: Reward = -29512.46, Avg Reward (100) = -32189.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11479: Reward = -35499.61, Avg Reward (100) = -32129.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11480: Reward = -28683.61, Avg Reward (100) = -32129.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11481: Reward = -35499.61, Avg Reward (100) = -32061.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11482: Reward = -28653.56, Avg Reward (100) = -32121.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11483: Reward = -1000.00, Avg Reward (100) = -31987.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11484: Reward = -12446.80, Avg Reward (100) = -31642.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11485: Reward = -35499.61, Avg Reward (100) = -31370.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11486: Reward = -28683.61, Avg Reward (100) = -31370.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11487: Reward = -32619.61, Avg Reward (100) = -31302.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11488: Reward = -25228.52, Avg Reward (100) = -31341.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11489: Reward = -35499.61, Avg Reward (100) = -31249.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11490: Reward = -36089.25, Avg Reward (100) = -31299.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11491: Reward = -35499.61, Avg Reward (100) = -31305.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11492: Reward = -37669.33, Avg Reward (100) = -31305.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11493: Reward = -35499.61, Avg Reward (100) = -31670.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11494: Reward = -29512.46, Avg Reward (100) = -31670.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11495: Reward = -35499.61, Avg Reward (100) = -31713.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11496: Reward = -1147.00, Avg Reward (100) = -31713.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11497: Reward = -43263.20, Avg Reward (100) = -31370.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11498: Reward = -35499.61, Avg Reward (100) = -31791.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11499: Reward = -35499.61, Avg Reward (100) = -31791.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11500: Reward = -35499.61, Avg Reward (100) = -31791.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11501: Reward = -35499.61, Avg Reward (100) = -31791.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11502: Reward = -36089.25, Avg Reward (100) = -31650.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11503: Reward = -35499.61, Avg Reward (100) = -31556.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11504: Reward = -35499.61, Avg Reward (100) = -31898.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11505: Reward = -1196.00, Avg Reward (100) = -31898.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11506: Reward = -35499.61, Avg Reward (100) = -31635.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11507: Reward = -35499.61, Avg Reward (100) = -31494.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11508: Reward = -28653.56, Avg Reward (100) = -31562.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11509: Reward = -1049.00, Avg Reward (100) = -31494.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11510: Reward = -35499.61, Avg Reward (100) = -31143.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11511: Reward = -35499.61, Avg Reward (100) = -31143.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11512: Reward = -35499.61, Avg Reward (100) = -31143.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11513: Reward = -35499.61, Avg Reward (100) = -31143.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11514: Reward = -52585.18, Avg Reward (100) = -31152.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 11515: Reward = -1147.00, Avg Reward (100) = -31322.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11516: Reward = -35499.61, Avg Reward (100) = -30997.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11517: Reward = -1000.00, Avg Reward (100) = -30919.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11518: Reward = -34685.86, Avg Reward (100) = -30574.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11519: Reward = -33469.53, Avg Reward (100) = -30566.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 11520: Reward = -1098.00, Avg Reward (100) = -30546.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11521: Reward = -35499.61, Avg Reward (100) = -30202.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11522: Reward = -35499.61, Avg Reward (100) = -30202.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11523: Reward = -35499.61, Avg Reward (100) = -30202.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11524: Reward = -35499.61, Avg Reward (100) = -30280.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11525: Reward = -35499.61, Avg Reward (100) = -30280.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11526: Reward = -35499.61, Avg Reward (100) = -30280.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11527: Reward = -1098.00, Avg Reward (100) = -30280.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11528: Reward = -1147.00, Avg Reward (100) = -29799.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11529: Reward = -1000.00, Avg Reward (100) = -29476.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11530: Reward = -1147.00, Avg Reward (100) = -29063.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11531: Reward = -32245.59, Avg Reward (100) = -29062.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11532: Reward = -35499.61, Avg Reward (100) = -29002.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11533: Reward = -35499.61, Avg Reward (100) = -29020.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11534: Reward = -35499.61, Avg Reward (100) = -29020.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11535: Reward = -37185.15, Avg Reward (100) = -29020.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37185.15, Border Penalty: -36230.21, Obstacle Penalty: -50.00
Episode 11536: Reward = -32619.61, Avg Reward (100) = -29381.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11537: Reward = -35499.61, Avg Reward (100) = -29352.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11538: Reward = -35499.61, Avg Reward (100) = -29352.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11539: Reward = -35499.61, Avg Reward (100) = -29352.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11540: Reward = -35499.61, Avg Reward (100) = -29421.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11541: Reward = -1351.40, Avg Reward (100) = -29523.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11542: Reward = -35499.61, Avg Reward (100) = -29176.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11543: Reward = -35499.61, Avg Reward (100) = -29176.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11544: Reward = -35499.61, Avg Reward (100) = -29176.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11545: Reward = -28683.61, Avg Reward (100) = -29176.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11546: Reward = -35499.61, Avg Reward (100) = -29108.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11547: Reward = -1196.00, Avg Reward (100) = -29128.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11548: Reward = -35499.61, Avg Reward (100) = -29130.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11549: Reward = -35499.61, Avg Reward (100) = -29130.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11550: Reward = -35499.61, Avg Reward (100) = -29130.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11551: Reward = -35499.61, Avg Reward (100) = -29130.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11552: Reward = -35499.61, Avg Reward (100) = -28993.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11553: Reward = -33701.04, Avg Reward (100) = -28993.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11554: Reward = -47848.55, Avg Reward (100) = -29319.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11555: Reward = -33907.14, Avg Reward (100) = -29443.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -33907.14, Border Penalty: -35584.52, Obstacle Penalty: -50.00
Episode 11556: Reward = -35499.61, Avg Reward (100) = -29427.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11557: Reward = -35499.61, Avg Reward (100) = -29303.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11558: Reward = -35499.61, Avg Reward (100) = -29303.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11559: Reward = -35499.61, Avg Reward (100) = -29303.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11560: Reward = -35499.61, Avg Reward (100) = -29646.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11561: Reward = -36089.25, Avg Reward (100) = -29646.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11562: Reward = -35499.61, Avg Reward (100) = -29652.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11563: Reward = -32245.59, Avg Reward (100) = -29685.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11564: Reward = -35499.61, Avg Reward (100) = -29996.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11565: Reward = -35499.61, Avg Reward (100) = -29991.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11566: Reward = -35499.61, Avg Reward (100) = -30059.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11567: Reward = -48567.86, Avg Reward (100) = -30161.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 11568: Reward = -35499.61, Avg Reward (100) = -30361.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11569: Reward = -35499.61, Avg Reward (100) = -30361.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11570: Reward = -35499.61, Avg Reward (100) = -30237.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11571: Reward = -35499.61, Avg Reward (100) = -30578.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11572: Reward = -35499.61, Avg Reward (100) = -30596.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11573: Reward = -35499.61, Avg Reward (100) = -30596.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11574: Reward = -47439.38, Avg Reward (100) = -30596.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 11575: Reward = -35499.61, Avg Reward (100) = -30729.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11576: Reward = -35499.61, Avg Reward (100) = -30729.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11577: Reward = -35499.61, Avg Reward (100) = -30729.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11578: Reward = -35499.61, Avg Reward (100) = -30729.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11579: Reward = -35499.61, Avg Reward (100) = -30789.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11580: Reward = -35499.61, Avg Reward (100) = -30789.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11581: Reward = -28683.61, Avg Reward (100) = -30857.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11582: Reward = -35499.61, Avg Reward (100) = -30789.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11583: Reward = -49176.10, Avg Reward (100) = -30857.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11584: Reward = -35499.61, Avg Reward (100) = -31339.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11585: Reward = -34685.86, Avg Reward (100) = -31569.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11586: Reward = -35499.61, Avg Reward (100) = -31561.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11587: Reward = -35499.61, Avg Reward (100) = -31629.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11588: Reward = -1147.00, Avg Reward (100) = -31658.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11589: Reward = -35499.61, Avg Reward (100) = -31417.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11590: Reward = -35499.61, Avg Reward (100) = -31417.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11591: Reward = -35499.61, Avg Reward (100) = -31412.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11592: Reward = -1000.00, Avg Reward (100) = -31412.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11593: Reward = -35499.61, Avg Reward (100) = -31045.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11594: Reward = -35499.61, Avg Reward (100) = -31045.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11595: Reward = -35499.61, Avg Reward (100) = -31105.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11596: Reward = -35499.61, Avg Reward (100) = -31105.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11597: Reward = -35499.61, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11598: Reward = -43263.20, Avg Reward (100) = -31371.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11599: Reward = -35499.61, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11600: Reward = -35499.61, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11601: Reward = -35499.61, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11602: Reward = -35499.61, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11603: Reward = -36089.25, Avg Reward (100) = -31442.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11604: Reward = -1394.00, Avg Reward (100) = -31448.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11605: Reward = -1049.00, Avg Reward (100) = -31107.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11606: Reward = -35499.61, Avg Reward (100) = -31106.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11607: Reward = -49176.10, Avg Reward (100) = -31106.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11608: Reward = -35499.61, Avg Reward (100) = -31242.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11609: Reward = -47848.55, Avg Reward (100) = -31311.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11610: Reward = -35499.61, Avg Reward (100) = -31779.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11611: Reward = -35499.61, Avg Reward (100) = -31779.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11612: Reward = -35499.61, Avg Reward (100) = -31779.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11613: Reward = -1098.00, Avg Reward (100) = -31779.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11614: Reward = -1049.00, Avg Reward (100) = -31435.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11615: Reward = -35499.61, Avg Reward (100) = -30920.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11616: Reward = -32683.02, Avg Reward (100) = -31263.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -32683.02, Border Penalty: -33928.53, Obstacle Penalty: -50.00
Episode 11617: Reward = -35499.61, Avg Reward (100) = -31235.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11618: Reward = -1098.00, Avg Reward (100) = -31580.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11619: Reward = -28653.56, Avg Reward (100) = -31244.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11620: Reward = -32245.59, Avg Reward (100) = -31196.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11621: Reward = -1000.00, Avg Reward (100) = -31507.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11622: Reward = -28653.56, Avg Reward (100) = -31162.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11623: Reward = -34685.86, Avg Reward (100) = -31094.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11624: Reward = -35499.61, Avg Reward (100) = -31086.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11625: Reward = -35499.61, Avg Reward (100) = -31086.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11626: Reward = -35499.61, Avg Reward (100) = -31086.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11627: Reward = -35499.61, Avg Reward (100) = -31086.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11628: Reward = -35499.61, Avg Reward (100) = -31430.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11629: Reward = -1196.00, Avg Reward (100) = -31773.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11630: Reward = -1196.00, Avg Reward (100) = -31775.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11631: Reward = -35499.61, Avg Reward (100) = -31776.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11632: Reward = -35499.61, Avg Reward (100) = -31808.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11633: Reward = -1049.00, Avg Reward (100) = -31808.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11634: Reward = -35499.61, Avg Reward (100) = -31464.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11635: Reward = -35499.61, Avg Reward (100) = -31464.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11636: Reward = -1049.00, Avg Reward (100) = -31447.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11637: Reward = -34685.86, Avg Reward (100) = -31131.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11638: Reward = -35499.61, Avg Reward (100) = -31123.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11639: Reward = -35499.61, Avg Reward (100) = -31123.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11640: Reward = -35499.61, Avg Reward (100) = -31123.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11641: Reward = -35499.61, Avg Reward (100) = -31123.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11642: Reward = -35499.61, Avg Reward (100) = -31465.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11643: Reward = -51657.72, Avg Reward (100) = -31465.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -51657.72, Border Penalty: -40292.43, Obstacle Penalty: -50.00
Episode 11644: Reward = -1049.00, Avg Reward (100) = -31626.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11645: Reward = -35499.61, Avg Reward (100) = -31282.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11646: Reward = -35499.61, Avg Reward (100) = -31350.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11647: Reward = -35499.61, Avg Reward (100) = -31350.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11648: Reward = -34685.86, Avg Reward (100) = -31693.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11649: Reward = -35499.61, Avg Reward (100) = -31685.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11650: Reward = -35499.61, Avg Reward (100) = -31685.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11651: Reward = -35499.61, Avg Reward (100) = -31685.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11652: Reward = -1394.00, Avg Reward (100) = -31685.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11653: Reward = -35499.61, Avg Reward (100) = -31344.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11654: Reward = -1147.00, Avg Reward (100) = -31362.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11655: Reward = -35499.61, Avg Reward (100) = -30895.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11656: Reward = -28653.56, Avg Reward (100) = -30911.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11657: Reward = -35499.61, Avg Reward (100) = -30842.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11658: Reward = -35499.61, Avg Reward (100) = -30842.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11659: Reward = -34685.86, Avg Reward (100) = -30842.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11660: Reward = -35499.61, Avg Reward (100) = -30834.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11661: Reward = -1000.00, Avg Reward (100) = -30834.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11662: Reward = -1098.00, Avg Reward (100) = -30483.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11663: Reward = -9566.81, Avg Reward (100) = -30139.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -9566.81, Border Penalty: -16787.81, Obstacle Penalty: -50.00
Episode 11664: Reward = -35499.61, Avg Reward (100) = -29912.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11665: Reward = -35499.61, Avg Reward (100) = -29912.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11666: Reward = -1196.00, Avg Reward (100) = -29912.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11667: Reward = -1196.00, Avg Reward (100) = -29569.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11668: Reward = -35499.61, Avg Reward (100) = -29096.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11669: Reward = -35499.61, Avg Reward (100) = -29096.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11670: Reward = -35499.61, Avg Reward (100) = -29096.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11671: Reward = -28198.29, Avg Reward (100) = -29096.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 11672: Reward = -35499.61, Avg Reward (100) = -29022.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11673: Reward = -35499.61, Avg Reward (100) = -29022.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11674: Reward = -35499.61, Avg Reward (100) = -29022.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11675: Reward = -1196.00, Avg Reward (100) = -28903.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11676: Reward = -35499.61, Avg Reward (100) = -28560.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11677: Reward = -35499.61, Avg Reward (100) = -28560.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11678: Reward = -35499.61, Avg Reward (100) = -28560.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11679: Reward = -49626.26, Avg Reward (100) = -28560.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 11680: Reward = -25228.52, Avg Reward (100) = -28701.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11681: Reward = -35499.61, Avg Reward (100) = -28599.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11682: Reward = -35499.61, Avg Reward (100) = -28667.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11683: Reward = -35499.61, Avg Reward (100) = -28667.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11684: Reward = -35499.61, Avg Reward (100) = -28530.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11685: Reward = -35499.61, Avg Reward (100) = -28530.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11686: Reward = -35499.61, Avg Reward (100) = -28538.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11687: Reward = -46653.19, Avg Reward (100) = -28538.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 11688: Reward = -36089.25, Avg Reward (100) = -28650.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11689: Reward = -49176.10, Avg Reward (100) = -28999.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11690: Reward = -35499.61, Avg Reward (100) = -29136.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11691: Reward = -1295.00, Avg Reward (100) = -29136.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11692: Reward = -35499.61, Avg Reward (100) = -28794.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11693: Reward = -33701.04, Avg Reward (100) = -29139.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11694: Reward = -35499.61, Avg Reward (100) = -29121.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11695: Reward = -1049.00, Avg Reward (100) = -29121.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11696: Reward = -1394.00, Avg Reward (100) = -28776.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11697: Reward = -35499.61, Avg Reward (100) = -28435.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11698: Reward = -35499.61, Avg Reward (100) = -28435.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11699: Reward = -35499.61, Avg Reward (100) = -28358.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11700: Reward = -34685.86, Avg Reward (100) = -28358.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11701: Reward = -35499.61, Avg Reward (100) = -28349.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11702: Reward = -39967.05, Avg Reward (100) = -28349.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -39967.05, Border Penalty: -35059.72, Obstacle Penalty: -50.00
Episode 11703: Reward = -1394.00, Avg Reward (100) = -28394.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11704: Reward = -35499.61, Avg Reward (100) = -28047.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11705: Reward = -33469.53, Avg Reward (100) = -28388.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11706: Reward = -34685.86, Avg Reward (100) = -28712.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 11707: Reward = -35499.61, Avg Reward (100) = -28704.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11708: Reward = -35499.61, Avg Reward (100) = -28568.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11709: Reward = -28653.56, Avg Reward (100) = -28568.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11710: Reward = -1443.00, Avg Reward (100) = -28376.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1443.00, Border Penalty: -5276.28, Obstacle Penalty: -50.00
Episode 11711: Reward = -32619.61, Avg Reward (100) = -28035.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11712: Reward = -36089.25, Avg Reward (100) = -28006.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11713: Reward = -36089.25, Avg Reward (100) = -28012.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11714: Reward = -35499.61, Avg Reward (100) = -28362.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11715: Reward = -35499.61, Avg Reward (100) = -28707.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11716: Reward = -35499.61, Avg Reward (100) = -28707.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11717: Reward = -35499.61, Avg Reward (100) = -28735.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11718: Reward = -1000.00, Avg Reward (100) = -28735.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11719: Reward = -35499.61, Avg Reward (100) = -28734.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11720: Reward = -35499.61, Avg Reward (100) = -28802.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11721: Reward = -35499.61, Avg Reward (100) = -28835.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11722: Reward = -35499.61, Avg Reward (100) = -29180.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11723: Reward = -35499.61, Avg Reward (100) = -29248.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11724: Reward = -1000.00, Avg Reward (100) = -29256.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11725: Reward = -35499.61, Avg Reward (100) = -28911.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11726: Reward = -38924.96, Avg Reward (100) = -28911.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38924.96, Border Penalty: -36612.80, Obstacle Penalty: -50.00
Episode 11727: Reward = -37669.33, Avg Reward (100) = -28946.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11728: Reward = -35499.61, Avg Reward (100) = -28967.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11729: Reward = -35499.61, Avg Reward (100) = -28967.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11730: Reward = -35499.61, Avg Reward (100) = -29310.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11731: Reward = -35499.61, Avg Reward (100) = -29653.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11732: Reward = -35499.61, Avg Reward (100) = -29653.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11733: Reward = -29512.46, Avg Reward (100) = -29653.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11734: Reward = -35499.61, Avg Reward (100) = -29938.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11735: Reward = -35499.61, Avg Reward (100) = -29938.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11736: Reward = -28653.56, Avg Reward (100) = -29938.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11737: Reward = -39606.20, Avg Reward (100) = -30214.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11738: Reward = -35499.61, Avg Reward (100) = -30263.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11739: Reward = -35499.61, Avg Reward (100) = -30263.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11740: Reward = -32245.59, Avg Reward (100) = -30263.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11741: Reward = -35499.61, Avg Reward (100) = -30231.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11742: Reward = -1000.00, Avg Reward (100) = -30231.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11743: Reward = -32245.59, Avg Reward (100) = -29886.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11744: Reward = -1394.00, Avg Reward (100) = -29692.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11745: Reward = -39606.20, Avg Reward (100) = -29695.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11746: Reward = -35499.61, Avg Reward (100) = -29736.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11747: Reward = -35499.61, Avg Reward (100) = -29736.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11748: Reward = -35499.61, Avg Reward (100) = -29736.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11749: Reward = -35499.61, Avg Reward (100) = -29744.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11750: Reward = -35499.61, Avg Reward (100) = -29744.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11751: Reward = -1000.00, Avg Reward (100) = -29744.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11752: Reward = -35499.61, Avg Reward (100) = -29399.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11753: Reward = -43263.20, Avg Reward (100) = -29740.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11754: Reward = -35499.61, Avg Reward (100) = -29818.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11755: Reward = -1098.00, Avg Reward (100) = -30161.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11756: Reward = -28683.61, Avg Reward (100) = -29817.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11757: Reward = -54870.38, Avg Reward (100) = -29818.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -54870.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 11758: Reward = -35499.61, Avg Reward (100) = -30011.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11759: Reward = -1394.00, Avg Reward (100) = -30011.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11760: Reward = -35499.61, Avg Reward (100) = -29679.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11761: Reward = -35499.61, Avg Reward (100) = -29679.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11762: Reward = -1147.00, Avg Reward (100) = -30024.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11763: Reward = -41419.64, Avg Reward (100) = -30024.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -41419.64, Border Penalty: -37106.64, Obstacle Penalty: -50.00
Episode 11764: Reward = -35499.61, Avg Reward (100) = -30343.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11765: Reward = -35499.61, Avg Reward (100) = -30343.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11766: Reward = -35499.61, Avg Reward (100) = -30343.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11767: Reward = -37054.55, Avg Reward (100) = -30686.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37054.55, Border Penalty: -35755.93, Obstacle Penalty: -50.00
Episode 11768: Reward = -39606.20, Avg Reward (100) = -31044.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11769: Reward = -49176.10, Avg Reward (100) = -31085.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11770: Reward = -35499.61, Avg Reward (100) = -31222.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11771: Reward = -25228.52, Avg Reward (100) = -31222.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 11772: Reward = -35499.61, Avg Reward (100) = -31192.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11773: Reward = -35499.61, Avg Reward (100) = -31192.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11774: Reward = -35499.61, Avg Reward (100) = -31192.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11775: Reward = -28683.61, Avg Reward (100) = -31192.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11776: Reward = -35499.61, Avg Reward (100) = -31467.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11777: Reward = -34685.86, Avg Reward (100) = -31467.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11778: Reward = -49285.73, Avg Reward (100) = -31459.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49285.73, Border Penalty: -40370.16, Obstacle Penalty: -50.00
Episode 11779: Reward = -44651.33, Avg Reward (100) = -31597.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44651.33, Border Penalty: -38718.66, Obstacle Penalty: -50.00
Episode 11780: Reward = -1196.00, Avg Reward (100) = -31547.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11781: Reward = -35499.61, Avg Reward (100) = -31307.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11782: Reward = -28653.56, Avg Reward (100) = -31307.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11783: Reward = -1098.00, Avg Reward (100) = -31238.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11784: Reward = -28683.61, Avg Reward (100) = -30894.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11785: Reward = -35499.61, Avg Reward (100) = -30826.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11786: Reward = -35499.61, Avg Reward (100) = -30826.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11787: Reward = -35499.61, Avg Reward (100) = -30826.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11788: Reward = -35499.61, Avg Reward (100) = -30715.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11789: Reward = -35499.61, Avg Reward (100) = -30709.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11790: Reward = -39606.20, Avg Reward (100) = -30572.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11791: Reward = -35499.61, Avg Reward (100) = -30613.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11792: Reward = -29512.46, Avg Reward (100) = -30955.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11793: Reward = -39606.20, Avg Reward (100) = -30895.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11794: Reward = -35499.61, Avg Reward (100) = -30954.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11795: Reward = -35499.61, Avg Reward (100) = -30954.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11796: Reward = -47848.55, Avg Reward (100) = -31299.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 11797: Reward = -35499.61, Avg Reward (100) = -31763.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11798: Reward = -39606.20, Avg Reward (100) = -31763.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11799: Reward = -35499.61, Avg Reward (100) = -31804.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11800: Reward = -35499.61, Avg Reward (100) = -31804.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11801: Reward = -35499.61, Avg Reward (100) = -31813.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11802: Reward = -1147.00, Avg Reward (100) = -31813.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11803: Reward = -35499.61, Avg Reward (100) = -31424.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11804: Reward = -32245.59, Avg Reward (100) = -31765.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11805: Reward = -35499.61, Avg Reward (100) = -31733.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11806: Reward = -1394.00, Avg Reward (100) = -31753.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11807: Reward = -1049.00, Avg Reward (100) = -31420.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11808: Reward = -1196.00, Avg Reward (100) = -31076.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11809: Reward = -35499.61, Avg Reward (100) = -30733.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11810: Reward = -35499.61, Avg Reward (100) = -30801.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11811: Reward = -1295.00, Avg Reward (100) = -31142.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11812: Reward = -35499.61, Avg Reward (100) = -30829.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11813: Reward = -35499.61, Avg Reward (100) = -30823.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11814: Reward = -37256.08, Avg Reward (100) = -30817.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 11815: Reward = -35499.61, Avg Reward (100) = -30834.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11816: Reward = -35499.61, Avg Reward (100) = -30834.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11817: Reward = -1295.00, Avg Reward (100) = -30834.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11818: Reward = -35499.61, Avg Reward (100) = -30492.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11819: Reward = -1245.00, Avg Reward (100) = -30837.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11820: Reward = -32612.87, Avg Reward (100) = -30495.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 11821: Reward = -35499.61, Avg Reward (100) = -30466.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11822: Reward = -35499.61, Avg Reward (100) = -30466.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11823: Reward = -35499.61, Avg Reward (100) = -30466.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11824: Reward = -35499.61, Avg Reward (100) = -30466.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11825: Reward = -35499.61, Avg Reward (100) = -30811.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11826: Reward = -35499.61, Avg Reward (100) = -30811.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11827: Reward = -1098.00, Avg Reward (100) = -30777.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11828: Reward = -35499.61, Avg Reward (100) = -30411.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11829: Reward = -1252.40, Avg Reward (100) = -30411.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 11830: Reward = -35499.61, Avg Reward (100) = -30068.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11831: Reward = -62084.51, Avg Reward (100) = -30068.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -62084.51, Border Penalty: -32936.85, Obstacle Penalty: -50.00
Episode 11832: Reward = -35499.61, Avg Reward (100) = -30334.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11833: Reward = -35499.61, Avg Reward (100) = -30334.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11834: Reward = -35499.61, Avg Reward (100) = -30394.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11835: Reward = -35499.61, Avg Reward (100) = -30394.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11836: Reward = -35499.61, Avg Reward (100) = -30394.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11837: Reward = -35499.61, Avg Reward (100) = -30463.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11838: Reward = -35499.61, Avg Reward (100) = -30421.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11839: Reward = -36089.25, Avg Reward (100) = -30421.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11840: Reward = -1196.00, Avg Reward (100) = -30427.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11841: Reward = -35499.61, Avg Reward (100) = -30117.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11842: Reward = -1000.00, Avg Reward (100) = -30117.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11843: Reward = -35499.61, Avg Reward (100) = -30117.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11844: Reward = -36089.25, Avg Reward (100) = -30149.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11845: Reward = -35499.61, Avg Reward (100) = -30496.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11846: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11847: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11848: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11849: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11850: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11851: Reward = -35499.61, Avg Reward (100) = -30455.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11852: Reward = -36089.25, Avg Reward (100) = -30800.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11853: Reward = -28653.56, Avg Reward (100) = -30806.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 11854: Reward = -35499.61, Avg Reward (100) = -30660.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11855: Reward = -35499.61, Avg Reward (100) = -30660.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11856: Reward = -35499.61, Avg Reward (100) = -31004.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11857: Reward = -1098.00, Avg Reward (100) = -31072.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11858: Reward = -35499.61, Avg Reward (100) = -30535.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11859: Reward = -33469.53, Avg Reward (100) = -30535.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11860: Reward = -1147.00, Avg Reward (100) = -30855.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11861: Reward = -35499.61, Avg Reward (100) = -30512.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11862: Reward = -43263.20, Avg Reward (100) = -30512.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 11863: Reward = -43263.20, Avg Reward (100) = -30933.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 11864: Reward = -35499.61, Avg Reward (100) = -30951.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11865: Reward = -1049.00, Avg Reward (100) = -30951.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11866: Reward = -35499.61, Avg Reward (100) = -30607.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11867: Reward = -1049.00, Avg Reward (100) = -30607.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11868: Reward = -1049.00, Avg Reward (100) = -30247.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11869: Reward = -35499.61, Avg Reward (100) = -29861.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11870: Reward = -35499.61, Avg Reward (100) = -29724.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11871: Reward = -1394.00, Avg Reward (100) = -29724.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11872: Reward = -35499.61, Avg Reward (100) = -29486.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 11873: Reward = -35499.61, Avg Reward (100) = -29486.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11874: Reward = -35499.61, Avg Reward (100) = -29486.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11875: Reward = -35499.61, Avg Reward (100) = -29486.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11876: Reward = -28653.56, Avg Reward (100) = -29554.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11877: Reward = -37669.33, Avg Reward (100) = -29486.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11878: Reward = -35499.61, Avg Reward (100) = -29516.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11879: Reward = -35499.61, Avg Reward (100) = -29378.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11880: Reward = -1147.00, Avg Reward (100) = -29286.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11881: Reward = -35499.61, Avg Reward (100) = -29286.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11882: Reward = -35499.61, Avg Reward (100) = -29286.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11883: Reward = -28683.61, Avg Reward (100) = -29354.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11884: Reward = -46653.19, Avg Reward (100) = -29630.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46653.19, Border Penalty: -38366.35, Obstacle Penalty: -50.00
Episode 11885: Reward = -35499.61, Avg Reward (100) = -29810.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11886: Reward = -1049.00, Avg Reward (100) = -29810.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11887: Reward = -35499.61, Avg Reward (100) = -29465.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11888: Reward = -35499.61, Avg Reward (100) = -29465.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11889: Reward = -35499.61, Avg Reward (100) = -29465.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11890: Reward = -34685.86, Avg Reward (100) = -29465.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 11891: Reward = -49176.10, Avg Reward (100) = -29416.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11892: Reward = -35499.61, Avg Reward (100) = -29553.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11893: Reward = -1147.00, Avg Reward (100) = -29613.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11894: Reward = -28683.61, Avg Reward (100) = -29228.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11895: Reward = -39606.20, Avg Reward (100) = -29160.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11896: Reward = -32455.23, Avg Reward (100) = -29201.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -32455.23, Border Penalty: -34159.55, Obstacle Penalty: -50.00
Episode 11897: Reward = -28683.61, Avg Reward (100) = -29047.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11898: Reward = -35499.61, Avg Reward (100) = -28979.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11899: Reward = -28653.56, Avg Reward (100) = -28938.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 11900: Reward = -35499.61, Avg Reward (100) = -28869.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11901: Reward = -55296.44, Avg Reward (100) = -28869.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -55296.44, Border Penalty: -41620.00, Obstacle Penalty: -50.00
Episode 11902: Reward = -35499.61, Avg Reward (100) = -29067.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11903: Reward = -32245.59, Avg Reward (100) = -29411.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 11904: Reward = -35499.61, Avg Reward (100) = -29378.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11905: Reward = -32619.61, Avg Reward (100) = -29411.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11906: Reward = -35499.61, Avg Reward (100) = -29382.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11907: Reward = -35499.61, Avg Reward (100) = -29723.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11908: Reward = -35499.61, Avg Reward (100) = -30068.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11909: Reward = -40955.38, Avg Reward (100) = -30411.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 11910: Reward = -1394.00, Avg Reward (100) = -30465.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11911: Reward = -35499.61, Avg Reward (100) = -30124.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11912: Reward = -35499.61, Avg Reward (100) = -30466.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11913: Reward = -1394.00, Avg Reward (100) = -30466.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11914: Reward = -1147.00, Avg Reward (100) = -30125.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11915: Reward = -28427.60, Avg Reward (100) = -29764.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28427.60, Border Penalty: -30641.62, Obstacle Penalty: -50.00
Episode 11916: Reward = -37669.33, Avg Reward (100) = -29693.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11917: Reward = -49636.01, Avg Reward (100) = -29715.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -49636.01, Border Penalty: -39732.59, Obstacle Penalty: -50.00
Episode 11918: Reward = -35499.61, Avg Reward (100) = -30199.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11919: Reward = -1147.00, Avg Reward (100) = -30199.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11920: Reward = -35499.61, Avg Reward (100) = -30198.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11921: Reward = -36089.25, Avg Reward (100) = -30226.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11922: Reward = -1098.00, Avg Reward (100) = -30232.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11923: Reward = -35499.61, Avg Reward (100) = -29888.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11924: Reward = -35499.61, Avg Reward (100) = -29888.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11925: Reward = -35499.61, Avg Reward (100) = -29888.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11926: Reward = -1147.00, Avg Reward (100) = -29888.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11927: Reward = -28683.61, Avg Reward (100) = -29545.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11928: Reward = -35499.61, Avg Reward (100) = -29821.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11929: Reward = -37669.33, Avg Reward (100) = -29821.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11930: Reward = -33469.53, Avg Reward (100) = -30185.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11931: Reward = -35499.61, Avg Reward (100) = -30164.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11932: Reward = -32619.61, Avg Reward (100) = -29899.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11933: Reward = -35499.61, Avg Reward (100) = -29870.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11934: Reward = -35499.61, Avg Reward (100) = -29870.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11935: Reward = -35499.61, Avg Reward (100) = -29870.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11936: Reward = -36089.25, Avg Reward (100) = -29870.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 11937: Reward = -49176.10, Avg Reward (100) = -29876.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11938: Reward = -37054.55, Avg Reward (100) = -30013.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37054.55, Border Penalty: -32237.38, Obstacle Penalty: -50.00
Episode 11939: Reward = -54726.48, Avg Reward (100) = -30028.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54726.48, Border Penalty: -41575.92, Obstacle Penalty: -50.00
Episode 11940: Reward = -28683.61, Avg Reward (100) = -30214.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11941: Reward = -35499.61, Avg Reward (100) = -30489.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11942: Reward = -39606.20, Avg Reward (100) = -30489.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11943: Reward = -35499.61, Avg Reward (100) = -30875.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11944: Reward = -35499.61, Avg Reward (100) = -30875.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11945: Reward = -39606.20, Avg Reward (100) = -30869.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 11946: Reward = -32619.61, Avg Reward (100) = -30911.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 11947: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11948: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11949: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11950: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11951: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 11952: Reward = -35499.61, Avg Reward (100) = -30882.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11953: Reward = -35499.61, Avg Reward (100) = -30876.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11954: Reward = -35499.61, Avg Reward (100) = -30944.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11955: Reward = -35499.61, Avg Reward (100) = -30944.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11956: Reward = -35499.61, Avg Reward (100) = -30944.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11957: Reward = -12446.80, Avg Reward (100) = -30944.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11958: Reward = -1098.00, Avg Reward (100) = -31058.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11959: Reward = -35499.61, Avg Reward (100) = -30714.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11960: Reward = -33701.04, Avg Reward (100) = -30734.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 11961: Reward = -35499.61, Avg Reward (100) = -31060.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11962: Reward = -33469.53, Avg Reward (100) = -31060.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 11963: Reward = -40334.49, Avg Reward (100) = -30962.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 11964: Reward = -35499.61, Avg Reward (100) = -30932.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11965: Reward = -35499.61, Avg Reward (100) = -30932.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11966: Reward = -12446.80, Avg Reward (100) = -31277.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 11967: Reward = -35499.61, Avg Reward (100) = -31046.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11968: Reward = -35499.61, Avg Reward (100) = -31391.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11969: Reward = -35499.61, Avg Reward (100) = -31735.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11970: Reward = -35499.61, Avg Reward (100) = -31735.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11971: Reward = -1049.00, Avg Reward (100) = -31735.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11972: Reward = -35499.61, Avg Reward (100) = -31732.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11973: Reward = -25751.89, Avg Reward (100) = -31732.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 11974: Reward = -37669.33, Avg Reward (100) = -31634.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 11975: Reward = -26326.21, Avg Reward (100) = -31656.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26326.21, Border Penalty: -30952.06, Obstacle Penalty: -50.00
Episode 11976: Reward = -35499.61, Avg Reward (100) = -31564.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11977: Reward = -47439.38, Avg Reward (100) = -31633.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 11978: Reward = -49176.10, Avg Reward (100) = -31731.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 11979: Reward = -35499.61, Avg Reward (100) = -31867.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11980: Reward = -52315.20, Avg Reward (100) = -31867.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 11981: Reward = -35499.61, Avg Reward (100) = -32379.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11982: Reward = -1196.00, Avg Reward (100) = -32379.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 11983: Reward = -29512.46, Avg Reward (100) = -32036.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 11984: Reward = -35499.61, Avg Reward (100) = -32044.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11985: Reward = -1394.00, Avg Reward (100) = -31933.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11986: Reward = -35499.61, Avg Reward (100) = -31592.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11987: Reward = -1000.00, Avg Reward (100) = -31936.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11988: Reward = -35499.61, Avg Reward (100) = -31591.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11989: Reward = -1394.00, Avg Reward (100) = -31591.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11990: Reward = -35499.61, Avg Reward (100) = -31250.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11991: Reward = -35499.61, Avg Reward (100) = -31258.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11992: Reward = -35499.61, Avg Reward (100) = -31122.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11993: Reward = -1049.00, Avg Reward (100) = -31122.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 11994: Reward = -35499.61, Avg Reward (100) = -31121.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11995: Reward = -35499.61, Avg Reward (100) = -31189.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11996: Reward = -35499.61, Avg Reward (100) = -31148.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11997: Reward = -1394.00, Avg Reward (100) = -31178.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 11998: Reward = -35499.61, Avg Reward (100) = -30905.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 11999: Reward = -35499.61, Avg Reward (100) = -30905.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12000: Reward = -1147.00, Avg Reward (100) = -30974.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12001: Reward = -1000.00, Avg Reward (100) = -30630.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12002: Reward = -35499.61, Avg Reward (100) = -30087.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12003: Reward = -1000.00, Avg Reward (100) = -30087.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12004: Reward = -35499.61, Avg Reward (100) = -29775.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12005: Reward = -1394.00, Avg Reward (100) = -29775.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12006: Reward = -42304.65, Avg Reward (100) = -29462.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 12007: Reward = -28683.61, Avg Reward (100) = -29530.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12008: Reward = -37669.33, Avg Reward (100) = -29462.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12009: Reward = -1049.00, Avg Reward (100) = -29484.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12010: Reward = -47848.55, Avg Reward (100) = -29085.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12011: Reward = -35499.61, Avg Reward (100) = -29549.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12012: Reward = -32967.34, Avg Reward (100) = -29549.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32967.34, Border Penalty: -33721.27, Obstacle Penalty: -50.00
Episode 12013: Reward = -49176.10, Avg Reward (100) = -29524.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12014: Reward = -35499.61, Avg Reward (100) = -30002.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12015: Reward = -35499.61, Avg Reward (100) = -30346.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12016: Reward = -35499.61, Avg Reward (100) = -30416.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12017: Reward = -37669.33, Avg Reward (100) = -30395.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12018: Reward = -35499.61, Avg Reward (100) = -30275.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12019: Reward = -35499.61, Avg Reward (100) = -30275.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12020: Reward = -35499.61, Avg Reward (100) = -30618.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12021: Reward = -32235.76, Avg Reward (100) = -30618.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 12022: Reward = -49176.10, Avg Reward (100) = -30580.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12023: Reward = -55917.21, Avg Reward (100) = -31061.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -55917.21, Border Penalty: -37175.56, Obstacle Penalty: -50.00
Episode 12024: Reward = -28653.56, Avg Reward (100) = -31265.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12025: Reward = -35499.61, Avg Reward (100) = -31196.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12026: Reward = -28653.56, Avg Reward (100) = -31196.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12027: Reward = -35499.61, Avg Reward (100) = -31471.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12028: Reward = -35499.61, Avg Reward (100) = -31540.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12029: Reward = -35499.61, Avg Reward (100) = -31540.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12030: Reward = -1000.00, Avg Reward (100) = -31518.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12031: Reward = -1049.00, Avg Reward (100) = -31193.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12032: Reward = -25228.52, Avg Reward (100) = -30849.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12033: Reward = -35499.61, Avg Reward (100) = -30775.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12034: Reward = -35499.61, Avg Reward (100) = -30775.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12035: Reward = -35499.61, Avg Reward (100) = -30775.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12036: Reward = -35499.61, Avg Reward (100) = -30775.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12037: Reward = -27702.15, Avg Reward (100) = -30769.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27702.15, Border Penalty: -30554.88, Obstacle Penalty: -50.00
Episode 12038: Reward = -35499.61, Avg Reward (100) = -30554.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12039: Reward = -33701.04, Avg Reward (100) = -30539.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12040: Reward = -35499.61, Avg Reward (100) = -30328.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12041: Reward = -33469.53, Avg Reward (100) = -30396.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12042: Reward = -1000.00, Avg Reward (100) = -30376.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12043: Reward = -36089.25, Avg Reward (100) = -29990.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12044: Reward = -1049.00, Avg Reward (100) = -29996.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12045: Reward = -35499.61, Avg Reward (100) = -29652.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12046: Reward = -35499.61, Avg Reward (100) = -29610.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12047: Reward = -35499.61, Avg Reward (100) = -29639.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12048: Reward = -61242.66, Avg Reward (100) = -29639.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -39298.61, Obstacle Penalty: -50.00
Episode 12049: Reward = -32245.59, Avg Reward (100) = -29897.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 12050: Reward = -1295.00, Avg Reward (100) = -29864.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12051: Reward = -35499.61, Avg Reward (100) = -29522.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12052: Reward = -35499.61, Avg Reward (100) = -29522.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12053: Reward = -35499.61, Avg Reward (100) = -29522.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12054: Reward = -35499.61, Avg Reward (100) = -29522.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12055: Reward = -36726.20, Avg Reward (100) = -29522.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36726.20, Border Penalty: -32739.82, Obstacle Penalty: -50.00
Episode 12056: Reward = -1394.00, Avg Reward (100) = -29534.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12057: Reward = -35499.61, Avg Reward (100) = -29193.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12058: Reward = -35499.61, Avg Reward (100) = -29424.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12059: Reward = -35499.61, Avg Reward (100) = -29768.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12060: Reward = -35499.61, Avg Reward (100) = -29768.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12061: Reward = -29512.46, Avg Reward (100) = -29786.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12062: Reward = -12446.80, Avg Reward (100) = -29726.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12063: Reward = -1196.00, Avg Reward (100) = -29516.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12064: Reward = -49626.26, Avg Reward (100) = -29124.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12065: Reward = -29512.46, Avg Reward (100) = -29266.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12066: Reward = -35499.61, Avg Reward (100) = -29206.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12067: Reward = -35499.61, Avg Reward (100) = -29436.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12068: Reward = -28683.61, Avg Reward (100) = -29436.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12069: Reward = -35499.61, Avg Reward (100) = -29368.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12070: Reward = -1049.00, Avg Reward (100) = -29368.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12071: Reward = -1295.00, Avg Reward (100) = -29024.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12072: Reward = -35499.61, Avg Reward (100) = -29026.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12073: Reward = -35499.61, Avg Reward (100) = -29026.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12074: Reward = -35499.61, Avg Reward (100) = -29124.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12075: Reward = -35499.61, Avg Reward (100) = -29102.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12076: Reward = -1147.00, Avg Reward (100) = -29194.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12077: Reward = -35499.61, Avg Reward (100) = -28850.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12078: Reward = -32245.59, Avg Reward (100) = -28731.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12079: Reward = -1196.00, Avg Reward (100) = -28561.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12080: Reward = -35499.61, Avg Reward (100) = -28218.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12081: Reward = -35499.61, Avg Reward (100) = -28050.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12082: Reward = -42103.80, Avg Reward (100) = -28050.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42103.80, Border Penalty: -37936.77, Obstacle Penalty: -50.00
Episode 12083: Reward = -35499.61, Avg Reward (100) = -28459.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12084: Reward = -28653.56, Avg Reward (100) = -28519.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12085: Reward = -35499.61, Avg Reward (100) = -28451.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12086: Reward = -35499.61, Avg Reward (100) = -28792.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12087: Reward = -53334.41, Avg Reward (100) = -28792.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 12088: Reward = -41656.72, Avg Reward (100) = -29315.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41656.72, Border Penalty: -35485.22, Obstacle Penalty: -50.00
Episode 12089: Reward = -35499.61, Avg Reward (100) = -29377.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12090: Reward = -1147.00, Avg Reward (100) = -29718.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12091: Reward = -12446.80, Avg Reward (100) = -29374.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12092: Reward = -35499.61, Avg Reward (100) = -29144.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12093: Reward = -25228.52, Avg Reward (100) = -29144.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12094: Reward = -12446.80, Avg Reward (100) = -29385.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12095: Reward = -50968.57, Avg Reward (100) = -29155.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50968.57, Border Penalty: -40121.91, Obstacle Penalty: -50.00
Episode 12096: Reward = -35499.61, Avg Reward (100) = -29310.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12097: Reward = -1196.00, Avg Reward (100) = -29310.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12098: Reward = -49176.10, Avg Reward (100) = -29308.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12099: Reward = -36089.25, Avg Reward (100) = -29444.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12100: Reward = -35499.61, Avg Reward (100) = -29450.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12101: Reward = -35499.61, Avg Reward (100) = -29794.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12102: Reward = -35499.61, Avg Reward (100) = -30139.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12103: Reward = -1000.00, Avg Reward (100) = -30139.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12104: Reward = -35499.61, Avg Reward (100) = -30139.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12105: Reward = -35499.61, Avg Reward (100) = -30139.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12106: Reward = -35499.61, Avg Reward (100) = -30480.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12107: Reward = -29512.46, Avg Reward (100) = -30412.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12108: Reward = -33469.53, Avg Reward (100) = -30420.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12109: Reward = -34685.86, Avg Reward (100) = -30378.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12110: Reward = -35499.61, Avg Reward (100) = -30714.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12111: Reward = -35499.61, Avg Reward (100) = -30591.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12112: Reward = -1147.00, Avg Reward (100) = -30591.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12113: Reward = -28653.56, Avg Reward (100) = -30273.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12114: Reward = -35499.61, Avg Reward (100) = -30068.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12115: Reward = -1147.00, Avg Reward (100) = -30068.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12116: Reward = -35499.61, Avg Reward (100) = -29724.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12117: Reward = -35499.61, Avg Reward (100) = -29724.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12118: Reward = -35499.61, Avg Reward (100) = -29702.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12119: Reward = -35499.61, Avg Reward (100) = -29702.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12120: Reward = -26061.91, Avg Reward (100) = -29702.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26061.91, Border Penalty: -30748.40, Obstacle Penalty: -50.00
Episode 12121: Reward = -35499.61, Avg Reward (100) = -29608.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12122: Reward = -49963.65, Avg Reward (100) = -29641.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49963.65, Border Penalty: -40063.56, Obstacle Penalty: -50.00
Episode 12123: Reward = -1049.00, Avg Reward (100) = -29648.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12124: Reward = -1450.40, Avg Reward (100) = -29100.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 12125: Reward = -35499.61, Avg Reward (100) = -28828.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12126: Reward = -28683.61, Avg Reward (100) = -28828.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12127: Reward = -36089.25, Avg Reward (100) = -28828.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12128: Reward = -49626.26, Avg Reward (100) = -28834.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12129: Reward = -35499.61, Avg Reward (100) = -28975.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12130: Reward = -35499.61, Avg Reward (100) = -28975.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12131: Reward = -35499.61, Avg Reward (100) = -29320.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12132: Reward = -44239.55, Avg Reward (100) = -29665.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -44239.55, Border Penalty: -33822.50, Obstacle Penalty: -50.00
Episode 12133: Reward = -34685.86, Avg Reward (100) = -29855.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12134: Reward = -35499.61, Avg Reward (100) = -29847.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12135: Reward = -35499.61, Avg Reward (100) = -29847.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12136: Reward = -43263.20, Avg Reward (100) = -29847.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12137: Reward = -33701.04, Avg Reward (100) = -29924.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12138: Reward = -43263.20, Avg Reward (100) = -29984.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12139: Reward = -49176.10, Avg Reward (100) = -30062.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 12140: Reward = -1147.00, Avg Reward (100) = -30217.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12141: Reward = -35499.61, Avg Reward (100) = -29873.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12142: Reward = -47848.55, Avg Reward (100) = -29893.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12143: Reward = -23648.50, Avg Reward (100) = -30362.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -23648.50, Border Penalty: -30211.19, Obstacle Penalty: -50.00
Episode 12144: Reward = -32619.61, Avg Reward (100) = -30238.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12145: Reward = -40716.65, Avg Reward (100) = -30553.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40716.65, Border Penalty: -36777.90, Obstacle Penalty: -50.00
Episode 12146: Reward = -35499.61, Avg Reward (100) = -30605.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12147: Reward = -28683.61, Avg Reward (100) = -30605.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12148: Reward = -35499.61, Avg Reward (100) = -30537.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12149: Reward = -1049.00, Avg Reward (100) = -30280.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12150: Reward = -35499.61, Avg Reward (100) = -29968.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12151: Reward = -1295.00, Avg Reward (100) = -30310.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12152: Reward = -47848.55, Avg Reward (100) = -29968.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12153: Reward = -35499.61, Avg Reward (100) = -30091.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12154: Reward = -32619.61, Avg Reward (100) = -30091.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12155: Reward = -35499.61, Avg Reward (100) = -30063.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12156: Reward = -49626.26, Avg Reward (100) = -30050.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12157: Reward = -35499.61, Avg Reward (100) = -30533.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12158: Reward = -28653.56, Avg Reward (100) = -30533.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12159: Reward = -43263.20, Avg Reward (100) = -30464.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12160: Reward = -35499.61, Avg Reward (100) = -30542.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12161: Reward = -39606.20, Avg Reward (100) = -30542.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12162: Reward = -43263.20, Avg Reward (100) = -30643.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12163: Reward = -1000.00, Avg Reward (100) = -30951.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12164: Reward = -35499.61, Avg Reward (100) = -30949.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12165: Reward = -34685.86, Avg Reward (100) = -30808.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12166: Reward = -35499.61, Avg Reward (100) = -30859.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12167: Reward = -35499.61, Avg Reward (100) = -30859.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12168: Reward = -35499.61, Avg Reward (100) = -30859.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12169: Reward = -35499.61, Avg Reward (100) = -30928.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12170: Reward = -35499.61, Avg Reward (100) = -30928.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12171: Reward = -35499.61, Avg Reward (100) = -31272.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12172: Reward = -35499.61, Avg Reward (100) = -31614.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12173: Reward = -1196.00, Avg Reward (100) = -31614.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12174: Reward = -35499.61, Avg Reward (100) = -31271.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12175: Reward = -35499.61, Avg Reward (100) = -31271.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12176: Reward = -35499.61, Avg Reward (100) = -31271.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12177: Reward = -35499.61, Avg Reward (100) = -31615.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12178: Reward = -28683.61, Avg Reward (100) = -31615.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12179: Reward = -35499.61, Avg Reward (100) = -31579.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12180: Reward = -35499.61, Avg Reward (100) = -31922.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12181: Reward = -34685.86, Avg Reward (100) = -31922.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12182: Reward = -36089.25, Avg Reward (100) = -31914.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12183: Reward = -43263.20, Avg Reward (100) = -31854.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12184: Reward = -35499.61, Avg Reward (100) = -31931.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12185: Reward = -35499.61, Avg Reward (100) = -32000.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12186: Reward = -39606.20, Avg Reward (100) = -32000.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12187: Reward = -1196.00, Avg Reward (100) = -32041.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12188: Reward = -33469.53, Avg Reward (100) = -31520.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12189: Reward = -1049.00, Avg Reward (100) = -31438.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12190: Reward = -35499.61, Avg Reward (100) = -31093.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12191: Reward = -35499.61, Avg Reward (100) = -31437.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12192: Reward = -32245.59, Avg Reward (100) = -31667.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12193: Reward = -35499.61, Avg Reward (100) = -31635.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12194: Reward = -29512.46, Avg Reward (100) = -31737.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12195: Reward = -35499.61, Avg Reward (100) = -31908.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12196: Reward = -43263.20, Avg Reward (100) = -31753.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12197: Reward = -34685.86, Avg Reward (100) = -31831.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12198: Reward = -35499.61, Avg Reward (100) = -32166.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12199: Reward = -35499.61, Avg Reward (100) = -32029.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12200: Reward = -35499.61, Avg Reward (100) = -32023.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12201: Reward = -43263.20, Avg Reward (100) = -32023.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12202: Reward = -1295.00, Avg Reward (100) = -32101.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12203: Reward = -47848.55, Avg Reward (100) = -31759.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12204: Reward = -35499.61, Avg Reward (100) = -32227.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12205: Reward = -29512.46, Avg Reward (100) = -32227.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 12206: Reward = -35499.61, Avg Reward (100) = -32167.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12207: Reward = -35499.61, Avg Reward (100) = -32167.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12208: Reward = -35499.61, Avg Reward (100) = -32227.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12209: Reward = -35499.61, Avg Reward (100) = -32248.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12210: Reward = -35499.61, Avg Reward (100) = -32256.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12211: Reward = -49626.26, Avg Reward (100) = -32256.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12212: Reward = -1147.00, Avg Reward (100) = -32397.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12213: Reward = -43263.20, Avg Reward (100) = -32397.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12214: Reward = -37669.33, Avg Reward (100) = -32543.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12215: Reward = -35499.61, Avg Reward (100) = -32565.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12216: Reward = -35499.61, Avg Reward (100) = -32908.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12217: Reward = -35499.61, Avg Reward (100) = -32908.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12218: Reward = -35499.61, Avg Reward (100) = -32908.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12219: Reward = -36089.25, Avg Reward (100) = -32908.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12220: Reward = -39606.20, Avg Reward (100) = -32914.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12221: Reward = -28198.29, Avg Reward (100) = -33050.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28198.29, Border Penalty: -31918.41, Obstacle Penalty: -50.00
Episode 12222: Reward = -35499.61, Avg Reward (100) = -32977.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12223: Reward = -36089.25, Avg Reward (100) = -32832.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12224: Reward = -35499.61, Avg Reward (100) = -33182.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12225: Reward = -49626.26, Avg Reward (100) = -33523.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 12226: Reward = -35499.61, Avg Reward (100) = -33664.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12227: Reward = -35499.61, Avg Reward (100) = -33732.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12228: Reward = -35499.61, Avg Reward (100) = -33726.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12229: Reward = -32632.70, Avg Reward (100) = -33585.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 12230: Reward = -35499.61, Avg Reward (100) = -33556.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12231: Reward = -45485.92, Avg Reward (100) = -33556.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -45485.92, Border Penalty: -38304.26, Obstacle Penalty: -50.00
Episode 12232: Reward = -35499.61, Avg Reward (100) = -33656.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12233: Reward = -35499.61, Avg Reward (100) = -33569.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12234: Reward = -35499.61, Avg Reward (100) = -33577.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12235: Reward = -1098.00, Avg Reward (100) = -33577.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12236: Reward = -44507.68, Avg Reward (100) = -33233.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 12237: Reward = -52270.10, Avg Reward (100) = -33245.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 12238: Reward = -1394.00, Avg Reward (100) = -33431.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12239: Reward = -12446.80, Avg Reward (100) = -33012.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12240: Reward = -40955.38, Avg Reward (100) = -32645.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 12241: Reward = -35499.61, Avg Reward (100) = -33043.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12242: Reward = -54261.02, Avg Reward (100) = -33043.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54261.02, Border Penalty: -40768.21, Obstacle Penalty: -50.00
Episode 12243: Reward = -29512.46, Avg Reward (100) = -33107.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12244: Reward = -33701.04, Avg Reward (100) = -33166.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12245: Reward = -33469.53, Avg Reward (100) = -33177.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -31745.04, Obstacle Penalty: -50.00
Episode 12246: Reward = -40334.49, Avg Reward (100) = -33104.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 12247: Reward = -25228.52, Avg Reward (100) = -33153.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12248: Reward = -35499.61, Avg Reward (100) = -33118.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12249: Reward = -35499.61, Avg Reward (100) = -33118.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12250: Reward = -35499.61, Avg Reward (100) = -33463.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12251: Reward = -29512.46, Avg Reward (100) = -33463.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12252: Reward = -1098.00, Avg Reward (100) = -33745.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12253: Reward = -32245.59, Avg Reward (100) = -33277.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12254: Reward = -1196.00, Avg Reward (100) = -33245.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12255: Reward = -33469.53, Avg Reward (100) = -32931.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12256: Reward = -35499.61, Avg Reward (100) = -32910.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12257: Reward = -44239.55, Avg Reward (100) = -32769.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -44239.55, Border Penalty: -33822.50, Obstacle Penalty: -50.00
Episode 12258: Reward = -35499.61, Avg Reward (100) = -32856.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12259: Reward = -1147.00, Avg Reward (100) = -32925.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12260: Reward = -12446.80, Avg Reward (100) = -32504.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12261: Reward = -54036.93, Avg Reward (100) = -32273.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41191.29, Obstacle Penalty: -50.00
Episode 12262: Reward = -35499.61, Avg Reward (100) = -32418.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12263: Reward = -35499.61, Avg Reward (100) = -32340.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12264: Reward = -35499.61, Avg Reward (100) = -32685.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12265: Reward = -35499.61, Avg Reward (100) = -32685.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12266: Reward = -35499.61, Avg Reward (100) = -32693.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12267: Reward = -32245.59, Avg Reward (100) = -32693.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12268: Reward = -1295.00, Avg Reward (100) = -32660.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12269: Reward = -28683.61, Avg Reward (100) = -32318.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12270: Reward = -35499.61, Avg Reward (100) = -32250.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12271: Reward = -1049.00, Avg Reward (100) = -32250.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12272: Reward = -35499.61, Avg Reward (100) = -31906.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12273: Reward = -35499.61, Avg Reward (100) = -31906.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12274: Reward = -1196.00, Avg Reward (100) = -32249.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12275: Reward = -35499.61, Avg Reward (100) = -31906.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12276: Reward = -43263.20, Avg Reward (100) = -31906.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12277: Reward = -1000.00, Avg Reward (100) = -31983.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12278: Reward = -35499.61, Avg Reward (100) = -31638.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12279: Reward = -35499.61, Avg Reward (100) = -31707.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12280: Reward = -35499.61, Avg Reward (100) = -31707.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12281: Reward = -35499.61, Avg Reward (100) = -31707.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12282: Reward = -35499.61, Avg Reward (100) = -31715.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12283: Reward = -32235.76, Avg Reward (100) = -31709.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 12284: Reward = -35499.61, Avg Reward (100) = -31599.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12285: Reward = -35499.61, Avg Reward (100) = -31599.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12286: Reward = -43263.20, Avg Reward (100) = -31599.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 12287: Reward = -35499.61, Avg Reward (100) = -31635.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12288: Reward = -35499.61, Avg Reward (100) = -31978.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12289: Reward = -33701.04, Avg Reward (100) = -31998.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12290: Reward = -35141.95, Avg Reward (100) = -32325.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35141.95, Border Penalty: -34414.47, Obstacle Penalty: -50.00
Episode 12291: Reward = -35499.61, Avg Reward (100) = -32321.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12292: Reward = -32245.59, Avg Reward (100) = -32321.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 12293: Reward = -35499.61, Avg Reward (100) = -32321.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12294: Reward = -1394.00, Avg Reward (100) = -32321.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12295: Reward = -1294.00, Avg Reward (100) = -32040.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12296: Reward = -1000.00, Avg Reward (100) = -31698.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12297: Reward = -35499.61, Avg Reward (100) = -31275.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12298: Reward = -35499.61, Avg Reward (100) = -31284.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12299: Reward = -35499.61, Avg Reward (100) = -31284.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12300: Reward = -1196.00, Avg Reward (100) = -31284.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12301: Reward = -35499.61, Avg Reward (100) = -30941.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12302: Reward = -28653.56, Avg Reward (100) = -30863.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12303: Reward = -35499.61, Avg Reward (100) = -31137.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12304: Reward = -35499.61, Avg Reward (100) = -31013.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12305: Reward = -35499.61, Avg Reward (100) = -31013.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12306: Reward = -28683.61, Avg Reward (100) = -31073.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12307: Reward = -1196.00, Avg Reward (100) = -31005.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12308: Reward = -1394.00, Avg Reward (100) = -30662.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12309: Reward = -35499.61, Avg Reward (100) = -30321.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12310: Reward = -54726.48, Avg Reward (100) = -30321.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54726.48, Border Penalty: -41575.92, Obstacle Penalty: -50.00
Episode 12311: Reward = -47848.55, Avg Reward (100) = -30513.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12312: Reward = -35499.61, Avg Reward (100) = -30495.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12313: Reward = -35499.61, Avg Reward (100) = -30839.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12314: Reward = -35499.61, Avg Reward (100) = -30761.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12315: Reward = -1000.00, Avg Reward (100) = -30739.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12316: Reward = -35499.61, Avg Reward (100) = -30394.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12317: Reward = -1196.00, Avg Reward (100) = -30394.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12318: Reward = -25228.52, Avg Reward (100) = -30051.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12319: Reward = -35499.61, Avg Reward (100) = -29949.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12320: Reward = -35499.61, Avg Reward (100) = -29943.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12321: Reward = -53254.21, Avg Reward (100) = -29902.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -53254.21, Border Penalty: -35716.88, Obstacle Penalty: -50.00
Episode 12322: Reward = -35499.61, Avg Reward (100) = -30152.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12323: Reward = -34685.86, Avg Reward (100) = -30152.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12324: Reward = -35499.61, Avg Reward (100) = -30138.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12325: Reward = -35499.61, Avg Reward (100) = -30138.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12326: Reward = -35499.61, Avg Reward (100) = -29997.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12327: Reward = -37669.33, Avg Reward (100) = -29997.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12328: Reward = -1000.00, Avg Reward (100) = -30019.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12329: Reward = -35499.61, Avg Reward (100) = -29674.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12330: Reward = -1000.00, Avg Reward (100) = -29702.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12331: Reward = -36749.99, Avg Reward (100) = -29357.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36749.99, Border Penalty: -34055.39, Obstacle Penalty: -50.00
Episode 12332: Reward = -28683.61, Avg Reward (100) = -29270.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12333: Reward = -47848.55, Avg Reward (100) = -29202.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12334: Reward = -35499.61, Avg Reward (100) = -29325.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12335: Reward = -49176.10, Avg Reward (100) = -29325.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12336: Reward = -1049.00, Avg Reward (100) = -29806.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12337: Reward = -1351.40, Avg Reward (100) = -29371.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1351.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12338: Reward = -35499.61, Avg Reward (100) = -28862.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12339: Reward = -1049.00, Avg Reward (100) = -29203.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12340: Reward = -35499.61, Avg Reward (100) = -29089.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12341: Reward = -12446.80, Avg Reward (100) = -29035.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12342: Reward = -49626.26, Avg Reward (100) = -28804.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12343: Reward = -47848.55, Avg Reward (100) = -28758.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12344: Reward = -35499.61, Avg Reward (100) = -28941.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12345: Reward = -1049.00, Avg Reward (100) = -28959.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12346: Reward = -29512.46, Avg Reward (100) = -28635.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12347: Reward = -47848.55, Avg Reward (100) = -28527.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12348: Reward = -35499.61, Avg Reward (100) = -28753.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12349: Reward = -35499.61, Avg Reward (100) = -28753.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12350: Reward = -35499.61, Avg Reward (100) = -28753.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12351: Reward = -35499.61, Avg Reward (100) = -28753.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12352: Reward = -40955.38, Avg Reward (100) = -28813.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40955.38, Border Penalty: -35418.79, Obstacle Penalty: -50.00
Episode 12353: Reward = -28799.26, Avg Reward (100) = -29211.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 15, Reward Breakdown -> Delta_x Reward: -28799.26, Border Penalty: -31805.92, Obstacle Penalty: -50.00
Episode 12354: Reward = -35499.61, Avg Reward (100) = -29177.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12355: Reward = -49176.10, Avg Reward (100) = -29520.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12356: Reward = -12446.80, Avg Reward (100) = -29677.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12357: Reward = -38636.47, Avg Reward (100) = -29447.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38636.47, Border Penalty: -36757.25, Obstacle Penalty: -50.00
Episode 12358: Reward = -53075.23, Avg Reward (100) = -29391.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -40537.98, Obstacle Penalty: -50.00
Episode 12359: Reward = -35499.61, Avg Reward (100) = -29566.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12360: Reward = -33701.04, Avg Reward (100) = -29910.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12361: Reward = -33701.04, Avg Reward (100) = -30122.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12362: Reward = -32619.61, Avg Reward (100) = -29919.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12363: Reward = -1147.00, Avg Reward (100) = -29890.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12364: Reward = -49626.26, Avg Reward (100) = -29547.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 12365: Reward = -25468.63, Avg Reward (100) = -29688.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25468.63, Border Penalty: -30469.79, Obstacle Penalty: -50.00
Episode 12366: Reward = -49626.26, Avg Reward (100) = -29588.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12367: Reward = -37669.33, Avg Reward (100) = -29729.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12368: Reward = -35499.61, Avg Reward (100) = -29783.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12369: Reward = -47848.55, Avg Reward (100) = -30125.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12370: Reward = -1000.00, Avg Reward (100) = -30317.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12371: Reward = -35499.61, Avg Reward (100) = -29972.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12372: Reward = -35499.61, Avg Reward (100) = -30316.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12373: Reward = -35499.61, Avg Reward (100) = -30316.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12374: Reward = -47848.55, Avg Reward (100) = -30316.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12375: Reward = -28653.56, Avg Reward (100) = -30783.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12376: Reward = -32245.59, Avg Reward (100) = -30714.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12377: Reward = -1394.00, Avg Reward (100) = -30604.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12378: Reward = -35499.61, Avg Reward (100) = -30608.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12379: Reward = -35499.61, Avg Reward (100) = -30608.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12380: Reward = -35499.61, Avg Reward (100) = -30608.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12381: Reward = -1049.00, Avg Reward (100) = -30608.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12382: Reward = -35499.61, Avg Reward (100) = -30264.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12383: Reward = -35499.61, Avg Reward (100) = -30264.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12384: Reward = -35499.61, Avg Reward (100) = -30296.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12385: Reward = -35499.61, Avg Reward (100) = -30296.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12386: Reward = -35499.61, Avg Reward (100) = -30296.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12387: Reward = -835.48, Avg Reward (100) = -30219.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -835.48, Border Penalty: -2362.18, Obstacle Penalty: -60.63
Episode 12388: Reward = -35499.61, Avg Reward (100) = -29872.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12389: Reward = -35499.61, Avg Reward (100) = -29872.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12390: Reward = -32245.59, Avg Reward (100) = -29890.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12391: Reward = -35499.61, Avg Reward (100) = -29861.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12392: Reward = -35499.61, Avg Reward (100) = -29861.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12393: Reward = -35499.61, Avg Reward (100) = -29894.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12394: Reward = -35499.61, Avg Reward (100) = -29894.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12395: Reward = -35499.61, Avg Reward (100) = -30235.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12396: Reward = -35499.61, Avg Reward (100) = -30577.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12397: Reward = -35499.61, Avg Reward (100) = -30922.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12398: Reward = -1394.00, Avg Reward (100) = -30922.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 12399: Reward = -12446.80, Avg Reward (100) = -30581.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12400: Reward = -35499.61, Avg Reward (100) = -30350.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12401: Reward = -1295.00, Avg Reward (100) = -30693.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12402: Reward = -32619.61, Avg Reward (100) = -30351.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 12403: Reward = -35499.61, Avg Reward (100) = -30391.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12404: Reward = -35499.61, Avg Reward (100) = -30391.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12405: Reward = -35499.61, Avg Reward (100) = -30391.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12406: Reward = -35499.61, Avg Reward (100) = -30391.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12407: Reward = -35499.61, Avg Reward (100) = -30459.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12408: Reward = -28683.61, Avg Reward (100) = -30802.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12409: Reward = -33469.53, Avg Reward (100) = -31075.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12410: Reward = -35499.61, Avg Reward (100) = -31055.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12411: Reward = -35499.61, Avg Reward (100) = -30862.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12412: Reward = -28683.61, Avg Reward (100) = -30739.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12413: Reward = -35499.61, Avg Reward (100) = -30671.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12414: Reward = -35499.61, Avg Reward (100) = -30671.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12415: Reward = -35499.61, Avg Reward (100) = -30671.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12416: Reward = -1000.00, Avg Reward (100) = -31016.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12417: Reward = -32619.61, Avg Reward (100) = -30671.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12418: Reward = -39606.20, Avg Reward (100) = -30985.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -33795.82, Obstacle Penalty: -50.00
Episode 12419: Reward = -12446.80, Avg Reward (100) = -31129.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12420: Reward = -35499.61, Avg Reward (100) = -30898.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12421: Reward = -32612.87, Avg Reward (100) = -30898.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32612.87, Border Penalty: -33574.94, Obstacle Penalty: -50.00
Episode 12422: Reward = -35499.61, Avg Reward (100) = -30692.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12423: Reward = -32245.59, Avg Reward (100) = -30692.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12424: Reward = -35499.61, Avg Reward (100) = -30667.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12425: Reward = -35499.61, Avg Reward (100) = -30667.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12426: Reward = -35499.61, Avg Reward (100) = -30667.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12427: Reward = -37669.33, Avg Reward (100) = -30667.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12428: Reward = -35499.61, Avg Reward (100) = -30667.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12429: Reward = -36089.25, Avg Reward (100) = -31012.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 12430: Reward = -35499.61, Avg Reward (100) = -31018.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12431: Reward = -54870.38, Avg Reward (100) = -31363.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -54870.38, Border Penalty: -41391.79, Obstacle Penalty: -50.00
Episode 12432: Reward = -28683.61, Avg Reward (100) = -31544.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12433: Reward = -1196.00, Avg Reward (100) = -31544.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12434: Reward = -35499.61, Avg Reward (100) = -31078.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12435: Reward = -1147.00, Avg Reward (100) = -31078.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12436: Reward = -1394.00, Avg Reward (100) = -30598.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12437: Reward = -35499.61, Avg Reward (100) = -30601.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12438: Reward = -49626.26, Avg Reward (100) = -30943.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12439: Reward = -35499.61, Avg Reward (100) = -31084.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12440: Reward = -49176.10, Avg Reward (100) = -31428.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 12441: Reward = -34685.86, Avg Reward (100) = -31565.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12442: Reward = -35499.61, Avg Reward (100) = -31787.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12443: Reward = -35499.61, Avg Reward (100) = -31646.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12444: Reward = -1098.00, Avg Reward (100) = -31523.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12445: Reward = -27492.00, Avg Reward (100) = -31179.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 12446: Reward = -35499.61, Avg Reward (100) = -31443.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12447: Reward = -49626.26, Avg Reward (100) = -31503.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12448: Reward = -35499.61, Avg Reward (100) = -31521.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12449: Reward = -34982.32, Avg Reward (100) = -31521.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34982.32, Border Penalty: -33449.43, Obstacle Penalty: -50.00
Episode 12450: Reward = -35499.61, Avg Reward (100) = -31516.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12451: Reward = -1295.00, Avg Reward (100) = -31516.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12452: Reward = -35499.61, Avg Reward (100) = -31174.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12453: Reward = -49626.26, Avg Reward (100) = -31119.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12454: Reward = -35499.61, Avg Reward (100) = -31327.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12455: Reward = -35499.61, Avg Reward (100) = -31327.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12456: Reward = -35499.61, Avg Reward (100) = -31190.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12457: Reward = -1147.00, Avg Reward (100) = -31421.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12458: Reward = -35499.61, Avg Reward (100) = -31046.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12459: Reward = -49176.10, Avg Reward (100) = -30870.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12460: Reward = -35499.61, Avg Reward (100) = -31007.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12461: Reward = -1394.00, Avg Reward (100) = -31025.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12462: Reward = -33382.70, Avg Reward (100) = -30702.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33382.70, Border Penalty: -34178.79, Obstacle Penalty: -50.00
Episode 12463: Reward = -1394.00, Avg Reward (100) = -30710.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12464: Reward = -29879.41, Avg Reward (100) = -30712.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -29879.41, Border Penalty: -31642.21, Obstacle Penalty: -50.00
Episode 12465: Reward = -35499.61, Avg Reward (100) = -30515.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12466: Reward = -35499.61, Avg Reward (100) = -30615.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12467: Reward = -39606.20, Avg Reward (100) = -30474.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12468: Reward = -35499.61, Avg Reward (100) = -30493.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12469: Reward = -28683.61, Avg Reward (100) = -30493.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12470: Reward = -49176.10, Avg Reward (100) = -30301.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12471: Reward = -35499.61, Avg Reward (100) = -30783.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12472: Reward = -1294.00, Avg Reward (100) = -30783.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12473: Reward = -1098.00, Avg Reward (100) = -30441.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12474: Reward = -1394.00, Avg Reward (100) = -30097.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12475: Reward = -33469.53, Avg Reward (100) = -29633.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 12476: Reward = -34685.86, Avg Reward (100) = -29681.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12477: Reward = -35499.61, Avg Reward (100) = -29705.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12478: Reward = -35499.61, Avg Reward (100) = -30046.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12479: Reward = -35499.61, Avg Reward (100) = -30046.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12480: Reward = -1000.00, Avg Reward (100) = -30046.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12481: Reward = -35499.61, Avg Reward (100) = -29701.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12482: Reward = -35499.61, Avg Reward (100) = -30046.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12483: Reward = -35499.61, Avg Reward (100) = -30046.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12484: Reward = -35499.61, Avg Reward (100) = -30046.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12485: Reward = -40334.49, Avg Reward (100) = -30046.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 12486: Reward = -28653.56, Avg Reward (100) = -30094.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12487: Reward = -43263.20, Avg Reward (100) = -30026.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12488: Reward = -35499.61, Avg Reward (100) = -30450.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12489: Reward = -35499.61, Avg Reward (100) = -30450.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12490: Reward = -1394.00, Avg Reward (100) = -30450.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12491: Reward = -35499.61, Avg Reward (100) = -30141.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12492: Reward = -35499.61, Avg Reward (100) = -30141.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12493: Reward = -35499.61, Avg Reward (100) = -30141.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12494: Reward = -35499.61, Avg Reward (100) = -30141.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12495: Reward = -47848.55, Avg Reward (100) = -30141.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12496: Reward = -35499.61, Avg Reward (100) = -30265.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12497: Reward = -35499.61, Avg Reward (100) = -30265.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12498: Reward = -36089.25, Avg Reward (100) = -30265.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12499: Reward = -37054.55, Avg Reward (100) = -30612.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37054.55, Border Penalty: -35755.93, Obstacle Penalty: -50.00
Episode 12500: Reward = -47439.38, Avg Reward (100) = -30858.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47439.38, Border Penalty: -39279.86, Obstacle Penalty: -50.00
Episode 12501: Reward = -35499.61, Avg Reward (100) = -30977.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12502: Reward = -35499.61, Avg Reward (100) = -31319.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12503: Reward = -35499.61, Avg Reward (100) = -31348.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12504: Reward = -35499.61, Avg Reward (100) = -31348.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12505: Reward = -1295.00, Avg Reward (100) = -31348.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12506: Reward = -42113.29, Avg Reward (100) = -31006.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42113.29, Border Penalty: -35930.51, Obstacle Penalty: -50.00
Episode 12507: Reward = -43802.69, Avg Reward (100) = -31072.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 12508: Reward = -12446.80, Avg Reward (100) = -31155.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12509: Reward = -33469.53, Avg Reward (100) = -30993.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12510: Reward = -43263.20, Avg Reward (100) = -30993.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12511: Reward = -35499.61, Avg Reward (100) = -31071.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12512: Reward = -35499.61, Avg Reward (100) = -31071.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12513: Reward = -35499.61, Avg Reward (100) = -31139.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12514: Reward = -35499.61, Avg Reward (100) = -31139.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12515: Reward = -35499.61, Avg Reward (100) = -31139.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12516: Reward = -35499.61, Avg Reward (100) = -31139.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12517: Reward = -12446.80, Avg Reward (100) = -31484.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12518: Reward = -47848.55, Avg Reward (100) = -31282.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12519: Reward = -35499.61, Avg Reward (100) = -31364.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12520: Reward = -35499.61, Avg Reward (100) = -31595.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12521: Reward = -35499.61, Avg Reward (100) = -31595.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12522: Reward = -35499.61, Avg Reward (100) = -31624.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12523: Reward = -35499.61, Avg Reward (100) = -31624.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12524: Reward = -1295.00, Avg Reward (100) = -31656.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12525: Reward = -35499.61, Avg Reward (100) = -31314.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12526: Reward = -35499.61, Avg Reward (100) = -31314.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12527: Reward = -35499.61, Avg Reward (100) = -31314.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12528: Reward = -35499.61, Avg Reward (100) = -31293.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12529: Reward = -35499.61, Avg Reward (100) = -31293.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12530: Reward = -35499.61, Avg Reward (100) = -31287.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12531: Reward = -32619.61, Avg Reward (100) = -31287.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12532: Reward = -35499.61, Avg Reward (100) = -31064.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12533: Reward = -37669.33, Avg Reward (100) = -31132.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12534: Reward = -35499.61, Avg Reward (100) = -31497.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12535: Reward = -35499.61, Avg Reward (100) = -31497.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12536: Reward = -35499.61, Avg Reward (100) = -31841.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12537: Reward = -43263.20, Avg Reward (100) = -32182.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12538: Reward = -35499.61, Avg Reward (100) = -32259.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12539: Reward = -35499.61, Avg Reward (100) = -32118.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12540: Reward = -32619.61, Avg Reward (100) = -32118.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12541: Reward = -35499.61, Avg Reward (100) = -31952.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12542: Reward = -35499.61, Avg Reward (100) = -31961.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12543: Reward = -35499.61, Avg Reward (100) = -31961.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12544: Reward = -1049.00, Avg Reward (100) = -31961.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12545: Reward = -48567.86, Avg Reward (100) = -31960.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 12546: Reward = -12446.80, Avg Reward (100) = -32171.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12547: Reward = -43263.20, Avg Reward (100) = -31940.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12548: Reward = -1295.00, Avg Reward (100) = -31877.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12549: Reward = -53955.87, Avg Reward (100) = -31535.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 12550: Reward = -35499.61, Avg Reward (100) = -31724.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12551: Reward = -49176.10, Avg Reward (100) = -31724.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12552: Reward = -40716.65, Avg Reward (100) = -32203.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -40716.65, Border Penalty: -36777.90, Obstacle Penalty: -50.00
Episode 12553: Reward = -35499.61, Avg Reward (100) = -32255.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12554: Reward = -35499.61, Avg Reward (100) = -32114.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12555: Reward = -35499.61, Avg Reward (100) = -32114.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12556: Reward = -35499.61, Avg Reward (100) = -32114.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12557: Reward = -35499.61, Avg Reward (100) = -32114.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12558: Reward = -37669.33, Avg Reward (100) = -32458.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12559: Reward = -35499.61, Avg Reward (100) = -32479.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12560: Reward = -1098.00, Avg Reward (100) = -32343.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12561: Reward = -35499.61, Avg Reward (100) = -31999.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12562: Reward = -28683.61, Avg Reward (100) = -32340.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12563: Reward = -1098.00, Avg Reward (100) = -32293.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12564: Reward = -35499.61, Avg Reward (100) = -32290.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12565: Reward = -31653.57, Avg Reward (100) = -32346.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -31653.57, Border Penalty: -33412.71, Obstacle Penalty: -50.00
Episode 12566: Reward = -35499.61, Avg Reward (100) = -32307.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12567: Reward = -35499.61, Avg Reward (100) = -32307.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12568: Reward = -1147.00, Avg Reward (100) = -32266.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12569: Reward = -47848.55, Avg Reward (100) = -31923.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12570: Reward = -49176.10, Avg Reward (100) = -32114.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12571: Reward = -35499.61, Avg Reward (100) = -32114.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12572: Reward = -25869.03, Avg Reward (100) = -32114.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -25869.03, Border Penalty: -30119.32, Obstacle Penalty: -50.00
Episode 12573: Reward = -49626.26, Avg Reward (100) = -32360.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12574: Reward = -35499.61, Avg Reward (100) = -32845.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12575: Reward = -35499.61, Avg Reward (100) = -33187.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12576: Reward = -29512.46, Avg Reward (100) = -33207.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12577: Reward = -35499.61, Avg Reward (100) = -33155.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12578: Reward = -35499.61, Avg Reward (100) = -33155.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12579: Reward = -37669.33, Avg Reward (100) = -33155.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12580: Reward = -33469.53, Avg Reward (100) = -33177.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12581: Reward = -35499.61, Avg Reward (100) = -33501.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12582: Reward = -35499.61, Avg Reward (100) = -33501.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12583: Reward = -35499.61, Avg Reward (100) = -33501.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12584: Reward = -35499.61, Avg Reward (100) = -33501.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12585: Reward = -35499.61, Avg Reward (100) = -33501.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12586: Reward = -35499.61, Avg Reward (100) = -33453.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12587: Reward = -35499.61, Avg Reward (100) = -33522.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12588: Reward = -37669.33, Avg Reward (100) = -33444.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12589: Reward = -35499.61, Avg Reward (100) = -33466.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12590: Reward = -35499.61, Avg Reward (100) = -33466.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12591: Reward = -1295.00, Avg Reward (100) = -33807.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12592: Reward = -1098.00, Avg Reward (100) = -33465.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12593: Reward = -35499.61, Avg Reward (100) = -33121.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12594: Reward = -1000.00, Avg Reward (100) = -33121.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12595: Reward = -35499.61, Avg Reward (100) = -32776.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12596: Reward = -35499.61, Avg Reward (100) = -32652.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12597: Reward = -35499.61, Avg Reward (100) = -32652.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12598: Reward = -35499.61, Avg Reward (100) = -32652.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12599: Reward = -35499.61, Avg Reward (100) = -32646.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12600: Reward = -35499.61, Avg Reward (100) = -32631.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12601: Reward = -28683.61, Avg Reward (100) = -32511.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12602: Reward = -35499.61, Avg Reward (100) = -32443.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12603: Reward = -35499.61, Avg Reward (100) = -32443.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12604: Reward = -12446.80, Avg Reward (100) = -32443.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12605: Reward = -35499.61, Avg Reward (100) = -32213.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12606: Reward = -35499.61, Avg Reward (100) = -32555.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12607: Reward = -35499.61, Avg Reward (100) = -32489.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12608: Reward = -35499.61, Avg Reward (100) = -32406.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12609: Reward = -35499.61, Avg Reward (100) = -32636.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12610: Reward = -35499.61, Avg Reward (100) = -32656.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12611: Reward = -35499.61, Avg Reward (100) = -32579.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12612: Reward = -36089.25, Avg Reward (100) = -32579.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12613: Reward = -35499.61, Avg Reward (100) = -32585.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12614: Reward = -25228.52, Avg Reward (100) = -32585.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12615: Reward = -35499.61, Avg Reward (100) = -32482.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12616: Reward = -52585.18, Avg Reward (100) = -32482.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 12617: Reward = -36089.25, Avg Reward (100) = -32653.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12618: Reward = -35499.61, Avg Reward (100) = -32889.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12619: Reward = -35499.61, Avg Reward (100) = -32766.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12620: Reward = -35499.61, Avg Reward (100) = -32766.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12621: Reward = -35499.61, Avg Reward (100) = -32766.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12622: Reward = -46242.48, Avg Reward (100) = -32766.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -46242.48, Border Penalty: -36037.65, Obstacle Penalty: -50.00
Episode 12623: Reward = -33701.04, Avg Reward (100) = -32873.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12624: Reward = -28653.56, Avg Reward (100) = -32855.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12625: Reward = -35499.61, Avg Reward (100) = -33129.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12626: Reward = -35499.61, Avg Reward (100) = -33129.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12627: Reward = -35499.61, Avg Reward (100) = -33129.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12628: Reward = -35499.61, Avg Reward (100) = -33129.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12629: Reward = -29512.46, Avg Reward (100) = -33129.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12630: Reward = -35499.61, Avg Reward (100) = -33069.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12631: Reward = -35499.61, Avg Reward (100) = -33069.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12632: Reward = -34685.86, Avg Reward (100) = -33098.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12633: Reward = -35499.61, Avg Reward (100) = -33090.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12634: Reward = -1000.00, Avg Reward (100) = -33068.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12635: Reward = -1147.00, Avg Reward (100) = -32723.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12636: Reward = -37669.33, Avg Reward (100) = -32379.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12637: Reward = -1098.00, Avg Reward (100) = -32401.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12638: Reward = -34685.86, Avg Reward (100) = -31979.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12639: Reward = -35499.61, Avg Reward (100) = -31971.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12640: Reward = -35499.61, Avg Reward (100) = -31971.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12641: Reward = -35499.61, Avg Reward (100) = -32000.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12642: Reward = -35499.61, Avg Reward (100) = -32000.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12643: Reward = -42304.65, Avg Reward (100) = -32000.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 12644: Reward = -35499.61, Avg Reward (100) = -32068.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12645: Reward = -35499.61, Avg Reward (100) = -32413.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12646: Reward = -25228.52, Avg Reward (100) = -32282.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12647: Reward = -32245.59, Avg Reward (100) = -32410.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12648: Reward = -33469.53, Avg Reward (100) = -32300.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12649: Reward = -52585.18, Avg Reward (100) = -32621.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 12650: Reward = -1295.00, Avg Reward (100) = -32608.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12651: Reward = -1049.00, Avg Reward (100) = -32265.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12652: Reward = -36089.25, Avg Reward (100) = -31784.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12653: Reward = -25228.52, Avg Reward (100) = -31738.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12654: Reward = -1147.00, Avg Reward (100) = -31635.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12655: Reward = -35499.61, Avg Reward (100) = -31292.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12656: Reward = -35499.61, Avg Reward (100) = -31292.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12657: Reward = -35499.61, Avg Reward (100) = -31292.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12658: Reward = -35499.61, Avg Reward (100) = -31292.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12659: Reward = -35499.61, Avg Reward (100) = -31270.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12660: Reward = -1394.00, Avg Reward (100) = -31270.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12661: Reward = -53955.87, Avg Reward (100) = -31273.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 12662: Reward = -35499.61, Avg Reward (100) = -31458.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12663: Reward = -35499.61, Avg Reward (100) = -31526.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12664: Reward = -35499.61, Avg Reward (100) = -31870.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12665: Reward = -35499.61, Avg Reward (100) = -31870.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12666: Reward = -33469.53, Avg Reward (100) = -31908.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12667: Reward = -35499.61, Avg Reward (100) = -31888.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12668: Reward = -33701.04, Avg Reward (100) = -31888.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12669: Reward = -35499.61, Avg Reward (100) = -32213.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12670: Reward = -35499.61, Avg Reward (100) = -32090.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12671: Reward = -46100.60, Avg Reward (100) = -31953.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46100.60, Border Penalty: -39023.41, Obstacle Penalty: -50.00
Episode 12672: Reward = -37669.33, Avg Reward (100) = -32059.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12673: Reward = -35499.61, Avg Reward (100) = -32177.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12674: Reward = -35499.61, Avg Reward (100) = -32036.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12675: Reward = -35499.61, Avg Reward (100) = -32036.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12676: Reward = -35499.61, Avg Reward (100) = -32036.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12677: Reward = -35499.61, Avg Reward (100) = -32096.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12678: Reward = -35499.61, Avg Reward (100) = -32096.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12679: Reward = -33469.53, Avg Reward (100) = -32096.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12680: Reward = -35499.61, Avg Reward (100) = -32054.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12681: Reward = -39606.20, Avg Reward (100) = -32074.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12682: Reward = -37664.73, Avg Reward (100) = -32115.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37664.73, Border Penalty: -34269.04, Obstacle Penalty: -50.00
Episode 12683: Reward = -34685.86, Avg Reward (100) = -32137.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12684: Reward = -49176.10, Avg Reward (100) = -32129.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12685: Reward = -1394.00, Avg Reward (100) = -32265.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12686: Reward = -35499.61, Avg Reward (100) = -31924.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12687: Reward = -35499.61, Avg Reward (100) = -31924.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12688: Reward = -33701.04, Avg Reward (100) = -31924.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12689: Reward = -1049.00, Avg Reward (100) = -31885.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12690: Reward = -1000.00, Avg Reward (100) = -31540.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12691: Reward = -35499.61, Avg Reward (100) = -31195.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12692: Reward = -35499.61, Avg Reward (100) = -31537.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12693: Reward = -35499.61, Avg Reward (100) = -31881.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12694: Reward = -35499.61, Avg Reward (100) = -31881.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12695: Reward = -35499.61, Avg Reward (100) = -32226.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12696: Reward = -35499.61, Avg Reward (100) = -32226.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12697: Reward = -1394.00, Avg Reward (100) = -32226.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12698: Reward = -32619.61, Avg Reward (100) = -31885.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12699: Reward = -35499.61, Avg Reward (100) = -31856.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12700: Reward = -35499.61, Avg Reward (100) = -31856.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12701: Reward = -35499.61, Avg Reward (100) = -31856.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12702: Reward = -35499.61, Avg Reward (100) = -31925.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12703: Reward = -29512.46, Avg Reward (100) = -31925.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12704: Reward = -12446.80, Avg Reward (100) = -31865.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12705: Reward = -12446.80, Avg Reward (100) = -31865.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12706: Reward = -32619.61, Avg Reward (100) = -31634.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12707: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12708: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12709: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12710: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12711: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12712: Reward = -35499.61, Avg Reward (100) = -31605.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12713: Reward = -1147.00, Avg Reward (100) = -31599.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12714: Reward = -35499.61, Avg Reward (100) = -31256.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12715: Reward = -35499.61, Avg Reward (100) = -31359.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12716: Reward = -1049.00, Avg Reward (100) = -31359.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12717: Reward = -35499.61, Avg Reward (100) = -30843.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12718: Reward = -25228.52, Avg Reward (100) = -30837.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12719: Reward = -1147.00, Avg Reward (100) = -30735.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12720: Reward = -36089.25, Avg Reward (100) = -30391.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12721: Reward = -5390.43, Avg Reward (100) = -30397.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -5390.43, Border Penalty: -12900.05, Obstacle Penalty: -50.00
Episode 12722: Reward = -35499.61, Avg Reward (100) = -30096.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12723: Reward = -29512.46, Avg Reward (100) = -29989.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12724: Reward = -1049.00, Avg Reward (100) = -29947.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12725: Reward = -35499.61, Avg Reward (100) = -29671.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12726: Reward = -1000.00, Avg Reward (100) = -29671.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12727: Reward = -1098.00, Avg Reward (100) = -29326.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12728: Reward = -1098.00, Avg Reward (100) = -28982.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12729: Reward = -12446.80, Avg Reward (100) = -28638.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12730: Reward = -35499.61, Avg Reward (100) = -28467.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12731: Reward = -35499.61, Avg Reward (100) = -28467.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12732: Reward = -35499.61, Avg Reward (100) = -28467.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12733: Reward = -1098.00, Avg Reward (100) = -28475.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12734: Reward = -35499.61, Avg Reward (100) = -28131.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12735: Reward = -35499.61, Avg Reward (100) = -28476.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12736: Reward = -1295.00, Avg Reward (100) = -28820.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12737: Reward = -1098.00, Avg Reward (100) = -28456.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12738: Reward = -35499.61, Avg Reward (100) = -28456.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12739: Reward = -35499.61, Avg Reward (100) = -28464.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12740: Reward = -35499.61, Avg Reward (100) = -28464.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12741: Reward = -35499.61, Avg Reward (100) = -28464.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12742: Reward = -39606.20, Avg Reward (100) = -28464.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12743: Reward = -1098.00, Avg Reward (100) = -28505.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12744: Reward = -36089.25, Avg Reward (100) = -28093.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 12745: Reward = -35499.61, Avg Reward (100) = -28099.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12746: Reward = -35499.61, Avg Reward (100) = -28099.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12747: Reward = -35499.61, Avg Reward (100) = -28202.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12748: Reward = -1147.00, Avg Reward (100) = -28234.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12749: Reward = -35499.61, Avg Reward (100) = -27911.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12750: Reward = -47848.55, Avg Reward (100) = -27740.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12751: Reward = -35499.61, Avg Reward (100) = -28206.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12752: Reward = -35499.61, Avg Reward (100) = -28550.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12753: Reward = -28683.61, Avg Reward (100) = -28544.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12754: Reward = -33378.53, Avg Reward (100) = -28579.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33378.53, Border Penalty: -34475.70, Obstacle Penalty: -50.00
Episode 12755: Reward = -39606.20, Avg Reward (100) = -28901.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12756: Reward = -35499.61, Avg Reward (100) = -28942.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12757: Reward = -35499.61, Avg Reward (100) = -28942.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12758: Reward = -1295.00, Avg Reward (100) = -28942.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12759: Reward = -35499.61, Avg Reward (100) = -28600.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12760: Reward = -33469.53, Avg Reward (100) = -28600.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12761: Reward = -35499.61, Avg Reward (100) = -28921.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12762: Reward = -40817.24, Avg Reward (100) = -28736.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40817.24, Border Penalty: -35385.96, Obstacle Penalty: -50.00
Episode 12763: Reward = -35499.61, Avg Reward (100) = -28789.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12764: Reward = -35499.61, Avg Reward (100) = -28789.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12765: Reward = -35499.61, Avg Reward (100) = -28789.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12766: Reward = -35499.61, Avg Reward (100) = -28789.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12767: Reward = -35499.61, Avg Reward (100) = -28810.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12768: Reward = -41554.36, Avg Reward (100) = -28810.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41554.36, Border Penalty: -34538.36, Obstacle Penalty: -50.00
Episode 12769: Reward = -35499.61, Avg Reward (100) = -28888.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12770: Reward = -35499.61, Avg Reward (100) = -28888.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12771: Reward = -12446.80, Avg Reward (100) = -28888.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12772: Reward = -35499.61, Avg Reward (100) = -28552.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12773: Reward = -47848.55, Avg Reward (100) = -28530.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12774: Reward = -35499.61, Avg Reward (100) = -28653.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12775: Reward = -26470.74, Avg Reward (100) = -28653.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -26470.74, Border Penalty: -30563.56, Obstacle Penalty: -50.00
Episode 12776: Reward = -35499.61, Avg Reward (100) = -28563.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12777: Reward = -49626.26, Avg Reward (100) = -28563.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12778: Reward = -1147.00, Avg Reward (100) = -28704.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12779: Reward = -35499.61, Avg Reward (100) = -28361.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12780: Reward = -1049.00, Avg Reward (100) = -28381.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12781: Reward = -35499.61, Avg Reward (100) = -28037.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12782: Reward = -32851.49, Avg Reward (100) = -27996.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 12783: Reward = -1000.00, Avg Reward (100) = -27948.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12784: Reward = -35499.61, Avg Reward (100) = -27611.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12785: Reward = -35499.61, Avg Reward (100) = -27474.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12786: Reward = -1000.00, Avg Reward (100) = -27815.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12787: Reward = -28653.56, Avg Reward (100) = -27470.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12788: Reward = -35499.61, Avg Reward (100) = -27402.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12789: Reward = -49176.10, Avg Reward (100) = -27420.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12790: Reward = -35499.61, Avg Reward (100) = -27901.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12791: Reward = -35499.61, Avg Reward (100) = -28246.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 12792: Reward = -35499.61, Avg Reward (100) = -28246.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12793: Reward = -50498.83, Avg Reward (100) = -28246.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50498.83, Border Penalty: -40565.62, Obstacle Penalty: -50.00
Episode 12794: Reward = -1295.00, Avg Reward (100) = -28396.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12795: Reward = -1098.00, Avg Reward (100) = -28054.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12796: Reward = -35499.61, Avg Reward (100) = -27710.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12797: Reward = -35499.61, Avg Reward (100) = -27710.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12798: Reward = -35499.61, Avg Reward (100) = -28051.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12799: Reward = -35499.61, Avg Reward (100) = -28080.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12800: Reward = -35499.61, Avg Reward (100) = -28080.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12801: Reward = -34685.86, Avg Reward (100) = -28080.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 12802: Reward = -44651.33, Avg Reward (100) = -28071.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44651.33, Border Penalty: -38718.66, Obstacle Penalty: -50.00
Episode 12803: Reward = -49174.12, Avg Reward (100) = -28163.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49174.12, Border Penalty: -39697.16, Obstacle Penalty: -50.00
Episode 12804: Reward = -1049.00, Avg Reward (100) = -28360.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12805: Reward = -35499.61, Avg Reward (100) = -28246.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12806: Reward = -35499.61, Avg Reward (100) = -28476.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12807: Reward = -35499.61, Avg Reward (100) = -28505.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12808: Reward = -35499.61, Avg Reward (100) = -28505.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12809: Reward = -34741.98, Avg Reward (100) = -28505.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34741.98, Border Penalty: -33918.71, Obstacle Penalty: -50.00
Episode 12810: Reward = -35499.61, Avg Reward (100) = -28497.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12811: Reward = -35499.61, Avg Reward (100) = -28497.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12812: Reward = -37690.71, Avg Reward (100) = -28497.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37690.71, Border Penalty: -33801.11, Obstacle Penalty: -50.00
Episode 12813: Reward = -28683.61, Avg Reward (100) = -28519.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12814: Reward = -35499.61, Avg Reward (100) = -28795.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12815: Reward = -1394.00, Avg Reward (100) = -28795.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12816: Reward = -32245.59, Avg Reward (100) = -28454.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12817: Reward = -39606.20, Avg Reward (100) = -28766.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12818: Reward = -35499.61, Avg Reward (100) = -28807.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12819: Reward = -35499.61, Avg Reward (100) = -28909.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12820: Reward = -49626.26, Avg Reward (100) = -29253.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12821: Reward = -35499.61, Avg Reward (100) = -29388.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12822: Reward = -35499.61, Avg Reward (100) = -29689.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12823: Reward = -28653.56, Avg Reward (100) = -29689.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 12824: Reward = -35499.61, Avg Reward (100) = -29681.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12825: Reward = -35499.61, Avg Reward (100) = -30025.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12826: Reward = -35499.61, Avg Reward (100) = -30025.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12827: Reward = -35499.61, Avg Reward (100) = -30370.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12828: Reward = -35499.61, Avg Reward (100) = -30714.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12829: Reward = -35499.61, Avg Reward (100) = -31058.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12830: Reward = -1196.00, Avg Reward (100) = -31289.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12831: Reward = -35499.61, Avg Reward (100) = -30946.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12832: Reward = -35368.76, Avg Reward (100) = -30946.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -35368.76, Border Penalty: -34840.38, Obstacle Penalty: -50.00
Episode 12833: Reward = -35499.61, Avg Reward (100) = -30944.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12834: Reward = -35499.61, Avg Reward (100) = -31288.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12835: Reward = -1196.00, Avg Reward (100) = -31288.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12836: Reward = -1000.00, Avg Reward (100) = -30945.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12837: Reward = -35499.61, Avg Reward (100) = -30942.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12838: Reward = -1098.00, Avg Reward (100) = -31286.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12839: Reward = -35499.61, Avg Reward (100) = -30942.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12840: Reward = -33469.53, Avg Reward (100) = -30942.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12841: Reward = -1196.00, Avg Reward (100) = -30922.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12842: Reward = -35499.61, Avg Reward (100) = -30579.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12843: Reward = -35499.61, Avg Reward (100) = -30538.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12844: Reward = -35499.61, Avg Reward (100) = -30882.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12845: Reward = -35499.61, Avg Reward (100) = -30876.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12846: Reward = -1196.00, Avg Reward (100) = -30876.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12847: Reward = -1295.00, Avg Reward (100) = -30533.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12848: Reward = -35295.52, Avg Reward (100) = -30191.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -31754.35, Obstacle Penalty: -50.00
Episode 12849: Reward = -1147.00, Avg Reward (100) = -30533.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12850: Reward = -35499.61, Avg Reward (100) = -30189.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12851: Reward = -35499.61, Avg Reward (100) = -30066.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12852: Reward = -35499.61, Avg Reward (100) = -30066.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12853: Reward = -35499.61, Avg Reward (100) = -30066.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12854: Reward = -49626.26, Avg Reward (100) = -30134.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12855: Reward = -43263.20, Avg Reward (100) = -30296.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12856: Reward = -45723.38, Avg Reward (100) = -30333.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -45723.38, Border Penalty: -38065.23, Obstacle Penalty: -50.00
Episode 12857: Reward = -36089.25, Avg Reward (100) = -30435.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12858: Reward = -33469.53, Avg Reward (100) = -30441.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 12859: Reward = -32851.49, Avg Reward (100) = -30763.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 12860: Reward = -35499.61, Avg Reward (100) = -30736.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12861: Reward = -35499.61, Avg Reward (100) = -30756.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12862: Reward = -32619.61, Avg Reward (100) = -30756.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12863: Reward = -49636.01, Avg Reward (100) = -30674.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -49636.01, Border Penalty: -36852.60, Obstacle Penalty: -50.00
Episode 12864: Reward = -1196.00, Avg Reward (100) = -30816.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12865: Reward = -32245.59, Avg Reward (100) = -30473.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 12866: Reward = -1147.00, Avg Reward (100) = -30440.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12867: Reward = -35499.61, Avg Reward (100) = -30097.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12868: Reward = -35499.61, Avg Reward (100) = -30097.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12869: Reward = -35499.61, Avg Reward (100) = -30036.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12870: Reward = -50498.83, Avg Reward (100) = -30036.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50498.83, Border Penalty: -40565.62, Obstacle Penalty: -50.00
Episode 12871: Reward = -33469.53, Avg Reward (100) = -30186.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 12872: Reward = -1394.00, Avg Reward (100) = -30396.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12873: Reward = -35499.61, Avg Reward (100) = -30055.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12874: Reward = -25228.52, Avg Reward (100) = -29932.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 12875: Reward = -35499.61, Avg Reward (100) = -29829.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12876: Reward = -1295.00, Avg Reward (100) = -29919.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 12877: Reward = -35499.61, Avg Reward (100) = -29577.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12878: Reward = -26588.16, Avg Reward (100) = -29436.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26588.16, Border Penalty: -30582.33, Obstacle Penalty: -50.00
Episode 12879: Reward = -35499.61, Avg Reward (100) = -29691.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12880: Reward = -35499.61, Avg Reward (100) = -29691.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12881: Reward = -47431.57, Avg Reward (100) = -30035.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47431.57, Border Penalty: -33586.45, Obstacle Penalty: -50.00
Episode 12882: Reward = -35499.61, Avg Reward (100) = -30154.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12883: Reward = -12446.80, Avg Reward (100) = -30181.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12884: Reward = -1394.00, Avg Reward (100) = -30295.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12885: Reward = -39606.20, Avg Reward (100) = -29954.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 12886: Reward = -53962.77, Avg Reward (100) = -29995.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53962.77, Border Penalty: -39528.81, Obstacle Penalty: -50.00
Episode 12887: Reward = -28653.56, Avg Reward (100) = -30525.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 12888: Reward = -43263.20, Avg Reward (100) = -30525.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12889: Reward = -35499.61, Avg Reward (100) = -30603.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12890: Reward = -35499.61, Avg Reward (100) = -30466.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12891: Reward = -35499.61, Avg Reward (100) = -30466.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12892: Reward = -35499.61, Avg Reward (100) = -30466.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12893: Reward = -35499.61, Avg Reward (100) = -30466.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12894: Reward = -35499.61, Avg Reward (100) = -30316.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12895: Reward = -35499.61, Avg Reward (100) = -30658.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12896: Reward = -1196.00, Avg Reward (100) = -31002.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12897: Reward = -37669.33, Avg Reward (100) = -30659.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 12898: Reward = -35499.61, Avg Reward (100) = -30681.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12899: Reward = -35499.61, Avg Reward (100) = -30681.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12900: Reward = -35499.61, Avg Reward (100) = -30681.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12901: Reward = -1147.00, Avg Reward (100) = -30681.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12902: Reward = -1196.00, Avg Reward (100) = -30345.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12903: Reward = -35499.61, Avg Reward (100) = -29911.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12904: Reward = -28683.61, Avg Reward (100) = -29774.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12905: Reward = -35499.61, Avg Reward (100) = -30050.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12906: Reward = -35499.61, Avg Reward (100) = -30050.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12907: Reward = -49176.10, Avg Reward (100) = -30050.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 12908: Reward = -1245.00, Avg Reward (100) = -30187.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12909: Reward = -33701.04, Avg Reward (100) = -29844.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 12910: Reward = -35499.61, Avg Reward (100) = -29834.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12911: Reward = -35499.61, Avg Reward (100) = -29834.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12912: Reward = -35499.61, Avg Reward (100) = -29834.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12913: Reward = -35499.61, Avg Reward (100) = -29812.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12914: Reward = -39606.20, Avg Reward (100) = -29880.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 12915: Reward = -35499.61, Avg Reward (100) = -29921.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12916: Reward = -1098.00, Avg Reward (100) = -30262.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12917: Reward = -36089.25, Avg Reward (100) = -29951.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12918: Reward = -35499.61, Avg Reward (100) = -29916.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12919: Reward = -1098.00, Avg Reward (100) = -29916.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12920: Reward = -35499.61, Avg Reward (100) = -29572.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12921: Reward = -1000.00, Avg Reward (100) = -29430.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12922: Reward = -35499.61, Avg Reward (100) = -29085.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12923: Reward = -35499.61, Avg Reward (100) = -29085.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12924: Reward = -35499.61, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12925: Reward = -35499.61, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12926: Reward = -35499.61, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12927: Reward = -35499.61, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12928: Reward = -35499.61, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12929: Reward = -49626.26, Avg Reward (100) = -29154.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12930: Reward = -29512.46, Avg Reward (100) = -29295.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12931: Reward = -35499.61, Avg Reward (100) = -29578.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12932: Reward = -35499.61, Avg Reward (100) = -29578.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12933: Reward = -43263.20, Avg Reward (100) = -29580.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 12934: Reward = -35499.61, Avg Reward (100) = -29657.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12935: Reward = -35499.61, Avg Reward (100) = -29657.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12936: Reward = -35499.61, Avg Reward (100) = -30000.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12937: Reward = -35499.61, Avg Reward (100) = -30345.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12938: Reward = -1098.00, Avg Reward (100) = -30345.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12939: Reward = -35499.61, Avg Reward (100) = -30345.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12940: Reward = -35499.61, Avg Reward (100) = -30345.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12941: Reward = -39606.20, Avg Reward (100) = -30366.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 12942: Reward = -49626.26, Avg Reward (100) = -30750.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12943: Reward = -35499.61, Avg Reward (100) = -30891.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12944: Reward = -35499.61, Avg Reward (100) = -30891.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12945: Reward = -34051.44, Avg Reward (100) = -30891.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34051.44, Border Penalty: -33610.83, Obstacle Penalty: -50.00
Episode 12946: Reward = -35499.61, Avg Reward (100) = -30877.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12947: Reward = -49626.26, Avg Reward (100) = -31220.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12948: Reward = -49285.73, Avg Reward (100) = -31703.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49285.73, Border Penalty: -40370.16, Obstacle Penalty: -50.00
Episode 12949: Reward = -28683.61, Avg Reward (100) = -31843.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12950: Reward = -35499.61, Avg Reward (100) = -32118.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12951: Reward = -35499.61, Avg Reward (100) = -32118.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12952: Reward = -1000.00, Avg Reward (100) = -32118.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12953: Reward = -35499.61, Avg Reward (100) = -31773.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12954: Reward = -1196.00, Avg Reward (100) = -31773.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 12955: Reward = -48438.64, Avg Reward (100) = -31289.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48438.64, Border Penalty: -33827.04, Obstacle Penalty: -50.00
Episode 12956: Reward = -46773.66, Avg Reward (100) = -31341.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46773.66, Border Penalty: -37426.48, Obstacle Penalty: -50.00
Episode 12957: Reward = -35499.61, Avg Reward (100) = -31351.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12958: Reward = -29512.46, Avg Reward (100) = -31345.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12959: Reward = -36089.25, Avg Reward (100) = -31306.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 12960: Reward = -35499.61, Avg Reward (100) = -31338.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12961: Reward = -35499.61, Avg Reward (100) = -31338.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12962: Reward = -35499.61, Avg Reward (100) = -31338.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12963: Reward = -35499.61, Avg Reward (100) = -31367.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12964: Reward = -12446.80, Avg Reward (100) = -31225.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12965: Reward = -35499.61, Avg Reward (100) = -31338.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12966: Reward = -12446.80, Avg Reward (100) = -31370.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 12967: Reward = -47848.55, Avg Reward (100) = -31483.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12968: Reward = -35499.61, Avg Reward (100) = -31607.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12969: Reward = -1147.00, Avg Reward (100) = -31607.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12970: Reward = -1394.00, Avg Reward (100) = -31263.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 12971: Reward = -35499.61, Avg Reward (100) = -30772.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12972: Reward = -29512.46, Avg Reward (100) = -30793.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 12973: Reward = -1000.00, Avg Reward (100) = -31074.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 12974: Reward = -35499.61, Avg Reward (100) = -30729.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12975: Reward = -35499.61, Avg Reward (100) = -30832.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12976: Reward = -35499.61, Avg Reward (100) = -30832.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12977: Reward = -35499.61, Avg Reward (100) = -31174.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12978: Reward = -35499.61, Avg Reward (100) = -31174.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12979: Reward = -35499.61, Avg Reward (100) = -31263.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12980: Reward = -35499.61, Avg Reward (100) = -31263.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12981: Reward = -35499.61, Avg Reward (100) = -31263.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12982: Reward = -35499.61, Avg Reward (100) = -31143.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12983: Reward = -35499.61, Avg Reward (100) = -31143.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12984: Reward = -35499.61, Avg Reward (100) = -31374.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12985: Reward = -49626.26, Avg Reward (100) = -31715.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 12986: Reward = -35499.61, Avg Reward (100) = -31815.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12987: Reward = -47848.55, Avg Reward (100) = -31631.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 12988: Reward = -35499.61, Avg Reward (100) = -31823.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12989: Reward = -35499.61, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12990: Reward = -35499.61, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12991: Reward = -35499.61, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12992: Reward = -35499.61, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12993: Reward = -35499.61, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12994: Reward = -26588.16, Avg Reward (100) = -31745.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26588.16, Border Penalty: -30582.33, Obstacle Penalty: -50.00
Episode 12995: Reward = -35499.61, Avg Reward (100) = -31656.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 12996: Reward = -35499.61, Avg Reward (100) = -31656.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12997: Reward = -35499.61, Avg Reward (100) = -31999.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 12998: Reward = -32619.61, Avg Reward (100) = -31977.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 12999: Reward = -27702.15, Avg Reward (100) = -31948.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -27702.15, Border Penalty: -30554.88, Obstacle Penalty: -50.00
Episode 13000: Reward = -47848.55, Avg Reward (100) = -31870.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13001: Reward = -1000.00, Avg Reward (100) = -31994.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13002: Reward = -35499.61, Avg Reward (100) = -31992.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13003: Reward = -52585.18, Avg Reward (100) = -32335.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52585.18, Border Penalty: -40207.57, Obstacle Penalty: -50.00
Episode 13004: Reward = -35499.61, Avg Reward (100) = -32506.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13005: Reward = -35499.61, Avg Reward (100) = -32574.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13006: Reward = -35499.61, Avg Reward (100) = -32574.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13007: Reward = -35499.61, Avg Reward (100) = -32574.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13008: Reward = -1049.00, Avg Reward (100) = -32438.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13009: Reward = -35499.61, Avg Reward (100) = -32436.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13010: Reward = -35499.61, Avg Reward (100) = -32454.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13011: Reward = -43263.20, Avg Reward (100) = -32454.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13012: Reward = -35499.61, Avg Reward (100) = -32531.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13013: Reward = -35499.61, Avg Reward (100) = -32531.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13014: Reward = -43263.20, Avg Reward (100) = -32531.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13015: Reward = -28653.56, Avg Reward (100) = -32568.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13016: Reward = -12446.80, Avg Reward (100) = -32499.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13017: Reward = -35499.61, Avg Reward (100) = -32613.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13018: Reward = -35499.61, Avg Reward (100) = -32607.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13019: Reward = -54036.93, Avg Reward (100) = -32607.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41791.35, Obstacle Penalty: -50.00
Episode 13020: Reward = -35499.61, Avg Reward (100) = -33136.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13021: Reward = -32245.59, Avg Reward (100) = -33136.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13022: Reward = -33469.53, Avg Reward (100) = -33449.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34025.04, Obstacle Penalty: -50.00
Episode 13023: Reward = -35499.61, Avg Reward (100) = -33429.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13024: Reward = -35499.61, Avg Reward (100) = -33429.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13025: Reward = -49626.26, Avg Reward (100) = -33429.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13026: Reward = -33469.53, Avg Reward (100) = -33570.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13027: Reward = -35499.61, Avg Reward (100) = -33550.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13028: Reward = -35499.61, Avg Reward (100) = -33550.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13029: Reward = -35499.61, Avg Reward (100) = -33550.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13030: Reward = -37669.33, Avg Reward (100) = -33408.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13031: Reward = -1000.00, Avg Reward (100) = -33490.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13032: Reward = -35499.61, Avg Reward (100) = -33145.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13033: Reward = -35499.61, Avg Reward (100) = -33145.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13034: Reward = -35499.61, Avg Reward (100) = -33067.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13035: Reward = -35499.61, Avg Reward (100) = -33067.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13036: Reward = -35499.61, Avg Reward (100) = -33067.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13037: Reward = -35499.61, Avg Reward (100) = -33067.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13038: Reward = -1147.00, Avg Reward (100) = -33067.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13039: Reward = -47848.55, Avg Reward (100) = -33068.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13040: Reward = -35499.61, Avg Reward (100) = -33191.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13041: Reward = -12446.80, Avg Reward (100) = -33191.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13042: Reward = -34685.86, Avg Reward (100) = -32920.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 13043: Reward = -35499.61, Avg Reward (100) = -32770.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13044: Reward = -35499.61, Avg Reward (100) = -32770.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13045: Reward = -35499.61, Avg Reward (100) = -32770.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13046: Reward = -35499.61, Avg Reward (100) = -32785.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13047: Reward = -34685.86, Avg Reward (100) = -32785.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13048: Reward = -42113.29, Avg Reward (100) = -32635.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42113.29, Border Penalty: -35930.51, Obstacle Penalty: -50.00
Episode 13049: Reward = -35499.61, Avg Reward (100) = -32564.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13050: Reward = -1295.00, Avg Reward (100) = -32632.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13051: Reward = -35499.61, Avg Reward (100) = -32290.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13052: Reward = -1098.00, Avg Reward (100) = -32290.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13053: Reward = -35499.61, Avg Reward (100) = -32291.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13054: Reward = -29512.46, Avg Reward (100) = -32291.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13055: Reward = -35499.61, Avg Reward (100) = -32574.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13056: Reward = -1000.00, Avg Reward (100) = -32444.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13057: Reward = -35499.61, Avg Reward (100) = -31987.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13058: Reward = -1358.25, Avg Reward (100) = -31987.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1358.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13059: Reward = -35499.61, Avg Reward (100) = -31705.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13060: Reward = -1147.00, Avg Reward (100) = -31699.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13061: Reward = -1000.00, Avg Reward (100) = -31356.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13062: Reward = -35499.61, Avg Reward (100) = -31011.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13063: Reward = -28653.56, Avg Reward (100) = -31011.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13064: Reward = -35499.61, Avg Reward (100) = -30942.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13065: Reward = -46355.43, Avg Reward (100) = -31173.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -46355.43, Border Penalty: -33771.59, Obstacle Penalty: -50.00
Episode 13066: Reward = -35499.61, Avg Reward (100) = -31281.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13067: Reward = -35499.61, Avg Reward (100) = -31512.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13068: Reward = -33469.53, Avg Reward (100) = -31388.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13069: Reward = -37669.33, Avg Reward (100) = -31368.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13070: Reward = -35499.61, Avg Reward (100) = -31733.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13071: Reward = -28962.03, Avg Reward (100) = -32074.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28962.03, Border Penalty: -30668.39, Obstacle Penalty: -50.00
Episode 13072: Reward = -35499.61, Avg Reward (100) = -32009.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13073: Reward = -49176.10, Avg Reward (100) = -32069.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -37163.81, Obstacle Penalty: -50.00
Episode 13074: Reward = -1049.00, Avg Reward (100) = -32551.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13075: Reward = -35499.61, Avg Reward (100) = -32206.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13076: Reward = -47848.55, Avg Reward (100) = -32206.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13077: Reward = -1098.00, Avg Reward (100) = -32330.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13078: Reward = -35499.61, Avg Reward (100) = -31986.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13079: Reward = -1450.40, Avg Reward (100) = -31986.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 13080: Reward = -34685.86, Avg Reward (100) = -31645.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13081: Reward = -1098.00, Avg Reward (100) = -31637.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13082: Reward = -33469.53, Avg Reward (100) = -31293.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13083: Reward = -29512.46, Avg Reward (100) = -31273.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13084: Reward = -1295.00, Avg Reward (100) = -31213.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13085: Reward = -35499.61, Avg Reward (100) = -30871.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13086: Reward = -35499.61, Avg Reward (100) = -30729.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13087: Reward = -35499.61, Avg Reward (100) = -30729.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13088: Reward = -36089.25, Avg Reward (100) = -30606.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13089: Reward = -35499.61, Avg Reward (100) = -30612.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13090: Reward = -33469.53, Avg Reward (100) = -30612.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13091: Reward = -1394.00, Avg Reward (100) = -30592.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13092: Reward = -35499.61, Avg Reward (100) = -30251.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13093: Reward = -58385.69, Avg Reward (100) = -30251.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -58385.69, Border Penalty: -40040.85, Obstacle Penalty: -50.00
Episode 13094: Reward = -35499.61, Avg Reward (100) = -30479.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13095: Reward = -29512.46, Avg Reward (100) = -30568.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13096: Reward = -35499.61, Avg Reward (100) = -30509.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13097: Reward = -35499.61, Avg Reward (100) = -30509.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13098: Reward = -35499.61, Avg Reward (100) = -30509.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13099: Reward = -33701.04, Avg Reward (100) = -30537.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13100: Reward = -35499.61, Avg Reward (100) = -30597.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13101: Reward = -47848.55, Avg Reward (100) = -30474.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -36300.06, Obstacle Penalty: -50.00
Episode 13102: Reward = -35499.61, Avg Reward (100) = -30942.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13103: Reward = -35499.61, Avg Reward (100) = -30942.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13104: Reward = -37669.33, Avg Reward (100) = -30772.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13105: Reward = -1049.00, Avg Reward (100) = -30793.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13106: Reward = -35499.61, Avg Reward (100) = -30449.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13107: Reward = -35499.61, Avg Reward (100) = -30449.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13108: Reward = -1394.00, Avg Reward (100) = -30449.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13109: Reward = -28683.61, Avg Reward (100) = -30452.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13110: Reward = -35499.61, Avg Reward (100) = -30384.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13111: Reward = -39606.20, Avg Reward (100) = -30384.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13112: Reward = -35499.61, Avg Reward (100) = -30347.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13113: Reward = -35499.61, Avg Reward (100) = -30347.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13114: Reward = -1196.00, Avg Reward (100) = -30347.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13115: Reward = -1098.00, Avg Reward (100) = -29927.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13116: Reward = -49176.10, Avg Reward (100) = -29651.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 13117: Reward = -35499.61, Avg Reward (100) = -30019.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13118: Reward = -54261.02, Avg Reward (100) = -30019.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54261.02, Border Penalty: -40768.21, Obstacle Penalty: -50.00
Episode 13119: Reward = -1000.00, Avg Reward (100) = -30206.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13120: Reward = -35499.61, Avg Reward (100) = -29676.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13121: Reward = -35499.61, Avg Reward (100) = -29676.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13122: Reward = -35499.61, Avg Reward (100) = -29708.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13123: Reward = -35499.61, Avg Reward (100) = -29729.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13124: Reward = -35499.61, Avg Reward (100) = -29729.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13125: Reward = -35499.61, Avg Reward (100) = -29729.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13126: Reward = -1000.00, Avg Reward (100) = -29587.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13127: Reward = -37669.33, Avg Reward (100) = -29263.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13128: Reward = -35499.61, Avg Reward (100) = -29284.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13129: Reward = -1147.00, Avg Reward (100) = -29284.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13130: Reward = -37669.33, Avg Reward (100) = -28941.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13131: Reward = -61242.66, Avg Reward (100) = -28941.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -61242.66, Border Penalty: -39298.61, Obstacle Penalty: -50.00
Episode 13132: Reward = -35499.61, Avg Reward (100) = -29543.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13133: Reward = -35499.61, Avg Reward (100) = -29543.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13134: Reward = -35499.61, Avg Reward (100) = -29543.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13135: Reward = -33469.53, Avg Reward (100) = -29543.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13136: Reward = -1147.00, Avg Reward (100) = -29523.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13137: Reward = -35499.61, Avg Reward (100) = -29179.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13138: Reward = -35499.61, Avg Reward (100) = -29179.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13139: Reward = -44524.86, Avg Reward (100) = -29523.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44524.86, Border Penalty: -38099.33, Obstacle Penalty: -50.00
Episode 13140: Reward = -33021.40, Avg Reward (100) = -29490.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -33021.40, Border Penalty: -34470.35, Obstacle Penalty: -50.00
Episode 13141: Reward = -34482.45, Avg Reward (100) = -29465.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 13142: Reward = -1098.00, Avg Reward (100) = -29685.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13143: Reward = -33469.53, Avg Reward (100) = -29349.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13144: Reward = -35499.61, Avg Reward (100) = -29329.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13145: Reward = -35499.61, Avg Reward (100) = -29329.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13146: Reward = -1394.00, Avg Reward (100) = -29329.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13147: Reward = -1000.00, Avg Reward (100) = -28988.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13148: Reward = -1394.00, Avg Reward (100) = -28651.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13149: Reward = -47848.55, Avg Reward (100) = -28244.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13150: Reward = -35499.61, Avg Reward (100) = -28367.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13151: Reward = -36089.25, Avg Reward (100) = -28710.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13152: Reward = -39606.20, Avg Reward (100) = -28715.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13153: Reward = -35499.61, Avg Reward (100) = -29101.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13154: Reward = -35499.61, Avg Reward (100) = -29101.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13155: Reward = -35499.61, Avg Reward (100) = -29160.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13156: Reward = -14881.38, Avg Reward (100) = -29160.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -14881.38, Border Penalty: -24075.82, Obstacle Penalty: -50.00
Episode 13157: Reward = -39216.62, Avg Reward (100) = -29299.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39216.62, Border Penalty: -36024.72, Obstacle Penalty: -50.00
Episode 13158: Reward = -33469.53, Avg Reward (100) = -29336.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13159: Reward = -32245.59, Avg Reward (100) = -29657.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13160: Reward = -1295.00, Avg Reward (100) = -29625.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13161: Reward = -35499.61, Avg Reward (100) = -29626.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13162: Reward = -37669.33, Avg Reward (100) = -29971.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13163: Reward = -38792.44, Avg Reward (100) = -29993.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 13164: Reward = -33701.04, Avg Reward (100) = -30094.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13165: Reward = -1049.00, Avg Reward (100) = -30077.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13166: Reward = -35499.61, Avg Reward (100) = -29623.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13167: Reward = -1049.00, Avg Reward (100) = -29623.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13168: Reward = -35499.61, Avg Reward (100) = -29279.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13169: Reward = -35499.61, Avg Reward (100) = -29299.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13170: Reward = -35499.61, Avg Reward (100) = -29278.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13171: Reward = -35499.61, Avg Reward (100) = -29278.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13172: Reward = -35499.61, Avg Reward (100) = -29343.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13173: Reward = -35499.61, Avg Reward (100) = -29343.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13174: Reward = -35499.61, Avg Reward (100) = -29206.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13175: Reward = -28683.61, Avg Reward (100) = -29551.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13176: Reward = -35499.61, Avg Reward (100) = -29482.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13177: Reward = -1196.00, Avg Reward (100) = -29359.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13178: Reward = -12446.80, Avg Reward (100) = -29360.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13179: Reward = -35499.61, Avg Reward (100) = -29129.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13180: Reward = -1344.00, Avg Reward (100) = -29470.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1344.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13181: Reward = -35499.61, Avg Reward (100) = -29137.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13182: Reward = -1196.00, Avg Reward (100) = -29481.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13183: Reward = -29512.46, Avg Reward (100) = -29158.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13184: Reward = -38924.96, Avg Reward (100) = -29158.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38924.96, Border Penalty: -36612.80, Obstacle Penalty: -50.00
Episode 13185: Reward = -35499.61, Avg Reward (100) = -29534.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13186: Reward = -35499.61, Avg Reward (100) = -29534.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13187: Reward = -35499.61, Avg Reward (100) = -29534.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13188: Reward = -35499.61, Avg Reward (100) = -29534.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13189: Reward = -35499.61, Avg Reward (100) = -29528.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13190: Reward = -1394.00, Avg Reward (100) = -29528.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13191: Reward = -35499.61, Avg Reward (100) = -29207.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13192: Reward = -35499.61, Avg Reward (100) = -29549.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13193: Reward = -35499.61, Avg Reward (100) = -29549.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13194: Reward = -35499.61, Avg Reward (100) = -29320.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13195: Reward = -48567.86, Avg Reward (100) = -29320.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48567.86, Border Penalty: -39479.64, Obstacle Penalty: -50.00
Episode 13196: Reward = -33469.53, Avg Reward (100) = -29510.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13197: Reward = -35499.61, Avg Reward (100) = -29490.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13198: Reward = -35499.61, Avg Reward (100) = -29490.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13199: Reward = -25228.52, Avg Reward (100) = -29490.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13200: Reward = -1000.00, Avg Reward (100) = -29405.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13201: Reward = -35499.61, Avg Reward (100) = -29060.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13202: Reward = -35499.61, Avg Reward (100) = -28937.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13203: Reward = -36224.14, Avg Reward (100) = -28937.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36224.14, Border Penalty: -34054.01, Obstacle Penalty: -50.00
Episode 13204: Reward = -35499.61, Avg Reward (100) = -28944.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13205: Reward = -35499.61, Avg Reward (100) = -28922.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13206: Reward = -49626.26, Avg Reward (100) = -29267.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13207: Reward = -1049.00, Avg Reward (100) = -29408.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13208: Reward = -49626.26, Avg Reward (100) = -29064.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13209: Reward = -35499.61, Avg Reward (100) = -29546.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13210: Reward = -32245.59, Avg Reward (100) = -29614.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13211: Reward = -35499.61, Avg Reward (100) = -29581.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13212: Reward = -35499.61, Avg Reward (100) = -29540.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13213: Reward = -29512.46, Avg Reward (100) = -29540.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13214: Reward = -35499.61, Avg Reward (100) = -29481.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13215: Reward = -1049.00, Avg Reward (100) = -29824.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13216: Reward = -37185.15, Avg Reward (100) = -29823.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37185.15, Border Penalty: -36230.21, Obstacle Penalty: -50.00
Episode 13217: Reward = -29649.77, Avg Reward (100) = -29703.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -29649.77, Border Penalty: -32871.24, Obstacle Penalty: -50.00
Episode 13218: Reward = -1147.00, Avg Reward (100) = -29645.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13219: Reward = -48116.97, Avg Reward (100) = -29114.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -48116.97, Border Penalty: -39756.41, Obstacle Penalty: -50.00
Episode 13220: Reward = -35499.61, Avg Reward (100) = -29585.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13221: Reward = -58564.79, Avg Reward (100) = -29585.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -58564.79, Border Penalty: -39949.70, Obstacle Penalty: -50.00
Episode 13222: Reward = -35499.61, Avg Reward (100) = -29815.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13223: Reward = -32245.59, Avg Reward (100) = -29815.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13224: Reward = -64684.01, Avg Reward (100) = -29783.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -64684.01, Border Penalty: -37459.96, Obstacle Penalty: -50.00
Episode 13225: Reward = -35499.61, Avg Reward (100) = -30075.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13226: Reward = -1000.00, Avg Reward (100) = -30075.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13227: Reward = -35499.61, Avg Reward (100) = -30075.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13228: Reward = -1394.00, Avg Reward (100) = -30053.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13229: Reward = -28683.61, Avg Reward (100) = -29712.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13230: Reward = -49176.10, Avg Reward (100) = -29987.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13231: Reward = -1000.00, Avg Reward (100) = -30102.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13232: Reward = -30619.04, Avg Reward (100) = -29500.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30619.04, Border Penalty: -32490.02, Obstacle Penalty: -50.00
Episode 13233: Reward = -35499.61, Avg Reward (100) = -29451.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13234: Reward = -1098.00, Avg Reward (100) = -29451.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13235: Reward = -35499.61, Avg Reward (100) = -29107.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13236: Reward = -1394.00, Avg Reward (100) = -29127.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13237: Reward = -1196.00, Avg Reward (100) = -29130.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13238: Reward = -33701.04, Avg Reward (100) = -28787.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13239: Reward = -1147.00, Avg Reward (100) = -28769.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13240: Reward = -32245.59, Avg Reward (100) = -28335.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13241: Reward = -35499.61, Avg Reward (100) = -28327.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13242: Reward = -35499.61, Avg Reward (100) = -28337.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13243: Reward = -35499.61, Avg Reward (100) = -28681.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13244: Reward = -35499.61, Avg Reward (100) = -28702.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13245: Reward = -35499.61, Avg Reward (100) = -28702.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13246: Reward = -1098.00, Avg Reward (100) = -28702.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13247: Reward = -35499.61, Avg Reward (100) = -28699.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13248: Reward = -1295.00, Avg Reward (100) = -29044.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13249: Reward = -35499.61, Avg Reward (100) = -29043.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13250: Reward = -28683.61, Avg Reward (100) = -28919.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13251: Reward = -49176.10, Avg Reward (100) = -28851.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.45, Obstacle Penalty: -50.00
Episode 13252: Reward = -34685.86, Avg Reward (100) = -28982.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -30953.80, Obstacle Penalty: -50.00
Episode 13253: Reward = -35499.61, Avg Reward (100) = -28933.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13254: Reward = -35499.61, Avg Reward (100) = -28933.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13255: Reward = -32245.59, Avg Reward (100) = -28933.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13256: Reward = -28653.56, Avg Reward (100) = -28900.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 13257: Reward = -43587.12, Avg Reward (100) = -29038.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -43587.12, Border Penalty: -37307.89, Obstacle Penalty: -50.00
Episode 13258: Reward = -29512.46, Avg Reward (100) = -29082.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13259: Reward = -36089.25, Avg Reward (100) = -29042.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13260: Reward = -74388.22, Avg Reward (100) = -29081.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -74388.22, Border Penalty: -36916.90, Obstacle Penalty: -50.00
Episode 13261: Reward = -35499.61, Avg Reward (100) = -29812.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13262: Reward = -30416.69, Avg Reward (100) = -29812.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -30416.69, Border Penalty: -33691.42, Obstacle Penalty: -50.00
Episode 13263: Reward = -35499.61, Avg Reward (100) = -29739.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13264: Reward = -49626.26, Avg Reward (100) = -29706.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13265: Reward = -35499.61, Avg Reward (100) = -29865.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13266: Reward = -32245.59, Avg Reward (100) = -30210.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13267: Reward = -33701.04, Avg Reward (100) = -30177.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13268: Reward = -35499.61, Avg Reward (100) = -30504.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13269: Reward = -35499.61, Avg Reward (100) = -30504.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13270: Reward = -35499.61, Avg Reward (100) = -30504.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13271: Reward = -32619.61, Avg Reward (100) = -30504.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13272: Reward = -35499.61, Avg Reward (100) = -30475.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13273: Reward = -35499.61, Avg Reward (100) = -30475.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13274: Reward = -35499.61, Avg Reward (100) = -30475.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13275: Reward = -43902.06, Avg Reward (100) = -30475.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 13276: Reward = -35499.61, Avg Reward (100) = -30627.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13277: Reward = -1049.00, Avg Reward (100) = -30627.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13278: Reward = -35499.61, Avg Reward (100) = -30626.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13279: Reward = -30437.18, Avg Reward (100) = -30856.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 13280: Reward = -35499.61, Avg Reward (100) = -30806.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13281: Reward = -35499.61, Avg Reward (100) = -31147.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13282: Reward = -35499.61, Avg Reward (100) = -31147.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13283: Reward = -35499.61, Avg Reward (100) = -31490.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13284: Reward = -28653.56, Avg Reward (100) = -31550.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13285: Reward = -35499.61, Avg Reward (100) = -31447.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13286: Reward = -35499.61, Avg Reward (100) = -31447.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13287: Reward = -1295.00, Avg Reward (100) = -31447.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13288: Reward = -35499.61, Avg Reward (100) = -31105.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13289: Reward = -35499.61, Avg Reward (100) = -31105.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13290: Reward = -39606.20, Avg Reward (100) = -31105.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36075.82, Obstacle Penalty: -50.00
Episode 13291: Reward = -35499.61, Avg Reward (100) = -31487.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13292: Reward = -35499.61, Avg Reward (100) = -31487.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13293: Reward = -53053.43, Avg Reward (100) = -31487.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -53053.43, Border Penalty: -39554.56, Obstacle Penalty: -50.00
Episode 13294: Reward = -35499.61, Avg Reward (100) = -31663.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13295: Reward = -35499.61, Avg Reward (100) = -31663.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13296: Reward = -39606.20, Avg Reward (100) = -31532.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13297: Reward = -35499.61, Avg Reward (100) = -31594.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13298: Reward = -35499.61, Avg Reward (100) = -31594.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13299: Reward = -35499.61, Avg Reward (100) = -31594.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13300: Reward = -35499.61, Avg Reward (100) = -31696.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13301: Reward = -1295.00, Avg Reward (100) = -32041.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13302: Reward = -35499.61, Avg Reward (100) = -31699.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13303: Reward = -1295.00, Avg Reward (100) = -31699.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13304: Reward = -35499.61, Avg Reward (100) = -31350.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13305: Reward = -49176.10, Avg Reward (100) = -31350.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.80, Obstacle Penalty: -50.00
Episode 13306: Reward = -47914.45, Avg Reward (100) = -31487.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47914.45, Border Penalty: -37690.09, Obstacle Penalty: -50.00
Episode 13307: Reward = -49626.26, Avg Reward (100) = -31470.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -39427.82, Obstacle Penalty: -50.00
Episode 13308: Reward = -35499.61, Avg Reward (100) = -31955.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13309: Reward = -1295.00, Avg Reward (100) = -31814.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13310: Reward = -34685.86, Avg Reward (100) = -31472.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13311: Reward = -49176.10, Avg Reward (100) = -31497.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13312: Reward = -1394.00, Avg Reward (100) = -31633.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13313: Reward = -35499.61, Avg Reward (100) = -31292.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13314: Reward = -35499.61, Avg Reward (100) = -31352.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13315: Reward = -35499.61, Avg Reward (100) = -31352.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13316: Reward = -1147.00, Avg Reward (100) = -31697.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13317: Reward = -45417.44, Avg Reward (100) = -31336.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45417.44, Border Penalty: -38590.88, Obstacle Penalty: -50.00
Episode 13318: Reward = -35499.61, Avg Reward (100) = -31494.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13319: Reward = -33469.53, Avg Reward (100) = -31837.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13320: Reward = -34685.86, Avg Reward (100) = -31691.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13321: Reward = -35499.61, Avg Reward (100) = -31683.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13322: Reward = -35499.61, Avg Reward (100) = -31452.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13323: Reward = -33701.04, Avg Reward (100) = -31452.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13324: Reward = -35499.61, Avg Reward (100) = -31467.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13325: Reward = -1147.00, Avg Reward (100) = -31175.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13326: Reward = -1000.00, Avg Reward (100) = -30831.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13327: Reward = -1147.00, Avg Reward (100) = -30831.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13328: Reward = -34345.81, Avg Reward (100) = -30488.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34345.81, Border Penalty: -35118.36, Obstacle Penalty: -50.00
Episode 13329: Reward = -35499.61, Avg Reward (100) = -30817.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13330: Reward = -35499.61, Avg Reward (100) = -30886.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13331: Reward = -35499.61, Avg Reward (100) = -30749.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13332: Reward = -49626.26, Avg Reward (100) = -31094.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13333: Reward = -35499.61, Avg Reward (100) = -31284.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13334: Reward = -35499.61, Avg Reward (100) = -31284.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13335: Reward = -43263.20, Avg Reward (100) = -31628.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13336: Reward = -35499.61, Avg Reward (100) = -31705.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13337: Reward = -35499.61, Avg Reward (100) = -32047.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13338: Reward = -35499.61, Avg Reward (100) = -32390.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13339: Reward = -35499.61, Avg Reward (100) = -32408.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13340: Reward = -35499.61, Avg Reward (100) = -32751.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13341: Reward = -35499.61, Avg Reward (100) = -32784.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13342: Reward = -53334.41, Avg Reward (100) = -32784.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 13343: Reward = -35499.61, Avg Reward (100) = -32962.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13344: Reward = -35499.61, Avg Reward (100) = -32962.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13345: Reward = -37669.33, Avg Reward (100) = -32962.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13346: Reward = -37833.70, Avg Reward (100) = -32984.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -37833.70, Border Penalty: -36129.36, Obstacle Penalty: -50.00
Episode 13347: Reward = -35499.61, Avg Reward (100) = -33351.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13348: Reward = -33701.04, Avg Reward (100) = -33351.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13349: Reward = -35499.61, Avg Reward (100) = -33675.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13350: Reward = -35499.61, Avg Reward (100) = -33675.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13351: Reward = -35499.61, Avg Reward (100) = -33743.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13352: Reward = -34164.73, Avg Reward (100) = -33606.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34164.73, Border Penalty: -35369.23, Obstacle Penalty: -50.00
Episode 13353: Reward = -35499.61, Avg Reward (100) = -33601.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13354: Reward = -47848.55, Avg Reward (100) = -33601.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13355: Reward = -35499.61, Avg Reward (100) = -33725.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13356: Reward = -43263.20, Avg Reward (100) = -33757.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13357: Reward = -37669.33, Avg Reward (100) = -33903.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13358: Reward = -1196.00, Avg Reward (100) = -33844.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13359: Reward = -1098.00, Avg Reward (100) = -33561.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13360: Reward = -35499.61, Avg Reward (100) = -33211.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13361: Reward = -1049.00, Avg Reward (100) = -32822.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13362: Reward = -35499.61, Avg Reward (100) = -32478.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13363: Reward = -35499.61, Avg Reward (100) = -32529.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13364: Reward = -33469.53, Avg Reward (100) = -32529.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13365: Reward = -12446.80, Avg Reward (100) = -32367.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13366: Reward = -35499.61, Avg Reward (100) = -32136.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13367: Reward = -1049.00, Avg Reward (100) = -32169.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13368: Reward = -49176.10, Avg Reward (100) = -31843.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13369: Reward = -35499.61, Avg Reward (100) = -31979.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13370: Reward = -35499.61, Avg Reward (100) = -31979.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13371: Reward = -35499.61, Avg Reward (100) = -31979.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13372: Reward = -1098.00, Avg Reward (100) = -32008.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13373: Reward = -35499.61, Avg Reward (100) = -31664.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13374: Reward = -35499.61, Avg Reward (100) = -31664.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13375: Reward = -33469.53, Avg Reward (100) = -31664.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -31745.04, Obstacle Penalty: -50.00
Episode 13376: Reward = -35499.61, Avg Reward (100) = -31560.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13377: Reward = -35499.61, Avg Reward (100) = -31560.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13378: Reward = -35499.61, Avg Reward (100) = -31904.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13379: Reward = -35499.61, Avg Reward (100) = -31904.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13380: Reward = -1000.00, Avg Reward (100) = -31955.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13381: Reward = -35499.61, Avg Reward (100) = -31610.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13382: Reward = -33701.04, Avg Reward (100) = -31610.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13383: Reward = -12446.80, Avg Reward (100) = -31592.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13384: Reward = -43263.20, Avg Reward (100) = -31361.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13385: Reward = -1394.00, Avg Reward (100) = -31507.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13386: Reward = -1049.00, Avg Reward (100) = -31166.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13387: Reward = -1000.00, Avg Reward (100) = -30822.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13388: Reward = -37669.33, Avg Reward (100) = -30819.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13389: Reward = -35499.61, Avg Reward (100) = -30841.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13390: Reward = -55296.44, Avg Reward (100) = -30841.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -55296.44, Border Penalty: -41620.00, Obstacle Penalty: -50.00
Episode 13391: Reward = -6072.82, Avg Reward (100) = -30998.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -6072.82, Border Penalty: -13452.59, Obstacle Penalty: -50.00
Episode 13392: Reward = -33701.04, Avg Reward (100) = -30703.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13393: Reward = -35499.61, Avg Reward (100) = -30685.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13394: Reward = -1098.00, Avg Reward (100) = -30510.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13395: Reward = -35499.61, Avg Reward (100) = -30166.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13396: Reward = -35499.61, Avg Reward (100) = -30166.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13397: Reward = -35499.61, Avg Reward (100) = -30125.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13398: Reward = -35499.61, Avg Reward (100) = -30125.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13399: Reward = -35499.61, Avg Reward (100) = -30125.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13400: Reward = -35035.86, Avg Reward (100) = -30125.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -35035.86, Border Penalty: -35679.66, Obstacle Penalty: -50.00
Episode 13401: Reward = -33701.04, Avg Reward (100) = -30120.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13402: Reward = -35499.61, Avg Reward (100) = -30444.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13403: Reward = -35499.61, Avg Reward (100) = -30444.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13404: Reward = -12446.80, Avg Reward (100) = -30786.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13405: Reward = -49176.10, Avg Reward (100) = -30556.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13406: Reward = -35499.61, Avg Reward (100) = -30556.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13407: Reward = -1394.00, Avg Reward (100) = -30431.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13408: Reward = -32245.59, Avg Reward (100) = -29949.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13409: Reward = -35499.61, Avg Reward (100) = -29917.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13410: Reward = -37256.08, Avg Reward (100) = -30259.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 13411: Reward = -35499.61, Avg Reward (100) = -30284.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13412: Reward = -32619.61, Avg Reward (100) = -30148.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13413: Reward = -35499.61, Avg Reward (100) = -30460.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13414: Reward = -35499.61, Avg Reward (100) = -30460.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13415: Reward = -37669.33, Avg Reward (100) = -30460.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13416: Reward = -28653.56, Avg Reward (100) = -30482.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13417: Reward = -1098.00, Avg Reward (100) = -30757.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13418: Reward = -35499.61, Avg Reward (100) = -30313.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13419: Reward = -35499.61, Avg Reward (100) = -30313.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13420: Reward = -35499.61, Avg Reward (100) = -30334.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13421: Reward = -49176.10, Avg Reward (100) = -30342.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13422: Reward = -35499.61, Avg Reward (100) = -30479.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13423: Reward = -35499.61, Avg Reward (100) = -30479.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13424: Reward = -35499.61, Avg Reward (100) = -30497.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13425: Reward = -1049.00, Avg Reward (100) = -30497.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13426: Reward = -35499.61, Avg Reward (100) = -30496.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13427: Reward = -1394.00, Avg Reward (100) = -30841.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13428: Reward = -35499.61, Avg Reward (100) = -30843.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13429: Reward = -35499.61, Avg Reward (100) = -30855.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13430: Reward = -35499.61, Avg Reward (100) = -30855.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13431: Reward = -47690.34, Avg Reward (100) = -30855.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47690.34, Border Penalty: -38034.31, Obstacle Penalty: -50.00
Episode 13432: Reward = -32619.61, Avg Reward (100) = -30977.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13433: Reward = -1000.00, Avg Reward (100) = -30806.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13434: Reward = -28683.61, Avg Reward (100) = -30461.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13435: Reward = -35499.61, Avg Reward (100) = -30393.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13436: Reward = -35499.61, Avg Reward (100) = -30316.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13437: Reward = -1049.00, Avg Reward (100) = -30316.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13438: Reward = -35499.61, Avg Reward (100) = -29971.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13439: Reward = -33469.53, Avg Reward (100) = -29971.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13440: Reward = -34685.86, Avg Reward (100) = -29951.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13441: Reward = -35499.61, Avg Reward (100) = -29943.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13442: Reward = -1196.00, Avg Reward (100) = -29943.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13443: Reward = -35499.61, Avg Reward (100) = -29421.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13444: Reward = -35499.61, Avg Reward (100) = -29421.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13445: Reward = -35499.61, Avg Reward (100) = -29421.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13446: Reward = -35499.61, Avg Reward (100) = -29400.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13447: Reward = -1147.00, Avg Reward (100) = -29376.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13448: Reward = -1147.00, Avg Reward (100) = -29033.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13449: Reward = -39606.20, Avg Reward (100) = -28707.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13450: Reward = -1098.00, Avg Reward (100) = -28748.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13451: Reward = -35499.61, Avg Reward (100) = -28404.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13452: Reward = -35499.61, Avg Reward (100) = -28404.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13453: Reward = -35499.61, Avg Reward (100) = -28418.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13454: Reward = -28653.56, Avg Reward (100) = -28418.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13455: Reward = -35499.61, Avg Reward (100) = -28226.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13456: Reward = -1000.00, Avg Reward (100) = -28226.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13457: Reward = -35499.61, Avg Reward (100) = -27803.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13458: Reward = -35499.61, Avg Reward (100) = -27781.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13459: Reward = -35499.61, Avg Reward (100) = -28124.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13460: Reward = -36089.25, Avg Reward (100) = -28468.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13461: Reward = -35499.61, Avg Reward (100) = -28474.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13462: Reward = -35499.61, Avg Reward (100) = -28819.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13463: Reward = -35499.61, Avg Reward (100) = -28819.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13464: Reward = -1147.00, Avg Reward (100) = -28819.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13465: Reward = -28653.56, Avg Reward (100) = -28496.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13466: Reward = -47848.55, Avg Reward (100) = -28658.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13467: Reward = -47848.55, Avg Reward (100) = -28781.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13468: Reward = -35499.61, Avg Reward (100) = -29249.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13469: Reward = -30490.07, Avg Reward (100) = -29112.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -30490.07, Border Penalty: -31851.75, Obstacle Penalty: -50.00
Episode 13470: Reward = -35499.61, Avg Reward (100) = -29062.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13471: Reward = -35499.61, Avg Reward (100) = -29062.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13472: Reward = -35499.61, Avg Reward (100) = -29062.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13473: Reward = -35499.61, Avg Reward (100) = -29406.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13474: Reward = -28683.61, Avg Reward (100) = -29406.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13475: Reward = -35499.61, Avg Reward (100) = -29338.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13476: Reward = -1147.00, Avg Reward (100) = -29358.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13477: Reward = -35499.61, Avg Reward (100) = -29015.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13478: Reward = -34685.86, Avg Reward (100) = -29015.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13479: Reward = -29220.94, Avg Reward (100) = -29007.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -29220.94, Border Penalty: -32231.25, Obstacle Penalty: -50.00
Episode 13480: Reward = -35499.61, Avg Reward (100) = -28944.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13481: Reward = -35499.61, Avg Reward (100) = -29289.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13482: Reward = -35499.61, Avg Reward (100) = -29289.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13483: Reward = -35499.61, Avg Reward (100) = -29307.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13484: Reward = -1196.00, Avg Reward (100) = -29537.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13485: Reward = -33701.04, Avg Reward (100) = -29117.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13486: Reward = -35499.61, Avg Reward (100) = -29440.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13487: Reward = -35499.61, Avg Reward (100) = -29784.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13488: Reward = -35499.61, Avg Reward (100) = -30129.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13489: Reward = -34685.86, Avg Reward (100) = -30108.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13490: Reward = -47848.55, Avg Reward (100) = -30100.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13491: Reward = -1000.00, Avg Reward (100) = -30025.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13492: Reward = -36089.25, Avg Reward (100) = -29974.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13493: Reward = -29512.46, Avg Reward (100) = -29998.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13494: Reward = -35499.61, Avg Reward (100) = -29938.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13495: Reward = -35499.61, Avg Reward (100) = -30282.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13496: Reward = -35499.61, Avg Reward (100) = -30282.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13497: Reward = -32619.61, Avg Reward (100) = -30282.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13498: Reward = -35499.61, Avg Reward (100) = -30254.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13499: Reward = -80624.98, Avg Reward (100) = -30254.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -80624.98, Border Penalty: -38908.12, Obstacle Penalty: -50.00
Episode 13500: Reward = -35499.61, Avg Reward (100) = -30705.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13501: Reward = -35499.61, Avg Reward (100) = -30709.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13502: Reward = -43263.20, Avg Reward (100) = -30727.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13503: Reward = -37185.63, Avg Reward (100) = -30805.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37185.63, Border Penalty: -30338.18, Obstacle Penalty: -50.00
Episode 13504: Reward = -33701.04, Avg Reward (100) = -30822.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13505: Reward = -1295.00, Avg Reward (100) = -31034.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13506: Reward = -35499.61, Avg Reward (100) = -30556.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13507: Reward = -49176.10, Avg Reward (100) = -30556.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13508: Reward = -47848.55, Avg Reward (100) = -31033.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13509: Reward = -35499.61, Avg Reward (100) = -31190.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13510: Reward = -47848.55, Avg Reward (100) = -31190.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13511: Reward = -35499.61, Avg Reward (100) = -31295.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13512: Reward = -35499.61, Avg Reward (100) = -31295.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13513: Reward = -35499.61, Avg Reward (100) = -31324.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13514: Reward = -35499.61, Avg Reward (100) = -31324.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13515: Reward = -49626.26, Avg Reward (100) = -31324.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13516: Reward = -35499.61, Avg Reward (100) = -31444.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13517: Reward = -32619.61, Avg Reward (100) = -31512.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13518: Reward = -1147.00, Avg Reward (100) = -31827.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13519: Reward = -35499.61, Avg Reward (100) = -31484.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13520: Reward = -28653.56, Avg Reward (100) = -31484.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13521: Reward = -36089.25, Avg Reward (100) = -31416.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13522: Reward = -35499.61, Avg Reward (100) = -31285.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13523: Reward = -1196.00, Avg Reward (100) = -31285.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13524: Reward = -35499.61, Avg Reward (100) = -30942.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13525: Reward = -54061.77, Avg Reward (100) = -30942.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -54061.77, Border Penalty: -41464.82, Obstacle Penalty: -50.00
Episode 13526: Reward = -47848.55, Avg Reward (100) = -31472.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13527: Reward = -35499.61, Avg Reward (100) = -31595.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13528: Reward = -35499.61, Avg Reward (100) = -31936.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13529: Reward = -33701.04, Avg Reward (100) = -31936.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13530: Reward = -35499.61, Avg Reward (100) = -31918.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13531: Reward = -35499.61, Avg Reward (100) = -31918.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13532: Reward = -1394.00, Avg Reward (100) = -31796.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13533: Reward = -35499.61, Avg Reward (100) = -31484.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13534: Reward = -35499.61, Avg Reward (100) = -31829.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13535: Reward = -36791.87, Avg Reward (100) = -31897.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36791.87, Border Penalty: -35260.12, Obstacle Penalty: -50.00
Episode 13536: Reward = -35499.61, Avg Reward (100) = -31910.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13537: Reward = -35499.61, Avg Reward (100) = -31910.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13538: Reward = -49176.10, Avg Reward (100) = -32255.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13539: Reward = -35499.61, Avg Reward (100) = -32391.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13540: Reward = -35499.61, Avg Reward (100) = -32412.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13541: Reward = -35499.61, Avg Reward (100) = -32420.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13542: Reward = -35499.61, Avg Reward (100) = -32420.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13543: Reward = -43263.20, Avg Reward (100) = -32763.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13544: Reward = -29512.46, Avg Reward (100) = -32841.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13545: Reward = -1000.00, Avg Reward (100) = -32781.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13546: Reward = -35499.61, Avg Reward (100) = -32436.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13547: Reward = -59645.17, Avg Reward (100) = -32436.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -41164.81, Obstacle Penalty: -50.00
Episode 13548: Reward = -35499.61, Avg Reward (100) = -33021.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13549: Reward = -34685.86, Avg Reward (100) = -33364.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13550: Reward = -35499.61, Avg Reward (100) = -33315.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13551: Reward = -47848.55, Avg Reward (100) = -33659.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13552: Reward = -35499.61, Avg Reward (100) = -33783.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13553: Reward = -52333.05, Avg Reward (100) = -33783.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40617.02, Obstacle Penalty: -50.00
Episode 13554: Reward = -35499.61, Avg Reward (100) = -33951.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13555: Reward = -35499.61, Avg Reward (100) = -34019.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13556: Reward = -35499.61, Avg Reward (100) = -34019.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13557: Reward = -35499.61, Avg Reward (100) = -34364.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13558: Reward = -1000.00, Avg Reward (100) = -34364.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13559: Reward = -35499.61, Avg Reward (100) = -34019.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13560: Reward = -35499.61, Avg Reward (100) = -34019.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13561: Reward = -43263.20, Avg Reward (100) = -34013.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13562: Reward = -29512.46, Avg Reward (100) = -34091.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13563: Reward = -35499.61, Avg Reward (100) = -34031.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13564: Reward = -35499.61, Avg Reward (100) = -34031.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13565: Reward = -35499.61, Avg Reward (100) = -34375.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13566: Reward = -1394.00, Avg Reward (100) = -34443.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13567: Reward = -35499.61, Avg Reward (100) = -33979.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13568: Reward = -35499.61, Avg Reward (100) = -33855.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13569: Reward = -1049.00, Avg Reward (100) = -33855.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13570: Reward = -35499.61, Avg Reward (100) = -33561.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13571: Reward = -53955.87, Avg Reward (100) = -33561.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 13572: Reward = -35499.61, Avg Reward (100) = -33745.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13573: Reward = -35499.61, Avg Reward (100) = -33745.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13574: Reward = -1147.00, Avg Reward (100) = -33745.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13575: Reward = -35499.61, Avg Reward (100) = -33470.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13576: Reward = -35499.61, Avg Reward (100) = -33470.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13577: Reward = -1049.00, Avg Reward (100) = -33813.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13578: Reward = -1000.00, Avg Reward (100) = -33469.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13579: Reward = -34685.86, Avg Reward (100) = -33132.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13580: Reward = -35499.61, Avg Reward (100) = -33187.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13581: Reward = -1295.00, Avg Reward (100) = -33187.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13582: Reward = -1000.00, Avg Reward (100) = -32845.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13583: Reward = -35499.61, Avg Reward (100) = -32500.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13584: Reward = -35499.61, Avg Reward (100) = -32500.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13585: Reward = -47848.55, Avg Reward (100) = -32843.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13586: Reward = -35499.61, Avg Reward (100) = -32984.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13587: Reward = -35499.61, Avg Reward (100) = -32984.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13588: Reward = -35499.61, Avg Reward (100) = -32984.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13589: Reward = -35499.61, Avg Reward (100) = -32984.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13590: Reward = -35499.61, Avg Reward (100) = -32992.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13591: Reward = -35499.61, Avg Reward (100) = -32869.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13592: Reward = -32675.73, Avg Reward (100) = -33214.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32675.73, Border Penalty: -30294.06, Obstacle Penalty: -50.00
Episode 13593: Reward = -47848.55, Avg Reward (100) = -33180.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13594: Reward = -35499.61, Avg Reward (100) = -33363.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13595: Reward = -35499.61, Avg Reward (100) = -33363.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13596: Reward = -35499.61, Avg Reward (100) = -33363.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13597: Reward = -1295.00, Avg Reward (100) = -33363.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13598: Reward = -1147.00, Avg Reward (100) = -33050.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13599: Reward = -1049.00, Avg Reward (100) = -32706.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13600: Reward = -37669.33, Avg Reward (100) = -31911.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13601: Reward = -47848.55, Avg Reward (100) = -31932.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13602: Reward = -35499.61, Avg Reward (100) = -32056.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13603: Reward = -46069.40, Avg Reward (100) = -31978.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -46069.40, Border Penalty: -35227.66, Obstacle Penalty: -50.00
Episode 13604: Reward = -20619.50, Avg Reward (100) = -32067.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -20619.50, Border Penalty: -25851.06, Obstacle Penalty: -50.00
Episode 13605: Reward = -35499.61, Avg Reward (100) = -31936.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13606: Reward = -35499.61, Avg Reward (100) = -32278.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13607: Reward = -35499.61, Avg Reward (100) = -32278.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13608: Reward = -35499.61, Avg Reward (100) = -32141.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13609: Reward = -35499.61, Avg Reward (100) = -32018.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13610: Reward = -35499.61, Avg Reward (100) = -32018.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13611: Reward = -1049.00, Avg Reward (100) = -31894.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13612: Reward = -35499.61, Avg Reward (100) = -31550.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13613: Reward = -39606.20, Avg Reward (100) = -31550.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13614: Reward = -35499.61, Avg Reward (100) = -31591.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13615: Reward = -1049.00, Avg Reward (100) = -31591.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13616: Reward = -35499.61, Avg Reward (100) = -31105.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13617: Reward = -35499.61, Avg Reward (100) = -31105.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13618: Reward = -35499.61, Avg Reward (100) = -31134.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13619: Reward = -1147.00, Avg Reward (100) = -31478.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13620: Reward = -39606.20, Avg Reward (100) = -31134.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13621: Reward = -35499.61, Avg Reward (100) = -31244.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13622: Reward = -1295.00, Avg Reward (100) = -31238.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13623: Reward = -35499.61, Avg Reward (100) = -30896.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13624: Reward = -47848.55, Avg Reward (100) = -31239.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 13625: Reward = -53955.87, Avg Reward (100) = -31362.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53955.87, Border Penalty: -41441.48, Obstacle Penalty: -50.00
Episode 13626: Reward = -1098.00, Avg Reward (100) = -31361.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13627: Reward = -35499.61, Avg Reward (100) = -30894.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13628: Reward = -35499.61, Avg Reward (100) = -30894.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13629: Reward = -1049.00, Avg Reward (100) = -30894.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13630: Reward = -1394.00, Avg Reward (100) = -30567.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13631: Reward = -35499.61, Avg Reward (100) = -30226.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13632: Reward = -1049.00, Avg Reward (100) = -30226.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13633: Reward = -32619.61, Avg Reward (100) = -30223.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13634: Reward = -1000.00, Avg Reward (100) = -30194.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13635: Reward = -30651.53, Avg Reward (100) = -29849.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30651.53, Border Penalty: -32266.32, Obstacle Penalty: -50.00
Episode 13636: Reward = -35499.61, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13637: Reward = -49176.10, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13638: Reward = -35499.61, Avg Reward (100) = -29924.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13639: Reward = -35499.61, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13640: Reward = -35499.61, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13641: Reward = -35499.61, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13642: Reward = -35499.61, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13643: Reward = -1295.00, Avg Reward (100) = -29787.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13644: Reward = -35499.61, Avg Reward (100) = -29368.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13645: Reward = -28683.61, Avg Reward (100) = -29428.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13646: Reward = -35499.61, Avg Reward (100) = -29704.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13647: Reward = -35499.61, Avg Reward (100) = -29704.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13648: Reward = -49626.26, Avg Reward (100) = -29463.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13649: Reward = -35499.61, Avg Reward (100) = -29604.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13650: Reward = -35499.61, Avg Reward (100) = -29612.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13651: Reward = -33701.04, Avg Reward (100) = -29612.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13652: Reward = -34927.46, Avg Reward (100) = -29471.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 13653: Reward = -35499.61, Avg Reward (100) = -29465.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13654: Reward = -1049.00, Avg Reward (100) = -29297.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13655: Reward = -35499.61, Avg Reward (100) = -28952.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13656: Reward = -35499.61, Avg Reward (100) = -28952.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13657: Reward = -35499.61, Avg Reward (100) = -28952.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13658: Reward = -54280.34, Avg Reward (100) = -28952.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54280.34, Border Penalty: -41966.66, Obstacle Penalty: -50.00
Episode 13659: Reward = -35499.61, Avg Reward (100) = -29485.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13660: Reward = -35499.61, Avg Reward (100) = -29485.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13661: Reward = -1000.00, Avg Reward (100) = -29485.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13662: Reward = -49626.26, Avg Reward (100) = -29062.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13663: Reward = -49626.26, Avg Reward (100) = -29264.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13664: Reward = -35499.61, Avg Reward (100) = -29405.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13665: Reward = -35499.61, Avg Reward (100) = -29405.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13666: Reward = -35499.61, Avg Reward (100) = -29405.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13667: Reward = -35499.61, Avg Reward (100) = -29746.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13668: Reward = -1147.00, Avg Reward (100) = -29746.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13669: Reward = -40334.49, Avg Reward (100) = -29402.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 13670: Reward = -33701.04, Avg Reward (100) = -29795.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13671: Reward = -35499.61, Avg Reward (100) = -29777.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13672: Reward = -35499.61, Avg Reward (100) = -29593.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13673: Reward = -1000.00, Avg Reward (100) = -29593.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13674: Reward = -49626.26, Avg Reward (100) = -29248.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13675: Reward = -35499.61, Avg Reward (100) = -29732.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13676: Reward = -35499.61, Avg Reward (100) = -29732.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13677: Reward = -35499.61, Avg Reward (100) = -29732.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13678: Reward = -1147.00, Avg Reward (100) = -30077.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13679: Reward = -35499.61, Avg Reward (100) = -30078.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13680: Reward = -35499.61, Avg Reward (100) = -30087.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13681: Reward = -29879.41, Avg Reward (100) = -30087.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -29879.41, Border Penalty: -31642.21, Obstacle Penalty: -50.00
Episode 13682: Reward = -35499.61, Avg Reward (100) = -30372.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13683: Reward = -49176.10, Avg Reward (100) = -30717.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13684: Reward = -53615.70, Avg Reward (100) = -30854.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53615.70, Border Penalty: -41236.93, Obstacle Penalty: -50.00
Episode 13685: Reward = -1098.00, Avg Reward (100) = -31035.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13686: Reward = -35499.61, Avg Reward (100) = -30568.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13687: Reward = -35499.61, Avg Reward (100) = -30568.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13688: Reward = -35499.61, Avg Reward (100) = -30568.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13689: Reward = -35499.61, Avg Reward (100) = -30568.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13690: Reward = -25228.52, Avg Reward (100) = -30568.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13691: Reward = -1147.00, Avg Reward (100) = -30465.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13692: Reward = -35499.61, Avg Reward (100) = -30122.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13693: Reward = -35499.61, Avg Reward (100) = -30150.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13694: Reward = -1098.00, Avg Reward (100) = -30026.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13695: Reward = -35499.61, Avg Reward (100) = -29682.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13696: Reward = -43263.20, Avg Reward (100) = -29682.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13697: Reward = -1196.00, Avg Reward (100) = -29760.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13698: Reward = -35499.61, Avg Reward (100) = -29759.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13699: Reward = -35499.61, Avg Reward (100) = -30103.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13700: Reward = -35499.61, Avg Reward (100) = -30447.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13701: Reward = -47517.68, Avg Reward (100) = -30425.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47517.68, Border Penalty: -34133.74, Obstacle Penalty: -50.00
Episode 13702: Reward = -34685.86, Avg Reward (100) = -30422.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13703: Reward = -1196.00, Avg Reward (100) = -30414.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13704: Reward = -35499.61, Avg Reward (100) = -29965.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13705: Reward = -1000.00, Avg Reward (100) = -30114.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13706: Reward = -35499.61, Avg Reward (100) = -29769.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13707: Reward = -1196.00, Avg Reward (100) = -29769.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13708: Reward = -34685.86, Avg Reward (100) = -29426.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13709: Reward = -43263.20, Avg Reward (100) = -29418.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13710: Reward = -35499.61, Avg Reward (100) = -29495.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13711: Reward = -49626.26, Avg Reward (100) = -29495.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13712: Reward = -35499.61, Avg Reward (100) = -29981.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13713: Reward = -35499.61, Avg Reward (100) = -29981.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13714: Reward = -35499.61, Avg Reward (100) = -29940.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13715: Reward = -35499.61, Avg Reward (100) = -29940.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13716: Reward = -1049.00, Avg Reward (100) = -30285.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13717: Reward = -36089.25, Avg Reward (100) = -29940.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13718: Reward = -35499.61, Avg Reward (100) = -29946.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13719: Reward = -35499.61, Avg Reward (100) = -29946.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13720: Reward = -35499.61, Avg Reward (100) = -30290.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13721: Reward = -37669.33, Avg Reward (100) = -30248.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13722: Reward = -579.25, Avg Reward (100) = -30270.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -579.25, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 13723: Reward = -35499.61, Avg Reward (100) = -30263.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13724: Reward = -49176.10, Avg Reward (100) = -30263.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13725: Reward = -34482.45, Avg Reward (100) = -30276.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -34482.45, Border Penalty: -35002.89, Obstacle Penalty: -50.00
Episode 13726: Reward = -35499.61, Avg Reward (100) = -30082.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13727: Reward = -35499.61, Avg Reward (100) = -30426.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13728: Reward = -35499.61, Avg Reward (100) = -30426.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13729: Reward = -35499.61, Avg Reward (100) = -30426.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13730: Reward = -35499.61, Avg Reward (100) = -30770.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13731: Reward = -49626.26, Avg Reward (100) = -31111.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13732: Reward = -35499.61, Avg Reward (100) = -31252.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13733: Reward = -35499.61, Avg Reward (100) = -31597.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13734: Reward = -1049.00, Avg Reward (100) = -31626.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13735: Reward = -35499.61, Avg Reward (100) = -31626.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13736: Reward = -35499.61, Avg Reward (100) = -31675.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13737: Reward = -35499.61, Avg Reward (100) = -31675.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13738: Reward = -35499.61, Avg Reward (100) = -31538.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13739: Reward = -1049.00, Avg Reward (100) = -31538.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13740: Reward = -35499.61, Avg Reward (100) = -31193.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13741: Reward = -35499.61, Avg Reward (100) = -31193.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13742: Reward = -28683.61, Avg Reward (100) = -31193.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13743: Reward = -35499.61, Avg Reward (100) = -31125.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13744: Reward = -35499.61, Avg Reward (100) = -31467.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13745: Reward = -35499.61, Avg Reward (100) = -31467.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13746: Reward = -25751.89, Avg Reward (100) = -31535.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 13747: Reward = -28653.56, Avg Reward (100) = -31438.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13748: Reward = -33701.04, Avg Reward (100) = -31370.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13749: Reward = -35499.61, Avg Reward (100) = -31210.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13750: Reward = -35499.61, Avg Reward (100) = -31210.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13751: Reward = -1147.00, Avg Reward (100) = -31210.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13752: Reward = -35499.61, Avg Reward (100) = -30885.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13753: Reward = -35499.61, Avg Reward (100) = -30890.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13754: Reward = -32619.61, Avg Reward (100) = -30890.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13755: Reward = -37669.33, Avg Reward (100) = -31206.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13756: Reward = -35499.61, Avg Reward (100) = -31228.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13757: Reward = -35499.61, Avg Reward (100) = -31228.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13758: Reward = -35499.61, Avg Reward (100) = -31228.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13759: Reward = -35499.61, Avg Reward (100) = -31040.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13760: Reward = -37669.33, Avg Reward (100) = -31040.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13761: Reward = -35499.61, Avg Reward (100) = -31062.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13762: Reward = -1000.00, Avg Reward (100) = -31407.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13763: Reward = -35499.61, Avg Reward (100) = -30920.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13764: Reward = -51921.07, Avg Reward (100) = -30779.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -51921.07, Border Penalty: -39998.94, Obstacle Penalty: -50.00
Episode 13765: Reward = -1098.00, Avg Reward (100) = -30943.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13766: Reward = -35499.61, Avg Reward (100) = -30599.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13767: Reward = -43902.06, Avg Reward (100) = -30599.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43902.06, Border Penalty: -38184.57, Obstacle Penalty: -50.00
Episode 13768: Reward = -49176.10, Avg Reward (100) = -30683.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13769: Reward = -1394.00, Avg Reward (100) = -31164.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13770: Reward = -1196.00, Avg Reward (100) = -30774.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13771: Reward = -36089.25, Avg Reward (100) = -30449.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13772: Reward = -28683.61, Avg Reward (100) = -30455.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13773: Reward = -29512.46, Avg Reward (100) = -30387.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 13774: Reward = -35499.61, Avg Reward (100) = -30672.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13775: Reward = -28683.61, Avg Reward (100) = -30531.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13776: Reward = -25751.89, Avg Reward (100) = -30463.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 13777: Reward = -35499.61, Avg Reward (100) = -30365.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13778: Reward = -35499.61, Avg Reward (100) = -30365.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13779: Reward = -1000.00, Avg Reward (100) = -30709.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13780: Reward = -32245.59, Avg Reward (100) = -30364.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13781: Reward = -1000.00, Avg Reward (100) = -30331.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13782: Reward = -32245.59, Avg Reward (100) = -30042.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13783: Reward = -35499.61, Avg Reward (100) = -30010.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 13784: Reward = -35499.61, Avg Reward (100) = -29873.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13785: Reward = -35499.61, Avg Reward (100) = -29692.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13786: Reward = -1098.00, Avg Reward (100) = -30036.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13787: Reward = -35499.61, Avg Reward (100) = -29692.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13788: Reward = -35499.61, Avg Reward (100) = -29692.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13789: Reward = -33469.53, Avg Reward (100) = -29692.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13790: Reward = -32245.59, Avg Reward (100) = -29672.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13791: Reward = -35499.61, Avg Reward (100) = -29742.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13792: Reward = -1098.00, Avg Reward (100) = -30085.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13793: Reward = -35499.61, Avg Reward (100) = -29741.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13794: Reward = -35499.61, Avg Reward (100) = -29741.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13795: Reward = -28683.61, Avg Reward (100) = -30085.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13796: Reward = -28683.61, Avg Reward (100) = -30017.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13797: Reward = -39606.20, Avg Reward (100) = -29871.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 13798: Reward = -35499.61, Avg Reward (100) = -30255.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13799: Reward = -25228.52, Avg Reward (100) = -30255.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13800: Reward = -35499.61, Avg Reward (100) = -30153.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13801: Reward = -35499.61, Avg Reward (100) = -30153.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13802: Reward = -35499.61, Avg Reward (100) = -30033.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13803: Reward = -35499.61, Avg Reward (100) = -30041.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13804: Reward = -38306.90, Avg Reward (100) = -30384.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 13805: Reward = -35499.61, Avg Reward (100) = -30412.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13806: Reward = -35499.61, Avg Reward (100) = -30757.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13807: Reward = -28653.56, Avg Reward (100) = -30757.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13808: Reward = -1294.00, Avg Reward (100) = -31031.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -67.46
Episode 13809: Reward = -28683.61, Avg Reward (100) = -30698.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13810: Reward = -35499.61, Avg Reward (100) = -30552.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13811: Reward = -35499.61, Avg Reward (100) = -30552.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13812: Reward = -1000.00, Avg Reward (100) = -30410.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13813: Reward = -1000.00, Avg Reward (100) = -30065.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13814: Reward = -25228.52, Avg Reward (100) = -29720.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13815: Reward = -35499.61, Avg Reward (100) = -29618.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13816: Reward = -35499.61, Avg Reward (100) = -29618.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13817: Reward = -49176.10, Avg Reward (100) = -29962.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13818: Reward = -37669.33, Avg Reward (100) = -30093.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13819: Reward = -36726.20, Avg Reward (100) = -30115.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36726.20, Border Penalty: -32739.82, Obstacle Penalty: -50.00
Episode 13820: Reward = -1147.00, Avg Reward (100) = -30127.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13821: Reward = -35499.61, Avg Reward (100) = -29784.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13822: Reward = -33469.53, Avg Reward (100) = -29762.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13823: Reward = -28653.56, Avg Reward (100) = -30091.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -30956.28, Obstacle Penalty: -50.00
Episode 13824: Reward = -35499.61, Avg Reward (100) = -30022.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13825: Reward = -34685.86, Avg Reward (100) = -29886.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13826: Reward = -28653.56, Avg Reward (100) = -29888.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13827: Reward = -35499.61, Avg Reward (100) = -29819.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13828: Reward = -35499.61, Avg Reward (100) = -29819.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13829: Reward = -34685.86, Avg Reward (100) = -29819.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13830: Reward = -28653.56, Avg Reward (100) = -29811.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13831: Reward = -40411.33, Avg Reward (100) = -29743.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 13832: Reward = -35499.61, Avg Reward (100) = -29650.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13833: Reward = -35499.61, Avg Reward (100) = -29650.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13834: Reward = -35499.61, Avg Reward (100) = -29650.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13835: Reward = -1049.00, Avg Reward (100) = -29995.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13836: Reward = -35499.61, Avg Reward (100) = -29650.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13837: Reward = -28653.56, Avg Reward (100) = -29650.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13838: Reward = -49626.26, Avg Reward (100) = -29582.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 13839: Reward = -12446.80, Avg Reward (100) = -29723.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13840: Reward = -1196.00, Avg Reward (100) = -29837.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13841: Reward = -53272.28, Avg Reward (100) = -29494.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -53272.28, Border Penalty: -39685.49, Obstacle Penalty: -50.00
Episode 13842: Reward = -35499.61, Avg Reward (100) = -29672.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13843: Reward = -35499.61, Avg Reward (100) = -29740.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13844: Reward = -35499.61, Avg Reward (100) = -29740.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13845: Reward = -1049.00, Avg Reward (100) = -29740.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13846: Reward = -35499.61, Avg Reward (100) = -29395.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13847: Reward = -35499.61, Avg Reward (100) = -29493.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13848: Reward = -42363.56, Avg Reward (100) = -29561.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42363.56, Border Penalty: -37030.08, Obstacle Penalty: -50.00
Episode 13849: Reward = -35499.61, Avg Reward (100) = -29648.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13850: Reward = -35499.61, Avg Reward (100) = -29648.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13851: Reward = -5390.43, Avg Reward (100) = -29648.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -5390.43, Border Penalty: -12900.05, Obstacle Penalty: -50.00
Episode 13852: Reward = -37669.33, Avg Reward (100) = -29690.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13853: Reward = -43263.20, Avg Reward (100) = -29712.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13854: Reward = -35499.61, Avg Reward (100) = -29790.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13855: Reward = -33701.04, Avg Reward (100) = -29819.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13856: Reward = -35499.61, Avg Reward (100) = -29779.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13857: Reward = -35499.61, Avg Reward (100) = -29779.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13858: Reward = -1196.00, Avg Reward (100) = -29779.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13859: Reward = -35499.61, Avg Reward (100) = -29436.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13860: Reward = -49176.10, Avg Reward (100) = -29436.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13861: Reward = -35499.61, Avg Reward (100) = -29551.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13862: Reward = -28653.56, Avg Reward (100) = -29551.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13863: Reward = -35499.61, Avg Reward (100) = -29828.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13864: Reward = -28683.61, Avg Reward (100) = -29828.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13865: Reward = -32245.59, Avg Reward (100) = -29595.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13866: Reward = -49176.10, Avg Reward (100) = -29907.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 13867: Reward = -32619.61, Avg Reward (100) = -30043.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13868: Reward = -35499.61, Avg Reward (100) = -29931.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13869: Reward = -35499.61, Avg Reward (100) = -29794.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13870: Reward = -37054.55, Avg Reward (100) = -30135.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37054.55, Border Penalty: -35755.93, Obstacle Penalty: -50.00
Episode 13871: Reward = -35499.61, Avg Reward (100) = -30493.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13872: Reward = -1049.00, Avg Reward (100) = -30488.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13873: Reward = -35499.61, Avg Reward (100) = -30211.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13874: Reward = -35499.61, Avg Reward (100) = -30271.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13875: Reward = -33701.04, Avg Reward (100) = -30271.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -31129.77, Obstacle Penalty: -50.00
Episode 13876: Reward = -35499.61, Avg Reward (100) = -30321.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13877: Reward = -46501.31, Avg Reward (100) = -30419.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 14, Reward Breakdown -> Delta_x Reward: -46501.31, Border Penalty: -38880.88, Obstacle Penalty: -50.00
Episode 13878: Reward = -35499.61, Avg Reward (100) = -30529.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13879: Reward = -35499.61, Avg Reward (100) = -30529.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13880: Reward = -35499.61, Avg Reward (100) = -30874.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13881: Reward = -35499.61, Avg Reward (100) = -30906.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13882: Reward = -1000.00, Avg Reward (100) = -31251.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13883: Reward = -35499.61, Avg Reward (100) = -30939.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13884: Reward = -35499.61, Avg Reward (100) = -30939.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13885: Reward = -35499.61, Avg Reward (100) = -30939.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13886: Reward = -28653.56, Avg Reward (100) = -30939.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 13887: Reward = -35499.61, Avg Reward (100) = -31214.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13888: Reward = -35499.61, Avg Reward (100) = -31214.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13889: Reward = -35499.61, Avg Reward (100) = -31214.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13890: Reward = -35499.61, Avg Reward (100) = -31235.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13891: Reward = -48252.80, Avg Reward (100) = -31267.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 13892: Reward = -35499.61, Avg Reward (100) = -31395.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13893: Reward = -35499.61, Avg Reward (100) = -31739.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13894: Reward = -35499.61, Avg Reward (100) = -31739.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13895: Reward = -35499.61, Avg Reward (100) = -31739.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13896: Reward = -25228.52, Avg Reward (100) = -31807.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13897: Reward = -25228.52, Avg Reward (100) = -31772.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13898: Reward = -35499.61, Avg Reward (100) = -31629.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13899: Reward = -25228.52, Avg Reward (100) = -31629.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13900: Reward = -53595.81, Avg Reward (100) = -31629.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53595.81, Border Penalty: -41871.31, Obstacle Penalty: -50.00
Episode 13901: Reward = -35499.61, Avg Reward (100) = -31810.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13902: Reward = -32619.61, Avg Reward (100) = -31810.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13903: Reward = -28683.61, Avg Reward (100) = -31781.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13904: Reward = -35499.61, Avg Reward (100) = -31713.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13905: Reward = -1147.00, Avg Reward (100) = -31684.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13906: Reward = -39216.62, Avg Reward (100) = -31341.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -39216.62, Border Penalty: -36024.72, Obstacle Penalty: -50.00
Episode 13907: Reward = -35499.61, Avg Reward (100) = -31378.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13908: Reward = -35499.61, Avg Reward (100) = -31447.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13909: Reward = -37669.33, Avg Reward (100) = -31789.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 13910: Reward = -28438.08, Avg Reward (100) = -31879.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -28438.08, Border Penalty: -30917.02, Obstacle Penalty: -50.00
Episode 13911: Reward = -35499.61, Avg Reward (100) = -31808.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13912: Reward = -35499.61, Avg Reward (100) = -31808.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13913: Reward = -35499.61, Avg Reward (100) = -32153.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13914: Reward = -34685.86, Avg Reward (100) = -32498.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13915: Reward = -35499.61, Avg Reward (100) = -32592.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13916: Reward = -34685.86, Avg Reward (100) = -32592.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 13917: Reward = -32632.70, Avg Reward (100) = -32584.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 13918: Reward = -35499.61, Avg Reward (100) = -32419.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13919: Reward = -35499.61, Avg Reward (100) = -32397.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13920: Reward = -52333.05, Avg Reward (100) = -32385.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52333.05, Border Penalty: -40017.01, Obstacle Penalty: -50.00
Episode 13921: Reward = -35499.61, Avg Reward (100) = -32897.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13922: Reward = -35499.61, Avg Reward (100) = -32897.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13923: Reward = -35499.61, Avg Reward (100) = -32917.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13924: Reward = -35499.61, Avg Reward (100) = -32986.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 13925: Reward = -28683.61, Avg Reward (100) = -32986.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13926: Reward = -35499.61, Avg Reward (100) = -32926.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13927: Reward = -35499.61, Avg Reward (100) = -32994.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13928: Reward = -51631.62, Avg Reward (100) = -32994.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -51631.62, Border Penalty: -40769.86, Obstacle Penalty: -50.00
Episode 13929: Reward = -35499.61, Avg Reward (100) = -33155.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13930: Reward = -35499.61, Avg Reward (100) = -33163.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13931: Reward = -35499.61, Avg Reward (100) = -33232.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13932: Reward = -1049.00, Avg Reward (100) = -33183.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13933: Reward = -1196.00, Avg Reward (100) = -32838.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13934: Reward = -35499.61, Avg Reward (100) = -32495.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13935: Reward = -35499.61, Avg Reward (100) = -32495.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13936: Reward = -35499.61, Avg Reward (100) = -32840.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13937: Reward = -35499.61, Avg Reward (100) = -32840.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13938: Reward = -1049.00, Avg Reward (100) = -32908.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13939: Reward = -32619.61, Avg Reward (100) = -32422.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13940: Reward = -54036.93, Avg Reward (100) = -32624.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54036.93, Border Penalty: -41191.29, Obstacle Penalty: -50.00
Episode 13941: Reward = -35499.61, Avg Reward (100) = -33153.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13942: Reward = -36089.25, Avg Reward (100) = -32975.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13943: Reward = -35499.61, Avg Reward (100) = -32981.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13944: Reward = -35499.61, Avg Reward (100) = -32981.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13945: Reward = -12446.80, Avg Reward (100) = -32981.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 13946: Reward = -43263.20, Avg Reward (100) = -33095.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13947: Reward = -1049.00, Avg Reward (100) = -33172.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13948: Reward = -35499.61, Avg Reward (100) = -32828.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13949: Reward = -35499.61, Avg Reward (100) = -32759.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13950: Reward = -52416.78, Avg Reward (100) = -32759.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -52416.78, Border Penalty: -37024.93, Obstacle Penalty: -50.00
Episode 13951: Reward = -43802.69, Avg Reward (100) = -32928.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -43802.69, Border Penalty: -38518.16, Obstacle Penalty: -50.00
Episode 13952: Reward = -35499.61, Avg Reward (100) = -33313.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13953: Reward = -35499.61, Avg Reward (100) = -33291.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13954: Reward = -1098.00, Avg Reward (100) = -33213.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13955: Reward = -36089.25, Avg Reward (100) = -32869.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13956: Reward = -35499.61, Avg Reward (100) = -32893.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13957: Reward = -35499.61, Avg Reward (100) = -32893.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13958: Reward = -1098.00, Avg Reward (100) = -32893.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13959: Reward = -35499.61, Avg Reward (100) = -32892.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13960: Reward = -32619.61, Avg Reward (100) = -32892.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13961: Reward = -35499.61, Avg Reward (100) = -32727.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13962: Reward = -35499.61, Avg Reward (100) = -32727.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13963: Reward = -1049.00, Avg Reward (100) = -32795.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13964: Reward = -35499.61, Avg Reward (100) = -32450.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13965: Reward = -35499.61, Avg Reward (100) = -32519.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13966: Reward = -1394.00, Avg Reward (100) = -32551.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 13967: Reward = -32245.59, Avg Reward (100) = -32073.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 13968: Reward = -35499.61, Avg Reward (100) = -32070.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13969: Reward = -1000.00, Avg Reward (100) = -32070.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13970: Reward = -1492.00, Avg Reward (100) = -31725.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 13971: Reward = -35499.61, Avg Reward (100) = -31369.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13972: Reward = -43263.20, Avg Reward (100) = -31369.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 13973: Reward = -33469.53, Avg Reward (100) = -31791.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 13974: Reward = -1196.00, Avg Reward (100) = -31771.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 13975: Reward = -38924.96, Avg Reward (100) = -31428.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38924.96, Border Penalty: -36612.80, Obstacle Penalty: -50.00
Episode 13976: Reward = -47848.55, Avg Reward (100) = -31480.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -38580.06, Obstacle Penalty: -50.00
Episode 13977: Reward = -35499.61, Avg Reward (100) = -31604.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13978: Reward = -25228.52, Avg Reward (100) = -31493.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13979: Reward = -57378.85, Avg Reward (100) = -31391.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -57378.85, Border Penalty: -37340.29, Obstacle Penalty: -50.00
Episode 13980: Reward = -25228.52, Avg Reward (100) = -31610.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 13981: Reward = -35499.61, Avg Reward (100) = -31507.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13982: Reward = -1000.00, Avg Reward (100) = -31507.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13983: Reward = -30092.93, Avg Reward (100) = -31507.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30092.93, Border Penalty: -31776.74, Obstacle Penalty: -50.00
Episode 13984: Reward = -36089.25, Avg Reward (100) = -31453.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 13985: Reward = -35499.61, Avg Reward (100) = -31459.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13986: Reward = -35499.61, Avg Reward (100) = -31459.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13987: Reward = -35499.61, Avg Reward (100) = -31527.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13988: Reward = -32619.61, Avg Reward (100) = -31527.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 13989: Reward = -33701.04, Avg Reward (100) = -31498.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 13990: Reward = -35499.61, Avg Reward (100) = -31480.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13991: Reward = -1000.00, Avg Reward (100) = -31480.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13992: Reward = -34685.86, Avg Reward (100) = -31008.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 13993: Reward = -35499.61, Avg Reward (100) = -31000.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13994: Reward = -35499.61, Avg Reward (100) = -31000.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13995: Reward = -1098.00, Avg Reward (100) = -31000.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 13996: Reward = -35499.61, Avg Reward (100) = -30656.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13997: Reward = -35499.61, Avg Reward (100) = -30758.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13998: Reward = -35499.61, Avg Reward (100) = -30861.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 13999: Reward = -34685.86, Avg Reward (100) = -30861.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14000: Reward = -35499.61, Avg Reward (100) = -30956.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14001: Reward = -1098.00, Avg Reward (100) = -30775.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14002: Reward = -35499.61, Avg Reward (100) = -30431.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14003: Reward = -35499.61, Avg Reward (100) = -30460.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14004: Reward = -37669.33, Avg Reward (100) = -30528.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -35743.02, Obstacle Penalty: -50.00
Episode 14005: Reward = -42304.65, Avg Reward (100) = -30549.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -42304.65, Border Penalty: -35757.61, Obstacle Penalty: -50.00
Episode 14006: Reward = -35499.61, Avg Reward (100) = -30961.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14007: Reward = -28683.61, Avg Reward (100) = -30924.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14008: Reward = -49176.10, Avg Reward (100) = -30856.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14009: Reward = -36089.25, Avg Reward (100) = -30992.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14010: Reward = -35499.61, Avg Reward (100) = -30977.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14011: Reward = -35499.61, Avg Reward (100) = -31047.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14012: Reward = -35499.61, Avg Reward (100) = -31047.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14013: Reward = -32619.61, Avg Reward (100) = -31047.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14014: Reward = -35499.61, Avg Reward (100) = -31018.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14015: Reward = -32245.59, Avg Reward (100) = -31027.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14016: Reward = -52270.10, Avg Reward (100) = -30994.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -52270.10, Border Penalty: -37947.39, Obstacle Penalty: -50.00
Episode 14017: Reward = -35499.61, Avg Reward (100) = -31170.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14018: Reward = -1000.00, Avg Reward (100) = -31198.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14019: Reward = -35499.61, Avg Reward (100) = -30853.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14020: Reward = -35499.61, Avg Reward (100) = -30853.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14021: Reward = -34685.86, Avg Reward (100) = -30685.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14022: Reward = -39606.20, Avg Reward (100) = -30677.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14023: Reward = -1196.00, Avg Reward (100) = -30718.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14024: Reward = -32619.61, Avg Reward (100) = -30375.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14025: Reward = -35499.61, Avg Reward (100) = -30346.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14026: Reward = -35499.61, Avg Reward (100) = -30414.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14027: Reward = -35499.61, Avg Reward (100) = -30414.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14028: Reward = -29512.46, Avg Reward (100) = -30414.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14029: Reward = -1296.78, Avg Reward (100) = -30193.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1296.78, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14030: Reward = -35499.61, Avg Reward (100) = -29851.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14031: Reward = -1196.00, Avg Reward (100) = -29851.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14032: Reward = -1000.00, Avg Reward (100) = -29508.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14033: Reward = -41280.90, Avg Reward (100) = -29508.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 14034: Reward = -35499.61, Avg Reward (100) = -29909.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14035: Reward = -35499.61, Avg Reward (100) = -29909.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14036: Reward = -25228.52, Avg Reward (100) = -29909.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14037: Reward = -36915.70, Avg Reward (100) = -29806.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36915.70, Border Penalty: -30949.31, Obstacle Penalty: -50.00
Episode 14038: Reward = -35499.61, Avg Reward (100) = -29820.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14039: Reward = -35499.61, Avg Reward (100) = -30164.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14040: Reward = -35499.61, Avg Reward (100) = -30193.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14041: Reward = -49626.26, Avg Reward (100) = -30008.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14042: Reward = -35499.61, Avg Reward (100) = -30149.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14043: Reward = -35499.61, Avg Reward (100) = -30143.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14044: Reward = -35499.61, Avg Reward (100) = -30143.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14045: Reward = -35499.61, Avg Reward (100) = -30143.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14046: Reward = -1295.00, Avg Reward (100) = -30374.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14047: Reward = -35499.61, Avg Reward (100) = -29954.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14048: Reward = -40411.33, Avg Reward (100) = -30299.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -40411.33, Border Penalty: -36707.39, Obstacle Penalty: -50.00
Episode 14049: Reward = -1098.00, Avg Reward (100) = -30348.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14050: Reward = -39606.20, Avg Reward (100) = -30004.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14051: Reward = -1147.00, Avg Reward (100) = -29876.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14052: Reward = -1196.00, Avg Reward (100) = -29449.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14053: Reward = -35499.61, Avg Reward (100) = -29106.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14054: Reward = -35499.61, Avg Reward (100) = -29106.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14055: Reward = -43263.20, Avg Reward (100) = -29450.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14056: Reward = -35499.61, Avg Reward (100) = -29522.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14057: Reward = -35499.61, Avg Reward (100) = -29522.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14058: Reward = -35499.61, Avg Reward (100) = -29522.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14059: Reward = -35499.61, Avg Reward (100) = -29866.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14060: Reward = -35295.52, Avg Reward (100) = -29866.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34781.11, Obstacle Penalty: -50.00
Episode 14061: Reward = -1147.00, Avg Reward (100) = -29893.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14062: Reward = -35499.61, Avg Reward (100) = -29549.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14063: Reward = -35499.61, Avg Reward (100) = -29549.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14064: Reward = -44507.68, Avg Reward (100) = -29894.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44507.68, Border Penalty: -38483.32, Obstacle Penalty: -50.00
Episode 14065: Reward = -35499.61, Avg Reward (100) = -29984.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14066: Reward = -35499.61, Avg Reward (100) = -29984.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14067: Reward = -35499.61, Avg Reward (100) = -30325.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14068: Reward = -42103.80, Avg Reward (100) = -30357.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -42103.80, Border Penalty: -37936.77, Obstacle Penalty: -50.00
Episode 14069: Reward = -35499.61, Avg Reward (100) = -30423.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14070: Reward = -35499.61, Avg Reward (100) = -30768.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14071: Reward = -36022.43, Avg Reward (100) = -31108.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -36022.43, Border Penalty: -35167.21, Obstacle Penalty: -50.00
Episode 14072: Reward = -34685.86, Avg Reward (100) = -31114.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 14073: Reward = -9048.28, Avg Reward (100) = -31028.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -9048.28, Border Penalty: -18608.47, Obstacle Penalty: -50.00
Episode 14074: Reward = -1196.00, Avg Reward (100) = -30784.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14075: Reward = -35499.61, Avg Reward (100) = -30784.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14076: Reward = -25228.52, Avg Reward (100) = -30749.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14077: Reward = -1098.00, Avg Reward (100) = -30523.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14078: Reward = -35499.61, Avg Reward (100) = -30179.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14079: Reward = -47848.55, Avg Reward (100) = -30282.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14080: Reward = -28683.61, Avg Reward (100) = -30187.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14081: Reward = -35499.61, Avg Reward (100) = -30221.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14082: Reward = -35499.61, Avg Reward (100) = -30221.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14083: Reward = -29512.46, Avg Reward (100) = -30566.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14084: Reward = -36089.25, Avg Reward (100) = -30560.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14085: Reward = -1196.00, Avg Reward (100) = -30560.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14086: Reward = -1147.00, Avg Reward (100) = -30217.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14087: Reward = -35499.61, Avg Reward (100) = -29874.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14088: Reward = -35499.61, Avg Reward (100) = -29874.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14089: Reward = -1245.00, Avg Reward (100) = -29902.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14090: Reward = -35499.61, Avg Reward (100) = -29578.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14091: Reward = -35499.61, Avg Reward (100) = -29578.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14092: Reward = -35499.61, Avg Reward (100) = -29923.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14093: Reward = -35499.61, Avg Reward (100) = -29931.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14094: Reward = -32619.61, Avg Reward (100) = -29931.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14095: Reward = -35499.61, Avg Reward (100) = -29902.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14096: Reward = -35499.61, Avg Reward (100) = -30246.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14097: Reward = -39606.20, Avg Reward (100) = -30246.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14098: Reward = -1294.00, Avg Reward (100) = -30287.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1294.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14099: Reward = -32245.59, Avg Reward (100) = -29945.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14100: Reward = -1196.00, Avg Reward (100) = -29921.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14101: Reward = -35499.61, Avg Reward (100) = -29578.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14102: Reward = -1295.00, Avg Reward (100) = -29922.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14103: Reward = -36618.19, Avg Reward (100) = -29580.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -36618.19, Border Penalty: -35596.62, Obstacle Penalty: -50.00
Episode 14104: Reward = -35499.61, Avg Reward (100) = -29591.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14105: Reward = -35499.61, Avg Reward (100) = -29569.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14106: Reward = -35499.61, Avg Reward (100) = -29501.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14107: Reward = -49626.26, Avg Reward (100) = -29501.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14108: Reward = -35499.61, Avg Reward (100) = -29711.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14109: Reward = -1098.00, Avg Reward (100) = -29574.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14110: Reward = -35499.61, Avg Reward (100) = -29224.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14111: Reward = -35499.61, Avg Reward (100) = -29224.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14112: Reward = -35499.61, Avg Reward (100) = -29224.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14113: Reward = -35499.61, Avg Reward (100) = -29224.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14114: Reward = -43263.20, Avg Reward (100) = -29253.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14115: Reward = -1196.00, Avg Reward (100) = -29330.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14116: Reward = -37256.08, Avg Reward (100) = -29020.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -37256.08, Border Penalty: -35674.41, Obstacle Penalty: -50.00
Episode 14117: Reward = -39606.20, Avg Reward (100) = -28870.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14118: Reward = -32245.59, Avg Reward (100) = -28911.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -32727.79, Obstacle Penalty: -50.00
Episode 14119: Reward = -33469.53, Avg Reward (100) = -29223.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14120: Reward = -35499.61, Avg Reward (100) = -29203.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14121: Reward = -1295.00, Avg Reward (100) = -29203.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14122: Reward = -49626.26, Avg Reward (100) = -28869.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14123: Reward = -35499.61, Avg Reward (100) = -28969.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14124: Reward = -35499.61, Avg Reward (100) = -29312.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14125: Reward = -35499.61, Avg Reward (100) = -29341.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14126: Reward = -35499.61, Avg Reward (100) = -29341.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14127: Reward = -33701.04, Avg Reward (100) = -29341.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14128: Reward = -1394.00, Avg Reward (100) = -29323.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14129: Reward = -1049.00, Avg Reward (100) = -29042.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14130: Reward = -35499.61, Avg Reward (100) = -29040.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14131: Reward = -35499.61, Avg Reward (100) = -29040.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14132: Reward = -35499.61, Avg Reward (100) = -29383.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14133: Reward = -35499.61, Avg Reward (100) = -29728.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14134: Reward = -35499.61, Avg Reward (100) = -29670.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14135: Reward = -33469.53, Avg Reward (100) = -29670.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14136: Reward = -25228.52, Avg Reward (100) = -29649.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14137: Reward = -12446.80, Avg Reward (100) = -29649.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14138: Reward = -34685.86, Avg Reward (100) = -29405.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14139: Reward = -12446.80, Avg Reward (100) = -29397.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14140: Reward = -47848.55, Avg Reward (100) = -29166.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14141: Reward = -35499.61, Avg Reward (100) = -29290.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14142: Reward = -35499.61, Avg Reward (100) = -29148.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14143: Reward = -35499.61, Avg Reward (100) = -29148.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14144: Reward = -35499.61, Avg Reward (100) = -29148.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14145: Reward = -35499.61, Avg Reward (100) = -29148.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14146: Reward = -33469.53, Avg Reward (100) = -29148.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14147: Reward = -1450.40, Avg Reward (100) = -29470.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 14148: Reward = -28683.61, Avg Reward (100) = -29130.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14149: Reward = -35499.61, Avg Reward (100) = -29012.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14150: Reward = -1049.00, Avg Reward (100) = -29356.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14151: Reward = -35499.61, Avg Reward (100) = -28971.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14152: Reward = -35499.61, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14153: Reward = -1196.00, Avg Reward (100) = -29657.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14154: Reward = -35499.61, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14155: Reward = -35499.61, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14156: Reward = -43263.20, Avg Reward (100) = -29237.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14157: Reward = -35499.61, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14158: Reward = -35499.61, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14159: Reward = -33701.04, Avg Reward (100) = -29314.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14160: Reward = -35499.61, Avg Reward (100) = -29296.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14161: Reward = -28683.61, Avg Reward (100) = -29298.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14162: Reward = -49176.10, Avg Reward (100) = -29574.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14163: Reward = -35499.61, Avg Reward (100) = -29710.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14164: Reward = -32235.76, Avg Reward (100) = -29710.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32235.76, Border Penalty: -33969.67, Obstacle Penalty: -50.00
Episode 14165: Reward = -1394.00, Avg Reward (100) = -29588.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14166: Reward = -35499.61, Avg Reward (100) = -29247.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14167: Reward = -35499.61, Avg Reward (100) = -29247.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14168: Reward = -1147.00, Avg Reward (100) = -29247.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14169: Reward = -35499.61, Avg Reward (100) = -28837.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14170: Reward = -35499.61, Avg Reward (100) = -28837.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14171: Reward = -36089.25, Avg Reward (100) = -28837.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14172: Reward = -35499.61, Avg Reward (100) = -28838.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14173: Reward = -49176.10, Avg Reward (100) = -28846.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14174: Reward = -35499.61, Avg Reward (100) = -29247.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14175: Reward = -35499.61, Avg Reward (100) = -29590.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14176: Reward = -1098.00, Avg Reward (100) = -29590.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14177: Reward = -33701.04, Avg Reward (100) = -29349.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14178: Reward = -35499.61, Avg Reward (100) = -29675.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14179: Reward = -25751.89, Avg Reward (100) = -29675.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -25751.89, Border Penalty: -30168.98, Obstacle Penalty: -50.00
Episode 14180: Reward = -35499.61, Avg Reward (100) = -29454.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14181: Reward = -35499.61, Avg Reward (100) = -29522.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14182: Reward = -1000.00, Avg Reward (100) = -29522.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14183: Reward = -1196.00, Avg Reward (100) = -29177.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14184: Reward = -1196.00, Avg Reward (100) = -28894.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14185: Reward = -25228.52, Avg Reward (100) = -28545.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14186: Reward = -28653.56, Avg Reward (100) = -28785.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14187: Reward = -1196.00, Avg Reward (100) = -29060.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14188: Reward = -35499.61, Avg Reward (100) = -28717.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14189: Reward = -35499.61, Avg Reward (100) = -28717.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14190: Reward = -33469.53, Avg Reward (100) = -29060.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14191: Reward = -35499.61, Avg Reward (100) = -29040.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14192: Reward = -35499.61, Avg Reward (100) = -29040.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14193: Reward = -1196.00, Avg Reward (100) = -29040.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14194: Reward = -35499.61, Avg Reward (100) = -28697.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14195: Reward = -1196.00, Avg Reward (100) = -28725.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14196: Reward = -35499.61, Avg Reward (100) = -28382.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14197: Reward = -35499.61, Avg Reward (100) = -28382.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14198: Reward = -25228.52, Avg Reward (100) = -28341.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14199: Reward = -32619.61, Avg Reward (100) = -28581.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14200: Reward = -32619.61, Avg Reward (100) = -28584.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14201: Reward = -37669.33, Avg Reward (100) = -28899.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14202: Reward = -54261.02, Avg Reward (100) = -28920.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -54261.02, Border Penalty: -40768.21, Obstacle Penalty: -50.00
Episode 14203: Reward = -35499.61, Avg Reward (100) = -29450.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14204: Reward = -12446.80, Avg Reward (100) = -29439.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14205: Reward = -32619.61, Avg Reward (100) = -29208.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14206: Reward = -35499.61, Avg Reward (100) = -29179.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14207: Reward = -35499.61, Avg Reward (100) = -29179.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14208: Reward = -35499.61, Avg Reward (100) = -29038.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14209: Reward = -1000.00, Avg Reward (100) = -29038.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14210: Reward = -35499.61, Avg Reward (100) = -29037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14211: Reward = -1049.00, Avg Reward (100) = -29037.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14212: Reward = -34380.43, Avg Reward (100) = -28693.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -34380.43, Border Penalty: -32388.96, Obstacle Penalty: -50.00
Episode 14213: Reward = -1147.00, Avg Reward (100) = -28682.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14214: Reward = -35499.61, Avg Reward (100) = -28338.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14215: Reward = -35499.61, Avg Reward (100) = -28260.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14216: Reward = -35499.61, Avg Reward (100) = -28603.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14217: Reward = -1049.00, Avg Reward (100) = -28586.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14218: Reward = -35499.61, Avg Reward (100) = -28200.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14219: Reward = -1394.00, Avg Reward (100) = -28233.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14220: Reward = -35499.61, Avg Reward (100) = -27912.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14221: Reward = -35499.61, Avg Reward (100) = -27912.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14222: Reward = -1000.00, Avg Reward (100) = -28254.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14223: Reward = -35499.61, Avg Reward (100) = -27768.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14224: Reward = -35499.61, Avg Reward (100) = -27768.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14225: Reward = -1049.00, Avg Reward (100) = -27768.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14226: Reward = -47848.55, Avg Reward (100) = -27423.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14227: Reward = -35499.61, Avg Reward (100) = -27547.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14228: Reward = -1147.00, Avg Reward (100) = -27565.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14229: Reward = -32619.61, Avg Reward (100) = -27562.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14230: Reward = -35499.61, Avg Reward (100) = -27878.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14231: Reward = -35499.61, Avg Reward (100) = -27878.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14232: Reward = -35499.61, Avg Reward (100) = -27878.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14233: Reward = -50011.42, Avg Reward (100) = -27878.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -50011.42, Border Penalty: -38178.67, Obstacle Penalty: -50.00
Episode 14234: Reward = -35499.61, Avg Reward (100) = -28023.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14235: Reward = -1098.00, Avg Reward (100) = -28023.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14236: Reward = -1638.00, Avg Reward (100) = -27699.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -1638.00, Border Penalty: -5395.89, Obstacle Penalty: -50.00
Episode 14237: Reward = -1098.00, Avg Reward (100) = -27464.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14238: Reward = -33469.53, Avg Reward (100) = -27350.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14239: Reward = -28653.56, Avg Reward (100) = -27338.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14240: Reward = -1295.00, Avg Reward (100) = -27500.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14241: Reward = -35499.61, Avg Reward (100) = -27034.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14242: Reward = -35499.61, Avg Reward (100) = -27034.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14243: Reward = -35499.61, Avg Reward (100) = -27034.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14244: Reward = -29512.46, Avg Reward (100) = -27034.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14245: Reward = -1049.00, Avg Reward (100) = -26975.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14246: Reward = -35499.61, Avg Reward (100) = -26630.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14247: Reward = -35499.61, Avg Reward (100) = -26650.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14248: Reward = -30437.18, Avg Reward (100) = -26991.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -30437.18, Border Penalty: -32801.88, Obstacle Penalty: -50.00
Episode 14249: Reward = -1000.00, Avg Reward (100) = -27008.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14250: Reward = -1196.00, Avg Reward (100) = -26663.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14251: Reward = -35499.61, Avg Reward (100) = -26665.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14252: Reward = -35499.61, Avg Reward (100) = -26665.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14253: Reward = -1049.00, Avg Reward (100) = -26665.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14254: Reward = -35499.61, Avg Reward (100) = -26663.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14255: Reward = -39606.20, Avg Reward (100) = -26663.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14256: Reward = -35499.61, Avg Reward (100) = -26704.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14257: Reward = -36089.25, Avg Reward (100) = -26627.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14258: Reward = -35499.61, Avg Reward (100) = -26633.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14259: Reward = -35499.61, Avg Reward (100) = -26633.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14260: Reward = -36499.46, Avg Reward (100) = -26651.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36499.46, Border Penalty: -35826.99, Obstacle Penalty: -50.00
Episode 14261: Reward = -43263.20, Avg Reward (100) = -26661.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14262: Reward = -33469.53, Avg Reward (100) = -26806.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14263: Reward = -12446.80, Avg Reward (100) = -26649.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14264: Reward = -35499.61, Avg Reward (100) = -26419.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14265: Reward = -35499.61, Avg Reward (100) = -26452.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14266: Reward = -35499.61, Avg Reward (100) = -26793.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14267: Reward = -35499.61, Avg Reward (100) = -26793.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14268: Reward = -35499.61, Avg Reward (100) = -26793.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14269: Reward = -35499.61, Avg Reward (100) = -27136.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14270: Reward = -35499.61, Avg Reward (100) = -27136.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14271: Reward = -35499.61, Avg Reward (100) = -27136.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14272: Reward = -1049.00, Avg Reward (100) = -27130.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14273: Reward = -33469.53, Avg Reward (100) = -26786.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14274: Reward = -34685.86, Avg Reward (100) = -26629.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14275: Reward = -49176.10, Avg Reward (100) = -26620.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14276: Reward = -35499.61, Avg Reward (100) = -26757.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14277: Reward = -28653.56, Avg Reward (100) = -27101.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14278: Reward = -1196.00, Avg Reward (100) = -27051.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14279: Reward = -1394.00, Avg Reward (100) = -26708.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14280: Reward = -35499.61, Avg Reward (100) = -26464.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14281: Reward = -35499.61, Avg Reward (100) = -26464.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14282: Reward = -35499.61, Avg Reward (100) = -26464.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14283: Reward = -1295.00, Avg Reward (100) = -26809.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14284: Reward = -35499.61, Avg Reward (100) = -26810.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14285: Reward = -1245.00, Avg Reward (100) = -27153.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14286: Reward = -35499.61, Avg Reward (100) = -26913.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14287: Reward = -12446.80, Avg Reward (100) = -26982.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14288: Reward = -1049.00, Avg Reward (100) = -27094.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14289: Reward = -35499.61, Avg Reward (100) = -26750.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14290: Reward = -35499.61, Avg Reward (100) = -26750.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14291: Reward = -35499.61, Avg Reward (100) = -26770.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14292: Reward = -35499.61, Avg Reward (100) = -26770.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14293: Reward = -35499.61, Avg Reward (100) = -26770.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14294: Reward = -1049.00, Avg Reward (100) = -27113.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14295: Reward = -35499.61, Avg Reward (100) = -26769.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14296: Reward = -29512.46, Avg Reward (100) = -27112.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14297: Reward = -35499.61, Avg Reward (100) = -27052.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14298: Reward = -35499.61, Avg Reward (100) = -27052.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14299: Reward = -26787.09, Avg Reward (100) = -27155.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -26787.09, Border Penalty: -30999.65, Obstacle Penalty: -50.00
Episode 14300: Reward = -34927.46, Avg Reward (100) = -27096.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -34927.46, Border Penalty: -33579.46, Obstacle Penalty: -50.00
Episode 14301: Reward = -35499.61, Avg Reward (100) = -27119.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14302: Reward = -1049.00, Avg Reward (100) = -27098.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14303: Reward = -1147.00, Avg Reward (100) = -26565.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14304: Reward = -2932.87, Avg Reward (100) = -26222.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -2932.87, Border Penalty: -10945.23, Obstacle Penalty: -50.00
Episode 14305: Reward = -35499.61, Avg Reward (100) = -26127.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14306: Reward = -1049.00, Avg Reward (100) = -26156.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14307: Reward = -34685.86, Avg Reward (100) = -25811.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14308: Reward = -35499.61, Avg Reward (100) = -25803.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14309: Reward = -1049.00, Avg Reward (100) = -25803.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14310: Reward = -47848.55, Avg Reward (100) = -25803.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14311: Reward = -35499.61, Avg Reward (100) = -25927.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14312: Reward = -35499.61, Avg Reward (100) = -26271.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14313: Reward = -1343.00, Avg Reward (100) = -26283.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1343.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14314: Reward = -35499.61, Avg Reward (100) = -26285.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14315: Reward = -48044.60, Avg Reward (100) = -26285.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48044.60, Border Penalty: -36689.55, Obstacle Penalty: -50.00
Episode 14316: Reward = -1000.00, Avg Reward (100) = -26410.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14317: Reward = -35499.61, Avg Reward (100) = -26065.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14318: Reward = -35499.61, Avg Reward (100) = -26410.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14319: Reward = -35499.61, Avg Reward (100) = -26410.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14320: Reward = -59645.17, Avg Reward (100) = -26751.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -59645.17, Border Penalty: -36958.67, Obstacle Penalty: -50.00
Episode 14321: Reward = -35499.61, Avg Reward (100) = -26992.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14322: Reward = -32619.61, Avg Reward (100) = -26992.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14323: Reward = -1295.00, Avg Reward (100) = -27308.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14324: Reward = -35499.61, Avg Reward (100) = -26966.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14325: Reward = -35499.61, Avg Reward (100) = -26966.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14326: Reward = -33469.53, Avg Reward (100) = -27311.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14327: Reward = -35499.61, Avg Reward (100) = -27167.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14328: Reward = -1098.00, Avg Reward (100) = -27167.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14329: Reward = -35499.61, Avg Reward (100) = -27166.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14330: Reward = -35499.61, Avg Reward (100) = -27195.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14331: Reward = -49176.10, Avg Reward (100) = -27195.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14332: Reward = -35499.61, Avg Reward (100) = -27332.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14333: Reward = -35499.61, Avg Reward (100) = -27332.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14334: Reward = -35499.61, Avg Reward (100) = -27187.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14335: Reward = -35499.61, Avg Reward (100) = -27187.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14336: Reward = -35499.61, Avg Reward (100) = -27531.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14337: Reward = -35499.61, Avg Reward (100) = -27870.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14338: Reward = -35499.61, Avg Reward (100) = -28214.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14339: Reward = -35499.61, Avg Reward (100) = -28234.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14340: Reward = -35499.61, Avg Reward (100) = -28302.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14341: Reward = -35499.61, Avg Reward (100) = -28644.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14342: Reward = -35499.61, Avg Reward (100) = -28644.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14343: Reward = -35499.61, Avg Reward (100) = -28644.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14344: Reward = -1394.00, Avg Reward (100) = -28644.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14345: Reward = -33701.04, Avg Reward (100) = -28363.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14346: Reward = -35499.61, Avg Reward (100) = -28690.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14347: Reward = -1147.00, Avg Reward (100) = -28690.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14348: Reward = -1147.00, Avg Reward (100) = -28346.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14349: Reward = -35499.61, Avg Reward (100) = -28053.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14350: Reward = -42651.70, Avg Reward (100) = -28398.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -42651.70, Border Penalty: -37572.03, Obstacle Penalty: -50.00
Episode 14351: Reward = -35499.61, Avg Reward (100) = -28813.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14352: Reward = -35499.61, Avg Reward (100) = -28813.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14353: Reward = -35499.61, Avg Reward (100) = -28813.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14354: Reward = -52315.20, Avg Reward (100) = -29157.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -52315.20, Border Penalty: -41333.20, Obstacle Penalty: -50.00
Episode 14355: Reward = -35499.61, Avg Reward (100) = -29325.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14356: Reward = -32619.61, Avg Reward (100) = -29284.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14357: Reward = -35499.61, Avg Reward (100) = -29256.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14358: Reward = -32619.61, Avg Reward (100) = -29250.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14359: Reward = -35499.61, Avg Reward (100) = -29221.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14360: Reward = -35499.61, Avg Reward (100) = -29221.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14361: Reward = -29512.46, Avg Reward (100) = -29211.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14362: Reward = -36089.25, Avg Reward (100) = -29073.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14363: Reward = -28653.56, Avg Reward (100) = -29100.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14364: Reward = -35499.61, Avg Reward (100) = -29262.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14365: Reward = -35499.61, Avg Reward (100) = -29262.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14366: Reward = -35499.61, Avg Reward (100) = -29262.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14367: Reward = -1000.00, Avg Reward (100) = -29262.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14368: Reward = -35499.61, Avg Reward (100) = -28917.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14369: Reward = -35499.61, Avg Reward (100) = -28917.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14370: Reward = -35499.61, Avg Reward (100) = -28917.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14371: Reward = -1098.00, Avg Reward (100) = -28917.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14372: Reward = -35499.61, Avg Reward (100) = -28573.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14373: Reward = -38625.36, Avg Reward (100) = -28917.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38625.36, Border Penalty: -36583.92, Obstacle Penalty: -50.00
Episode 14374: Reward = -35499.61, Avg Reward (100) = -28969.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14375: Reward = -35499.61, Avg Reward (100) = -28977.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14376: Reward = -30619.04, Avg Reward (100) = -28840.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30619.04, Border Penalty: -32490.02, Obstacle Penalty: -50.00
Episode 14377: Reward = -1000.00, Avg Reward (100) = -28791.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14378: Reward = -35499.61, Avg Reward (100) = -28515.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14379: Reward = -35499.61, Avg Reward (100) = -28858.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14380: Reward = -28683.61, Avg Reward (100) = -29199.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14381: Reward = -1295.00, Avg Reward (100) = -29131.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14382: Reward = -35499.61, Avg Reward (100) = -28789.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14383: Reward = -35499.61, Avg Reward (100) = -28789.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14384: Reward = -47848.55, Avg Reward (100) = -29131.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14385: Reward = -35499.61, Avg Reward (100) = -29254.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14386: Reward = -35499.61, Avg Reward (100) = -29597.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14387: Reward = -1394.00, Avg Reward (100) = -29597.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14388: Reward = -36089.25, Avg Reward (100) = -29486.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14389: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14390: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14391: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14392: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14393: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14394: Reward = -35499.61, Avg Reward (100) = -29837.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14395: Reward = -1295.00, Avg Reward (100) = -30181.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14396: Reward = -1295.00, Avg Reward (100) = -29839.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14397: Reward = -41483.66, Avg Reward (100) = -29557.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -41483.66, Border Penalty: -37315.89, Obstacle Penalty: -50.00
Episode 14398: Reward = -1147.00, Avg Reward (100) = -29617.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14399: Reward = -1394.00, Avg Reward (100) = -29273.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14400: Reward = -35499.61, Avg Reward (100) = -29019.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14401: Reward = -57983.46, Avg Reward (100) = -29025.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -57983.46, Border Penalty: -41230.57, Obstacle Penalty: -50.00
Episode 14402: Reward = -34685.86, Avg Reward (100) = -29250.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14403: Reward = -35499.61, Avg Reward (100) = -29586.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14404: Reward = -35499.61, Avg Reward (100) = -29930.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14405: Reward = -35499.61, Avg Reward (100) = -30255.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14406: Reward = -1000.00, Avg Reward (100) = -30255.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14407: Reward = -35499.61, Avg Reward (100) = -30255.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14408: Reward = -36726.20, Avg Reward (100) = -30263.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -36726.20, Border Penalty: -32739.82, Obstacle Penalty: -50.00
Episode 14409: Reward = -35499.61, Avg Reward (100) = -30275.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14410: Reward = -35499.61, Avg Reward (100) = -30620.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14411: Reward = -35499.61, Avg Reward (100) = -30496.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14412: Reward = -35499.61, Avg Reward (100) = -30496.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14413: Reward = -35499.61, Avg Reward (100) = -30496.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14414: Reward = -28683.61, Avg Reward (100) = -30838.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14415: Reward = -33478.05, Avg Reward (100) = -30770.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -33478.05, Border Penalty: -33234.14, Obstacle Penalty: -50.00
Episode 14416: Reward = -36004.66, Avg Reward (100) = -30624.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 14417: Reward = -1196.00, Avg Reward (100) = -30974.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14418: Reward = -35499.61, Avg Reward (100) = -30631.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14419: Reward = -35499.61, Avg Reward (100) = -30631.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14420: Reward = -35499.61, Avg Reward (100) = -30631.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14421: Reward = -1295.00, Avg Reward (100) = -30390.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14422: Reward = -1049.00, Avg Reward (100) = -30048.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14423: Reward = -37669.33, Avg Reward (100) = -29732.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14424: Reward = -1049.00, Avg Reward (100) = -30096.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14425: Reward = -35499.61, Avg Reward (100) = -29751.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14426: Reward = -35499.61, Avg Reward (100) = -29751.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14427: Reward = -32851.49, Avg Reward (100) = -29771.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -32851.49, Border Penalty: -34027.25, Obstacle Penalty: -50.00
Episode 14428: Reward = -35499.61, Avg Reward (100) = -29745.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14429: Reward = -32619.61, Avg Reward (100) = -30089.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14430: Reward = -35499.61, Avg Reward (100) = -30060.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14431: Reward = -39606.20, Avg Reward (100) = -30060.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14432: Reward = -39606.20, Avg Reward (100) = -29964.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14433: Reward = -35499.61, Avg Reward (100) = -30005.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14434: Reward = -35499.61, Avg Reward (100) = -30005.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14435: Reward = -1394.00, Avg Reward (100) = -30005.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14436: Reward = -36089.25, Avg Reward (100) = -29664.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14437: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14438: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14439: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14440: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14441: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14442: Reward = -35499.61, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14443: Reward = -1098.00, Avg Reward (100) = -29670.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14444: Reward = -32632.70, Avg Reward (100) = -29326.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32632.70, Border Penalty: -33600.80, Obstacle Penalty: -50.00
Episode 14445: Reward = -29512.46, Avg Reward (100) = -29639.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14446: Reward = -35499.61, Avg Reward (100) = -29597.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14447: Reward = -39606.20, Avg Reward (100) = -29597.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14448: Reward = -35499.61, Avg Reward (100) = -29981.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14449: Reward = -29512.46, Avg Reward (100) = -30325.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14450: Reward = -1196.00, Avg Reward (100) = -30265.56, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14451: Reward = -43263.20, Avg Reward (100) = -29851.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14452: Reward = -35499.61, Avg Reward (100) = -29928.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14453: Reward = -35499.61, Avg Reward (100) = -29928.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14454: Reward = -34685.86, Avg Reward (100) = -29928.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14455: Reward = -34685.86, Avg Reward (100) = -29752.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14456: Reward = -35499.61, Avg Reward (100) = -29744.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14457: Reward = -49176.10, Avg Reward (100) = -29773.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14458: Reward = -47848.55, Avg Reward (100) = -29909.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14459: Reward = -28683.61, Avg Reward (100) = -30062.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14460: Reward = -34685.86, Avg Reward (100) = -29993.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14461: Reward = -35499.61, Avg Reward (100) = -29985.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14462: Reward = -44987.75, Avg Reward (100) = -30045.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -44987.75, Border Penalty: -38825.57, Obstacle Penalty: -50.00
Episode 14463: Reward = -35499.61, Avg Reward (100) = -30134.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14464: Reward = -39606.20, Avg Reward (100) = -30203.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14465: Reward = -35499.61, Avg Reward (100) = -30244.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14466: Reward = -1295.00, Avg Reward (100) = -30244.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14467: Reward = -35499.61, Avg Reward (100) = -29902.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14468: Reward = -35499.61, Avg Reward (100) = -30247.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14469: Reward = -32619.61, Avg Reward (100) = -30247.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 14470: Reward = -1049.00, Avg Reward (100) = -30218.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14471: Reward = -35499.61, Avg Reward (100) = -29873.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14472: Reward = -35499.61, Avg Reward (100) = -30217.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14473: Reward = -35499.61, Avg Reward (100) = -30217.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14474: Reward = -49176.10, Avg Reward (100) = -30186.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14475: Reward = -35499.61, Avg Reward (100) = -30323.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14476: Reward = -35499.61, Avg Reward (100) = -30323.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14477: Reward = -37669.33, Avg Reward (100) = -30372.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14478: Reward = -32245.59, Avg Reward (100) = -30738.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14479: Reward = -35499.61, Avg Reward (100) = -30706.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14480: Reward = -35499.61, Avg Reward (100) = -30706.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14481: Reward = -35499.61, Avg Reward (100) = -30774.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14482: Reward = -1196.00, Avg Reward (100) = -31116.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14483: Reward = -1000.00, Avg Reward (100) = -30773.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14484: Reward = -35499.61, Avg Reward (100) = -30428.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14485: Reward = -12446.80, Avg Reward (100) = -30304.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14486: Reward = -25228.52, Avg Reward (100) = -30074.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14487: Reward = -35499.61, Avg Reward (100) = -29971.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14488: Reward = -47848.55, Avg Reward (100) = -30312.77, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14489: Reward = -1049.00, Avg Reward (100) = -30430.37, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14490: Reward = -54726.48, Avg Reward (100) = -30085.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -54726.48, Border Penalty: -41575.92, Obstacle Penalty: -50.00
Episode 14491: Reward = -35499.61, Avg Reward (100) = -30278.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14492: Reward = -35499.61, Avg Reward (100) = -30278.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14493: Reward = -35499.61, Avg Reward (100) = -30278.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14494: Reward = -35499.61, Avg Reward (100) = -30278.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14495: Reward = -35499.61, Avg Reward (100) = -30278.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14496: Reward = -35499.61, Avg Reward (100) = -30620.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14497: Reward = -32619.61, Avg Reward (100) = -30962.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14498: Reward = -47848.55, Avg Reward (100) = -30873.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14499: Reward = -36089.25, Avg Reward (100) = -31340.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14500: Reward = -32619.61, Avg Reward (100) = -31687.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14501: Reward = -25228.52, Avg Reward (100) = -31658.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14502: Reward = -33469.53, Avg Reward (100) = -31331.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14503: Reward = -35468.23, Avg Reward (100) = -31319.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35468.23, Border Penalty: -35365.46, Obstacle Penalty: -50.00
Episode 14504: Reward = -1098.00, Avg Reward (100) = -31318.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14505: Reward = -35499.61, Avg Reward (100) = -30974.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14506: Reward = -35499.61, Avg Reward (100) = -30974.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14507: Reward = -43263.20, Avg Reward (100) = -31319.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14508: Reward = -33701.04, Avg Reward (100) = -31397.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14509: Reward = -35499.61, Avg Reward (100) = -31367.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14510: Reward = -35499.61, Avg Reward (100) = -31367.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14511: Reward = -37669.33, Avg Reward (100) = -31367.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14512: Reward = -35499.61, Avg Reward (100) = -31388.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14513: Reward = -35499.61, Avg Reward (100) = -31388.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14514: Reward = -35499.61, Avg Reward (100) = -31388.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14515: Reward = -35499.61, Avg Reward (100) = -31456.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14516: Reward = -35499.61, Avg Reward (100) = -31477.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14517: Reward = -33469.53, Avg Reward (100) = -31472.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14518: Reward = -49626.26, Avg Reward (100) = -31794.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14519: Reward = -12446.80, Avg Reward (100) = -31936.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14520: Reward = -1295.00, Avg Reward (100) = -31705.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14521: Reward = -35499.61, Avg Reward (100) = -31363.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14522: Reward = -43263.20, Avg Reward (100) = -31705.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14523: Reward = -49626.26, Avg Reward (100) = -32127.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14524: Reward = -1147.00, Avg Reward (100) = -32247.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14525: Reward = -32499.04, Avg Reward (100) = -32248.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32499.04, Border Penalty: -32458.42, Obstacle Penalty: -50.00
Episode 14526: Reward = -35499.61, Avg Reward (100) = -32218.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14527: Reward = -34685.86, Avg Reward (100) = -32218.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 14528: Reward = -1196.00, Avg Reward (100) = -32236.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14529: Reward = -35207.64, Avg Reward (100) = -31893.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -35207.64, Border Penalty: -35406.49, Obstacle Penalty: -50.00
Episode 14530: Reward = -43263.20, Avg Reward (100) = -31919.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -35267.92, Obstacle Penalty: -50.00
Episode 14531: Reward = -49626.26, Avg Reward (100) = -31997.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -37147.83, Obstacle Penalty: -50.00
Episode 14532: Reward = -44910.13, Avg Reward (100) = -32097.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -44910.13, Border Penalty: -35790.18, Obstacle Penalty: -50.00
Episode 14533: Reward = -37669.33, Avg Reward (100) = -32150.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14534: Reward = -1295.00, Avg Reward (100) = -32172.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14535: Reward = -35499.61, Avg Reward (100) = -31829.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14536: Reward = -35499.61, Avg Reward (100) = -32171.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14537: Reward = -35499.61, Avg Reward (100) = -32165.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14538: Reward = -1049.00, Avg Reward (100) = -32165.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14539: Reward = -12446.80, Avg Reward (100) = -31820.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14540: Reward = -35499.61, Avg Reward (100) = -31590.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14541: Reward = -35499.61, Avg Reward (100) = -31590.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14542: Reward = -1049.00, Avg Reward (100) = -31590.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14543: Reward = -35499.61, Avg Reward (100) = -31245.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14544: Reward = -41656.72, Avg Reward (100) = -31589.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41656.72, Border Penalty: -35485.22, Obstacle Penalty: -50.00
Episode 14545: Reward = -35499.61, Avg Reward (100) = -31679.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14546: Reward = -35499.61, Avg Reward (100) = -31739.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14547: Reward = -35499.61, Avg Reward (100) = -31739.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14548: Reward = -1098.00, Avg Reward (100) = -31698.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14549: Reward = -35499.61, Avg Reward (100) = -31354.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14550: Reward = -1049.00, Avg Reward (100) = -31414.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14551: Reward = -35499.61, Avg Reward (100) = -31413.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14552: Reward = -35499.61, Avg Reward (100) = -31335.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14553: Reward = -1049.00, Avg Reward (100) = -31335.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14554: Reward = -35499.61, Avg Reward (100) = -30990.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14555: Reward = -35499.61, Avg Reward (100) = -30999.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14556: Reward = -35499.61, Avg Reward (100) = -31007.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14557: Reward = -35499.61, Avg Reward (100) = -31007.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14558: Reward = -1147.00, Avg Reward (100) = -30870.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14559: Reward = -1000.00, Avg Reward (100) = -30403.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14560: Reward = -33469.53, Avg Reward (100) = -30126.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14561: Reward = -35499.61, Avg Reward (100) = -30114.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14562: Reward = -35499.61, Avg Reward (100) = -30114.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14563: Reward = -35499.61, Avg Reward (100) = -30019.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14564: Reward = -33701.04, Avg Reward (100) = -30019.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14565: Reward = -29512.46, Avg Reward (100) = -29960.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14566: Reward = -35499.61, Avg Reward (100) = -29900.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14567: Reward = -35499.61, Avg Reward (100) = -30242.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14568: Reward = -35499.61, Avg Reward (100) = -30242.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14569: Reward = -35499.61, Avg Reward (100) = -30242.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14570: Reward = -33701.04, Avg Reward (100) = -30271.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14571: Reward = -33469.53, Avg Reward (100) = -30597.97, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14572: Reward = -43263.20, Avg Reward (100) = -30577.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14573: Reward = -35499.61, Avg Reward (100) = -30655.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14574: Reward = -32619.61, Avg Reward (100) = -30655.30, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14575: Reward = -1098.00, Avg Reward (100) = -30489.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14576: Reward = -43263.20, Avg Reward (100) = -30145.72, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -37547.93, Obstacle Penalty: -50.00
Episode 14577: Reward = -1049.00, Avg Reward (100) = -30223.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14578: Reward = -49176.10, Avg Reward (100) = -29857.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14579: Reward = -1098.00, Avg Reward (100) = -30026.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14580: Reward = -35499.61, Avg Reward (100) = -29682.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14581: Reward = -35499.61, Avg Reward (100) = -29682.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14582: Reward = -35499.61, Avg Reward (100) = -29682.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14583: Reward = -35499.61, Avg Reward (100) = -30025.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14584: Reward = -33469.53, Avg Reward (100) = -30370.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14585: Reward = -1295.00, Avg Reward (100) = -30350.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14586: Reward = -29512.46, Avg Reward (100) = -30238.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14587: Reward = -35499.61, Avg Reward (100) = -30281.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14588: Reward = -35499.61, Avg Reward (100) = -30281.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14589: Reward = -35499.61, Avg Reward (100) = -30158.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14590: Reward = -35499.61, Avg Reward (100) = -30502.51, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14591: Reward = -1049.00, Avg Reward (100) = -30310.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14592: Reward = -1295.00, Avg Reward (100) = -29965.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14593: Reward = -12446.80, Avg Reward (100) = -29623.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14594: Reward = -35499.61, Avg Reward (100) = -29393.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14595: Reward = -49626.26, Avg Reward (100) = -29393.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14596: Reward = -32619.61, Avg Reward (100) = -29534.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14597: Reward = -1147.00, Avg Reward (100) = -29505.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14598: Reward = -35499.61, Avg Reward (100) = -29190.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14599: Reward = -49176.10, Avg Reward (100) = -29067.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -39443.45, Obstacle Penalty: -50.00
Episode 14600: Reward = -1295.00, Avg Reward (100) = -29198.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14601: Reward = -35499.61, Avg Reward (100) = -28885.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14602: Reward = -35499.61, Avg Reward (100) = -28987.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14603: Reward = -49176.10, Avg Reward (100) = -29008.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14604: Reward = -35499.61, Avg Reward (100) = -29145.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14605: Reward = -1000.00, Avg Reward (100) = -29489.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14606: Reward = -35499.61, Avg Reward (100) = -29144.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14607: Reward = -43263.20, Avg Reward (100) = -29144.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14608: Reward = -1196.00, Avg Reward (100) = -29144.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14609: Reward = -35499.61, Avg Reward (100) = -28819.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14610: Reward = -38306.90, Avg Reward (100) = -28819.10, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 14611: Reward = -35499.61, Avg Reward (100) = -28847.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14612: Reward = -35499.61, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14613: Reward = -35499.61, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14614: Reward = -35499.61, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14615: Reward = -35499.61, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14616: Reward = -35499.61, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14617: Reward = -28653.56, Avg Reward (100) = -28825.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14618: Reward = -35499.61, Avg Reward (100) = -28777.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14619: Reward = -49626.26, Avg Reward (100) = -28636.05, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14620: Reward = -1147.00, Avg Reward (100) = -29007.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14621: Reward = -47848.55, Avg Reward (100) = -29006.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14622: Reward = -35499.61, Avg Reward (100) = -29129.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14623: Reward = -1492.00, Avg Reward (100) = -29052.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 14624: Reward = -37669.33, Avg Reward (100) = -28570.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14625: Reward = -33469.53, Avg Reward (100) = -28936.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14626: Reward = -1049.00, Avg Reward (100) = -28945.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14627: Reward = -38792.44, Avg Reward (100) = -28601.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -38792.44, Border Penalty: -35873.75, Obstacle Penalty: -50.00
Episode 14628: Reward = -33701.04, Avg Reward (100) = -28642.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14629: Reward = -35499.61, Avg Reward (100) = -28967.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14630: Reward = -35499.61, Avg Reward (100) = -28970.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14631: Reward = -41280.90, Avg Reward (100) = -28892.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -41280.90, Border Penalty: -37224.51, Obstacle Penalty: -50.00
Episode 14632: Reward = -35499.61, Avg Reward (100) = -28809.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14633: Reward = -35499.61, Avg Reward (100) = -28715.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14634: Reward = -35499.61, Avg Reward (100) = -28693.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14635: Reward = -35499.61, Avg Reward (100) = -29035.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14636: Reward = -1049.00, Avg Reward (100) = -29035.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14637: Reward = -34685.86, Avg Reward (100) = -28690.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -33233.80, Obstacle Penalty: -50.00
Episode 14638: Reward = -35499.61, Avg Reward (100) = -28682.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14639: Reward = -35499.61, Avg Reward (100) = -29027.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14640: Reward = -1098.00, Avg Reward (100) = -29257.87, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14641: Reward = -35499.61, Avg Reward (100) = -28913.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14642: Reward = -35499.61, Avg Reward (100) = -28913.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14643: Reward = -1147.00, Avg Reward (100) = -29258.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14644: Reward = -35499.61, Avg Reward (100) = -28914.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14645: Reward = -47848.55, Avg Reward (100) = -28853.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14646: Reward = -35499.61, Avg Reward (100) = -28976.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14647: Reward = -1295.00, Avg Reward (100) = -28976.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14648: Reward = -35499.61, Avg Reward (100) = -28634.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14649: Reward = -1049.00, Avg Reward (100) = -28978.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14650: Reward = -47848.55, Avg Reward (100) = -28634.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14651: Reward = -35499.61, Avg Reward (100) = -29102.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14652: Reward = -35499.61, Avg Reward (100) = -29102.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14653: Reward = -12446.80, Avg Reward (100) = -29102.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14654: Reward = -35499.61, Avg Reward (100) = -29216.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14655: Reward = -35499.61, Avg Reward (100) = -29216.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14656: Reward = -47025.21, Avg Reward (100) = -29216.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47025.21, Border Penalty: -33060.16, Obstacle Penalty: -50.00
Episode 14657: Reward = -35499.61, Avg Reward (100) = -29331.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14658: Reward = -34685.86, Avg Reward (100) = -29331.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14659: Reward = -35499.61, Avg Reward (100) = -29666.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14660: Reward = -35499.61, Avg Reward (100) = -30011.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14661: Reward = -33701.04, Avg Reward (100) = -30032.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14662: Reward = -1147.00, Avg Reward (100) = -30014.15, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14663: Reward = -35499.61, Avg Reward (100) = -29670.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14664: Reward = -35499.61, Avg Reward (100) = -29670.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14665: Reward = -29512.46, Avg Reward (100) = -29688.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14666: Reward = -35499.61, Avg Reward (100) = -29688.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14667: Reward = -35499.61, Avg Reward (100) = -29688.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14668: Reward = -35499.61, Avg Reward (100) = -29688.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14669: Reward = -1147.00, Avg Reward (100) = -29688.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14670: Reward = -35499.61, Avg Reward (100) = -29345.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14671: Reward = -1252.40, Avg Reward (100) = -29363.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1252.40, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14672: Reward = -35499.61, Avg Reward (100) = -29040.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14673: Reward = -35499.61, Avg Reward (100) = -28963.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14674: Reward = -35499.61, Avg Reward (100) = -28963.26, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14675: Reward = -1196.00, Avg Reward (100) = -28992.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14676: Reward = -35499.61, Avg Reward (100) = -28993.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14677: Reward = -47848.55, Avg Reward (100) = -28915.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14678: Reward = -35499.61, Avg Reward (100) = -29383.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14679: Reward = -35499.61, Avg Reward (100) = -29246.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14680: Reward = -28653.56, Avg Reward (100) = -29590.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14681: Reward = -35499.61, Avg Reward (100) = -29522.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14682: Reward = -35499.61, Avg Reward (100) = -29522.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14683: Reward = -35499.61, Avg Reward (100) = -29522.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14684: Reward = -35499.61, Avg Reward (100) = -29522.19, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14685: Reward = -39606.20, Avg Reward (100) = -29542.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14686: Reward = -35499.61, Avg Reward (100) = -29925.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14687: Reward = -35499.61, Avg Reward (100) = -29985.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14688: Reward = -28683.61, Avg Reward (100) = -29985.48, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14689: Reward = -35499.61, Avg Reward (100) = -29917.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14690: Reward = -35499.61, Avg Reward (100) = -29917.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14691: Reward = -29512.46, Avg Reward (100) = -29917.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14692: Reward = -12446.80, Avg Reward (100) = -30201.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14693: Reward = -49176.10, Avg Reward (100) = -30313.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14694: Reward = -35499.61, Avg Reward (100) = -30680.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14695: Reward = -53334.41, Avg Reward (100) = -30680.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -53334.41, Border Penalty: -39090.43, Obstacle Penalty: -50.00
Episode 14696: Reward = -35295.52, Avg Reward (100) = -30717.84, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -35295.52, Border Penalty: -34781.11, Obstacle Penalty: -50.00
Episode 14697: Reward = -35499.61, Avg Reward (100) = -30744.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14698: Reward = -28653.56, Avg Reward (100) = -31088.13, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14699: Reward = -1098.00, Avg Reward (100) = -31019.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14700: Reward = -35499.61, Avg Reward (100) = -30538.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14701: Reward = -32245.59, Avg Reward (100) = -30880.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14702: Reward = -49626.26, Avg Reward (100) = -30848.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14703: Reward = -35499.61, Avg Reward (100) = -30989.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14704: Reward = -28653.56, Avg Reward (100) = -30852.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14705: Reward = -35499.61, Avg Reward (100) = -30784.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14706: Reward = -34685.86, Avg Reward (100) = -31129.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14707: Reward = -35499.61, Avg Reward (100) = -31121.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14708: Reward = -47848.55, Avg Reward (100) = -31043.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14709: Reward = -35499.61, Avg Reward (100) = -31510.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14710: Reward = -35499.61, Avg Reward (100) = -31510.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14711: Reward = -33469.53, Avg Reward (100) = -31482.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14712: Reward = -50738.76, Avg Reward (100) = -31461.80, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -50738.76, Border Penalty: -37570.60, Obstacle Penalty: -50.00
Episode 14713: Reward = -49626.26, Avg Reward (100) = -31614.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14714: Reward = -1492.00, Avg Reward (100) = -31755.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -1492.00, Border Penalty: -8727.79, Obstacle Penalty: -50.00
Episode 14715: Reward = -35499.61, Avg Reward (100) = -31415.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14716: Reward = -12446.80, Avg Reward (100) = -31415.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14717: Reward = -49626.26, Avg Reward (100) = -31184.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14718: Reward = -35499.61, Avg Reward (100) = -31394.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14719: Reward = -1147.00, Avg Reward (100) = -31394.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14720: Reward = -1295.00, Avg Reward (100) = -30909.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14721: Reward = -35499.61, Avg Reward (100) = -30911.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14722: Reward = -36089.25, Avg Reward (100) = -30787.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14723: Reward = -35499.61, Avg Reward (100) = -30793.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14724: Reward = -28683.61, Avg Reward (100) = -31133.76, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14725: Reward = -34685.86, Avg Reward (100) = -31043.90, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14726: Reward = -35499.61, Avg Reward (100) = -31056.06, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14727: Reward = -35499.61, Avg Reward (100) = -31400.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14728: Reward = -32619.61, Avg Reward (100) = -31367.64, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14729: Reward = -1196.00, Avg Reward (100) = -31356.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14730: Reward = -35499.61, Avg Reward (100) = -31013.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14731: Reward = -28683.61, Avg Reward (100) = -31013.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14732: Reward = -35499.61, Avg Reward (100) = -30887.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14733: Reward = -43263.20, Avg Reward (100) = -30887.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14734: Reward = -47848.55, Avg Reward (100) = -30965.45, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14735: Reward = -35499.61, Avg Reward (100) = -31088.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14736: Reward = -43263.20, Avg Reward (100) = -31088.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14737: Reward = -35499.61, Avg Reward (100) = -31511.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14738: Reward = -29512.46, Avg Reward (100) = -31519.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14739: Reward = -28653.56, Avg Reward (100) = -31459.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14740: Reward = -1147.00, Avg Reward (100) = -31390.89, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14741: Reward = -1196.00, Avg Reward (100) = -31391.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14742: Reward = -33701.04, Avg Reward (100) = -31048.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14743: Reward = -35499.61, Avg Reward (100) = -31030.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14744: Reward = -35499.61, Avg Reward (100) = -31373.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14745: Reward = -35499.61, Avg Reward (100) = -31373.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14746: Reward = -29512.46, Avg Reward (100) = -31250.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14747: Reward = -35499.61, Avg Reward (100) = -31190.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14748: Reward = -35499.61, Avg Reward (100) = -31532.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14749: Reward = -29512.46, Avg Reward (100) = -31532.57, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14750: Reward = -35499.61, Avg Reward (100) = -31817.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14751: Reward = -1295.00, Avg Reward (100) = -31693.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14752: Reward = -1000.00, Avg Reward (100) = -31351.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14753: Reward = -28683.61, Avg Reward (100) = -31006.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14754: Reward = -47848.55, Avg Reward (100) = -31169.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14755: Reward = -35499.61, Avg Reward (100) = -31292.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14756: Reward = -35499.61, Avg Reward (100) = -31292.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14757: Reward = -49626.26, Avg Reward (100) = -31177.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14758: Reward = -39606.20, Avg Reward (100) = -31318.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14759: Reward = -35499.61, Avg Reward (100) = -31367.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14760: Reward = -29512.46, Avg Reward (100) = -31367.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14761: Reward = -12446.80, Avg Reward (100) = -31307.88, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14762: Reward = -1295.00, Avg Reward (100) = -31095.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14763: Reward = -29512.46, Avg Reward (100) = -31096.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -31347.28, Obstacle Penalty: -50.00
Episode 14764: Reward = -35499.61, Avg Reward (100) = -31036.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14765: Reward = -12446.80, Avg Reward (100) = -31036.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14766: Reward = -38306.90, Avg Reward (100) = -30866.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -38306.90, Border Penalty: -36018.44, Obstacle Penalty: -50.00
Episode 14767: Reward = -35499.61, Avg Reward (100) = -30894.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14768: Reward = -32245.59, Avg Reward (100) = -30894.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14769: Reward = -35499.61, Avg Reward (100) = -30861.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14770: Reward = -1000.00, Avg Reward (100) = -31205.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14771: Reward = -32245.59, Avg Reward (100) = -30860.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14772: Reward = -36089.25, Avg Reward (100) = -31170.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14773: Reward = -35499.61, Avg Reward (100) = -31176.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14774: Reward = -35499.61, Avg Reward (100) = -31176.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14775: Reward = -1295.00, Avg Reward (100) = -31176.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14776: Reward = -35499.61, Avg Reward (100) = -31177.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14777: Reward = -35499.61, Avg Reward (100) = -31177.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14778: Reward = -33469.53, Avg Reward (100) = -31053.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14779: Reward = -35499.61, Avg Reward (100) = -31033.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14780: Reward = -12446.80, Avg Reward (100) = -31033.38, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14781: Reward = -35499.61, Avg Reward (100) = -30871.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14782: Reward = -1000.00, Avg Reward (100) = -30871.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14783: Reward = -35499.61, Avg Reward (100) = -30526.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14784: Reward = -35499.61, Avg Reward (100) = -30526.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14785: Reward = -35499.61, Avg Reward (100) = -30526.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14786: Reward = -35499.61, Avg Reward (100) = -30485.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14787: Reward = -28683.61, Avg Reward (100) = -30485.25, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14788: Reward = -36089.25, Avg Reward (100) = -30417.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14789: Reward = -32619.61, Avg Reward (100) = -30491.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14790: Reward = -35499.61, Avg Reward (100) = -30462.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14791: Reward = -39606.20, Avg Reward (100) = -30462.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14792: Reward = -12446.80, Avg Reward (100) = -30563.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14793: Reward = -35499.61, Avg Reward (100) = -30563.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14794: Reward = -35499.61, Avg Reward (100) = -30426.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14795: Reward = -35499.61, Avg Reward (100) = -30426.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14796: Reward = -35499.61, Avg Reward (100) = -30248.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14797: Reward = -1049.00, Avg Reward (100) = -30250.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14798: Reward = -53191.82, Avg Reward (100) = -29905.70, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53191.82, Border Penalty: -41028.11, Obstacle Penalty: -50.00
Episode 14799: Reward = -25228.52, Avg Reward (100) = -30151.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14800: Reward = -25228.52, Avg Reward (100) = -30392.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14801: Reward = -35499.61, Avg Reward (100) = -30289.68, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14802: Reward = -1295.00, Avg Reward (100) = -30322.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14803: Reward = -36004.66, Avg Reward (100) = -29838.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36004.66, Border Penalty: -35650.77, Obstacle Penalty: -50.00
Episode 14804: Reward = -35499.61, Avg Reward (100) = -29843.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14805: Reward = -53075.23, Avg Reward (100) = -29912.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -53075.23, Border Penalty: -41137.98, Obstacle Penalty: -50.00
Episode 14806: Reward = -12446.80, Avg Reward (100) = -30088.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14807: Reward = -35499.61, Avg Reward (100) = -29865.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14808: Reward = -44239.55, Avg Reward (100) = -29865.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -44239.55, Border Penalty: -31542.50, Obstacle Penalty: -50.00
Episode 14809: Reward = -35499.61, Avg Reward (100) = -29829.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14810: Reward = -35499.61, Avg Reward (100) = -29829.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14811: Reward = -35499.61, Avg Reward (100) = -29829.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14812: Reward = -35499.61, Avg Reward (100) = -29849.99, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14813: Reward = -49626.26, Avg Reward (100) = -29697.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14814: Reward = -39606.20, Avg Reward (100) = -29697.60, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14815: Reward = -35499.61, Avg Reward (100) = -30078.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14816: Reward = -35499.61, Avg Reward (100) = -30078.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14817: Reward = -35499.61, Avg Reward (100) = -30309.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14818: Reward = -47477.73, Avg Reward (100) = -30168.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -47477.73, Border Penalty: -38905.30, Obstacle Penalty: -50.00
Episode 14819: Reward = -36089.25, Avg Reward (100) = -30287.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -34670.43, Obstacle Penalty: -50.00
Episode 14820: Reward = -1147.00, Avg Reward (100) = -30637.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14821: Reward = -33701.04, Avg Reward (100) = -30635.73, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14822: Reward = -1147.00, Avg Reward (100) = -30617.74, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14823: Reward = -35499.61, Avg Reward (100) = -30268.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14824: Reward = -1098.00, Avg Reward (100) = -30268.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14825: Reward = -1394.00, Avg Reward (100) = -29992.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -1667.43, Obstacle Penalty: -72.21
Episode 14826: Reward = -35499.61, Avg Reward (100) = -29659.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14827: Reward = -35499.61, Avg Reward (100) = -29659.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14828: Reward = -35499.61, Avg Reward (100) = -29659.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14829: Reward = -43263.20, Avg Reward (100) = -29688.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14830: Reward = -48252.80, Avg Reward (100) = -30109.02, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -48252.80, Border Penalty: -38888.80, Obstacle Penalty: -50.00
Episode 14831: Reward = -35499.61, Avg Reward (100) = -30236.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14832: Reward = -35499.61, Avg Reward (100) = -30304.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14833: Reward = -1000.00, Avg Reward (100) = -30304.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14834: Reward = -35499.61, Avg Reward (100) = -29882.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14835: Reward = -37669.33, Avg Reward (100) = -29758.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14836: Reward = -28683.61, Avg Reward (100) = -29780.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14837: Reward = -35499.61, Avg Reward (100) = -29634.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14838: Reward = -35499.61, Avg Reward (100) = -29634.49, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14839: Reward = -43263.20, Avg Reward (100) = -29694.36, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14840: Reward = -35499.61, Avg Reward (100) = -29840.46, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14841: Reward = -1245.00, Avg Reward (100) = -30183.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1245.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14842: Reward = -1196.00, Avg Reward (100) = -30184.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14843: Reward = -33469.53, Avg Reward (100) = -29859.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14844: Reward = -10868.79, Avg Reward (100) = -29839.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -10868.79, Border Penalty: -20727.79, Obstacle Penalty: -50.00
Episode 14845: Reward = -35499.61, Avg Reward (100) = -29592.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14846: Reward = -35499.61, Avg Reward (100) = -29592.81, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14847: Reward = -35499.61, Avg Reward (100) = -29652.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14848: Reward = -1394.00, Avg Reward (100) = -29652.69, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 7, Reward Breakdown -> Delta_x Reward: -1394.00, Border Penalty: -10403.80, Obstacle Penalty: -50.00
Episode 14849: Reward = -35499.61, Avg Reward (100) = -29311.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14850: Reward = -1049.00, Avg Reward (100) = -29371.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14851: Reward = -35499.61, Avg Reward (100) = -29027.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14852: Reward = -35499.61, Avg Reward (100) = -29369.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14853: Reward = -35499.61, Avg Reward (100) = -29714.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14854: Reward = -1450.40, Avg Reward (100) = -29782.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1450.40, Border Penalty: -8990.43, Obstacle Penalty: -50.00
Episode 14855: Reward = -35499.61, Avg Reward (100) = -29318.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14856: Reward = -29512.46, Avg Reward (100) = -29318.22, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14857: Reward = -40334.49, Avg Reward (100) = -29258.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -40334.49, Border Penalty: -34149.46, Obstacle Penalty: -50.00
Episode 14858: Reward = -49626.26, Avg Reward (100) = -29165.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14859: Reward = -35499.61, Avg Reward (100) = -29265.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14860: Reward = -35499.61, Avg Reward (100) = -29265.63, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14861: Reward = -35499.61, Avg Reward (100) = -29325.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14862: Reward = -35499.61, Avg Reward (100) = -29556.03, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14863: Reward = -35499.61, Avg Reward (100) = -29898.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14864: Reward = -1000.00, Avg Reward (100) = -29957.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14865: Reward = -28683.61, Avg Reward (100) = -29612.95, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14866: Reward = -49176.10, Avg Reward (100) = -29775.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -49176.10, Border Penalty: -40068.86, Obstacle Penalty: -50.00
Episode 14867: Reward = -33469.53, Avg Reward (100) = -29884.01, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14868: Reward = -1196.00, Avg Reward (100) = -29863.71, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14869: Reward = -28653.56, Avg Reward (100) = -29553.21, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14870: Reward = -35499.61, Avg Reward (100) = -29484.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14871: Reward = -1098.00, Avg Reward (100) = -29829.75, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14872: Reward = -12446.80, Avg Reward (100) = -29518.27, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14873: Reward = -25228.52, Avg Reward (100) = -29281.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -25228.52, Border Penalty: -30066.86, Obstacle Penalty: -50.00
Episode 14874: Reward = -35499.61, Avg Reward (100) = -29179.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14875: Reward = -35499.61, Avg Reward (100) = -29179.14, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14876: Reward = -32815.85, Avg Reward (100) = -29521.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32815.85, Border Penalty: -33233.24, Obstacle Penalty: -50.00
Episode 14877: Reward = -1196.00, Avg Reward (100) = -29494.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14878: Reward = -35499.61, Avg Reward (100) = -29151.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14879: Reward = -30056.79, Avg Reward (100) = -29171.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -30056.79, Border Penalty: -33036.80, Obstacle Penalty: -50.00
Episode 14880: Reward = -37669.33, Avg Reward (100) = -29117.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -37669.33, Border Penalty: -36362.88, Obstacle Penalty: -50.00
Episode 14881: Reward = -35499.61, Avg Reward (100) = -29369.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14882: Reward = -35499.61, Avg Reward (100) = -29369.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14883: Reward = -35499.61, Avg Reward (100) = -29714.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14884: Reward = -35499.61, Avg Reward (100) = -29714.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14885: Reward = -1000.00, Avg Reward (100) = -29714.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14886: Reward = -35499.61, Avg Reward (100) = -29369.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14887: Reward = -34685.86, Avg Reward (100) = -29369.41, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14888: Reward = -35499.61, Avg Reward (100) = -29429.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14889: Reward = -36089.25, Avg Reward (100) = -29423.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -32390.43, Obstacle Penalty: -50.00
Episode 14890: Reward = -35499.61, Avg Reward (100) = -29458.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14891: Reward = -28683.61, Avg Reward (100) = -29458.23, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14892: Reward = -1196.00, Avg Reward (100) = -29349.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14893: Reward = -35499.61, Avg Reward (100) = -29236.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14894: Reward = -35499.61, Avg Reward (100) = -29236.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14895: Reward = -35499.61, Avg Reward (100) = -29236.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14896: Reward = -35499.61, Avg Reward (100) = -29236.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14897: Reward = -35499.61, Avg Reward (100) = -29236.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14898: Reward = -35499.61, Avg Reward (100) = -29581.00, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14899: Reward = -35499.61, Avg Reward (100) = -29404.08, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14900: Reward = -35499.61, Avg Reward (100) = -29506.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14901: Reward = -35499.61, Avg Reward (100) = -29609.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14902: Reward = -35499.61, Avg Reward (100) = -29609.50, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14903: Reward = -32245.59, Avg Reward (100) = -29951.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14904: Reward = -12446.80, Avg Reward (100) = -29913.96, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14905: Reward = -1098.00, Avg Reward (100) = -29683.43, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 3, Reward Breakdown -> Delta_x Reward: -1098.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14906: Reward = -1147.00, Avg Reward (100) = -29163.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14907: Reward = -49626.26, Avg Reward (100) = -29050.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -49626.26, Border Penalty: -40027.83, Obstacle Penalty: -50.00
Episode 14908: Reward = -35499.61, Avg Reward (100) = -29191.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14909: Reward = -36089.25, Avg Reward (100) = -29104.53, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14910: Reward = -27492.00, Avg Reward (100) = -29110.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -27492.00, Border Penalty: -30396.10, Obstacle Penalty: -50.00
Episode 14911: Reward = -35499.61, Avg Reward (100) = -29030.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14912: Reward = -1196.00, Avg Reward (100) = -29030.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14913: Reward = -34685.86, Avg Reward (100) = -28687.31, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14914: Reward = -39606.20, Avg Reward (100) = -28537.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -39606.20, Border Penalty: -36675.82, Obstacle Penalty: -50.00
Episode 14915: Reward = -28653.56, Avg Reward (100) = -28537.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14916: Reward = -12446.80, Avg Reward (100) = -28469.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 14917: Reward = -35499.61, Avg Reward (100) = -28238.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14918: Reward = -1393.00, Avg Reward (100) = -28238.92, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -1393.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14919: Reward = -1147.00, Avg Reward (100) = -27778.07, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 4, Reward Breakdown -> Delta_x Reward: -1147.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14920: Reward = -35499.61, Avg Reward (100) = -27428.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14921: Reward = -43263.20, Avg Reward (100) = -27772.17, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14922: Reward = -35499.61, Avg Reward (100) = -27867.79, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14923: Reward = -35499.61, Avg Reward (100) = -28211.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14924: Reward = -35499.61, Avg Reward (100) = -28211.32, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14925: Reward = -35499.61, Avg Reward (100) = -28555.34, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14926: Reward = -32245.59, Avg Reward (100) = -28896.39, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -33327.79, Obstacle Penalty: -50.00
Episode 14927: Reward = -35499.61, Avg Reward (100) = -28863.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14928: Reward = -1196.00, Avg Reward (100) = -28863.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 5, Reward Breakdown -> Delta_x Reward: -1196.00, Border Penalty: 0.00, Obstacle Penalty: -95.40
Episode 14929: Reward = -35499.61, Avg Reward (100) = -28520.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14930: Reward = -35499.61, Avg Reward (100) = -28443.18, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14931: Reward = -36089.25, Avg Reward (100) = -28315.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -36089.25, Border Penalty: -35270.43, Obstacle Penalty: -50.00
Episode 14932: Reward = -35499.61, Avg Reward (100) = -28321.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14933: Reward = -35499.61, Avg Reward (100) = -28321.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14934: Reward = -33469.53, Avg Reward (100) = -28666.54, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -33469.53, Border Penalty: -34642.74, Obstacle Penalty: -50.00
Episode 14935: Reward = -29512.46, Avg Reward (100) = -28646.24, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -29512.46, Border Penalty: -32091.60, Obstacle Penalty: -50.00
Episode 14936: Reward = -35499.61, Avg Reward (100) = -28564.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14937: Reward = -28683.61, Avg Reward (100) = -28632.83, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14938: Reward = -35499.61, Avg Reward (100) = -28564.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14939: Reward = -35499.61, Avg Reward (100) = -28564.67, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14940: Reward = -35499.61, Avg Reward (100) = -28487.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14941: Reward = -32619.61, Avg Reward (100) = -28487.04, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -28787.81, Obstacle Penalty: -50.00
Episode 14942: Reward = -35499.61, Avg Reward (100) = -28800.78, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14943: Reward = -35499.61, Avg Reward (100) = -29143.82, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14944: Reward = -34685.86, Avg Reward (100) = -29164.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14945: Reward = -35499.61, Avg Reward (100) = -29402.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14946: Reward = -35499.61, Avg Reward (100) = -29402.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14947: Reward = -35499.61, Avg Reward (100) = -29402.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14948: Reward = -35499.61, Avg Reward (100) = -29402.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14949: Reward = -35499.61, Avg Reward (100) = -29743.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14950: Reward = -35499.61, Avg Reward (100) = -29743.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14951: Reward = -1049.00, Avg Reward (100) = -30087.85, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14952: Reward = -43263.20, Avg Reward (100) = -29743.35, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -43263.20, Border Penalty: -38170.22, Obstacle Penalty: -50.00
Episode 14953: Reward = -35499.61, Avg Reward (100) = -29820.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -32123.81, Obstacle Penalty: -50.00
Episode 14954: Reward = -35499.61, Avg Reward (100) = -29820.98, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14955: Reward = -35499.61, Avg Reward (100) = -30161.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14956: Reward = -32619.61, Avg Reward (100) = -30161.47, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -32619.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14957: Reward = -35499.61, Avg Reward (100) = -30192.55, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14958: Reward = -35499.61, Avg Reward (100) = -30144.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14959: Reward = -35499.61, Avg Reward (100) = -30002.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14960: Reward = -1000.00, Avg Reward (100) = -30002.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14961: Reward = -47848.55, Avg Reward (100) = -29657.93, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -47848.55, Border Penalty: -39180.06, Obstacle Penalty: -50.00
Episode 14962: Reward = -35499.61, Avg Reward (100) = -29781.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14963: Reward = -34685.86, Avg Reward (100) = -29781.42, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14964: Reward = -35499.61, Avg Reward (100) = -29773.29, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14965: Reward = -45417.44, Avg Reward (100) = -30118.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -45417.44, Border Penalty: -35710.88, Obstacle Penalty: -50.00
Episode 14966: Reward = -1000.00, Avg Reward (100) = -30285.62, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14967: Reward = -1000.00, Avg Reward (100) = -29803.86, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14968: Reward = -1000.00, Avg Reward (100) = -29479.16, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14969: Reward = -35499.61, Avg Reward (100) = -29477.20, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14970: Reward = -35499.61, Avg Reward (100) = -29545.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14971: Reward = -28683.61, Avg Reward (100) = -29545.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -28683.61, Border Penalty: -31067.80, Obstacle Penalty: -50.00
Episode 14972: Reward = -34685.86, Avg Reward (100) = -29821.52, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -34685.86, Border Penalty: -34201.73, Obstacle Penalty: -50.00
Episode 14973: Reward = -1295.00, Avg Reward (100) = -30043.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14974: Reward = -35499.61, Avg Reward (100) = -29804.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14975: Reward = -28653.56, Avg Reward (100) = -29804.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 10, Reward Breakdown -> Delta_x Reward: -28653.56, Border Penalty: -31556.28, Obstacle Penalty: -50.00
Episode 14976: Reward = -1295.00, Avg Reward (100) = -29736.11, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 6, Reward Breakdown -> Delta_x Reward: -1295.00, Border Penalty: 0.00, Obstacle Penalty: -100.00
Episode 14977: Reward = -35499.61, Avg Reward (100) = -29420.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14978: Reward = -1049.00, Avg Reward (100) = -29763.94, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14979: Reward = -51973.94, Avg Reward (100) = -29419.44, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -51973.94, Border Penalty: -40846.27, Obstacle Penalty: -50.00
Episode 14980: Reward = -35499.61, Avg Reward (100) = -29638.61, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14981: Reward = -35499.61, Avg Reward (100) = -29616.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14982: Reward = -35499.61, Avg Reward (100) = -29616.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14983: Reward = -1049.00, Avg Reward (100) = -29616.91, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14984: Reward = -35499.61, Avg Reward (100) = -29272.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14985: Reward = -35499.61, Avg Reward (100) = -29272.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14986: Reward = -35499.61, Avg Reward (100) = -29617.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14987: Reward = -47054.80, Avg Reward (100) = -29617.40, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 12, Reward Breakdown -> Delta_x Reward: -47054.80, Border Penalty: -37715.52, Obstacle Penalty: -50.00
Episode 14988: Reward = -1049.00, Avg Reward (100) = -29741.09, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 2, Reward Breakdown -> Delta_x Reward: -1049.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14989: Reward = -27842.83, Avg Reward (100) = -29396.58, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 13, Reward Breakdown -> Delta_x Reward: -27842.83, Border Penalty: -30575.46, Obstacle Penalty: -50.00
Episode 14990: Reward = -35499.61, Avg Reward (100) = -29314.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14991: Reward = -35499.61, Avg Reward (100) = -29314.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14992: Reward = -33701.04, Avg Reward (100) = -29382.28, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -33701.04, Border Penalty: -34061.12, Obstacle Penalty: -50.00
Episode 14993: Reward = -35499.61, Avg Reward (100) = -29707.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -34403.80, Obstacle Penalty: -50.00
Episode 14994: Reward = -35499.61, Avg Reward (100) = -29707.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14995: Reward = -31431.83, Avg Reward (100) = -29707.33, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -31431.83, Border Penalty: -32525.72, Obstacle Penalty: -50.00
Episode 14996: Reward = -1000.00, Avg Reward (100) = -29666.65, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 1, Reward Breakdown -> Delta_x Reward: -1000.00, Border Penalty: 0.00, Obstacle Penalty: -50.00
Episode 14997: Reward = -35499.61, Avg Reward (100) = -29321.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
Episode 14998: Reward = -32245.59, Avg Reward (100) = -29321.66, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 11, Reward Breakdown -> Delta_x Reward: -32245.59, Border Penalty: -30447.79, Obstacle Penalty: -50.00
Episode 14999: Reward = -12446.80, Avg Reward (100) = -29289.12, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 8, Reward Breakdown -> Delta_x Reward: -12446.80, Border Penalty: -22403.80, Obstacle Penalty: -50.00
Episode 15000: Reward = -35499.61, Avg Reward (100) = -29058.59, Epsilon = 0.100, Avg Loss = 0.0000, Max Q-Value = 1.16, Steps = 9, Reward Breakdown -> Delta_x Reward: -35499.61, Border Penalty: -35003.80, Obstacle Penalty: -50.00
